---

title: Circular buffer in a redundant virtualization environment
abstract: Embodiments of systems, apparatuses, and methods for a circular buffer in a redundant virtualization environment are disclosed. In one embodiment, an apparatus includes a head indicator storage location, an outgoing tail indicator storage location, a buffer tail storage location, and fetch hardware. The head indicator, outgoing tail indicators, and buffer tail indicators are to indicate a head, outgoing tail, and buffer tail, respectively, of a circular buffer. The fetch hardware is to fetch from the head of the circular buffer and advance the head no further than the outgoing tail. The buffer tail is to be filled by software and advanced no further than the head.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08533390&OS=08533390&RS=08533390
owner: Intel Corporation
number: 08533390
owner_city: Santa Clara
owner_country: US
publication_date: 20100831
---
The present disclosure pertains to the field of information processing and more particularly to the field of virtualization in information processing systems.

Generally the concept of virtualization in information processing systems allows multiple instances of one or more operating systems each an OS to run on a single information processing system even though each OS is designed to have complete direct control over the system and its resources. Virtualization is typically implemented by using software e.g. a virtual machine monitor or a VMM to present to each OS a virtual machine VM having virtual resources including one or more virtual processors that the OS may completely and directly control while the VMM maintains a system environment for implementing virtualization policies such as sharing and or allocating the physical resources among the VMs the virtualization environment . Each OS and any other software that runs on a VM may be referred to as a guest or as guest software.

A physical processor in an information processing system may support virtualization for example by supporting an instruction to enter a virtualization environment to run a guest on a virtual processor i.e. a physical processor under constraints imposed by a VMM in a VM. In the virtualization environment certain events operations and situations such as external interrupts or attempts to access privileged registers or resources may be intercepted i.e. cause the processor to exit the virtualization environment so that a VMM may operate for example to implement virtualization policies.

A physical resource in the system such as an input output device controller may be assigned or allocated to a VM on a dedicated basis. Alternatively a physical resource may be shared by multiple VMs by intercepting all transactions involving the resource so that the VMM may perform redirect or restrict each transaction. A third approach may be to design the physical resource to provide the capability for it to be used as multiple virtual resources.

Embodiments of systems apparatuses and methods for a circular buffer in a redundant virtualization environment are described. In this description numerous specific details such as component and system configurations may be set forth in order to provide a more thorough understanding of the present invention. It will be appreciated however by one skilled in the art that the invention may be practiced without such specific details. Additionally some well known structures circuits and the like have not been shown in detail to avoid unnecessarily obscuring the present invention.

Embodiments of the present invention provide for a physical or a virtual resource such as an I O device controller to be dedicated to a virtual machine in a redundant virtualization environment. A redundant virtualization environment is a virtualization environment in which the state of a first virtual machine the primary or active VM is replicated on a second virtual machine the secondary or backup VM . Redundancy may be useful to provide a secondary VM in the event of a fault affecting the primary VM and or to provide for error checking of the outputs from the primary VM.

Redundancy may involve synchronizing the primary and secondary VMs at checkpoints. Between each checkpoint the output and or state changes of the primary VM are buffered so that each checkpoint the output and or state changes of the primary VM may be compared with the output and or state changes of the secondary VM or saved in order to create the secondary VM if necessary. After receiving acknowledgement that the state changes based on the buffered output have been received and or saved the buffered output may be released. This synchronization may be performed by a VMM.

If the execution of the primary VM is deterministic e.g. execution of arithmetic memory and branch instructions the secondary VM may execute independently from the primary VM and produce the same output and reach the same state. However if the execution of the primary VM is non deterministic e.g. handling of asynchronous events such as interrupts from I O devices the primary and secondary VMs may both execute correctly but with different outputs and or reach a different state. Therefore a log and replay technique may be used to generate an execution record or log that may be used to replay the execution of a primary VM on a secondary VM to identically replicate the output and the state of the primary VM typically starting from a checkpoint even when the execution is not entirely deterministic.

In some virtualization environments an access by a VM to a system resource such as an I O device controller is intercepted by the VMM a VM exit to virtualize the resource. In these virtualization environments the VMM controls the transfer of data by the device therefore the VMM can control buffering of the output for checkpointing and can convert non deterministic events in the hardware to deterministic events in the software for log and replay.

In other virtualization environments a system resource may be dedicated to a VM e.g. direct I O . This technique may provide for more efficient virtualization because the VM is able to access the system resource without causing a virtual machine exit that would consume many clock cycles for state saving operations. However since the VMM does not control the transfer of data by the device embodiments of the present invention may be desirable to provide for the buffering of the output for checkpointing and or the deterministic operation of direct I O for log and replay.

Processors and may be any type of processor including a general purpose microprocessor such as a processor in the Intel Pentium Processor Family Itanium Processor Family Core Processor Family or other processor family from Intel Corporation or another processor from another company or a digital signal processor or microcontroller. Processors and may each include multiple threads and multiple execution cores in any combination. Although shows two processors information processing system may include only a single processor or any number of processors.

System memory may be static or dynamic random access memory or any other type of medium readable by processors and or any combination of such mediums.

MCH may include any logic circuitry or other hardware to control the transfer of information between system memory and any other component in information processing system such as processors and . MCH may also include any other logic circuitry or other hardware to perform any other functions such as passing and or translating transactions and or other communications between ICH and processors and and system memory .

ICH may include logic circuitry or other hardware to manage system logic peripherals and I O devices in information processing system which may be integrated into ICH and or may communicate with ICH and to control the transfer of information between these devices and any other component in information processing system such processors and and system memory . ICH may also include any other logic circuitry or other hardware to perform any other functions such as passing and or translating transactions and or other communications between MCH and any peripherals I O devices or other components in information processing system .

I O device may represent any I O or peripheral device and or a controller or adapter for any such device. I O device may be integrated into or separate from ICH . I O device may support I O virtualization for example I O device may include or provide a physical function PF that may be controlled by a VMM and one or more virtual functions each a VF where the VMM may configure and manage the physical resources of I O device such that each of the VFs may be controlled and or accessed directly by a VM. Therefore a VF supported by I O device and assigned to a VM may transfer data within into or out of system under control of the VM without the intervention of a VMM. In one embodiment I O device may be a network interface controller NIC . In another embodiment I O device may be a disk drive controller.

I O device may be capable of transferring data to and from system memory and or other memory in or accessible to information processing system through direct memory access DMA . I O device may include five registers or other storage locations described below which may be used to define a circular buffer such as circular buffer illustrated in . Circular buffer may include entries to identify data or the location of data to be transmitted and or received by I O device . The entries may be implemented using physical storage locations in I O device in system memory e.g. in a region allocated to I O device or elsewhere in or accessible to information processing system or any combination of such physical storage locations. Each entry may be of any desired size.

For example in an embodiment where I O device represents a virtual NIC controlled by a VM the VM may set up I O device to use circular buffer to receive data from the network and transfer the data without intervention by a VMM or processor or to a region of system memory allocated to the VM. Similarly the VM may set up I O device to use circular buffer to transfer data from a region of system memory allocated to the VM and transmit the data onto the network without intervention by a VMM or processor or . Circular buffer may include any number of entries where each entry may be used to store a descriptor to identify data to be transferred.

In I O device the five registers or other storage locations used to define circular buffer are base address register length register head pointer register outgoing tail pointer register and buffer tail pointer register to identify the base address length head outgoing tail and buffer tail respectively of circular buffer using any known technique of addressing or direct or indirect referencing. These storage locations may be programmed by software such as a device driver running on a VMM and or a VM to which a virtual NIC supported by I O device is allocated.

For example the location and size of circular buffer may be defined by the values in base address register and length register respectively i.e. the location of first entry in circular buffer may be defined by the base address and the location of last entry in circular buffer may be defined by the base address plus the length. Circular buffer may be used to create an endless queue by starting to fill the buffer at first entry and continuing to fill entries consecutively towards last entry . After last entry is filled the queue wraps around to first entry to be filled again and continues towards last entry again. Fetching entries from circular buffer proceeds in the same manner such that the descriptor in an entry is fetched before the entry is filled with another descriptor.

The filling of and fetching from circular buffer may be managed using head outgoing tail and buffer tail to ensure that the descriptor in an entry is fetched before the entry is filled with a different descriptor and also to provide for buffering of the output of I O device to support a redundant virtualization environment. Circular buffer is filled by software and fetched from by hardware as further described below. Filling any one particular entry with a descriptor occurs before fetching that descriptor from that particular but for convenience the fetch hardware is described first.

Fetch hardware is configured to fetch from circular buffer by fetching from the entry at head advancing head to the next consecutive entry and repeating the fetch from head and the advancing of head until head reaches outgoing tail . Therefore in an embodiment where circular buffer is used for a transmit queue of a NIC hardware owns the entries in section of circular buffer the entries starting at head and ending at the entry immediately before outgoing tail and hardware is to fetch the descriptors from these entries and transmit the data corresponding to these entries.

Buffer tail is provided as the location at which software e.g. a device driver running in the VM to which a VF supported by I O device is assigned is to fill circular buffer then advance buffer tail to the next consecutive entry and continue filling if desired until buffer tail reaches head . Therefore software e.g. a device driver running in a VM owns the entries in section of circular buffer starting at buffer tail and ending at the entry immediately before head and may store descriptors in these entries.

Outgoing tail is provided to define a section of circular buffer in which output may be buffered to support a redundant virtualization environment. The entries in section of circular buffer starting at outgoing tail and ending at the entry immediately before buffer tail are filled but are not available for hardware to transmit because they are not in section of circular buffer . These entries are owned by software but unlike the entries in section of circular buffer are not available to be filled by a device driver running in a VM. Instead section of circular buffer is owned by VMM software to provide for a VMM to buffer the output of I O device even when the output of I O device is for a VF dedicated to a primary VM. These entries remain stored until the primary VM is intercepted by the VMM at which time the VMM may synchronize the secondary VM with the primary VM and then release these entries by advancing outgoing tail to buffer tail . These interceptions may occur at checkpoints or any other points at which VM exits occur but need not occur every time I O device transmits data from a VM as may be necessary in a redundant virtualization environment not including an embodiment of the present invention.

In box of a VF such as an NIC function of an I O device including a circular buffer may be assigned to a primary VM for example by configuration of the PF of the I O device by a VMM.

In box the base address register for the circular buffer may be programmed. In box the length register for the circular buffer may be programmed. In box the head pointer register for the circular buffer may be programmed with the base address. In box the outgoing tail pointer register for the circular buffer may be programmed with the base address. In box the buffer tail pointer register for the circular buffer may be programmed with the base address. From box method may proceed to method .

In box of a device driver running in the primary VM fills an entry at the buffer tail of the circular buffer with a descriptor. In box the device driver advances the buffer tail to the next consecutive entry. In box a determination is made as to whether the buffer tail has reached the head of the circular buffer. If yes then method waits in box until the head of the circular buffer is advanced in method . If no then in box a determination is made as to whether another entry is to be filled with a descriptor. If yes then method returns to box . If no then method waits in box .

Method may be entered when a VM exit occurs in box . In box the VMM synchronizes a secondary VM with the primary VM. The descriptors in the entries starting at the outgoing tail and ending at the entry immediately before the buffer tail may be used and or updated in connection with this synchronization. In box the VMM advances the outgoing tail to the buffer tail thereby releasing the output represented by the entries referred to in box .

Method may begin any time after the first time the device driver advances the buffer tail in box . In box fetch hardware in the I O device fetches a descriptor from the entry at the head of the circular buffer. In box the I O device transmits data according to the fetched descriptor. In box the fetch hardware updates the fetched descriptor status to indicate that the corresponding data has been transmitted. In box the fetch hardware advances the head to the next consecutive entry. In box a determination is made as to whether the head has reached the outgoing tail of the circular buffer. If yes then method waits in box until the outgoing tail of the circular buffer is advanced in method . If no method returns to box .

Within the scope of the present invention the methods illustrated in and and or the actions taken in performing methods and may be performed together or separately in a different order with illustrated boxes omitted with additional boxes added or with a combination of reordered omitted or additional boxes.

Furthermore other embodiments of the present invention are possible. In one embodiment a programmable bit or flag may be used to provide for backward compatibility. For example when the flag is set the circular buffer hardware will operate as described above but when the flag is clear the circular buffer hardware will automatically synchronize the outgoing tail with the buffer tail every time the buffer tail is changed by software. In another embodiment dirty bits may be used by an I O memory management unit to mark DMA input pages that have changed since the last checkpoint so that the inputs to a primary VM may be synchronized with a secondary VM.

I O device may include four registers or other storage locations to define circular buffer . The four registers are base address register length register head pointer register and tail pointer register to identify the base address length head and tail respectively of circular buffer using any known technique of addressing or direct or indirect referencing. These storage locations may be programmed by software such as a device driver running on a VMM and or a VM to which a virtual NIC supported by I O device is allocated.

For example the location and size of circular buffer may be defined by the values in base address register and length register respectively i.e. the location of first entry in circular buffer may be defined by the base address and the location of last entry in circular buffer may be defined by the base address plus the length. Circular buffer may be used to create an endless queue by starting to fill the buffer at first entry and continuing to fill entries consecutively towards last entry . After last entry is filled the queue wraps around to first entry to be filled again and continues towards last entry again. Fetching entries from circular buffer proceeds in the same manner such that the descriptor in an entry is fetched before the entry is filled with another descriptor.

The filling of and fetching from circular buffer may be managed using head and tail to ensure that the descriptor in an entry is fetched before the entry is filled with a different descriptor. Circular buffer is filled by software and fetched from by hardware as further described below. Filling any one particular entry with a descriptor occurs before fetching that descriptor from that particular but for convenience the fetch hardware is described first.

Fetch hardware is configured to fetch from circular buffer by fetching from the entry at head advancing head to the next consecutive entry and repeating the fetch from head and the advancing of head until head reaches tail . Therefore in an embodiment where circular buffer is used for a transmit queue of a NIC hardware owns the entries in section of circular buffer the entries starting at head and ending at the entry immediately before tail and hardware is to fetch the descriptors from these entries and transmit the data corresponding to these entries.

Tail is provided as the location at which software e.g. a device driver running in the VM to which a VF supported by I O device is assigned is to fill circular buffer then advance outgoing to the next consecutive entry and continue filling if desired until tail reaches head . Therefore software e.g. a device driver running in a VM owns the entries in section of circular buffer starting at tail and ending at the entry immediately before head and may store descriptors in these entries.

In box of a VF such as an NIC function of an I O device including a circular buffer may be assigned to a primary VM for example by configuration of the PF of the I O device by a VMM.

In box the base address register for the circular buffer may be programmed. In box the length register for the circular buffer may be programmed. In box the head pointer register for the circular buffer may be programmed with the base address. In box the tail pointer register for the circular buffer may be programmed with the base address. From box method may proceed to method .

In box of a device driver running in the primary VM fills an entry at the tail of the circular buffer with a descriptor. In box the device driver advances the tail to the next consecutive entry. In box a determination is made as to whether the tail has reached the head of the circular buffer. If yes then method waits in box until the head of the circular buffer is advanced in method . If no then in box a determination is made as to whether another entry is to be filled with a descriptor. If yes then method returns to box . If no then method waits in box .

Method may begin in the primary VM any time after the first time the device driver advances the tail in box . In box a determination is made for example by fetch hardware in the I O device as to whether the head has matches the tail of the circular buffer. If yes then method waits in box until the tail of the circular buffer is advanced in method . If no method proceeds to box .

In box fetch hardware in the I O device fetches a descriptor from an entry in the circular buffer. In box fetch hardware in the I O device fetches a packet of data corresponding to the fetched descriptor. In box the I O device transmits the packet. In one embodiment boxes and may be repeated starting from the head of the circular buffer and proceeding towards the tail and ending no further than the entry immediately before the tail. In box the I O device indicates that the data transmission in complete for example by sending an interrupt signal or interrupt message to one or more processors.

In box guest software for example an interrupt handler and or a device driver for the I O device runs in the primary VM in response to the indication from box . In box a VM exit occurs in response to the indication from box and or the execution of guest software in box for example in response to a hypercall or other instruction or operation issued and or executed by or for the guest software and control is transferred to a VMM in method .

Note that methods and may also be performed in a secondary VM. In one embodiment the secondary VM may operate in parallel with the primary VM. The input stream to the primary VM may be replicated to be input to the secondary VM. However the output from the secondary VM may be blocked or otherwise suppressed to prevent a conflict between the secondary VM and the primary VM.

In box the VMM determines how many packets of data have been transmitted by the primary VM. In one embodiment the VMM may determine how many packets have been transmitted using an application programming interface API developed for use according to an embodiment of the present invention. In box the VMM updates the fetched descriptor status in the primary VM for each of the transmitted packets. In one embodiment the VMM may perform box using an API developed for use according to an embodiment of the present invention. In box the update to the fetched descriptor status is logged in an execution log maintained by the VMM or other software. In box the VMM advances the head in the primary VM by the number of entries for which data has been transferred e.g. by the number of packets that have been transmitted as determined in box . In one embodiment the VMM may perform box using an API developed for use according to an embodiment of the present invention. In box the advancement of the head is logged in an execution log maintained by the VMM or other software. In box the VMM transfers control to guest software running in the primary VM i.e. a VM entry .

Note that since boxes and are performed by a VMM instead of by hardware in the I O device the execution of boxes and is deterministic because the point in the execution stream that changes are made to the fetched descriptor status and to the head pointer can be determined. Therefore embodiments of the present invention provide for deterministic direct I O and changes to the fetched descriptor status and to the head pointer may be accurately logged and replayed.

Any time a failure occurs involving the operation of the primary VM the secondary VM may be used to recover for example according to method illustrated in . In box the VMM or other software may begin to execute a fault recovery routine. In box the VMM may use an API to stop the transmission of data by the I O device assigned directly to the primary VM. In box the VMM may use the API used in box to determine how many packets if any have been transmitted by the primary VM since the last synchronization. In box the information needed to replicate the primary VM on the secondary VM is transferred if necessary for example from the system hosting the primary VM or wherever the information is backed up to the system hosting the secondary VM. In box the VMM may use the API used in box to update the fetched descriptor status in the secondary VM for each of the transmitted packets. In box the VMM may use the API used in box to advance the head in the secondary VM. In box the VMM may unblock the output from the secondary VM to allow the secondary VM to replace the primary VM. In box the VMM transfers control to guest software running in the secondary VM i.e. a VM entry .

Within the scope of the present invention the methods illustrated in and or and or the actions taken in performing methods and or may be performed together or separately in a different order with illustrated boxes omitted with additional boxes added or with a combination of reordered omitted or additional boxes. As one example one or more of the APIs described above may be combined.

Furthermore other embodiments of the present invention are possible. In one embodiment a programmable bit or flag may be used to provide for backward compatibility. For example when the flag is set the circular buffer hardware will operate as described above but when the flag is clear the circular buffer hardware will operate according to an approach in which hardware performs the changes to the fetched descriptor status and to the head pointer.

Thus embodiments of systems apparatuses and methods for a circular buffer in a redundant virtualization environment have been described. While certain embodiments have been described and shown in the accompanying drawings it is to be understood that such embodiments are merely illustrative and not restrictive of the broad invention and that this invention not be limited to the specific constructions and arrangements shown and described since various other modifications may occur to those ordinarily skilled in the art upon studying this disclosure. In an area of technology such as this where growth is fast and further advancements are not easily foreseen the disclosed embodiments may be readily modifiable in arrangement and detail as facilitated by enabling technological advancements without departing from the principles of the present disclosure or the scope of the accompanying claims.

