---

title: Command tag checking in a multi-initiator media controller architecture
abstract: Described embodiments provide a method of allocating resources of a media controller for a data transfer. A data transfer request is received from at least one host device, and includes a host device ID and a data transfer request ID. The media controller generates a Tag ID of the data transfer request based on the host device ID and the data transfer request ID, and generates a starting memory address of a tag table based on the Tag ID of the data transfer request. A tag count value is read from the starting memory address of the tag table. If the tag count value reaches a threshold, an absence of a tag overlap is determined and the Tag ID of the data transfer request is added to the tag table at the starting memory address.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08352689&OS=08352689&RS=08352689
owner: LSI Corporation
number: 08352689
owner_city: Milpitas
owner_country: US
publication_date: 20101123
---
This application claims the benefit of the filing date of U.S. provisional application No. 61 265 109 filed 30 Nov. 2009 the teachings of which are incorporated herein in their entireties by reference.

The subject matter of this application is related to U.S. patent application Ser. No. 12 436 227 filed 6 May 2009 Ser. No. 12 475 710 filed 1 Jun. 2009 Ser. No. 12 475 716 filed 1 Jun. 2009 Ser. No. 12 477 996 filed 4 Jun. 2009 Ser. No. 12 478 013 filed 4 Jun. 2009 Ser. No. 12 508 879 filed 24 Jul. 2009 Ser. No. 12 508 915 filed 24 Jul. 2009 Ser. No. 12 643 471 filed 21 Dec. 2009 Ser. No. 12 649 490 filed 30 Dec. 2009 Ser. No. 12 722 828 filed 12 Mar. 2010 Ser. No. 12 730 627 filed 24 Mar. 2010 Ser. No. 12 731 631 filed 25 Mar. 2010 Ser. No. 12 767 985 filed 27 Apr. 2010 Ser. No. 12 768 058 filed 27 Apr. 2010 Ser. No. 12 769 882 filed 29 Apr. 2010 Ser. No. 12 769 910 filed 29 Apr. 2010 Ser. No. 12 873 450 filed 1 Sep. 2010 Ser. No. 12 873 512 filed 1 Sep. 2010 Ser. No. 12 873 548 filed 1 Sep. 2010 Ser. No. 12 952 201 filed on 23 Nov. 2010 Ser. No. 12 952 206 filed on 23 Nov. 2010 Ser. No. 12 952 205 filed on 23 Nov. 2010 Ser. No. 12 952 200 filed on 23 Nov. 2010 and Ser. No. 12 952 202 filed on 23 Nov. 2010 the teachings of all of which are incorporated herein in their entireties by reference.

The present invention relates to memory storage systems and more specifically to a host interface of a media controller.

Flash memory is a type of non volatile memory that is electrically erasable and re programmable. Flash memory is primarily used in memory cards and USB flash drives for general storage and transfer of data between computers and other digital products. Flash memory is a specific type of electrically erasable programmable read only memory EEPROM that is programmed and erased in large blocks. One commonly employed type of flash memory technology is NAND flash memory. NAND flash memory forms the core of the flash memory available today especially for removable universal serial bus USB storage devices known as USB flash drives as well as most memory cards. NAND flash memory exhibits fast erase and write times requires small chip area per cell and has high endurance. However the I O interface of NAND flash memory does not provide full address and data bus capability and thus generally does not allow random access to memory locations.

There are three basic operations for NAND devices read write and erase. The read and write operations are performed on a page by page basis. Page sizes are generally 2N bytes where N is an integer with typical page sizes of for example 2 048 bytes 2 kb 4 096 bytes 4 kb 8 192 bytes 8 kb or more per page. Pages are typically arranged in blocks and an erase operation is performed on a block by block basis. Typical block sizes are for example 64 or 128 pages per block. Pages must be written sequentially usually from a low address to a high address. Lower addresses cannot be rewritten until the block is erased.

Other storage devices such as conventional hard disk drives HDDs support additional disk access operations such skip write and skip read. A skip operation is used for reading or writing relatively closely located but non contiguous blocks on an HDD. The device requesting the skip read or skip write provides a starting logical block address LBA a length count of the number of blocks to read write and a skip mask. The skip mask comprises a number of bits where each bit in the mask corresponds to a block offset from the starting block address. A logic 1 bit in the skip mask signifies that the block corresponding to that bit position will be read written. A logic 0 bit in the skip mask signifies that the block corresponding to that bit position will not be read written and will be skipped. The length count comprises the total number of blocks to transfer not the span of the request. Thus the length count matches the total number of logic 1 bits in the skip mask. HDDs process skip commands at a media layer of the system for example corresponding to a layer in the OSI Open Systems Interconnection model. A skip operation is useful for reading or writing several non contiguous memory locations without issuing separate requests and requiring additional revolutions of the HDD. Further only the requested data is transferred to or from the HDD.

An HDD is addressed linearly by logical block address LBA . A hard disk write operation provides new data to be written to a given LBA. Old data is over written by new data at the same physical LBA. NAND flash memories are accessed analogously to block devices such as HDDs. NAND devices address memory linearly by page number. However each page might generally be written only once since a NAND device requires that a block of data be erased before new data is written to the block. Thus for a NAND device to write new data to a given LBA the new data is written to an erased page that is a different physical page than the page previously used for that LBA. Therefore NAND devices require device driver software or a separate controller chip with firmware to maintain a record of mappings of each LBA to the current page number where its data is stored. This record mapping is typically managed by a flash translation layer FTL in software that might generate a logical to physical translation table. The flash translation layer corresponds to the media layer of software and or firmware controlling an HDD.

For consumer applications HDDs generally have data sectors that are sized in powers of two e.g. 512 29 bytes per sector . Flash memories structured with page sizes that are a multiple of the HDD sector size might efficiently work with the HDD system by storing multiple entire sectors in a page e.g. a 4096 byte page can store eight 512 byte sectors . However enterprise based HDD systems generally do not use sectors sized by powers of two but use larger sectors generally either 520 or 528 bytes per sector instead of 512 bytes.

For write operations NAND devices store the new data for the LBA on a new page unlike hard disk drives HDDs that can rewrite individual physical sectors. Thus a NAND device generally requires that a block be erased before new data can be written to the block. Further as described above often a NAND device will write new data for a given LBA to an erased page that is a different physical page from the page previously used for that LBA. Thus NAND devices also generally require the device driver software or the separate controller chip periodically initiate a process to erase data that is stale or out of date. However NAND device blocks can be erased relatively few times before device failure typically on the order of 100 000 erasures . Therefore over the operational life of an SSD blocks of flash memory will fail and become unusable.

Storage device controllers generally interface with one or more host devices via one of various host computer interface protocols such as for example Serial Advanced Technology Attachment SATA in accordance with the Serial ATA 2.6 Specification February 2007 hereinafter SATA protocol available from Serial ATA International Organization and Serial Attached Small Computer System Interface SAS in accordance with Serial Attached SCSI 1.1 SAS 1.1 ANSI INCITS 417 2006 hereinafter SAS protocol available from the InterNational Committee for Information Technology Standards INCITS .

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

Described embodiments provide a method of allocating resources of a media controller for a data transfer. A data transfer request is received from at least one host device and includes a host device ID and a data transfer request ID. The media controller generates a Tag ID of the data transfer request based on the host device ID and the data transfer request ID and generates a starting memory address of a tag table based on the Tag ID of the data transfer request. A tag count value is read from the starting memory address of the tag table. If the tag count value reaches a threshold an absence of a tag overlap is determined and the Tag ID of the data transfer request is added to the tag table at the starting memory address.

As described herein embodiments of the present invention provide a method of allocating resources of a media controller for a data transfer. A data transfer request is received from at least one host device and includes a host device ID and a data transfer request ID. The media controller generates a Tag ID of the data transfer request based on the host device ID and the data transfer request ID and generates a starting memory address of a tag table based on the Tag ID of the data transfer request. A tag count value is read from the starting memory address of the tag table. If the tag count value reaches a threshold an absence of a tag overlap is determined and the Tag ID of the data transfer request is added to the tag table at the starting memory address.

Table 1 defines a list of acronyms employed throughout this specification as an aid to understanding the described embodiments of the present invention 

Media controller controls transfer of data between media and an external device coupled to communication link . Media controller might be implemented as a system on chip SoC . Media controller might include internal RAM buffer and might also be coupled to additional external memory shown as external RAM buffer . In an exemplary embodiment internal RAM buffer comprises 128 kB of static RAM SRAM and external RAM buffer comprises 512 MB of double data rate version 2 dynamic RAM DDR2 DRAM . RAM buffer might act as a cache for processor while RAM buffer might act as a read write buffer between media and communication link .

Although shown in as a single media device media might be implemented as one or more storage media. For example media might be implemented as an SSD including one or more physical flash silicon dies. In some embodiments host requests might be striped across two or more of the dies analogously to hard drives in a redundant array of independent disks RAID to provide parallel execution. In other embodiments each flash die might be configured as a separate stand alone flash memory device without data striping. Similarly media might be implemented as one or more physical drives which might be implemented as at least one of an SSD HDD or a hybrid magnetic and solid state storage system.

Although shown in as a single processor processor might be implemented by multiple processors. For example end users of media controller might require higher or lower performance depending on their intended application. The performance requirements might affect the type of processors employed in the SoC or the number of processors employed in the SoC. For example a lower performance media controller operating in accordance with the SATA protocol might employ a single ARM Cortex M3 processor while a higher performance media controller operating in accordance with the SAS protocol might employ three ARM Cortex R4 processors ARM Cortex processors are by ARM Holdings plc Cambridge UK . Processor includes software and or firmware as needed for operation. For embodiments having multiple processors inter processor communication might be employed such as described in related U.S. patent application Ser. No. 12 436 227 filed May 6 2009.

In operation for example media controller might receive requests for media access from external devices such as requests for read or write operations from communication link . Such requests for access to media generally include at least one logical block address LBA where data should be read or written. For example the requests could be to read from or write to a i single media address ii a group of contiguous media addresses or iii a group of non contiguous media addresses. Received requests are processed by host subsystem . In general host layer might process higher level host operations e.g. host command handlers and host LLD might process lower level host operations e.g. parsing host commands to the host layer . Commands accessing a group of non contiguous media addresses might be processed such as described in related U.S. patent application Ser. No. 12 508 915 filed Jul. 24 2009. One or more received commands might be queued or tracked as described in related U.S. patent application Ser. No. 12 649 490 filed Dec. 30 2009.

Media subsystem translates the LBA into a physical address of the desired data for example as described in related U.S. patent application Ser. No. 12 643 471 filed Dec. 21 2009 Ser. No. 12 769 910 filed Apr. 29 2010 and Ser. No. 12 769 882 filed Apr. 29 2010. Media subsystem interfaces with buffer subsystem . Media layer might process higher level media operations e.g. logical to physical address translation while media LLD might process lower level media operations e.g. media hardware specific read write erase . Media layer also might enable error recovery and wear leveling routines for media such as described in related U.S. patent application Ser. No. 12 475 710 filed Jun. 1 2009 Ser. No. 12 475 716 filed Jun. 1 2009 and Ser. No. 12 508 879 filed Jul. 24 2009. In embodiments of the present invention media layer might support enterprise system sector sizes e.g. 520 or 528 bytes per sector instead of 512 bytes per sector such as described in related U.S. patent application Ser. Nos. 12 477 996 and 12 478 013 both filed Jun. 4 2009.

Since data transfers between communication link and media might be temporarily stored in buffer memory buffer subsystem generally directs the data traffic between host subsystem and media subsystem . For example if an external host not shown provides via communication link data to be written to media buffer subsystem might coordinate temporary storage of the data in buffer until media subsystem coordinates writing the data to media . Similarly if the external host requests to read data from media buffer subsystem might temporarily store the data in buffer until host layer coordinates sending the data to the host via communication link .

In general buffer layer might process higher level buffer and cache operations e.g. cache and buffer allocation while buffer LLD processes lower level buffer operations e.g. RAM hardware specific commands . Buffering of data might occur for example as described in related U.S. patent application Ser. No. 12 722 828 filed Mar. 12 2010 Ser. No. 12 730 627 filed Mar. 24 2010 and Ser. No. 12 731 631 filed Mar. 25 2010. Infrastructure subsystem might generally serve as an operating system for media controller with infrastructure layer performing higher level processing operations e.g. operating system operations and infrastructure LLD performing lower level operating system operations e.g. initialization timers interrupts .

As shown in media controller also includes Buffer Allocation Module BAM . As shown BAM is coupled to host layer buffer layer and infrastructure layer . In embodiments of the present invention BAM might be employed to provide acceleration and flexibility in managing one or more cache buffers in RAM buffers and and the transfer of information between host layer and buffer layer . For example BAM might maintain cache management data that describes data blocks stored in a cache the status of the data blocks stored in the cache e.g. valid dirty etc. the physical address of that data and which modules of media controller are accessing the data.

As will be described in greater detail below BAM might typically include i a first control sequencer for host command and context processing and ii a second control sequencer for buffer command and context processing. In general a context is a data structure used within media controller that specifies the information necessary to send or receive data e.g. to send a data frame or frame information structure FIS on communication link to perform direct memory access DMA etc. . Since both host subsystem and buffer subsystem might access the same cache data structures BAM includes an arbiter to arbitrate between the first and second control sequencers to guarantee access to cache entries. BAM might be employed to perform cache lookup for a command to enhance performance or to process a command and generate a thread of contexts for that command. BAM might also be employed to perform buffer allocation for a context or to modify fields in a context. Thus BAM provides flexibility in manipulating context threads generating individual contexts and allocating cache data in the buffer. BAM will be described in greater detail with regard to .

Receive Data Path RXDP receives incoming data from communication link via link protocol core . RXDP routes incoming data to i buffer subsystem e.g. incoming user data might be temporarily stored in a buffer before being written to media or ii other internal modules of host system e.g. command handling module . RXDP might include buffer for synchronizing data between the timing requirements of link protocol core and the timing requirements of host subsystem . For example data might be sent in frames for a given link protocol and RXDP might reorganize the framed data into data blocks for further processing within media controller . RX buffer might be sized to support required bandwidth for both the link protocol and the internal communications within media controller . Buffer subsystem includes context buffer . Context buffer might be implemented as one or more first in first out FIFO linked lists for queuing contexts.

Encryption Data Path EDP might perform i encryption of data received by media controller for storage on media and ii decryption of data stored on media for transmission over communication link . EDP might be implemented as a pipeline stage in Transmit Data Path TXDP such that a first segment of decrypted data is provided from TXDP to Link Protocol Core while a next segment of data is decrypted by EDP . EDP might employ any suitable encryption methodology such as the Advanced Encryption Standard AES defined in Federal Information Processing Standard FIPS Publication 197. EDP might also employ key management such as described in related U.S. patent application Ser. Nos. 12 767 985 and 12 768 058 both filed Apr. 27 2010.

TXDP transfers outgoing data from media controller to communication link via link protocol core . Similarly as RXDP TXDP might include buffer for synchronizing data between the timing requirements of host subsystem and the timing requirements of link protocol core . Further TXDP might include a pre fetch engine for loading data for a next context into TX buffer while link protocol core is transmitting data for a previous context to transfer data for multiple contexts without gaps of idle time in link protocol core and communication link . Although shown in as being a single port system such as for SATA devices having a single link protocol core a single RXDP and a single TXDP embodiments of the present invention such as for SAS devices might include dual link protocol cores dual RXDPs and dual TXDPs to support 2 port communication. Such embodiments will be described subsequently in regard to .

As shown in host subsystem performs three main functions i transferring data between link protocol core and buffer subsystem ii processing received protocol commands e.g. by command handling module and iii managing and processing contexts corresponding to data transfers e.g. by context management module . Command handling module might typically verify a received command and normalize the received command e.g. from a protocol specific format to a normalized format and convert the command into one or more contexts for processing by media controller . For example Link Protocol Core might provide SATA or SAS command frames to command handling module and command handling module might then perform checks on the frame. Context management module might typically i execute a thread of contexts corresponding to a data transfer ii manage context pointer lists to provide fast context loading and iii generate interrupts based on the contexts. Instruction interface might typically process a transmit context to determine a corresponding protocol instruction and convert the context into the specific protocol instruction for Link Protocol Core . Instruction interface will be described in greater detail in regard to .

Pending Write Table PWT maintains a list of active write commands to media . As shown RXDP is in communication with PWT to provide PWT with data corresponding to one or more active write commands in host subsystem . For example RXDP might provide one or more write contexts corresponding to each active write command. A write context corresponds to a data stream being transferred to media controller for storage on media . The active write contexts might be stored in buffer subsystem for example context buffer . In embodiments of the present invention PWT is implemented as one of a RAM memory or a register file. RXDP Transmit Data Path TXDP Command Handling module Context Management module and Pending Write Table might generally provide a context processing pipeline for host subsystem .

Command Parser receives host commands from RXDP and provides one or more contexts to perform the command. New contexts might typically be added to the tail end of an active context queue which might be one of a plurality of linked lists stored in buffer subsystem . Each linked list has a corresponding a read and write pointer. In operation CP might receive a host command e.g. a SATA or SAS command from i RXDP if there are no commands queued in command FIFO or ii the head of command FIFO if one or more commands are queued. CP tracks the read and write pointers of the active command queue and might be configured to automatically load a next command from RX Buffer when the read and write pointers are not equal. The command is loaded to a command register of CP and might be rewritten in a normalized format. For example control fields that might vary depending on the host protocol such as starting LBA and transfer length might be placed in common command fields. CP might generate an interrupt when a valid and normalized command is ready to be parsed so as to generate one or more contexts in one or more context registers of CP . The one or more contexts correspond to one or more data transfers internal to media controller to perform the received host command. Once the corresponding one or more contexts are generated CP clears the host command from the command register to allow a next host command to be loaded and processed.

Parallel context generation might generally performed by Command Parser . As described herein command parser might generate one or more contexts to satisfy a received command. These contexts might be stored in two or more sets of context registers to store contexts in parallel. In embodiments of the present invention one set of context registers are reserved for high priority command processing while the other set of context registers are employed for normal command processing. While a command is being processed an interrupt might be generated for processor to process a subsequent received command that is a higher priority command. For example a high priority interrupt might be generated when a media side operation completes and a requested data transfer is available in buffer subsystem . Processing is switched to the high priority interrupt and a context is generated for that routine in the high priority context registers without disturbing the contexts for the normal command which are stored in one of the other parallel set of registers. Thus command parser returns to the previous command processing routine without requiring a large firmware stack for contexts because the state of the current context generation process is separately saved in parallel registers. This parallel context structure allows processor to handle the interrupt and generate contexts for the high priority command without disturbing command processing for the lower priority command.

ILT is typically used for the enterprise applications to store information for one or more SAS initiators in communication with media controller . ILT stores a 64 bit World Wide Name WWN of one or more initiators with active connections to media controller the 16 bit Initiator Connection Tag ICT corresponding to the active connection and a count of the number of commands outstanding from each initiator. The WWN is a 64 bit globally unique identifier assigned to a SAS device by its manufacturer that uniquely identifies each SAS device. The ICT is a 16 bit number sent to media controller by the SAS initiator. The ICT might be included by media controller in responses to the SAS initiator such that the SAS initiator can identify media controller . Each initiator WWN and ICT might be converted to an ILT ID that is included in each context for the command to reference back to the corresponding initiator information in ILT .

Embodiments of the present invention provide 8 entries in ILT to support 8 concurrent initiators. If another initiator establishes a connection beyond the maximum of 8 cached in ILT the new initiator might for example receive a Task Set Full or Busy response status and a connection would be denied. Alternatively embodiments of the present invention might replace an entry in ILT with the new initiator for example if a cached initiator had no outstanding commands with media controller . For example when RXDP receives a command RXDP checks ILT for the initiator. The 64 bit WWN is checked on each connection when receiving commands. If the WWN is cached in ILT the ILT ID is provided along with a command tag to Tag Manager . If the initiator is already in communication with media controller RXDP increments the command count in ILT corresponding to that initiator. When processing of that command is complete for example when instruction interface sends the response for the command instruction interface decrements the command count in ILT corresponding to that initiator.

ILT also provides an overall SAS command queue counter to track the overall maximum queue depth of media controller to indicate TASK SET FULL or BUSY when a new command is received. The overall maximum queue depth is maximum number of active commands allowed be media controller . As described herein for embodiments of the present invention the maximum queue depth of media controller might be 128 active commands. Typically BUSY status indicates that ILT cannot accept the new command because of a temporary hardware restriction such as command FIFO being full. When an initiator receives a BUSY indication the initiator might try to send the same command again later. Typically TASK SET FULL status indicates that a given initiator has reached the hardware limit of active commands for that particular initiator. When an initiator receives a TASK SET FULL indication the initiator might reduce its queue depth to avoid going over the limit of active commands for media controller .

Upon receiving a command from a SAS initiator RXDP checks ILT to determine whether sufficient resources exist to handle the command. If resources do not exist then RXDP rejects the command by transmitting a response of either a TASK SET FULL or BUSY frame via instruction interface . As shown in when a SAS command is received RXDP provides the WWN and the ICT to ILT . ILT checks the received WWN against the entries stored in initiator table . If the received WWN is not already stored in initiator table and there is space available in the table the received WWN is added to initiator table in the first available location along with the input ICT and count is set to 1 for the received command shown as entries and . If the received WWN is already stored in initiator table then the existing entry for the initiator is used and the count entry is incremented to reflect the additional command. ILT returns the ILT ID number shown as 518 to RXDP and the ILT ID is stored in the one or more contexts corresponding to the command.

If all entries in initiator table are occupied by other initiators and each entry has an active command count greater than 0 then ILT via interrupt interface might generate an interrupt to processor . RXDP might queue the received command until after the interrupt is processed. If the initiator table or command FIFO is full ILT might respond to RXDP with a BUSY message shown as signal to indicate to the initiator that media controller is busy and cannot yet receive the command. When a given initiator reaches its maximum allowed commands ILT might respond to RXDP with the TASK SET FULL message shown as signal to indicate to the initiator that media controller cannot yet receive another command from that initiator. After the BUSY or TASK SET FULL status is determined RXDP might then discard the received command.

ILT also might be accessed by instruction interface before the instruction interface issues a SAS instruction to link protocol core . As shown in ILT provides instruction interface with WWN and ICT . Instruction interface might provide data to ILT as commands are completed for example as shown instruction interface might provide the ILT ID number of the completed command and might request that ILT decrement the count of active commands for the corresponding initiator in initiator table .

As described herein resource availability might typically be determined based upon the total number of commands that have been received and a maximum number of commands allowed in the system the maximum queue depth. Embodiments of the present invention might alternatively make this determination based upon i a minimum number of commands per initiator which prevents any single initiator from being locked out while a different initiator consumes all available resources ii a maximum number of commands per initiator which balances available resources between initiators and iii the maximum queue depth of all allowed commands in the system. Embodiments of the present invention also provide that the number of active initiators is programmable and that the minimum and maximum number of commands per initiator and the maximum queue depth are also programmable. The number of allowed commands per initiator is based upon the total number of initiators supported and the total resources available within media controller . If a smaller number of initiators are supported then more resources are made available to each initiator if appropriate. Resources might be dynamically re allocated depending upon system characteristics.

For example during initialization of media controller ILT might be set to track information for up to 8 initiators and the maximum queue depth might be set to 128 total active commands. When 8 initiators are supported the minimum number of commands per initiator might typically be set in the range between 1 and 4 commands. The maximum number of commands per initiator might typically be set in the range between 32 and 96 commands. In a specific example the minimum number of commands per initiator is set to 1 and the maximum number of commands per initiator is set to 64. In this case the maximum queue depth might be set to 122 which would allow a first initiator to use its maximum of 64 commands and a second initiator to use a maximum of 58 commands while allowing each of the remaining 6 initiators command up to the maximum 128 active commands. Thus each of the 8 initiators would allowed at least the minimum 1 active command after the first two imitators have each attempted to use their maximum number of commands. Further the total number of commands accepted remains within the allowed maximum of 128 active commands.

As a second example ILT might be set to track information for two initiators and an interrupt is generated if a command from a third initiator is received. Again the maximum queue depth might be 128 commands. Since only two initiators are stored in initiator table the minimum number of commands per initiator might be set to a larger number such as 24 commands. The maximum number of commands per initiator might then be set as 103 to allow the minimum 24 commands to the other supported initiator . The total queue depth would be set to 128. The advantage in this example is that more resources are allocated for one or two initiators but if commands for more than two initiators are received an interrupt must be generated to allow the command for the third initiator to be received. To receive the command from the third initiator values for the minimum number and maximum number of commands that are allowed for each initiator are desirably reconfigured during the interrupt processing. Embodiments of the present invention thus provide flexibility to dynamically allocate resources among different initiators during operation of media controller .

Tag Manager verifies a command tag used to identify active commands in media controller for example in SATA systems with native command queuing or SAS systems with command queuing. Tag Manager verifies that a new command tag does not overlap with a command tag that is currently active. When RXDP receives a new command RXDP checks the command tag table of tag manager before the command is moved out of RX Buffer for processing. In embodiments of the present invention Tag Manager might support one host device with a limit of 32 active commands for example for SATA systems. In such embodiments Tag Manager might be implemented as a tag table to support the 32 active commands. In other embodiments Tag Manager might support multiple host devices and deeper command queues such as in a SAS system. In such embodiments Tag Manager might be implemented as a Pseudo CAM content addressable memory to support the larger and more complex tag memory. Such embodiments might support a maximum of 128 active SCSI Command Tags which might be equal to the maximum queue depth of media controller . shows greater detail of Tag Manager .

As shown in tag manager includes pseudo CAM which generally provides fast access for tag lookup without requiring a large external buffer in SAS systems having queued commands and multiple initiators. For SATA devices a simpler tag table might be employed instead of pseudo CAM . When a command is received RXDP checks a command tag of the corresponding command and provides the command tag to arbitration module . Arbitration module generally manages access to tag manager by processor RXDP and instruction interface . As indicated by the dashed lines in a SAS system arbitration module might also arbitrate access to tag manager between an instruction interface and an RXDP for a second port not shown . Embodiments of the present invention having 2 ports will be described with regard to

When a command is received RXDP requests access to tag manager and provides the tag ID of the received command to arbitration module as indicated by Tag ID signal . Arbitration module provides the tag ID to the appropriate one of tag table or pseudo CAM to perform a tag lookup. If the Tag ID does not exist in tag table or pseudo CAM the tag ID is added to the table and arbitration module provides acknowledge signal to RXDP . RXDP then moves the received command from the RX Buffer for example to buffer subsystem . As described herein checking the command tag before a received command is moved from RX Buffer simplifies error handling on tag error cases because processing of the received command is not yet started. If the received tag ID already exists in tag table or pseudo CAM a tag overlap condition exists and an interrupt is generated to processor to perform additional processing to handle the error condition.

Instruction interface might generally delete a command tag after sending the data corresponding to the received command. Instruction interface might send DELETE TAG signal and TAG ID signal to arbitration module . When arbitration module responds with ACK Signal after the command tag has been deleted instruction interface might clear the related command contexts. In embodiments of the present invention the number of stored command tags is equal to the current number of active commands the command queue depth . As described herein in some embodiments a desired maximum command queue depth might be 128 i.e. a maximum of 128 active commands supported .

Pseudo CAM might support one or more different hash algorithms. Different hash algorithms might be chosen to provide support for different numbers of active initiators and command queue depths for each initiator. Desirably the hash algorithm distributes the initial search address across all addresses of pseudo CAM . Embodiments of the present invention support 4 hash modes. Each hash mode provides an 8 bit output address. The first hash mode does not necessarily account for the initiator ID when searching pseudo CAM which might be preferred for single initiator systems. The second hash mode might provide 1 bit of the 8 bit output to account for the initiator ID which might be preferred for two initiator systems. Similarly the third hash mode might provide 2 bits of the 8 bit output to account for the initiator ID which might be preferred for four initiator systems and the fourth hash mode might provide 3 bits of the 8 bit output to account for the initiator ID which might be preferred for eight initiator systems. In exemplary embodiments the first hash mode might employ the hash algorithm Hash Tag ID 0 7 the second hash mode might employ the hash algorithm Hash initiator ID 0 Tag ID 0 6 the third hash mode might employ the hash algorithm Hash initiator ID 0 1 Tag ID 0 5 and the fourth hash mode might employ the hash algorithm Hash initiator ID 0 2 Tag ID 0 4 .

Pseudo CAM might generally include registers or memory locations to store the command tags in a tag table. Processor might add or delete tags or clear the entire table using a control register. In embodiments of the present invention each register or memory location is 32 bits. Within each 32 bit memory location one or more bits might indicate a VALID status that when set includes that location in the pseudo CAM search. When the VALID status is not set the location is not included in the pseudo CAM search. A second group of one or more bits might indicate a TAG COUNT that indicates a number of entries to be checked in the search. A third group of one or more bits might store the ILT ID number used to reference the SAS initiator. A fourth group of one or more bits might store the TAG ID representing the SCSI command tag. This general data structure is employed in performing tag searches when a new command is received by RXDP . The tag search operation is described in greater detail in regard to .

At step Tag Manager performs a hash function to convert the tag ID to a starting search address of pseudo CAM . At step tag manager reads TAG COUNT from the starting address location. As described TAG COUNT provides the number of entries stored in the tag table that is searched to determine if a tag overlap exists. At step if TAG COUNT is equal to zero no tag overlap is detected and the search is complete. Algorithm proceeds to step and adds the new tag ID to pseudo CAM . The new tag ID is stored in the first invalid entry of pseudo CAM which was stored at step . The TAG COUNT for this address of pseudo CAM is not changed. Once the tag ID is stored to pseudo CAM algorithm completes at step . This algorithm minimizes the search depth since the entries for a hash are clustered by the starting hash address.

If the TAG COUNT is non zero the search continues at step . At step the address is read from pseudo CAM . At step the VALID flag of the read address entry is checked. If the entry is not valid and no other non valid entry has been detected at step the address of the invalid entry is stored to add the tag ID and processing continues to step . Thus at step the first invalid entry of pseudo CAM is found and its address stored. At step the TAG COUNT is decremented. At step the address of pseudo CAM is incremented and processing returns to step . At step if the entry is valid processing continues at step . At step the tag ID stored at the address is read.

At step Tag Manager compares the read tag ID with the new tag ID. If the read tag ID matches the new tag ID then at step an overlap error is detected and an error interrupt is generated. The tag search is ended at step . If the read tag ID does not match the new tag ID the process continues to step . At step tag manager performs the hash algorithm on the read tag ID and at step the hashed read tag ID is compared with the starting search address i.e. the hashed new tag ID . At step if the hashed read tag ID matches the starting search address the TAG COUNT is decremented at step . If the hashed read tag ID does not match the starting search address TAG COUNT is unchanged and the address is incremented at step . The process continues until the TAG COUNT reaches zero or a tag overlap is detected.

At step if the TAG COUNT is equal to zero no entry matching the completed tag ID exists in pseudo CAM . This is an error condition since the tag ID should exist if it was completed and thus no entry can be deleted. At step the error condition is detected and an interrupt is generated. The tag search and deleted operation is ended at step . At step if the TAG COUNT is non zero the search continues to step . At step the address of pseudo CAM is read. At step the entry valid bit is checked. If the entry is not valid at step the address of pseudo CAM is incremented and processing returns to step . If at step the entry is valid processing continues to step .

At step tag manager reads the tag ID stored at the address in pseudo CAM . At step tag manager compares the read tag ID with the completed tag ID. If the read tag ID matches the completed tag ID then the proper entry has been located and processing proceeds to step . At step tag manager clears the valid bit for the entry but preserves the TAG COUNT for that address of pseudo CAM . The tag entry has been removed from future tag searches and is available to be reused for future commands. The process is complete at step .

If at step the read tag ID does not match the completed tag ID the process continues to step . At step tag manager performs the hash algorithm on the read tag ID to provide a hashed read tag. At step the hashed read tag is compared with the starting search address. If the hashed read tag matches the starting search address at step the TAG COUNT is decremented and the process continues to step . If at step the hashed read tag does not match the starting search address the TAG COUNT unchanged and the process continues to step . The process continues until TAG COUNT reaches zero or a tag error is detected.

Referring back to context management module includes Context Cache CC Consumed Context Manager CCM and Context Free Pointer Manager CFPM .

Context cache loads contexts from context buffer to perform the data transfer corresponding to the context. As described herein one or more contexts correspond to a data transfer for a host command. Context cache might include one or more context pointers to read contexts from one of context buffer or BAM . Context cache might provide retrieved contexts to one or more of instruction interface TXDP and PWT for further processing. For example context cache stages retrieved contexts at the head of the active context queue in TXDP before previous contexts complete execution. Context cache might stage a next context by modifying one or more contexts before they are executed or reordering the active context queue. For example the active context queue might typically include pointers to the next context to be executed thus linking the contexts together in a linked list. The pointer to the next context in the list is generated when the contexts are generated thus defining the order of the linked list of contexts. Context Cache thus allows the priority of a thread to be changed dynamically for example by modifying or reordering contexts in the active context queue before the data transfer corresponding to the context is started.

In embodiments of the present invention context cache might include parallel context linked lists to store context pointers from parallel context processing threads. For example context cache might employ one parallel context thread as a normal priority context thread and one parallel context thread as a high priority context thread. The priority of a context thread might be indicated by a control bit. Context cache might typically process the normal priority context thread until one or more contexts are present in the high priority thread. When the normal priority context thread reaches a protocol boundary e.g. a frame boundary context cache might pause the normal priority thread and process the contexts of the high priority thread. The protocol boundary might be indicated by a context control bit signifying that the context being processed is the last context for a given protocol unit. For SATA switching execution to the priority thread might typically be allowed at a Setup boundary since the device has committed to transferring that amount of data before switching to another thread. For SAS switching might be allowed at the data instruction commit amount boundaries for better efficiency on data transfers. The high priority context thread might typically be executed until it is empty and then context cache returns to complete processing of the normal priority context thread.

After a data transfer for a context is completed the command and data cache information should be updated to maintain the integrity of cached information. In general embodiments of the present invention might provide an interrupt to service a cache update routine. As described herein multiple data transfer contexts might be employed for a single command. Thus embodiments of the present invention provide cache update interrupts at data boundaries that are not tied to individual contexts but rather to entire data transfers. A context interrupt queue might be employed to allow multiple data transfer contexts to be processed by a single interrupt. Further embodiments of the present invention employ the context interrupt queue to allow the cache update interrupt routine to be performed outside of the data transfer performance path avoiding delays for data transfers.

Embodiments of the present invention generate an interrupt based on a context configuration bit that is set after one or more contexts are completed without error. If the one or more contexts are completed with at least one error the data transfer might be aborted. Once a context is completed the context is consumed. Embodiments of the present invention provide three processes for consuming contexts. The first process generates a cache update interrupt for each data transfer context that completes. The second process generates a cache update interrupt after a command that includes multiple data transfer contexts completes. The third process generates a cache update interrupt after a predetermined number of contexts complete. In cases where multiple data transfer contexts are completed before generating an interrupt the range of LBAs for all completed data transfer contexts is maintained in buffer memory.

As described context cache might retrieve a next context of a context thread from context buffer while a current context is being processed. Context cache compares the next context pointer with the end pointer corresponding to the end of the data transfer corresponding to the context thread. If the next context pointer is not equal to the end context pointer the next context is read from context buffer . Embodiments of the present invention might include one or more copies of the next pointer and end pointer such that the normal priority context thread can be interrupted to execute the high priority context thread. High priority threads might include contexts for operations such as SATA or SAS response frames SAS TRANSFER READY frames or other high priority data transfers.

CCM is employed to process completed contexts for example by deleting the context generating an interrupt indicating the context has completed or recycling the context pointer. shows greater detail of CCM . CFPM maintains a pool of unused context pointers e.g. the buffer address where the context is stored . CFPM provides free context pointers when new contexts are created and adds pointers back to the free pointer pool when the context completes without having to reorder contexts in the buffer memory. shows greater detail of CFPM .

As shown in CCM is coupled to instruction interface RXDP and TXDP which provide pointers for completed contexts shown as pointers N to CCM . A context pointer is an index of the buffer that corresponds to the buffer address where a context is stored. The hardware registers in CCM include buffer write FIFO and buffer read FIFO . Buffer write FIFO stores enough pointers to provide one burst write operation to buffer subsystem shown as pointers N . In exemplary embodiments buffer write FIFO stores 6 pointers in 3 datawords. Buffer read FIFO stores the same number of pointers as buffer write FIFO to provide a burst read operation to buffer subsystem . The entries in FIFOs and might include error correcting code ECC protection for example every 3 datawords of FIFO data might include 1 dataword of ECC data such that the overall burst operation size is 4 datawords 3 data 1 ECC .

When a context pointer is provided to CCM it is stored in one of buffer write FIFO and buffer read FIFO . Together the contents of buffer write FIFO buffer read FIFO and CCQ buffer form consumed context queue CCQ as indicated by the dashed line. As shown in to provide variable queue depths consumed context queue might be stored in buffer write FIFO buffer read FIFO CCQ buffer in buffer subsystem or a combination thereof. Context pointers are removed from CCQ in the order of context completion. If buffer read FIFO is empty context pointers are moved to buffer read FIFO from one of CCQ buffer or buffer write FIFO . CCQ buffer might be used to store context pointers received by buffer write FIFO when buffer read FIFO is full. To process a context pointer CCM loads the head entry of CCQ to current pointer register . CCM reads the original copy of the context shown as context from context buffer and based on the context data might generate an interrupt shown as to process the context.

One or more of the context pointers in CCQ might be processed during the same interrupt by employing flexible associations between the context interrupts and CCQ . For example by tracking LBAs for consumed contexts CCM might process contexts for contiguous LBAs in a single interrupt. Alternatively CCM might process a predetermined number of one or more consumed contexts in a single interrupt by tracking a tag for each command. After the interrupt is processed the corresponding entry of CCQ is cleared and the next entry in CCQ might be processed by generating a new interrupt corresponding to the next entry. This process is repeated for subsequent consumed contexts in CCQ .

Completed contexts provided to CCM might be consumed in one of four ways. First a completed context might be cleared without recycling the context pointer to CFPM and without generating an interrupt to perform any other processing. Second a context pointer might be cleared without generating an interrupt but is recycled to CFPM . These first two cases are generally controlled by multiplexer which optionally bypasses CFPM . Third CCM might generate an interrupt and recycle the context pointer to CFPM . The context pointers are provided to CCM which loads the pointer into CCQ . When the pointer is removed from CCQ CCM loads the matching context from context buffer and generates an interrupt. While processing the interrupt the context is read and operations are performed such as tracking how often a given LBA is accessed. When the interrupt is cleared CCM sends the context pointer to CFPM for recycling and CCM clears the context pointer from CCQ . Fourth CCM might generate an interrupt but not send the context pointer to CFPM for recycling.

Thus as described herein embodiments of the present invention provide support for generating and executing dual threads of contexts. For example embodiments of the present invention support a normal context thread and a parallel high priority context thread. This structure supports generation of context threads by having a parallel structure for generating contexts and also supports execution of parallel context threads by having a parallel context fetch structure to support inserting high priority contexts at an appropriate transfer boundary. Embodiments of the present invention provide the ability to generate a high priority context without changing a current context thread.

As described above with regard to embodiments of the present invention provide that a single data transfer at the communication link protocol level e.g. link protocol core might be split into one or more data transfer contexts for data transfers internal to media controller . The data related to the one or more contexts might be scattered in different locations in the data buffer and or media and need to be combined to form a single contiguous data transfer at the protocol level. Thus embodiments of the present invention allow a protocol command to be split into one or more contexts that can later be recombined. Splitting a protocol command into contexts might accommodate multiple buffer management techniques and multiple protocol techniques such as for example SATA programmed input output PIO multiple and SAS multiple pending write commands. As will be described embodiments of the present invention decouple a data transfer block boundary from a protocol frame boundary. Thus regardless the size of data frames transferred over communication link internal data contexts might be created to process the data transfer. The size of the data contexts is not dependent on the protocol employed by communication link .

As shown in command context might correspond to one or more write contexts N that are generated to process the data transfer. The size of write contexts N might correspond to chunk boundaries of data stored in media system for example data stored in media buffer or buffer . The chunk boundaries are generally independent of the protocol frame boundaries and the overall size of the data transfer. A counter is employed to track the number of chunk boundaries such that a new data transfer context can be processed without affecting the other contexts. As shown in command context corresponding to the SAS TRANSFER READY frame is linked to write contexts N that are linked together and provide pointer information for the buffer locations storing the data to be transferred. In exemplary embodiments of the present invention write contexts N might have the same configuration options and match the overall data length provided in command context . One or more of write contexts N might be stored in Pending Write Table PWT . As indicated by the dashed line contexts N might optionally be merged into a single data transfer between communication link and media shown as data transfer . This size of data transfer might be based on for example a maximum burst size to media or a number of contiguous chunks of the one or more write contexts.

In the SAS protocol multiple write commands might be active simultaneously so write contexts might be suspended at frame boundaries on the protocol. To support multiple suspended contexts PWT temporarily stores suspended contexts to decouple the suspended contexts from the protocol frame boundaries. Both frame boundaries and context boundaries are maintained in PWT so that write contexts are not necessarily required to be aligned to protocol frame boundaries.

As described above the one or more read contexts N are optional as embodiments of the present invention might depending on the size of the read data transfer or settings of media controller employ varying context boundaries. For example for small read operations only a single context per protocol command might be employed e.g. only read command context . In this case a single context is generated for the data transfer. Instruction interface issues an instruction for the data transfer length of the context and transmit data path TXDP transfers the data for that context. Alternatively multiple data transfer contexts might be merged together to create a larger protocol instruction for better protocol efficiency for example to send out data packets of a maximum packet size of communication link . As shown in read command context is used for the protocol instruction length and is linked to one or more read contexts N that satisfy the overall instruction length. Read contexts N are processed by transmit data path and data is seamlessly transferred to link protocol core until the instruction length from read command context is met. Protocol frame boundaries are maintained independently of context boundaries so frames of the maximum size allowed by the link protocol are sent until all of read contexts N have been processed. In general once processing of a read data context starts the read data context remains in the transmit data path until completion.

In embodiments of the present invention BAM might generate read data contexts without requiring a linked list of contexts in context buffer . As shown in generated read command context defines an entire data transfer length of the protocol instruction request but this context references a list of context structures accessible by BAM instead of contexts stored in buffer . Base pointer is employed to provide a single context in buffer for a transfer while the following contexts N might be generated by BAM . Base pointer might not be used when the one or more read contexts N are used or are not generated by BAM . BAM might generate read contexts N and employing an internal context lookup algorithm store data for each of read contexts N to Context Cache . The contexts are provided from Context Cache to TXDP which provides the data to link protocol core to perform the read data transfer. Thus BAM reduces the data structures that firmware running on processor generates and passes between routines and provides for faster processing of data contexts. This provides the ability to generate contexts for a data transfer command in three ways while still supporting the maximum transfer size i in a single context for the command and the data transfer in buffer e.g. context ii a command context e.g. context with a single data transfer context in buffer e.g. base pointer with multiple data transfer entries in BAM e.g. contexts N and iii one or more contexts in buffer split between a command context e.g. and one or more data contexts e.g. N .

TXDP based on the context configuration contained in command context determines processing of a read context and what actions are performed at context boundaries. For example TXDP tracks the context boundary using a context block count. If the current context being processed by TXDP indicates that there is another context in the data transfer TXDP loads the next context when the current context completes. Context Cache might provide the next context based on base pointer to TXDP to continue the transfer without affecting the protocol operation.

Embodiments of the present invention employing a host subsystem operating in conformance with the SATA protocol might generally support the same features as described above with regard to for host subsystems operating in conformance with the SAS protocol. For example a subsystem operating in conformance with either protocol might provide contexts such that the overall protocol transfer context is separate from one or more internal data transfer contexts.

In the SATA protocol data packets are sent using one or more frames that include a start of frame SOF delimiter a data payload a cyclic redundancy code CRC delimiter and an end of frame EOF delimiter. The data payload contains user data organized according to a predefined file information structure FIS . The FIS of the payload includes a value representing a type parameter of the FIS. For example a first party DMA FPDMA FIS generally requires the FIS indicate the total amount of data that media controller can transfer in one operation. Typically a SETUP FIS frame is sent which is then followed by data transfer frames. The SETUP FIS must be processed before data frames can be transmitted.

To support this protocol requirement the execution of FIS setup operations and the execution of data transfer operations are handled using different independent contexts. For example a data transfer context can be split from the command context e.g. the SATA setup command while separately maintaining counts of protocol frames. Similarly as described above with regard to embodiments of the present invention operating in conformance with the SATA protocol might process a setup command and a data transfer using one context or might split the command and data transfer into one or more contexts to provide scatter gather buffer management support. Other embodiments of the present invention might process a command and data transfer as a command context having a single data transfer context in the buffer with multiple data transfer entries in BAM .

As shown in embodiments of the present invention generate a number of contexts N that correspond to storage of data is in buffer subsystem . For substantially every discontinuity of data in the buffer a new context is required to point to that data. Each of contexts N transfers the SETUP FIS and also transfers the data corresponding to each FIS limiting the amount of data that can be transmitted for each SETUP FIS.

As shown in embodiments of the present invention generate a setup context and a number of contexts N that correspond to how data is stored in buffer subsystem . Each of data contexts N correspond to a single SETUP FIS context . As indicated by the dashed line data contexts N might be combined into a single data transfer . In data contexts N generally transmit more data than setup data contexts N of because each context N does not need to include a SETUP FIS. In this case Instruction Interface sends a SETUP FIS for the entire transfer and data contexts N are merged together e.g. by TXDP or RXDP providing a single data transfer.

Embodiments such as shown in might beneficially be employed for example to process SATA programmed input output PIO Multiple commands. PIO Multiple commands include data transfers for one or more memory addresses where the data in the PIO Multiple command is not necessarily aligned with a buffer management boundary. Thus embodiments of the present invention split PIO Multiple commands into one or more contexts that align to chunk boundaries of data stored in media system e.g. data stored in media buffer or buffer . Chunk boundaries might generally be independent of the protocol frame boundaries and the overall size of the transfer although chunk protocol frame context and media boundaries all align to the end of the last transfer.

As shown in embodiments of the present invention generate one or more data contexts independently of context buffer . Similarly as shown in one context is generated for the SETUP FIS setup context . A second context base pointer is generated and stored in context buffer to provide a reference pointer to a separate data transfer list in BAM . BAM generates individual data transfer contexts N and during the data transfer writes each of them to Context Cache in sequence. Individual data transfer contexts N are moved from Context Cache to the data paths e.g. TXDP to perform the data transfers. These data transfer contexts are not stored in context buffer and only exist in Context Cache and the corresponding data path. The data path merges data contexts N into a single data transfer. When BAM generates the final data transfer context e.g. M base pointer is cleared from Context Cache and Context Cache processes the next context its queue. Embodiments of the present invention might employ a single context combining the SETUP FIS context with the base pointer similarly as shown in except BAM generates data contexts N .

Embodiments of the present invention might employ independent receive and transmit direct memory access DMA modules in addition to context cache pending write table PWT and buffer allocation manager BAM . Independent RXDMA and TXDMA modules might allow for full duplex operations. Further independent RXDMA and TXDMA modules combined with context staging in context cache provide a context execution pipeline that provides the advantages of i allowing modifications to a context before it is executed by the corresponding DMA ii staging a next context in a context cache to improve performance and allow modification of the context before it is executed by the corresponding DMA and iii staging contexts to accommodate data encryption.

At step Instruction Interface requests that link protocol core send a TRANSFER READY frame to the host initiator. The TRANSFER READY frame includes a write transfer tag indicating a corresponding context entry in pending write table PWT . At step Instruction Interface sends the PWT ID to PWT and at step PWT adds the write context to a context list at location corresponding to transfer tag. PWT might retrieve the write context based on the PWT ID from context cache or a cache internal to PWT . At step link protocol core receives the data frame sent by the host initiator and the data frame is stored in RX Buffer . At step RXDP via RXDMA retrieves the write context from PWT based on the write tag which is provided in the header of the data frame stored in RX Buffer . PWT swaps contexts by i storing current context from RXDMA and ii providing requested contexts from PWT . At step RXDP via RXDMA transfers the received data frame from RX Buffer to buffer subsystem . At step if the last frame of the data transfer was processed then the data transfer is complete at step . Otherwise additional frames are left to process and the process returns to step to process additional data frames to satisfy the entire data transfer for example by PWT retrieving a next write context from the context cache.

Context process of corresponds to a SAS write data transfer but might be slightly different for SATA transfers. In SATA instead of TRANSFER READY there is a DMA Setup Write and only a single write is active at any one time. Thus for SATA Instruction Interface tracks the total transfer length and RXDP indicates to Instruction Interface whenever it receives a frame.

Embodiments of the present invention might provide that multiple contexts are combined into a single TRANSFER READY frame. When multiple contexts are combined into one TRANSFER READY frame PWT is configured to process a thread of contexts that are coalesced together as data for each context is received. Instruction Interface is configured to generate the TRANSFER READY frame to include a transfer count of all the contexts in the thread for that portion of the write command. The contexts are linked together and desirably have the same configuration such that only the transfer length and buffer pointer locations change between contexts in the thread. The linked contexts might be generated by Buffer Allocation Manager BAM . For example the thread of contexts might correspond to single context having multiple entries in BAM or multiple individual contexts in the buffer that are joined together to advantageously utilize the maximum frame transfer size.

Similarly as described in regard to write contexts and of TXDMA might employ two read contexts a first read context B C read context to perform buffer side context operations e.g. between TXDMA buffer FIFO and buffer subsystem and a second read context TX read context to perform transmit side context operations e.g. between TXDMA and TX Buffer . These two read contexts allow the transmit side operations and the buffer side operations to be performed independently of each other which supports operation of encryption datapath since for example encryption datapath might introduce delay in processing received data.

TXDMA moves data from buffer subsystem to TX Buffer to be provided to Link Protocol Core . Data is provided from buffer subsystem in one or more chunks of data for example in a chunk size employed by media . TX Buffer reformats the one or more data chunks into continuous data for transmission according to the protocol employed by communication link e.g. frames packets etc. . TX Buffer might supply data to link protocol core to reformat one or more data chunks into a frame of the maximum size allowed by the protocol employed by communication link . TX Buffer might also add parity data or other error correction data to the data for transmission. Link Protocol Core retrieves the data for transmission from TX Buffer and provides data frames to communication link .

Data transfers might be paused for a protocol disconnect or error and the context associated with the data transfer remains in TXDP until the data transfer can be completed. The context might block link protocol core until it is processed. Some frames might be manually formatted in TX Buffer while other frames might automatically be generated in TX Buffer .

At step a read context is provided to TXDMA to retrieve the corresponding data from buffer subsystem . At step the data is transferred to TX Buffer where the data is grouped into chunks corresponding to the protocol frame size at step . At step instruction interface requests that link protocol core send one or more data frames to fulfill the read request. At step data is transferred from TX Buffer to link protocol core for transmission over communication link .

At step if TX Buffer is loaded with the data to satisfy the current context so that context is complete. The completed context is discarded and data for a next context of the transfer is loaded into TXDMA as the data corresponding to a previous context of the transfer is provided to link protocol core at step so data corresponding to the next context is ready to be provided to link protocol core when the previous context is complete thus reducing idle time of link protocol core . As soon as all the data for a context is loaded into TX Buffer the context is cleared from TXDMA so data for the next context can be fetched from buffer subsystem . There are independent host side TXDMA and media side buffer client B C contexts for read data transfers such as were employed in the RX datapaths for write data transfers as described with regard to .

At step link protocol core sends the data frame over communication link . At step if additional data frames remain to be sent for the read request processing returns to step to transfer data from buffer to link protocol core . Otherwise if the last data frame has been sent the read transfer is complete at step .

Thus as shown in a two port SAS device might include a first context cache module to interface to TXDP and instruction interface for port A which has corresponding link protocol core . A second context cache module interfaces to TXDP and instruction interface for port B which has corresponding link protocol core . Each context cache module and also interfaces with PWT buffer subsystem and BAM which are shared between port A and port B. Each context cache module and retrieves the next context to be executed from the thread of contexts as described previously with respect to . Pending Write Table Tag Manager ILT and Command Parser might be scaled to support dual port operation but operate generally such as described in regard to . The RXDP and TXDP modules might be substantially unchanged between single port SATA applications and dual port SAS applications.

As described herein embodiments of the present invention might provide a write context split between the RXDMA module and the buffer interface to handle encryption pipeline operation. A split in contexts might be implemented because the size of incoming data frames to RXDPs and is not necessarily the same size as the size of outgoing data blocks. As shown RXDPs and might interface with Encryption Data Path . Encryption Data Path provides data encryption and decryption as a pipeline stage in the data path. Encryption Data Path might encrypt or decrypt one or more blocks of data being transferred between buffer subsystem and at least one of the link protocol cores and . RXDP might add any CRC cyclic redundancy check or other ECC error correction code protection to data blocks. As shown in the write context might be split and provided to pending write table as RX Write Context and a buffer client B C write context . This context split provides independent operation of RXDMA to receive data from RX buffer and buffer client DMA to provide data to buffer FIFO . This independent operation allows for delay variations caused by the operation of Encryption Datapath . For example Encryption Datapath might have nondeterministic delay since data frame boundaries are not necessarily aligned with encryption block boundaries.

Since the SAS protocol allows for multiple active write commands PWT provides RXDMA modules and access to a list of active write commands. The active write commands might be loaded relatively quickly into the respective RXDMA module to store the write data transfer of received data frames. Since the received frames do not necessarily align with host block boundaries or encryption block boundaries extra information might be maintained for each outstanding write command such as for example an intermediate CRC an intermediate data integrity field DIF block ECC or an intermediate block count. PWT might be implemented as RAM or as a register file that stores context information for each write transfer entry along with the associated intermediate information for each entry. The storage size of PWT might be determined such that the data transfer rate is maintained in RXDP while entries are being loaded to one of RXDMA module or from PWT . In embodiments of the present invention the data rate of RXDMA modules and might be faster than the data rate of the link protocol such that RXDMA modules and can process a currently received data frame and flush RX buffers and without throttling the link protocol. PWT will be described in greater detail with regard to .

As described herein embodiments of the present invention might provide a read context split between the TXDMA module and the buffer interface to handle encryption pipeline operation. A split in contexts might be implemented because the size of data chunks stored on media and buffer subsystem might not be the same as the size of outgoing data frames from TXDPs and to link protocol cores and respectively. As shown TXDPs and might interface with Encryption Data Path . Encryption Data Path provides data encryption and decryption as a pipeline stage in the data path. Encryption Data Path might encrypt or decrypt one or more blocks of data being transferred between buffer subsystem and at least one of the link protocol cores and . As describe with regard to the RX datapaths shown in this independent operation allows for delay variations caused by the operation of Encryption Datapath . For example Encryption Datapath might have nondeterministic delay since data frame boundaries are not necessarily aligned with encryption block boundaries.

Embodiments of the present invention provide for processing multiple write data contexts. Write data contexts might be processed in parallel with other context processing supporting multiple simultaneous outstanding write commands in parallel with other context operations. By employing a write data context thread that is independent from other context threads the write data context thread does not impact the execution of the other context threads allowing high performance full duplex operation.

There is a staged context for each PWT Entry e.g. RX context entries and B C context entries but PWT Context Cache is shared for all PWT entries. PWT Context Cache is first come first served context cache in the case of multiple simultaneous requests. Contexts stored in PWT Context Cache might be modified by processor before the context is loaded to PWT DMA Context entries . Thus contexts might be modified outside of the performance path of active contexts.

PWT Context Cache fetches write data contexts from buffer subsystem . PWT Context Cache is independent of the regular context cache for host data requests. PWT Context Cache allows media controller to quickly switch between different Pending Write Entries to handle the different received frame boundaries since a SAS Initiator can send data frames for a TRANSFER READY request at its convenience. Since there can be an entire thread of contexts associated with each Pending Write Entry PWT needs to react to incoming data traffic without impacting the context thread currently being processed. A staged context entry allows shared context cache to stay ahead of the active Pending entry.

As shown in for a SAS device one PWT is shared by both the Port A and Port B Receive Datapaths and respectively. In only the details of RXDMA module are shown but RXDMA module might generally be substantially the same. As indicated by the dashed line control signals are passed between each of RXDMA and and RX context control and B C context control . In embodiments of the present invention PWT stores information for up to eight contexts. These contexts are employed to move write data to buffer subsystem after transmitting TRANSFER READY frames. Thus B C context entries supports eight B C contexts RX context entries supports eight RX contexts and DMA context entries supports eight DMA contexts to feed the B C and RX contexts. DMA context entries might load contexts from up to eight context threads. As shown context completion module handles context completion tasks such as requesting that an instruction interface e.g. or transmit a response delete the command tag from tag manager not shown in and recycle the context pointer in CCM and CFPM .

When a series of contexts is created to transmit a TRANSFER READY frame and receive the corresponding data from the initiator an entry in PWT is allocated. When a data frame is provided at the output of the receive buffer e.g. or the RXDP e.g. or loads the corresponding context from RX context entries . The data frame might then be removed from the receive buffer. The data received by the RX buffers is possibly interleaved with one or more separate commands. In same context mode the entire data transfer is represented by a single context. If a data frame for a different command is received next by the RX buffer then RXDP writes the RX context for the previous frame to RX context control and loads the corresponding RX context for the current data frame. Once all data for a context has been moved to buffer subsystem and a status frame has optionally been sent then the entry of PWT is completed and can be allocated for a new transfer.

In different context mode one TRANSFER READY context is created for the instruction interface e.g. or to send the TRANSFER READY frame. A series of DMA contexts are created to process the TRANSFER READY context. The series of DMA contexts must be available to PWT as the matching data is received at the RX buffer. A separate thread of DMA contexts is created for each TRANSFER READY context. RX and B C context entries and provide the current contexts to RX context module and B C context module . PWT storage module also fetches and stores the next DMA context in the write thread. By having the next context available PWT and RX datapaths and can quickly change context threads when data for a different command is received. As each DMA context is consumed PWT Context cache fetches the next context from for example buffer subsystem .

Embodiments of the present invention provide generic DMA operation in media controller . This generic DMA capability might allow media controller to copy data from one buffer location to another and to change the format of data as it is moved. Embodiments of the present invention might provide a connection between the independent receive and transmit DMA modules e.g. RXDMA modules and and TXDMA modules allowing isolation of internal data transfers from link protocol cores e.g. and without a dedicated DMA module for internal data management. Thus embodiments of the present invention provide internal loopback capability using the RX and TXDMA modules. Embodiments of the present invention might support features employing the internal Generic DMA such as for example internal transfers of data in buffer memory memory test pattern generation and checking data copy with encryption and repetitive write operations to media .

Embodiments of the present invention might employ GDMA module to perform data operations where link protocol core is beneficially isolated from the data path. Such operations might include 1 move buffer data from one buffer location to another in buffer subsystem 2 move host data from one buffer location to another 3 read and overwrite host data from one or more buffer locations 4 read encrypted buffer cipher text data decrypt the buffer data and then write plain text data 5 read buffer plain text data encrypt the buffer data and then write cipher text data and 6 performing memory tests.

GDMA might support at least four transfer modes i loopback mode ii write same mode iii memory test mode and iv memory read test mode. In loopback mode GDMA is programmed with a Total Transfer Count indicating the size of the data transfer and configuration information indicating the type of the data transfer. GDMA then checks to determine if data can be stored in TX Buffer and if data can be moved from TX Buffer to RX Buffer . GDMA then moves the data from TX Buffer to RX Buffer and status generator creates a status entry after data has been written to RX Buffer . GDMA can be throttled by TX Buffer but will continue the data transfer until the Total Transfer Count reaches zero.

In write same mode GDMA is also programmed with the Total Transfer Count and configuration information. TX Buffer is loaded with a single block of data that is to be written to multiple locations in media . TX Buffer includes a wrap pointer that is adjusted to wrap at the block data boundary. In write same mode GDMA does not check to determine if data can be stored in TX Buffer since only one block is stored as TX Buffer repeats the same data block continuously until the Total Transfer Count reaches zero. TXDP is generally not involved in a write same operation because the data block is already stored in TX Buffer . GDMA routes the data through RX Buffer and RXDP .

In memory write test mode GDMA is programmed with total transfer count configuration information and a data pattern configuration. Memory test module generates a data pattern as defined by one or more data pattern configuration options set by a user. This data pattern is written to RX Buffer and routed through RXDP until the Total Transfer Count reaches zero. TX Buffer and TXDP are not involved in a memory write test operation. The data pattern is stored to media and optionally checked or validated using memory read test mode.

Memory test data patterns are defined by writing the data pattern configuration options to a register in GDMA . The test pattern is generated according to four data pattern configuration options i a Rotate Left option shifts the pattern left by a single bit for each dataword transferred ii a Rotate Right option shifts the pattern right by a single bit for each dataword transferred iii an Add option adds a predetermined value to the pattern for each dataword transferred and iv an Add byte wise option performs byte wise addition of a predetermined value and the pattern for each dataword transferred. Thus embodiments of the present invention support walking zeros test patterns walking ones test patterns and incrementing test patterns.

In memory read test mode GDMA is programmed with Total Transfer Count configuration information and the data pattern configuration. TXDP is programmed to route data through TX Buffer to GDMA . GDMA then compares the incoming data from TX Buffer with the data pattern configuration. Each dataword is compared and discarded until the Total Transfer Count reaches zero or a difference between received data and the test pattern is detected by memory test module . RX Buffer and RXDP are not used for memory read test operations.

GDMA operates with the same clock as Link Protocol Core and converts the output of TX Buffer into frame structures that are written to RX Buffer . During GDMA operations RXDP is configured to bypass ILT and Tag Manager . Data is sent directly from TX Buffer to RX Buffer and RX Buffer creates a frame format compatible with RXDP . RXDP is configured to bypass the header and frame checks as described below since the header and status fields of each test frame contain dummy data for the memory test modes.

Embodiments of the present invention pass status information along with each frame as it is synchronized between the link protocol and media controller . This frame status information allows media controller to perform checks on data and command frames before the frame is removed from the RX Buffer e.g. at least one of RX Buffers and simplifying handling of command and other frame errors. Embodiments of the present invention provide parallel frame checking and frame data buffering. Status information is extracted from the received frame before the frame is removed from the RX Buffer thus avoiding problems in handling exceptions that might occur with received frames that are moved further along the receive datapath which might result in partially moved frames.

To allow the frame checks to occur before the frame is removed from RX Buffer the data payload portion of the frame is separated from the status information for that frame shown as RX data and RX status . As shown RX frame status module receives RX status . RX status indicates that a frame is received and is available to RXDP before the frame is removed from RX Buffer . RXDP reads all of the status information for that frame. Since some of the status information required to perform the frame checks e.g. the Command Tag Initiator Information are contained in the frame or in other modules of media controller status parser and extractor extracts the status data from the frame and modules of media controller as the frame data is written to RX Buffer . Extracted status data is stored in RX status data module . For SAS since multiple initiators and connections are possible the RX status information includes i frame status e.g. data command header payload or other frame type ii frame link error information iii initiator information iv connection information and v the command tag. For SATA since there is only a single initiator the initiator and connection information is generally not required.

RX status data module might generally include one or more registers for storing RX status data. For example some embodiments might include 32 bit RX Buffer Status registers. When the frame status indicates that the received frame is a header frame the RX status data might include the initiator connection tag ICT a link protocol code an initiator port number and a starting address of the received frame in RX Buffer . When the frame status indicates that the received frame is a payload frame the RX status data might include the frame length and flags that are set to indicate frame errors such as for example CRC alignment parity overflow and other errors. Other flags might indicate that additional frames are included in the corresponding data transfer operation.

RX status validation module might include one or more registers for transferring RX status data to other modules of media controller such as for example RXDMA module tag manager command parser PWT and ILT . For example for a received SAS frame data might be extracted from the received frame that indicates the frame length of the command the protocol transfer rate which is saved with the command and stored in the corresponding context the Pending Write Table ID associated with the data transfer the Initiator Connection Tag ICT the command tag for a data frame and the WWN of the initiator. For example RX status validation module might pass the WWN and ICT to ILT to verify if the received frame was from a known active initiator.

Embodiments of the present invention employing an RX datapath as described herein provide the benefit of verifying a received frame before the frame is removed from the RX Buffer which allows for common handling of any frame exceptions.

Both the SATA and SAS protocols include certain commands that are defined as high priority commands that should be processed as fast as possible. Since high priority commands might be mixed with other normal commands an early indication that a high priority command was received without reordering other commands embodiments of the present invention provide an early indication that a high priority command was received which allows multiple high priority commands to be processed as part of the normal command processing sequence. As will be described herein embodiments of the present invention employ outstanding command FIFO that might be configured to detect and count high priority commands as they are added to the tail end of the FIFO. Upon detecting a high priority command an interrupt might be generated to process the high priority command.

The SATA protocol includes several QUEUED commands that might be handled as high priority commands. For example the NCQ QUEUE MANAGEMENT command a command with the SATA PRIORITY bit set or a command with an execution time limit might all be handled as high priority commands. The SAS protocol includes numerous types of SCSI queue management commands that might be handled as high priority commands.

As described herein SATA first party DMA FPDMA commands that have the PRIORITY bit set and SAS commands that are IMPLICIT HEAD OF QUEUE or have a Task Attribute that is HEAD OF QUEUE are handled as high priority commands. Priority command counter increments when RXDP moves a high priority command to the command queue. Priority command counter might also maintain status bits that indicate whether a command was HEAD OF QUEUE SAS or PRIORITY SATA . For example for SAS RXDP might increment a HEAD OF QUEUE counter maintained in priority command counter when a command is moved from RX Buffer if the command has the SAS Task Attribute field set to HEAD OF QUEUE ORDERED or ACA or if the command is an IMPLICIT HEAD OF QUEUE command. If these conditions are met command parser might set a status bit indicating a SAS priority command. For SATA RXDP might increment the Head of Queue counter maintained in priority command counter when an FPDMA command is moved from RX Buffer if the command has the PRIORITY bit set. If the PRIORITY bit is set command parser might set a status bit indicating a SATA priority command.

In general embodiments of the present invention process SATA and SAS priority commands similarly. For example whenever a new command is added to the command queue processor might check whether priority command counter is greater than zero. If the counter is greater than zero normal priority commands might be saved without creating contexts instead generating contexts for the high priority command.

The SCSI command set supports command re ordering with Task Attributes indicating ORDERED or HEAD OF QUEUE commands. In response to such commands the command queue must be reordered to place the Ordered SCSI commands ahead of other commands in the command queue. An interrupt might be generated when an ORDERED or HEAD OF QUEUE command is received and the number of ORDERED or HEAD OF QUEUE commands are tracked. For example priority command counter might maintain a HEAD OF QUEUE counter that is incremented every time an ORDERED or HEAD OF QUEUE command type is detected. Since the Task Attribute is embedded in the command RXDP might still write the command to the command queue and an interrupt is generated to indicate that a HEAD OF QUEUE command type has been received. After handling the HEAD OF QUEUE command the HEAD OF QUEUE counter is decremented. The HEAD OF QUEUE counter provides support for receiving multiple HEAD OF QUEUE command types before processing the first HEAD OF QUEUE interrupt.

After the HEAD OF QUEUE interrupt is generated and counter is incremented command parser might be frozen and RXDP might step through the commands stored in the command queue to find the HEAD OF QUEUE command. RXDP might move the HEAD OF QUEUE command to command parser for processing without changing the order of other commands in the command queue. Thus embodiments of the present invention employing an outstanding command FIFO provide support for processing high priority commands without changing the order of other commands in the command queue.

As described herein a context is a data structure that provides the information necessary to transmit or receive SAS frames or SATA FIS on the bus. In embodiments of the present invention contexts might be grouped into flow categories. Media controller data transfer performance is generally important for data transfers but other operations might not require high data transfer performance. For example special types of data transfers such as negotiation of bus parameters or error correction might operate at lesser priority levels than data transfers and be subject to higher latency than data transfers. However special types of transfers might require a higher degree of control over the frames that are transmitted. Embodiments of the present invention provide three data paths to generate SATA FIS or SAS frames i Automated Instruction Generation ii Non Automated Instruction Generation and iii Manual Frame Generation.

Approaches to context processing tend to be protocol specific. For example a SATA media controller might generate contexts containing all of the fields for an FIS reducing processing performance by having a context structure specific to the SATA protocol. Similarly a SAS media controller might employ SAS specific context processing hardware which does not easily provide support for non automated frames.

Automated Instruction Generation AIG mode provides a high performance path for data transfers. In AIG mode the context structure defines data block structures that share a highly common structure between SATA and SAS. Context execution hardware implements the transfer protocol e.g. SATA PIO mode SATA DMA mode SATA NCQ mode SAS etc. . Information in one context is employed to transfer a series of one or more frames on communication link in conformance with the appropriate protocol. For AIG mode firmware running on processor breaks up commands based upon the setup frame requirements for the protocol. Processor programs high level information about the transfer such as the protocol the amount of data response requirements at the end of the command etc.

For the data performance path e.g. RXDP and TXDP the majority of context fields are shared between the SATA protocol and the SAS protocol. Thus context data structures might be substantially equivalent for the SAS protocol and the SATA protocol allowing for increased design flexibility. For example typical data stored within a context might include context configuration data pointers to a next context for the data transfer and the buffer location of the data to transfer the total length of the data transfer an offset representing the location of the data transfer if the transfer is not aligned to boundaries of the buffer and the logical block address LBA of the data transfer. Contexts might also include other status data to be passed between processing modules of media controller . In embodiments of the present invention contexts might typically include 12 32 bit datawords. AIG mode will be described in greater detail in regard to .

Non Automated Instruction Generation NAIG mode provides control over the fields in the frames. In this mode context fields might correspond directly to frame fields and further single contexts might correspond one to one with single frames. Thus a context exists for each transferred frame. A non automated instruction thus might cause one FIS or frame to be transmitted. NAIG mode advantageously provides greater control over fields within the frame for example in NAIG mode firmware running on processor might have control over one or more fields within each type of FIS. NAIG mode might be employed for lower performance transfers such as error handling or transfers where more control of protocol fields is required. This allows greater design flexibility in response to changes in protocol specifications for future mode support. A non automated instruction is used for example to send status at the end of a command that failed.

Non automated instruction generation gives firmware running on processor control over most fields in each type of FIS. Non automated instruction generation might be used for example to send status at the end of a command that failed. Contexts are queued with each context generating one FIS.

Manual Frame Generation MFG builds one frame in a buffer and issues a context corresponding to this one frame. Firmware running on processor has full control over generation of the frame. Thus in MFG firmware builds all datawords of a FIS or frame in the buffer. Firmware then creates a buffer context that indicates to send a manual FIS frame and that contains the buffer address for the FIS frame and the length of the FIS frame. This frame is then transmitted from the buffer and onto the bus. MFG generally will not be used but could be employed to provide vendor specific frame s that might not be defined in a standard protocol and further allows for generation of customized test sequences. Thus as described herein embodiments of the present invention provide common context fields that can be applied to multiple frame bus transfers to facilitate fast bus transfers. A high level context structure allows firmware running on processor to generally be independent of protocol details for data block transfers because the majority of contexts are similar between SATA and SAS protocols. A non automated context flow provides control of individual frame fields.

Instruction interface processes protocol commands issuing instructions to link protocol core to transmit FIS SATA protocol or frames SAS protocol and to handshake with a host device in communication with communication link . Contexts provide the information to instruction interface necessary to process protocol commands. Firmware running on processor creates and writes these into linked lists in context buffer . Context Cache loads each context in the linked list and passes the context to instruction interface for execution. Instruction interface is also in communication with RXDP and pending write table . The path from RXDP to instruction interface provides support for SATA FPDMA commands e.g. to transmit a register FIS clearing busy . The path from pending write table is used to transmit a response after write data has been received by media controller . As described in regard to instruction interface for the SAS protocol includes a few additional modules versus instruction interface for the SATA protocol. For example for SAS protocol support additional modules such as PWT and initiator lookup table are in communication with instruction interface . Instruction interface includes a state machine to process frames as necessary to fulfill the protocol requirements. Block based data transfer commands are handed using automated instruction generation.

For example media controller might be in communication with a SATA device and receive a command to transmit 8 blocks of data using the SATA FPDMA NCQ protocol. As will be described with respect to the SATA protocol for this transfer is for the device to transmit a DMA SETUP FIS and then to transmit pairs of DMA Activate and Data FIS until all data has been transmitted at which point a SetDeviceBits FIS is transmitted as a response. In embodiments of the present invention one context is generated to transmit both the data and the response. Details of the transmitted FIS such as entries placed in the DMA Buffer Identifier field of a DMA SETUP FIS are handled by automated hardware.

Once the status FIS is processed instruction interface proceeds to clear context and command tag state as indicated by state transition . At clear context and command tag state instruction interface clears its context and the command tag is cleared from tag manager . After the context and command tag are cleared instruction interface returns to idle state as indicated by state transition .

If the SATA FPDMA request is a read data request instruction interface proceeds from SETUP FIS state to TX data state as indicated by state transition . At TX data state the context for the entire data transfer is processed. After all the data of the read request is transferred as indicated by state transition . Alternatively the command tag might be cleared as indicated by state transition . Once the status FIS is processed instruction interface proceeds to clear context and command tag state as indicated by state transition . At clear context and command tag state instruction interface clears its context and clears the command tag from tag manager . After the command tag is cleared instruction interface returns to idle state as indicated by state transition . Also as indicated by state transition instruction interface might proceed from idle state to clear context and command tag state for example to clear a context for an aborted transfer. As indicated by state transition a status FIS might be sent any time a data transfer or other command completes without error. Thus instruction interface transmits the necessary Setup or Activate FIS transmits one or more data FIS transmits a FIS to indicate good status at the end of a command deletes the command tag at the end of the command and optionally recycles the context pointer after each context has completed.

Embodiments of the present invention provide six automated FIS sequences for the SATA protocol Auto Status DMA data transfer PIO data transfer PIO Multiple Mode FPDMA Queued Commands and FPDMA Queued data transfers. Instruction interface automatically formats and sends an auto status FIS after a read data transfer completes without error. The auto status FIS is a register FIS for PIO and DMA read commands and is a Set Device Bits FIS for FPDMA Queued read or write commands e.g. state . The automated DMA data transfer sequence automatically controls a DMA data transfer including sending the DMA activate FIS e.g. state data transfer FIS e.g. states and and status FIS e.g. state . The context stored in context buffer indicates the data transfer amount and control bits for desired protocol sequence and instruction interface automatically steps through the DMA sequence e.g. DMA Activate for write transfer data FIS repeat until data transfer is complete then send status for read as shown in .

The automated PIO Data Transfer sequence automatically controls PIO data transfers including sending the PIO SETUP FIS the data transfer FIS and the status FIS for a read command. The context stored in context buffer indicates the data transfer amount and control bits for desired protocol sequence. Similarly as described for the automated DMA data transfer shown in instruction interface automatically steps through the PIO sequence PIO SETUP FIS data transfer FIS repeat until transfer is complete status FIS . The automated PIO Multiple Mode automatically combines contexts to transfer multiple blocks in a single FIS. As described with regard to separate contexts might be employed for the PIO SETUP FIS and subsequent data transfer contexts.

After receipt of FPDMA Queued Command the automated FPDMA Queued Command sequence automatically verifies the command FIS and the FIS tag and sends the Register FIS to clear the BUSY bit for that received command. The automated FPDMA Queued Data Transfer sequence automatically controls FPDMA Queued data transfers including sending the DMA SETUP FIS the DMA activate FIS the data transfer FIS and the status FIS. The context stored in context buffer indicates the data transfer amount and control bits for desired protocol sequence. Similarly as described for the automated DMA data transfer shown in instruction interface automatically steps through the FPDMA sequence DMA SETUP FIS DMA Activate FIS transfer data FIS repeat until data transfer is complete status FIS . Individual contexts might be split into one or more smaller contexts to control individual steps in the sequence if necessary. As described with regard to separate contexts might be employed for the DMA Setup Context and one or more smaller data transfer contexts.

Embodiments of the present invention provide automatic generation of SAS protocol frames similarly as described for SATA protocol FIS. Instruction interface might automate read and write sequences such that the context stored in context buffer only needs to indicate the overall length of the data transfer and include appropriate protocol control bits. For example instruction interface might automatically issue a SAS connection frame if a connection is currently not established which provides connection information to link protocol core to verify and establish a connection with a SAS host device via communication link . Instruction interface might also automatically format and send a status frame after a data transfer completes without error. Further read and write transfer frames might also be automatically generated. For example for a read data transfer instruction interface might automatically issue an instruction for multiple data frames and send the status frame once the transfer is complete. Similarly for a write data transfer instruction interface might automatically send the TRANSFER READY frame receive write data frames and send a status frame at the end of the transfer if write caching is enabled . As described herein multiple outstanding write streams are supported by employing Pending Write Table .

SATA compliant media controllers support Native Command Queuing NCQ . NCQ generally allows the media controller to control the order in which received read and write commands are performed. This might reduce the amount of drive head movement to process the received commands resulting in increased performance for workloads that have multiple simultaneous read write requests outstanding. NCQ allows for up to 32 commands to be queued and active at the same time. The SATA protocol uses First Party DMA FPDMA commands for NCQ.

NCQ requires a specific handshaking protocol after an FPDMA command is transmitted by a host. The handshake requires that the device transmit a Device to Host FIS to clear the SATA BUSY bit which releases the bus after the FPDMA command is received. Handshaking to release the bus might create a bottle neck in systems handling multiple queued commands. For example for NCQ the host transmits a Host to Device Register FIS containing an FPDMA write or read command. The SATA busy bit BSY is set to indicate that the drive is busy. After the media controller receives the command with no errors the device releases the bus e.g. communication link by transmitting a Device to Host Register FIS with BSY set to 0. Once the bus is released the host can transmit a new FPDMA command or the media controller can return data for previously queued commands.

Embodiments of the present invention provide that handshaking is handled in hardware which reduces the delay in transmitting the FIS versus handling the handshaking in firmware and also reduces the workload of processor . Specifically RXDP parses the incoming Register FIS to recognize FPDMA commands used for NCQ routes the incoming Register FIS to a command queue interrupts firmware when the command is queued automatically performs context execution and then instruction interface transmits the Register FIS which completes the handshake and releases the bus. By releasing the bus sooner the bus is free for transmission of additional data improving overall system performance and by reducing demand on processor the processor is available to process the current command rather than processing SATA protocol requirements. Finally by removing protocol details from firmware the resulting firmware is similar for both SATA and SAS.

RXDP parses the incoming FIS. If the FIS is a Register FIS containing an FPDMA command a plurality of checks is performed on the FIS. For example link protocol core verifies that the FIS has no Link Layer violations and writes the FIS into a receive buffer e.g. RX buffer . RXDP performs additional checks on the FIS verifying the command verifying the tag and adding the tag to a tag manager e.g. tag manager . As described herein a command tag is a unique ID assigned to commands e.g. SATA NCQ tags range from 0 31 SAS tags have a 16 bit value . Tag manager stores a list of active command tags and checks for tag overlap when new commands are received. RXDP requests that instruction interface transmit the Register FIS to clear busy bit and release the bus. RXDP and instruction interface have an interlock to allow instruction interface to transmit the Register FIS immediately after an FPDMA command is received and the tag is added to the tag manager.

The interlock is set when link protocol core writes the first dataword of an FIS into RX buffer and the interlock is cleared when the last dataword is removed from RX buffer . When the interlock is set instruction interface generally does not load a new context from context cache . If instruction interface already has a context loaded then instruction interface sends the data transfer corresponding to the context to link protocol core for transfer to communication link . Once the data transfer is sent to link protocol core instruction interface transmits the Register FIS. Embodiments of the present invention thus provide support for SATA Native Command Queuing NCQ .

As described herein embodiments of the present invention provide a method of allocating resources of a media controller for a data transfer. A data transfer request is received from at least one host device and includes a host device ID and a data transfer request ID. The media controller generates a Tag ID of the data transfer request based on the host device ID and the data transfer request ID and generates a starting memory address of a tag table based on the Tag ID of the data transfer request. A tag count value is read from the starting memory address of the tag table. If the tag count value reaches a threshold an absence of a tag overlap is determined and the Tag ID of the data transfer request is added to the tag table at the starting memory address.

Reference herein to one embodiment an exemplary embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment can be included in at least one embodiment of the invention. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment nor are separate or alternative embodiments necessarily mutually exclusive of other embodiments. The same applies to the term implementation. 

While the exemplary embodiments of the present invention have been described with respect to processing blocks in a software program including possible implementation as a digital signal processor micro controller or general purpose computer the present invention is not so limited. As would be apparent to one skilled in the art various functions of software might also be implemented as processes of circuits. Such circuits might be employed in for example a single integrated circuit a multi chip module a single card or a multi card circuit pack.

The present invention can be embodied in the form of methods and apparatuses for practicing those methods. The present invention can also be embodied in the form of program code embodied in tangible media such as magnetic recording media optical recording media solid state memory floppy diskettes CD ROMs hard drives or any other non transitory machine readable storage medium wherein when the program code is loaded into and executed by a machine such as a computer the machine becomes an apparatus for practicing the invention. The present invention can also be embodied in the form of program code for example whether stored in a non transitory machine readable storage medium loaded into and or executed by a machine or transmitted over some transmission medium or carrier such as over electrical wiring or cabling through fiber optics or via electromagnetic radiation wherein when the program code is loaded into and executed by a machine such as a computer the machine becomes an apparatus for practicing the invention. When implemented on a general purpose processor the program code segments combine with the processor to provide a unique device that operates analogously to specific logic circuits. The present invention can also be embodied in the form of a bitstream or other sequence of signal values electrically or optically transmitted through a medium stored magnetic field variations in a magnetic recording medium etc. generated using a method and or an apparatus of the present invention.

It should be understood that the steps of the exemplary methods set forth herein are not necessarily required to be performed in the order described and the order of the steps of such methods should be understood to be merely exemplary. Likewise additional steps might be included in such methods and certain steps might be omitted or combined in methods consistent with various embodiments of the present invention.

As used herein in reference to an element and a standard the term compatible means that the element communicates with other elements in a manner wholly or partially specified by the standard and would be recognized by other elements as sufficiently capable of communicating with the other elements in the manner specified by the standard. The compatible element does not need to operate internally in a manner specified by the standard.

Also for purposes of this description the terms couple coupling coupled connect connecting or connected refer to any manner known in the art or later developed in which energy is allowed to be transferred between two or more elements and the interposition of one or more additional elements is contemplated although not required. Conversely the terms directly coupled directly connected etc. imply the absence of such additional elements. Signals and corresponding nodes or ports might be referred to by the same name and are interchangeable for purposes here.

It will be further understood that various changes in the details materials and arrangements of the parts which have been described and illustrated in order to explain the nature of this invention might be made by those skilled in the art without departing from the scope of the invention as expressed in the following claims.

