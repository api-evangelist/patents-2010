---

title: Displaying and updating workspaces in a user interface
abstract: Providing a bridge interface for managing virtual workspaces is disclosed. A plurality of workspace images is presented in a user interface, each workspace image corresponding to a different virtual workspace available to a user of a computer system. A user input indicating a selection of a presented workspace image is received. The user interface is updated to display a plurality of application windows associated with the selected virtual workspace in addition to displaying the plurality of workspace images.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09542202&OS=09542202&RS=09542202
owner: APPLE INC.
number: 09542202
owner_city: Cupertino
owner_country: US
publication_date: 20101019
---
Modern graphical user interfaces allow a large number of graphical objects or items to be displayed on a display screen at the same time. Leading personal computer operating systems such as Apple Mac OS provide user interfaces in which a number of windows can be displayed overlapped resized moved configured and reformatted according to the needs of the user or application. Taskbars menus virtual buttons and other user interface elements provide mechanisms for accessing and activating windows even when they are hidden behind other windows.

As a result most computers today are capable of running a great number of different programs. This can be done by the computer executing software code locally available to the computer or by connecting the computer to a remote application server for example over the internet. Examples of application programs include mainly business related software such as records management programs and meeting organization programs software that is used alternatively for business or personal use such as word processors or email applications and software that is mainly intended for personal use such as online chat or music file management programs.

With the large number of different applications available users are encouraged to work with a multitude of items in their computers. Some categories of items such as files of a certain type can be limited to use by a particular application program while other item categories can be compatible with several programs. Depending on the user s needs he or she can need to use several different programs in a limited period of time as part of a daily work routine or to accomplish a particular goal. As a result users sometimes have several windows open on the computer display at the same time.

However with numerous windows open at once the desktop can become cluttered and difficult to overview. As a result it can be difficult for the user to find a particular application when needed. Further the numerous windows and running applications can be difficult to organize and manage efficiently. For example the user may have difficulty quickly identifying application windows that are associated with each other. In some instances the user may have multiple workspaces each workspace with a different configuration of graphical objects such and application windows. The user may need to quickly move from one workspace to the next while also being able to dynamically make changes to a workspace as needed.

In a first general aspect a method for managing virtual workspaces is disclosed. A plurality of workspace images is presented in a user interface each workspace image corresponding to a different virtual workspace available to a user of a computer system. A user input indicating a selection of a presented workspace image is received. The user interface is updated to display a plurality of application windows associated with the selected virtual workspace in addition to displaying the plurality of workspace images.

Implementations can include any or all of the following features. The method can further include detecting that the user has performed a predetermined gesture via a multi touch input device and changing an active virtual workspace designation from a current virtual workspace to a different virtual workspace associated with another of the workspace images presented in the user interface. The predetermined gesture can comprise a swipe by the user on the multi touch input device. The different virtual workspace corresponds to a workspace image that is visually adjacent to the workspace image associated with the current virtual workspace. The predetermined gesture can comprise a swipe by the user on the multi touch input device and a swipe in a direction from right to left can result in a change to a virtual workspace associated with a workspace image that is visually to the left of the workspace image associated with the current virtual workspace. Alternatively the swipe in a direction from left to right can result in a change to a virtual workspace associated with a workspace image that is visually to the right of the workspace image associated with the current virtual workspace. The displayed application windows can be visually grouped into one or more clusters each cluster corresponding to one or more application windows sharing a common characteristic.

In a second general aspect a computer program product is tangibly embodied in a computer readable storage medium and includes instructions that when executed generate on a display device a graphical user interface for presenting virtual workspaces and perform the following operations. A plurality of workspace images is presented in a user interface each workspace image corresponding to a different virtual workspace available to a user of a computer system. A user input indicating a selection of a presented workspace image is received. The user interface is updated to display a plurality of application windows associated with the selected virtual workspace in addition to displaying the plurality of workspace images.

Implementations can include any or all of the following features. The instructions can further include detecting that the user has performed a predetermined gesture via a multi touch input device and changing an active virtual workspace designation from a current virtual workspace to a different virtual workspace associated with another of the workspace images presented in the user interface. The predetermined gesture can comprise a swipe by the user on the multi touch input device. The different virtual workspace corresponds to a workspace image that is visually adjacent to the workspace image associated with the current virtual workspace. The predetermined gesture can comprise a swipe by the user on the multi touch input device and a swipe in a direction from right to left can result in a change to a virtual workspace associated with a workspace image that is visually to the left of the workspace image associated with the current virtual workspace. Alternatively the swipe in a direction from left to right can result in a change to a virtual workspace associated with a workspace image that is visually to the right of the workspace image associated with the current virtual workspace. The displayed application windows can be visually grouped into one or more clusters each cluster corresponding to one or more application windows sharing a common characteristic.

The details of one or more implementations of managing items in a user interface are set forth in the accompanying drawings and the description below. Other features aspects and advantages will become apparent from the description the drawings and the claims.

Computing systems such as personal computers handheld devices smart phones gaming devices portable computers and so on typically include hardware components such as a processing unit e.g. one or more processors memory and various input and output devices e.g. a display a keyboard a mouse a touch sensitive surface . An software operating system O S can be installed on the computing system and executed by the processing unit to control the operations of the computing system.

Many operating systems and software applications employ graphical user interfaces GUIs to present information to users and to receive user input for controlling the behavior and functionality of the underlying computing devices and or application programs. A typical two dimensional GUI of an operating system can be described as a desktop metaphor.

Visually a desktop of an operating system can provide a background e.g. a desktop plane on which other graphical objects such as icons representing connected peripheral devices e.g. disk drives network devices printers etc. installed programs stored documents open windows of executing application programs file system folders and so on can be presented. In addition user interface elements that allow user interaction with some aspects of the operating system can be presented at various locations on the desktop as well. For example a three dimensional menu bar showing basic controls of the desktop environment a system tray showing programs executing in the background a docking station for shortcuts to frequently used application programs and so on can also be presented on the desktop plane.

An operating system of a computing device can often support a large number of active applications at the same time and each of the active applications can have multiple open windows concurrently presented on the desktop plane. The user can switch among the active applications and the open windows by selecting e.g. clicking on the window he she wishes to access. Upon user selection the selected open window can obtain input focus and becomes the current active window or top window of the desktop. The user can interact with the current active window in a manner dictated by the application program providing the active window.

The windows icons application components taskbars and other graphical items currently displayed on the desktop are in some instances components that a user has recently used or plans to use. When the number of application windows and graphical objects displayed on a desktop increases the user may prefer to associate certain application windows with each other. For example a user may prefer to group together application windows that are related to the same task or application windows that have been or will be used within the same time frame.

In some implementations the graphical objects can be grouped together into one or more virtual workspaces or spaces. As used herein a space is a grouping of one or more applications or windows in relation to other applications or windows such that the program s application s of a single space is visible when the space is active and so that a view can be generated of all spaces and their contents. Each space can depict a different desktop arrangement including application windows desktop images icons or other graphical objects that are displayed only when the associated space is active. A user can focus a view of the windows in a particular selected space such that the windows are enlarged or brought forward in the GUI with respect to windows in unselected spaces. An application program can have more than one window in a space or an application can have windows in more than one space to name a few examples.

A bridge interface of the GUI can present an overview of the spaces currently available to the user to allow the user to efficiently manage the different spaces. As used herein a bridge view or bridge interface can be a display in a user interface of multiple virtual workspaces displayed concurrently with at least some of the application windows associated with one of the virtual workspaces. Thumbnail images can be displayed to represent each space providing a miniature representation of each space as the space would look if activated. In some implementations each thumbnail image is a live depiction of the status of application windows associated with the space represented by the thumbnail image. The user can navigate and select the thumbnails to activate a particular space using different user inputs. In the bridge interface an activated space includes presentation of application windows associated with the space in an organized format allowing the user to quickly identify and access application windows sharing a common characteristic.

Toolbars provided by applications or the operating system can be shown on a display of a computer. In some implementations the toolbar is hidden from view during display of the bridge view . The toolbar can include items such as menus icons and informative objects. Some menus can be general and not specific to a particular application such as a file menu. Other menus can be application dependent such as a terminal menu in which case they can be added to or removed from the toolbar depending on whether a corresponding application window is active. In general an active application window refers to a program window that is designated as the primary recipient of user input for input devices such as a keyboard touchpad or touch screen. The user or a component such as the operating system can cause a different program window to be designated as the active program window within a given space. Icons can be used to present information to the user such as status information and or can be used to access functions via for instance popup menus or commands for opening another application window. The display can also include a docking element which provides an area where commonly used or preferred applications can be easily accessed through selection of icons included in the docking element each icon associated with a different application.

A computer display with multiple spaces is shown including a first space a second space and a third space . In the illustrated bridge view the spaces are arranged in a row near the top of the display with each space showing portions of a larger desktop which may be zoomed for instance to show more detail. In some implementations the row of spaces can be arranged in different formats and different locations on the screen. For example the spaces in row can be separated into different groups based on whether the space is a system space such as dashboard or a user defined space. System spaces can be displayed together in row while user defined spaces can be displayed adjacent the system spaces for example. Each of the spaces is represented in the bridge view by a condensed representation of the application windows open within that space. In the illustrated example space is represented in the row of spaces by a visual workspace image or thumbnail image comprising a miniaturized depiction of the application windows opened within space . In zoom mode a single space can be active and presented with a larger size with the application windows contained in the other spaces being hidden or only partially visible. An active space is a selected space having its components readily available and visible for access by a user. While a particular space is active the visual components associated with other spaces may be hidden from view. The spaces represent a desktop surface larger than what can be shown on display at once. Thus application windows are depicted in reduced size to be able to show all or most of the active windows in the space.

In certain implementations a space can be dedicated to a particular application or arrangement of applications. For example as depicted in a space can function as a dashboard of commonly used applications such as a weather report clock calculator or other applications designated as dashboard applications. Spaces can also be dedicated for other uses such as a calendar or planner as represented by space .

Each space can also be associated with a particular image such as a desktop wallpaper . A desktop wallpaper functions as an image displayed in the background of a desktop interface. Accordingly in addition to being associated with a group of open application windows each space can be associated with certain display settings such as a particular desktop image to be displayed in the background when the space is activated. In this instance each space functions as its own desktop and a user can personalize each space by determining the background image the application windows used or other settings for a particular space according to the user s preferences.

One or more application windows can be arranged in multiple ways within a space. Application windows can be positioned such that they fully or partially overlap one another. They can be resized or moved around in spaces to accommodate the user. Particularly while many windows can be open at once and distributed among the spaces in some implementations only the application window s in a particular space will be visible when that space is active. In some instances programs or windows from another space that is not currently activated can be visible. For instance in the bridge view depicted in all available spaces can be shown in an organized arrangement such as the row of spaces . In other instances a small representation of another space can be visible on the display apart from the bridge view to achieve a picture in picture effect. In some cases an application or window can briefly appear even if its space is not being displayed for example some events such as finishing a task can cause a program window to appear for a limited time or until a user dismisses the window.

When a space is activated the application windows of the activated space are restored to their original positions before entering the bridge view . The display can exit the bridge view in some implementations and present only the contents of the activated space. The background image associated with the space is displayed as the desktop wallpaper. When the bridge view is displayed the application windows for a space are grouped or clustered together in available areas of the screen. In certain instances each grouping of windows includes all application windows or application instances associated with a particular application for a particular desktop. Further each grouping of windows can be described as a cluster of application windows. The grouping of windows can also be based on other shared characteristics such as windows that are associated with different applications but are similar in functionality. For example several web browser windows may be open in a particular space. If the space is activated the windows within the space are enlarged as if they are pulled into the forefront of the display. Each of the web browser windows in the space can be grouped together in a certain region of the screen forming a cluster of web browser windows. Each cluster of windows can be associated with an icon indicating the particular application associated with the windows in a certain cluster of windows. Accordingly a user can identify based on the icon displayed in the region of a particular cluster of windows the types of windows found in the cluster. Still further a user can optionally select application windows to group together as a cluster regardless of whether the application windows share a common characteristic or are associated with the same application.

In the illustrated example space is currently selected. As seen in each grouping of application windows associated with space is depicted in the selected desktop for space . Further each grouping of application windows can include open application windows for a particular application or that share a common characteristic. For example application windows associated with a web browser can be grouped together in one cluster and an icon can be displayed in the vicinity of the cluster to allow a user to quickly determine that the application windows in cluster are associated with a web browser application. A separate icon associated with the web browser application can also be depicted in a docking element for easy opening of additional windows of the web browser application. Similarly each cluster in space such as clusters and is associated with a different application. In some implementations the clusters are displayed such that no window of any cluster overlaps with any other window of a different cluster. As depicted in each of the clusters is a grouping of application windows associated with particular applications that a user can select from a docking element . The docking element includes icons for each application available to a user. In some implementations the dock is displayed in the user interface regardless of the space that is currently active allowing a user to navigate the dock without losing the selected space.

Each cluster of windows can contain windows that have been reduced in size to group the windows associated with the same application together in the same region of the GUI. In certain implementations the application windows across all clusters are reduced in size by the same scale factor to maintain the relative proportionality of the spaces. If a particular cluster has been activated or if a specific window within the cluster is selected the window s can be expanded to a larger size. If multiple windows are grouped in a cluster they can be arranged in a particular order such as in a cascading or overlapping arrangement. In some implementations an ordering algorithm can be used to determine a particular order for the arrangement of windows in a cluster. For example the ordering algorithm can use various heuristics settings user preferences or other parameters to determine an order to arrange the windows in a cluster. The parameters used by the ordering algorithm can include for example the dimensions associated with each window the type of window how recent a window was accessed relative to other windows in the cluster how recognizable a part of the window is empirical data related to a user s preferences and other factors used to determine an appropriate arrangement of the windows in a cluster. Further within each cluster the windows can be arranged such that windows with the highest priority are displayed with the most exposed areas compared to windows of lower priority. The priority of each window can depend on various factors such as how recently the window was accessed by the user for example. For example in a cluster of multiple application windows a particular window that a user most recently interacted with e.g. clicked on may be designated as the active window in the cluster. In some implementations windows in a cluster are grouped together in an area of the GUI and not necessarily stacked or overlapping. The clusters of windows can be grouped in a particular area based at least in part on where the windows were located in the GUI before the windows were clustered.

The bridge view shown in allows the user to see the available spaces and choose which space to use. In some implementations a user can transition into or out of the bridge view through a particular user input such as a keyboard input a particular gesture on a touchpad a selection using an input device such as a mouse or any other appropriate user input. When in the bridge view mode applications can continue to run and program windows can be displayed in a normal fashion for example on a smaller scale. Program windows can continue to update for example displaying animations refreshing their contents etc. The continuous updating of application windows can be shown in both the thumbnail images in row and the clusters of windows in the bridge view . In a sense the bridge view mode provides a visual overview of all spaces and the applications and visual settings within each space to a user. Users can navigate between spaces with appropriate user input such as by mouse keyboard hot keys key combinations gestures or other mechanisms. Other devices can also be used for input such as those for providing alternate input capability for physically handicapped users. It can be possible for the user to zoom in on a subset of spaces. In one implementation the system can automatically switch from one space to another based on a predefined event such as when a specific application is launched or an application makes a particular output.

In the illustrated example a user can drag and drop a space from one location and insert the space into a different area such as between different surrounding spaces. In certain implementations however some spaces are moveable and some are fixed. For example a particular desktop such as space can be designated as a default space and remains fixed in the row of thumbnails . As seen in space can be extracted from an original position between spaces and and inserted further to the right between spaces and . As a user navigates the row of spaces a pointer or other indicator of input sliding over a particular space thumbnail can trigger an animation that temporarily enlarges the space thumbnail to allow a user to view the contents of the space in greater detail while the surrounding spaces shrink in size to accommodate the temporary enlargement. If the space is moved to a new position already occupied by another space the other space can be automatically relocated to make room for the moved space. Also the relocated space or one or more other spaces can be adjusted to fill the vacated space position. In some implementations the animation of rearranging space can include a depiction of space being pulled from its original location by a cursor controlled by a user following the cursor as the cursor moves to a different area of the screen and detaching from the cursor onto a region of the screen after the user has entered an input such as releasing a button on an input device. Here space is moved between spaces and and space shifts to the left to assume space s original position in the row . A user can also specify a preferred way to handle space movements.

Other operations can be performed on a space such as for example renaming a particular space or selecting a new wallpaper for a space.

The user can select a different space such as space for activation using an appropriate input. In some instances a user can select space for activation by clicking on the image representing space in the row of thumbnails using a cursor or finger on a touchscreen entering a particular input on a keyboard or using a particular gesture with the user s fingers on a multi touch input device. The particular gesture can include a swipe of the user s fingers across the multi touch input device for example. The user s selection of space for activation causes a deactivation of space before activation of the workspace associated with space . The transition can be illustrated using any appropriate animation. For example as illustrated in the transition can be depicted as a sliding of workspaces across the screen. The animation can include sliding the workspace being deactivated off the screen to the left as the newly activated workspace including the desktop wallpaper and cluster of applications associated with selected space slides onto the screen from the right. The direction of the sliding workspaces can correspond to the relative positions of the spaces in the row of thumbnails . In the present example the newly activated space is located to the right of the previous space so the sliding motion of the workspaces and is from right to left.

The switch from one space to an adjacent space can be accomplished using different gestures on a multi touch input device. In some implementations a user can perform a swiping gesture on a multi touch input device in a direction from right to left in order to switch a currently active space to a space represented by a thumbnail image to the right of the thumbnail representing the currently active space. Alternatively a user can perform the swiping gesture from left to right in order to switch a currently active space to a space represented by a thumbnail image to the left of the thumbnail representing the currently active space.

Further as seen in the newly activated space is represented by a thumbnail that is adjacent to the previous space . Accordingly the animation includes transitioning from one workspace directly to another workspace . In certain implementations a sliding animation can also be used for transitioning between two spaces that are not adjacent to each other in the row of thumbnails such as transitioning directly from space to space for example. In this instance some detail from the desktops of spaces between the two spaces can be included in the animation to depict the spatial relationship between spaces and from one active space to another active space. Accordingly a transition from space to space in the illustrated example can include an animation showing details from space sliding across the entire screen between the animations of space sliding off the screen and space sliding onto the screen.

The user can signal his or her intentions to transfer an application window using a menu icon popup menu gesture hot key or key combinations to name some examples. The application window to be moved can be selected in some implementations via mouse clicks or gestures combinations of button presses such as tabs or arrows or combinations thereof. Various methods of moving the application windows can be used such as by using a mouse to drag the application window from the originating space and drop it into the destination space or using keyboard commands to reposition the application window into the destination space.

As illustrated in each of the application windows and can be grouped together in close proximity to each other. The application windows that are grouped together can be currently open windows in the respective spaces or windows representing recently closed windows and displaying an image of the last known appearance of the closed window. In some instances the application windows are visually presented as a stack of overlapping windows each of the overlapping windows having different associated z depths while in other instances the application windows are in close proximity but not overlapping. The particular arrangement of application windows in a cluster can be based on various factors such as user preferences common practices across a community of users visibility of the different windows or other potential factors. In the application windows and are visually presented as a stack of overlapping windows in a cluster. In some implementations each of the application window center points can be aligned.

The application windows in can also be displayed with a visual indicator of the common characteristic shared among the application windows in the cluster . The visual indicator is in some instances an icon depicting a visual representation of the common characteristic associated with the cluster . For example if the common characteristic of the application windows in the cluster is that the application windows are all instances of a specific web browser application the standard icon typically used to represent the web browser application can be used as the common characteristic indicator here. If the common characteristic of the application windows is a common functionality such as application windows associated with performing photo editing an icon of a camera for example can be used to denote that the application windows in the cluster are related to photo editing.

A user can perform one or more actions to expand the cluster of application windows so that the application windows are more visible to the user. In certain implementations the user can click on the indicator using a pointer associated with an input device to expand the application windows in the cluster as depicted in . After the user performs the action for expanding the cluster the application windows and can be visually shifted in a radial direction away from a center point where the centers of the application windows were formerly aligned so that the user can view the contents of the application windows. Further the dimensions of some or all of the application windows can be increased as the application windows are moved away from the cluster . In some instances the application windows of a cluster that has been expanded can cover up application windows in other clusters that have not been expanded. Further application windows in other clusters can further be de emphasized by being shifted toward the edges of the GUI or darkened relative to the cluster currently being expanded.

In some implementations the application windows are expanded from the center point of the cluster in a single step such that the application windows transition from their overlapping positions as seen in to their respective separated positions in . The application windows of a cluster can be displayed in expanded mode such that no window of the cluster overlaps with any other window of the cluster as seen in . In some instances the dimensions of the application windows can be reduced to achieve display of the application windows in such a non overlapping manner.

The application windows can also shift away from the center of the cluster in increments such that at each increment more of each application window is visible to the user as seen in . In certain implementations a user can enter successive iterations of input to effect a spreading apart of the application windows in the cluster in increments the application windows spreading in a radial direction gradually at each increment. In some instances the user may not want to spread the application windows completely apart and may only want to obtain a glimpse of the contents of the application windows in a cluster as depicted in . The user can enter an appropriate input such hovering a cursor over the cluster or entering slight gestures or movements around the cluster to effectively cause the application windows to move slightly apart from each other giving the impression that the cluster of application windows was nudged by the user. In some implementations a user can also identify a specific application window from a cluster of windows to be displayed in full in the GUI. For example a user can click directly on a titlebar of the application window to separate the window from the cluster to allow the user to view the complete window.

Different types of user inputs can be used to effect the visual manipulation of application windows in a cluster . User inputs associated with a cursor such as drag and drop operations can be used to effect visual movement of the application windows. In another example a user can also gradually spread apart the application windows by hovering a cursor associated with a mouse or touchpad or a finger in connection with a multi touch input device over the clustered application windows. A user can also spread apart application windows using a scrolling motion with the user s fingers for example. The spreading apart of the windows can be based on the speed or repetition of the user s scrolling. For example an upward scrolling motion using the fingers can trigger the spreading apart of application windows in a cluster while a downward scrolling motion can trigger collapsing of the application windows in the cluster. Further on a multi touch input device or touch screen a user can use two fingers in contact with the input device to simulate a spreading motion using the tips of the user s fingers for example. As the user s fingers move away from each other from a central position with the fingers in close proximity to one another to an expanded position the application windows in the cluster spread apart in proportion to the relative distance between the fingers.

A new desktop space can also be configured upon creation without the configuration tool . For example if a particular application window is already open in a different space a user can access the application window and explicitly tag the window for insertion into the newly created space . The user can also drag and drop the application window onto the thumbnail image representing the new space to include the window in the new space .

The virtual workspace can be conceptualized using a desktop metaphor and accordingly the virtual workspace is a desktop space or simply a space. A user input is received indicating a selection of a presented workspace image . The user can select a particular workspace image to activate the space represented by the image. In some implementations a plurality of workspace images are presented to the user allowing the user to navigate the images and select a particular image to access the contents of a space associated with the image. The user input for selecting a particular space can include for example using a cursor to click on the workspace image associated with the particular space a keyboard input or predefined gestures using a multi touch input device.

After selection of a workspace image application windows associated with the selected workspace are grouped into clusters based on a shared common characteristic of the application windows in each cluster . The shared common characteristic of application windows in a cluster can be a same application associated with the windows in the cluster. In some instances application windows that are instances of different applications but share a common functionality can be grouped together as a particular cluster.

The user interface is updated to display application windows associated with the selected workspace as visually grouped clusters . Each cluster of application windows can be visually depicted such that a user can efficiently differentiate application windows associated with different shared characteristic. For example the application windows in each cluster can be visually depicted within close proximity of one another and separate from application windows of other clusters.

Services layer can provide various graphics animations and UI services to support the graphical functions of the bridge view UI modification engine and applications in applications layer . In some implementations services layer can also include a touch model for interpreting and mapping raw touch data from a touch sensitive device to touch events e.g. gestures rotations which can be accessed by applications using call conventions defined in a touch model API. Services layer can also include communications software stacks for wireless communications.

OS layer can be a complete operating system e.g. MAC OS or a kernel e.g. UNIX kernel . Hardware layer includes hardware necessary to perform the tasks described in reference to including but not limited to processors or processing cores including application and communication baseband processors dedicated signal image processors ASICs graphics processors e.g. GNUs memory and storage devices communication ports and devices peripherals etc.

One or more Application Programming Interfaces APIs may be used in some implementations. An API is an interface implemented by a program code component or hardware component hereinafter API implementing component that allows a different program code component or hardware component hereinafter API calling component to access and use one or more functions methods procedures data structures classes and or other services provided by the API implementing component. An API can define one or more parameters that are passed between the API calling component and the API implementing component.

An API allows a developer of an API calling component which may be a third party developer to leverage specified features provided by an API implementing component. There may be one API calling component or there may be more than one such component. An API can be a source code interface that a computer system or program library provides in order to support requests for services from an application. An operating system OS can have multiple APIs to allow applications running on the OS to call one or more of those APIs and a service such as a program library can have multiple APIs to allow an application that uses the service to call one or more of those APIs. An API can be specified in terms of a programming language that can be interpreted or compiled when an application is built.

In some implementations the API implementing component may provide more than one API each providing a different view of or with different aspects that access different aspects of the functionality implemented by the API implementing component. For example one API of an API implementing component can provide a first set of functions and can be exposed to third party developers and another API of the API implementing component can be hidden not exposed and provide a subset of the first set of functions and also provide another set of functions such as testing or debugging functions which are not in the first set of functions. In other implementations the API implementing component may itself call one or more other components via an underlying API and thus be both an API calling component and an API implementing component.

An API defines the language and parameters that API calling components use when accessing and using specified features of the API implementing component. For example an API calling component accesses the specified features of the API implementing component through one or more API calls or invocations embodied for example by function or method calls exposed by the API and passes data and control information using parameters via the API calls or invocations. The API implementing component may return a value through the API in response to an API call from an API calling component. While the API defines the syntax and result of an API call e.g. how to invoke the API call and what the API call does the API may not reveal how the API call accomplishes the function specified by the API call. Various API calls are transferred via the one or more application programming interfaces between the calling API calling component and an API implementing component. Transferring the API calls may include issuing initiating invoking calling receiving returning or responding to the function calls or messages in other words transferring can describe actions by either of the API calling component or the API implementing component. The function calls or other invocations of the API may send or receive one or more parameters through a parameter list or other structure. A parameter can be a constant key data structure object object class variable data type pointer array list or a pointer to a function or method or another way to reference a data or other item to be passed via the API.

Furthermore data types or classes may be provided by the API and implemented by the API implementing component. Thus the API calling component may declare variables use pointers to use or instantiate constant values of such types or classes by using definitions provided in the API.

Generally an API can be used to access a service or data provided by the API implementing component or to initiate performance of an operation or computation provided by the API implementing component. By way of example the API implementing component and the API calling component may each be any one of an operating system a library a device driver an API an application program or other module it should be understood that the API implementing component and the API calling component may be the same or different type of module from each other . API implementing components may in some cases be embodied at least in part in firmware microcode or other hardware logic. In some implementations an API may allow a client program to use the services provided by a Software Development Kit SDK library. In other implementations an application or other client program may use an API provided by an Application Framework. In these implementations the application or client program may incorporate calls to functions or methods provided by the SDK and provided by the API or use data types or objects defined in the SDK and provided by the API. An Application Framework may in these implementations provide a main event loop for a program that responds to various events defined by the Framework. The API allows the application to specify the events and the responses to the events using the Application Framework. In some implementations an API call can report to an application the capabilities or state of a hardware device including those related to aspects such as input capabilities and state output capabilities and state processing capability power state storage capacity and state communications capability etc. and the API may be implemented in part by firmware microcode or other low level logic that executes in part on the hardware component.

The API calling component may be a local component i.e. on the same data processing system as the API implementing component or a remote component i.e. on a different data processing system from the API implementing component that communicates with the API implementing component through the API over a network. It should be understood that an API implementing component may also act as an API calling component i.e. it may make API calls to an API exposed by a different API implementing component and an API calling component may also act as an API implementing component by implementing an API that is exposed to a different API calling component.

The API may allow multiple API calling components written in different programming languages to communicate with the API implementing component thus the API may include features for translating calls and returns between the API implementing component and the API calling component however the API may be implemented in terms of a specific programming language. An API calling component can in one embedment call APIs from different providers such as a set of APIs from an OS provider and another set of APIs from a plug in provider and another set of APIs from another provider e.g. the provider of a software library or creator of the another set of APIs.

It will be appreciated that the API implementing component may include additional functions methods classes data structures and or other features that are not specified through the API and are not available to the API calling component . It should be understood that the API calling component may be on the same system as the API implementing component or may be located remotely and accesses the API implementing component using the API over a network. While illustrates a single API calling component interacting with the API it should be understood that other API calling components which may be written in different languages or the same language than the API calling component may use the API .

The API implementing component the API and the API calling component may be stored in a machine readable medium which includes any mechanism for storing information in a form readable by a machine e.g. a computer or other data processing system . For example a machine readable medium includes magnetic disks optical disks random access memory read only memory flash memory devices etc.

In Software Stack an exemplary implementation applications can make calls to Service A or Service B using several Service APIs Service API A and Service API B and to Operating System OS using several OS APIs. Service A and service B can make calls to OS using several OS APIs.

Note that the Service B has two APIs one of which Service B API A receives calls from and returns values to Application A and the other Service B API B receives calls from and returns values to Application B . Service A which can be for example a software library makes calls to and receives returned values from OS API A and Service B which can be for example a software library makes calls to and receives returned values from both OS API A and OS API B . Application B makes calls to and receives returned values from OS API B .

Sensors devices and subsystems can be coupled to peripherals interface to facilitate multiple functionalities. For example motion sensor light sensor and proximity sensor can be coupled to peripherals interface to facilitate orientation lighting and proximity functions of the mobile device. Location processor e.g. GPS receiver can be connected to peripherals interface to provide geopositioning. Electronic magnetometer e.g. an integrated circuit chip can also be connected to peripherals interface to provide data that can be used to determine the direction of magnetic North. Thus electronic magnetometer can be used as an electronic compass. Accelerometer can also be connected to peripherals interface to provide data that can be used to determine change of speed and direction of movement of the mobile device.

Camera subsystem and an optical sensor e.g. a charged coupled device CCD or a complementary metal oxide semiconductor CMOS optical sensor can be utilized to facilitate camera functions such as recording photographs and video clips.

Communication functions can be facilitated through one or more wireless communication subsystems which can include radio frequency receivers and transmitters and or optical e.g. infrared receivers and transmitters. The specific design and implementation of the communication subsystem can depend on the communication network s over which a mobile device is intended to operate. For example a mobile device can include communication subsystems designed to operate over a GSM network a GPRS network an EDGE network a Wi Fi or WiMax network and a Bluetooth network. In particular the wireless communication subsystems can include hosting protocols such that the mobile device can be configured as a base station for other wireless devices.

Audio subsystem can be coupled to a speaker and a microphone to facilitate voice enabled functions such as voice recognition voice replication digital recording and telephony functions.

I O subsystem can include touch screen controller and or other input controller s . Touch screen controller can be coupled to a touch screen or pad. Touch screen and touch screen controller can for example detect contact and movement or break thereof using any of a plurality of touch sensitivity technologies including but not limited to capacitive resistive infrared and surface acoustic wave technologies as well as other proximity sensor arrays or other elements for determining one or more points of contact with touch screen .

Other input controller s can be coupled to other input control devices such as one or more buttons rocker switches thumb wheel infrared port USB port and or a pointer device such as a stylus. The one or more buttons not shown can include an up down button for volume control of speaker and or microphone .

In one implementation a pressing of the button for a first duration may disengage a lock of the touch screen and a pressing of the button for a second duration that is longer than the first duration may turn power to the device on or off. The user may be able to customize a functionality of one or more of the buttons. The touch screen can for example also be used to implement virtual or soft buttons and or a keyboard.

In some implementations the device can present recorded audio and or video files such as MP3 AAC and MPEG files. In some implementations the device can include the functionality of an MP3 player such as an iPod . The device may therefore include a pin connector that is compatible with the iPod. Other input output and control devices can also be used.

Memory interface can be coupled to memory . Memory can include high speed random access memory and or non volatile memory such as one or more magnetic disk storage devices one or more optical storage devices and or flash memory e.g. NAND NOR . Memory can store operating system such as Darwin RTXC LINUX UNIX OS X WINDOWS or an embedded operating system such as VxWorks. Operating system may include instructions for handling basic system services and for performing hardware dependent tasks. In some implementations operating system can include a kernel e.g. UNIX kernel .

Memory may also store communication instructions to facilitate communicating with one or more additional devices one or more computers and or one or more servers. Memory may include graphical user interface instructions to facilitate graphic user interface processing sensor processing instructions to facilitate sensor related processing and functions phone instructions to facilitate phone related processes and functions electronic messaging instructions to facilitate electronic messaging related processes and functions web browsing instructions to facilitate web browsing related processes and functions media processing instructions to facilitate media processing related processes and functions GPS Navigation instructions to facilitate GPS and navigation related processes and instructions and camera instructions to facilitate camera related processes and functions. The memory may also store other software instructions not shown such as security instructions web video instructions to facilitate web video related processes and functions and or web shopping instructions to facilitate web shopping related processes and functions. In some implementations the media processing instructions are divided into audio processing instructions and video processing instructions to facilitate audio processing related processes and functions and video processing related processes and functions respectively. An activation record and International Mobile Equipment Identity IMEI or similar hardware identifier can also be stored in memory . Memory can also include other instructions .

Each of the above identified instructions and applications can correspond to a set of instructions for performing one or more functions described above. These instructions need not be implemented as separate software programs procedures or modules. Memory can include additional instructions or fewer instructions. Furthermore various functions of the mobile device may be implemented in hardware and or in software including in one or more signal processing and or application specific integrated circuits.

The features described can be implemented in digital electronic circuitry or in computer hardware firmware software or in combinations of them. The features can be implemented in a computer program product tangibly embodied in an information carrier e.g. in a machine readable storage device for execution by a programmable processor and method steps can be performed by a programmable processor executing a program of instructions to perform functions of the described implementations by operating on input data and generating output.

The described features can be implemented advantageously in one or more computer programs that are executable on a programmable system including at least one programmable processor coupled to receive data and instructions from and to transmit data and instructions to a data storage system at least one input device and at least one output device. A computer program is a set of instructions that can be used directly or indirectly in a computer to perform a certain activity or bring about a certain result. A computer program can be written in any form of programming language e.g. Objective C Java including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment.

Suitable processors for the execution of a program of instructions include by way of example both general and special purpose microprocessors and the sole processor or one of multiple processors or cores of any kind of computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for executing instructions and one or more memories for storing instructions and data. Generally a computer will also include or be operatively coupled to communicate with one or more mass storage devices for storing data files such devices include magnetic disks such as internal hard disks and removable disks magneto optical disks and optical disks. Storage devices suitable for tangibly embodying computer program instructions and data include all forms of non volatile memory including by way of example semiconductor memory devices such as EPROM EEPROM and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in ASICs application specific integrated circuits .

To provide for interaction with a user the features can be implemented on a computer having a display device such as a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard a mouse or a trackball or a pointing device e.g. a finger or stylus on a touch sensitive surface or touch sensitive display by which the user can provide input to the computer.

The features can be implemented in a computer system that includes a back end component such as a data server or that includes a middleware component such as an application server or an Internet server or that includes a front end component such as a client computer having a graphical user interface or an Internet browser or any combination of them. The components of the system can be connected by any form or medium of digital data communication such as a communication network. Examples of communication networks include e.g. a LAN a WAN and the computers and networks forming the Internet.

The computer system can include clients and servers. A client and server are generally remote from each other and typically interact through a network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

One or more features or steps as disclosed herein can be implemented using an API. An API can define on or more parameters that are passed between a calling application and other software code e.g. an operating system library routine function that provides a service that provides data or that performs an operation or a computation.

The API can be implemented as one or more calls in program code that send or receive one or more parameters through a parameter list or other structure based on a call convention defined in an API specification document. A parameter can be a constant a key a data structure an object an object class a variable a data type a pointer an array a list or another call. API calls and parameters can be implemented in any programming language. The programming language can define the vocabulary and calling convention that a programmer will employ to access functions supporting the API.

In some implementations an API call can report to an application the capabilities of a device running the application such as input capability output capability processing capability power capability communications capability etc.

A number of implementations have been described. Nevertheless it will be understood that various modifications may be made. For example elements of one or more implementations may be combined deleted modified or supplemented to form further implementations. As yet another example the logic flows depicted in the figures do not require the particular order shown or sequential order to achieve desirable results. In addition other steps may be provided or steps may be eliminated from the described flows and other components may be added to or removed from the described systems. Accordingly other implementations are within the scope of the following claims.

