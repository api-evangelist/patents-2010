---

title: Dynamic reallocation of physical memory responsive to virtual machine events
abstract: Described are methods and systems for dynamically reallocating memory amongst virtual machines executing within a virtualization environment. A computer can execute a virtualization environment that can include one or more virtual machines and that can include a memory manager. The memory manager can dynamically reallocate memory by identifying a maximum and minimum memory value for each virtual machine, determining a target memory value for each virtual machine using the maximum and minimum memory value, and identifying one or more virtual machines that have an actual memory usage value that is less than the target memory value calculated for those virtual machines. To re-allocate the memory, the memory manager can allocate additional memory to the identified virtual machines by inflating a balloon driver, then de-allocate the additional memory, and reallocate the de-allocated, additional memory to other virtual machines within the virtualization environment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08667207&OS=08667207&RS=08667207
owner: Citrix Systems, Inc.
number: 08667207
owner_city: Fort Lauderdale
owner_country: US
publication_date: 20100930
---
This U.S. patent application claims priority to U.S. Provisional Patent Application Ser. No. 61 247 555 filed on Sep. 30 2009 the disclosure of which is considered part of the disclosure of this application and is herein incorporated by reference in its entirety.

The present disclosure describes methods and systems for managing memory in a virtual machine. In particular this disclosure describes methods and systems for dynamically managing memory to reduce the memory footprint of a virtual machine.

In many virtualization environments the re balancing of memory resources can be necessary to ensure that memory resources are efficiently and appropriately utilized. Further re balancing memory resources within a virtualization environment and amongst multiple virtual machines can ensure that each virtual machine in the virtualization environment has a minimum memory footprint. Many systems accomplish the re balancing or redistribution of memory resources by compressing portions of memory or otherwise reducing the amount of memory within a particular virtual machine. In many instances adjusting the memory footprint or the amount of memory assigned to a particular virtual machine requires rebooting that virtual machine.

Re balancing memory in a virtualization environment is one way that a control virtual machine conserves memory resources. Memory reallocation or re balancing can require re balancing the memory partitions of a physical disk which as previously mentioned can require rebooting a virtual machine. The process of having to reboot a virtual machine each time a control virtual machine needs to re balance memory resources can be inefficient and may limit when and how often a control virtual machine can re balance the memory resources available in a virtualization environment. Thus there exists a need for methods and systems for managing the amount of memory allocated to each virtual machine that does not require rebooting each virtual machine.

In some instances described herein are methods and systems for re balancing memory partitions within a virtualization environment using balloon drivers and without requiring a virtual machine reboot. A memory manager executing within a control virtual machine of the virtualization environment can inflate balloon drivers within virtual machines or domains to cause the allocation of additional memory to those virtual machines or domains. The memory manager can then track the memory locations of the additional memory and upon deflating the balloon drivers can reallocate the memory locations of the additional memory to virtual machines needing additional memory.

In one aspect described herein are methods and systems for dynamically reallocating memory amongst virtual machines executing within a virtualization environment. The virtualization environment in some embodiments can execute on a computer and can include one or more virtual machines. The virtual machines can execute on the computer within the context of the virtualization environment. A memory manager executing on the computer within the context of the virtualization environment can identify a maximum memory value and a minimum memory value for each virtual machine of the virtualization environment. Using the identified maximum and minimum memory values the memory manager can determine a target memory value for each virtual machine of the virtualization environment. The memory manager can then identify at least one virtual machine that has an actual memory usage value less than the target memory value for the at least one virtual machine. In response to identifying the at least one virtual machine the memory manager can allocate additional memory to the at least one virtual machine by inflating a balloon driver. Upon allocating the additional memory the memory manager can de allocate the additional memory from the at least one virtual machine by deflating the balloon driver. In response to de allocating the additional memory the memory manager can then reallocate the de allocated memory to another virtual machine in the virtualization environment.

In some embodiments the maximum and minimum memory values are maximum and minimum physical memory values. In other embodiments the maximum and minimum memory values are maximum and minimum dynamic physical memory values.

The target memory values in some embodiments can be calculated using the maximum memory values the minimum memory values and a host compression ratio.

In one embodiment the memory manager can allocate the additional memory to the identified at least one virtual machine until the actual memory usage value of the at least one virtual machine substantially equals the target memory value for the at least one virtual machine. In some instances the memory manager can de allocate the additional memory upon determining that the actual memory usage value of the at least one virtual machine substantially equals the target memory value for the at least one virtual machine.

In other embodiments the memory manager enumerates the memory locations of the de allocated memory in response to de allocating the additional memory. The memory manager can then reallocate the enumerated memory locations to another virtual machine within the virtualization environment.

In some embodiments the memory manager can identify a second virtual machine that has an actual memory usage value greater than the target memory value for the second virtual machine. In those embodiments the memory manager can reclaim an amount of memory from the second virtual machine and reallocate the reclaimed memory to another virtual machine executing within the virtualization environment.

The memory manager in some embodiments can identify the maximum and minimum memory values in response to detecting a virtual machine event. A virtual machine event can be any one of a virtual machine reboot a virtual machine start and a dynamic constraint modification.

In one embodiment the computing environment can include an appliance installed between the server s and client machine s . This appliance can mange client server connections and in some cases can load balance client connections amongst a plurality of backend servers.

The client machine s can in some embodiment be referred to as a single client machine or a single group of client machines while server s may be referred to as a single server or a single group of servers . In one embodiment a single client machine communicates with more than one server while in another embodiment a single server communicates with more than one client machine . In yet another embodiment a single client machine communicates with a single server .

A client machine can in some embodiments be referenced by any one of the following terms client machine s client s client computer s client device s client computing device s local machine remote machine client node s endpoint s endpoint node s or a second machine. The server in some embodiments may be referenced by any one of the following terms server s local machine remote machine server farm s host computing device s or a first machine s .

In one embodiment the client machine can be a virtual machine C. The virtual machine C can be any virtual machine while in some embodiments the virtual machine C can be any virtual machine managed by a hypervisor developed by XenSolutions Citrix Systems IBM VMware or any other hypervisor. In other embodiments the virtual machine C can be managed by any hypervisor while in still other embodiments the virtual machine C can be managed by a hypervisor executing on a server or a hypervisor executing on a client .

The client machine can in some embodiments execute operate or otherwise provide an application that can be any one of the following software a program executable instructions a virtual machine a hypervisor a web browser a web based client a client server application a thin client computing client an ActiveX control a Java applet software related to voice over internet protocol VoIP communications like a soft IP telephone an application for streaming video and or audio an application for facilitating real time data communications a HTTP client a FTP client an Oscar client a Telnet client or any other set of executable instructions. Still other embodiments include a client device that displays application output generated by an application remotely executing on a server or other remotely located machine. In these embodiments the client device can display the application output in an application window a browser or other output window. In one embodiment the application is a desktop while in other embodiments the application is an application that generates a desktop.

The server in some embodiments executes a remote presentation client or other client or program that uses a thin client or remote display protocol to capture display output generated by an application executing on a server and transmits the application display output to a remote client . The thin client or remote display protocol can be any one of the following protocols the Independent Computing Architecture ICA protocol manufactured by Citrix Systems Inc. of Ft. Lauderdale Fla. or the Remote Desktop Protocol RDP manufactured by the Microsoft Corporation of Redmond Wash.

The computing environment can include more than one server A N such that the servers A N are logically grouped together into a server farm . The server farm can include servers that are geographically dispersed and logically grouped together in a server farm or servers that are located proximate to each other and logically grouped together in a server farm . Geographically dispersed servers A N within a server farm can in some embodiments communicate using a WAN MAN or LAN where different geographic regions can be characterized as different continents different regions of a continent different countries different states different cities different campuses different rooms or any combination of the preceding geographical locations. In some embodiments the server farm may be administered as a single entity while in other embodiments the server farm can include multiple server farms .

In some embodiments a server farm can include servers that execute a substantially similar type of operating system platform e.g. WINDOWS NT manufactured by Microsoft Corp. of Redmond Wash. UNIX LINUX or SNOW LEOPARD. In other embodiments the server farm can include a first group of servers that execute a first type of operating system platform and a second group of servers that execute a second type of operating system platform. The server farm in other embodiments can include servers that execute different types of operating system platforms.

The server in some embodiments can be any server type. In other embodiments the server can be any of the following server types a file server an application server a web server a proxy server an appliance a network appliance a gateway an application gateway a gateway server a virtualization server a deployment server a SSL VPN server a firewall a web server an application server or as a master application server a server executing an active directory or a server executing an application acceleration program that provides firewall functionality application functionality or load balancing functionality. In some embodiments a server may be a RADIUS server that includes a remote authentication dial in user service. In embodiments where the server comprises an appliance the server can be an appliance manufactured by any one of the following manufacturers the Citrix Application Networking Group Silver Peak Systems Inc Riverbed Technology Inc. F5 Networks Inc. or Juniper Networks Inc. Some embodiments include a first server A that receives requests from a client machine forwards the request to a second server B and responds to the request generated by the client machine with a response from the second server B. The first server A can acquire an enumeration of applications available to the client machine and well as address information associated with an application server hosting an application identified within the enumeration of applications. The first server A can then present a response to the client s request using a web interface and communicate directly with the client to provide the client with access to an identified application.

The server can in some embodiments execute any one of the following applications a thin client application using a thin client protocol to transmit application display data to a client a remote display presentation application any portion of the CITRIX ACCESS SUITE by Citrix Systems Inc. like the METAFRAME or CITRIX PRESENTATION SERVER MICROSOFT WINDOWS Terminal Services manufactured by the Microsoft Corporation or an ICA client developed by Citrix Systems Inc. Another embodiment includes a server that is an application server such as an email server that provides email services such as MICROSOFT EXCHANGE manufactured by the Microsoft Corporation a web or Internet server a desktop sharing server a collaboration server or any other type of application server. Still other embodiments include a server that executes any one of the following types of hosted servers applications GOTOMEETING provided by Citrix Online Division Inc. WEBEX provided by WebEx Inc. of Santa Clara Calif. or Microsoft Office LIVE MEETING provided by Microsoft Corporation.

Client machines can in some embodiments be a client node that seeks access to resources provided by a server . In other embodiments the server may provide clients or client nodes with access to hosted resources. The server in some embodiments functions as a master node such that it communicates with one or more clients or servers . In some embodiments the master node can identify and provide address information associated with a server hosting a requested application to one or more clients or servers . In still other embodiments the master node can be a server farm a client a cluster of client nodes or an appliance.

One or more clients and or one or more servers can transmit data over a network installed between machines and appliances within the computing environment . The network can comprise one or more sub networks and can be installed between any combination of the clients servers computing machines and appliances included within the computing environment . In some embodiments the network can be a local area network LAN a metropolitan area network MAN a wide area network WAN a primary network comprised of multiple sub networks located between the client machines and the servers a primary public network with a private sub network a primary private network with a public sub network or a primary private network with a private sub network . Still further embodiments include a network that can be any of the following network types a point to point network a broadcast network a telecommunications network a data communication network a computer network an ATM Asynchronous Transfer Mode network a SONET Synchronous Optical Network network a SDH Synchronous Digital Hierarchy network a wireless network a wireline network or a network that includes a wireless link where the wireless link can be an infrared channel or satellite band. The network topology of the network can differ within different embodiments possible network topologies include a bus network topology a star network topology a ring network topology a repeater based network topology or a tiered star network topology. Additional embodiments may include a network of mobile telephone networks that use a protocol to communicate among mobile devices where the protocol can be any one of the following AMPS TDMA CDMA GSM GPRS UMTS or any other protocol able to transmit data among mobile devices.

Illustrated in is an embodiment of a computing device where the client machine and server illustrated in can be deployed as and or executed on any embodiment of the computing device illustrated and described herein. Included within the computing device is a system bus that communicates with the following components a central processing unit a main memory storage memory an input output I O controller display devices A N an installation device and a network interface . In one embodiment the storage memory includes an operating system software routines and a client agent . The I O controller in some embodiments is further connected to a key board and a pointing device . Other embodiments may include an I O controller connected to more than one input output device A N.

Embodiments of the computing machine can include a central processing unit characterized by any one of the following component configurations logic circuits that respond to and process instructions fetched from the main memory unit a microprocessor unit such as those manufactured by Intel Corporation those manufactured by Motorola Corporation those manufactured by Transmeta Corporation of Santa Clara Calif. the RS 6000 processor such as those manufactured by International Business Machines a processor such as those manufactured by Advanced Micro Devices or any other combination of logic circuits. Still other embodiments of the central processing unit may include any combination of the following a microprocessor a microcontroller a central processing unit with a single processing core a central processing unit with two processing cores or a central processing unit with more than one processing core.

While illustrates a computing device that includes a single central processing unit in some embodiments the computing device can include one or more processing units . In these embodiments the computing device may store and execute firmware or other executable instructions that when executed direct the one or more processing units to simultaneously execute instructions or to simultaneously execute instructions on a single piece of data. In other embodiments the computing device may store and execute firmware or other executable instructions that when executed direct the one or more processing units to each execute a section of a group of instructions. For example each processing unit may be instructed to execute a portion of a program or a particular module within a program.

In some embodiments the processing unit can include one or more processing cores. For example the processing unit may have two cores four cores eight cores etc. In one embodiment the processing unit may comprise one or more parallel processing cores. The processing cores of the processing unit may in some embodiments access available memory as a global address space or in other embodiments memory within the computing device can be segmented and assigned to a particular core within the processing unit . In one embodiment the one or more processing cores or processors in the computing device can each access local memory. In still another embodiment memory within the computing device can be shared amongst one or more processors or processing cores while other memory can be accessed by particular processors or subsets of processors. In embodiments where the computing device includes more than one processing unit the multiple processing units can be included in a single integrated circuit IC . These multiple processors in some embodiments can be linked together by an internal high speed bus which may be referred to as an element interconnect bus.

In embodiments where the computing device includes one or more processing units or a processing unit including one or more processing cores the processors can execute a single instruction simultaneously on multiple pieces of data SIMD or in other embodiments can execute multiple instructions simultaneously on multiple pieces of data MIMD . In some embodiments the computing device can include any number of SIMD and MIMD processors.

The computing device in some embodiments can include a graphics processor or a graphics processing unit Not Shown . The graphics processing unit can include any combination of software and hardware and can further input graphics data and graphics instructions render a graphic from the inputted data and instructions and output the rendered graphic. In some embodiments the graphics processing unit can be included within the processing unit . In other embodiments the computing device can include one or more processing units where at least one processing unit is dedicated to processing and rendering graphics.

One embodiment of the computing machine includes a central processing unit that communicates with cache memory via a secondary bus also known as a backside bus while another embodiment of the computing machine includes a central processing unit that communicates with cache memory via the system bus . The local system bus can in some embodiments also be used by the central processing unit to communicate with more than one type of I O device A N. In some embodiments the local system bus can be any one of the following types of buses a VESA VL bus an ISA bus an EISA bus a MicroChannel Architecture MCA bus a PCI bus a PCI X bus a PCI Express bus or a NuBus. Other embodiments of the computing machine include an I O device A N that is a video display that communicates with the central processing unit . Still other versions of the computing machine include a processor connected to an I O device A N via any one of the following connections HyperTransport Rapid I O or InfiniBand. Further embodiments of the computing machine include a processor that communicates with one I O device A using a local interconnect bus and a second I O device B using a direct connection.

The computing device in some embodiments includes a main memory unit and cache memory . The cache memory can be any memory type and in some embodiments can be any one of the following types of memory SRAM BSRAM or EDRAM. Other embodiments include cache memory and a main memory unit that can be any one of the following types of memory Static random access memory SRAM Burst SRAM or SynchBurst SRAM BSRAM Dynamic random access memory DRAM Fast Page Mode DRAM FPM DRAM Enhanced DRAM EDRAM Extended Data Output RAM EDO RAM Extended Data Output DRAM EDO DRAM Burst Extended Data Output DRAM BEDO DRAM Enhanced DRAM EDRAM synchronous DRAM SDRAM JEDEC SRAM PC100 SDRAM Double Data Rate SDRAM DDR SDRAM Enhanced SDRAM ESDRAM SyncLink DRAM SLDRAM Direct Rambus DRAM DRDRAM Ferroelectric RAM FRAM or any other type of memory. Further embodiments include a central processing unit that can access the main memory via a system bus a memory port or any other connection bus or port that allows the processor to access memory .

One embodiment of the computing device provides support for any one of the following installation devices a CD ROM drive a CD R RW drive a DVD ROM drive tape drives of various formats USB device a bootable medium a bootable CD a bootable CD for GNU Linux distribution such as KNOPPIX a hard drive or any other device suitable for installing applications or software. Applications can in some embodiments include a client agent or any portion of a client agent . The computing device may further include a storage device that can be either one or more hard disk drives or one or more redundant arrays of independent disks where the storage device is configured to store an operating system software programs applications or at least a portion of the client agent . A further embodiment of the computing device includes an installation device that is used as the storage device .

The computing device may further include a network interface to interface to a Local Area Network LAN Wide Area Network WAN or the Internet through a variety of connections including but not limited to standard telephone lines LAN or WAN links e.g. 802.11 T1 T3 56 kb X.25 SNA DECNET broadband connections e.g. ISDN Frame Relay ATM Gigabit Ethernet Ethernet over SONET wireless connections or some combination of any or all of the above. Connections can also be established using a variety of communication protocols e.g. TCP IP IPX SPX NetBIOS Ethernet ARCNET SONET SDH Fiber Distributed Data Interface FDDI RS232 RS485 IEEE 802.11 IEEE 802.11a IEEE 802.11b IEEE 802.11g CDMA GSM WiMax and direct asynchronous connections . One version of the computing device includes a network interface able to communicate with additional computing devices via any type and or form of gateway or tunneling protocol such as Secure Socket Layer SSL or Transport Layer Security TLS or the Citrix Gateway Protocol manufactured by Citrix Systems Inc. Versions of the network interface can comprise any one of a built in network adapter a network interface card a PCMCIA network card a card bus network adapter a wireless network adapter a USB network adapter a modem or any other device suitable for interfacing the computing device to a network capable of communicating and performing the methods and systems described herein.

Embodiments of the computing device include any one of the following I O devices A N a keyboard a pointing device mice trackpads an optical pen trackballs microphones drawing tablets video displays speakers inkjet printers laser printers and dye sublimation printers or any other input output device able to perform the methods and systems described herein. An I O controller may in some embodiments connect to multiple I O devices A N to control the one or more I O devices. Some embodiments of the I O devices A N may be configured to provide storage or an installation medium while others may provide a universal serial bus USB interface for receiving USB storage devices such as the USB Flash Drive line of devices manufactured by Twintech Industry Inc. Still other embodiments include an I O device that may be a bridge between the system bus and an external communication bus such as a USB bus an Apple Desktop Bus an RS 232 serial connection a SCSI bus a FireWire bus a FireWire 800 bus an Ethernet bus an AppleTalk bus a Gigabit Ethernet bus an Asynchronous Transfer Mode bus a HIPPI bus a Super HIPPI bus a SerialPlus bus a SCI LAMP bus a FibreChannel bus or a Serial Attached small computer system interface bus.

In some embodiments the computing machine can connect to multiple display devices A N in other embodiments the computing device can connect to a single display device while in still other embodiments the computing device connects to display devices A N that are the same type or form of display or to display devices that are different types or forms. Embodiments of the display devices A N can be supported and enabled by the following one or multiple I O devices A N the I O controller a combination of I O device s A N and the I O controller any combination of hardware and software able to support a display device A N any type and or form of video adapter video card driver and or library to interface communicate connect or otherwise use the display devices A N. The computing device may in some embodiments be configured to use one or multiple display devices A N these configurations include having multiple connectors to interface to multiple display devices A N having multiple video adapters with each video adapter connected to one or more of the display devices A N having an operating system configured to support multiple displays A N using circuits and software included within the computing device to connect to and use multiple display devices A N and executing software on the main computing device and multiple secondary computing devices to enable the main computing device to use a secondary computing device s display as a display device A N for the main computing device . Still other embodiments of the computing device may include multiple display devices A N provided by multiple secondary computing devices and connected to the main computing device via a network.

In some embodiments the computing machine can execute any operating system while in other embodiments the computing machine can execute any of the following operating systems versions of the MICROSOFT WINDOWS operating systems such as WINDOWS 3.x WINDOWS 95 WINDOWS 98 WINDOWS 2000 WINDOWS NT 3.51 WINDOWS NT 4.0 WINDOWS CE WINDOWS XP and WINDOWS VISTA the different releases of the Unix and Linux operating systems any version of the MAC OS manufactured by Apple Computer OS 2 manufactured by International Business Machines any embedded operating system any real time operating system any open source operating system any proprietary operating system any operating systems for mobile computing devices or any other operating system. In still another embodiment the computing machine can execute multiple operating systems. For example the computing machine can execute PARALLELS or another virtualization platform that can execute or manage a virtual machine executing a first operating system while the computing machine executes a second operating system different from the first operating system.

The computing machine can be embodied in any one of the following computing devices a computing workstation a desktop computer a laptop or notebook computer a server a handheld computer a mobile telephone a portable telecommunication device a media playing device a gaming system a mobile computing device a netbook a device of the IPOD family of devices manufactured by Apple Computer any one of the PLAYSTATION family of devices manufactured by the Sony Corporation any one of the Nintendo family of devices manufactured by Nintendo Co any one of the XBOX family of devices manufactured by the Microsoft Corporation or any other type and or form of computing telecommunications or media device that is capable of communication and that has sufficient processor power and memory capacity to perform the methods and systems described herein. In other embodiments the computing machine can be a mobile device such as any one of the following mobile devices a JAVA enabled cellular telephone or personal digital assistant PDA such as the i55sr i58sr i85s i88s i90c i95cl or the im1100 all of which are manufactured by Motorola Corp the 6035 or the 7135 manufactured by Kyocera the i300 or i330 manufactured by Samsung Electronics Co. Ltd the TREO 180 270 600 650 680 700p 700w or 750 smart phone manufactured by Palm Inc any computing device that has different processors operating systems and input devices consistent with the device or any other mobile computing device capable of performing the methods and systems described herein. In still other embodiments the computing device can be any one of the following mobile computing devices any one series of Blackberry or other handheld device manufactured by Research In Motion Limited the iPhone manufactured by Apple Computer Palm Pre a Pocket PC a Pocket PC Phone or any other handheld mobile device.

Illustrated in is one embodiment of a virtualization environment. Included on a computing device is a hardware layer that can include one or more physical disks one or more physical devices one or more physical processors and a physical memory . In some embodiments firmware can be stored within a memory element in the physical memory and can be executed by one or more of the physical processors . The computing device can further include an operating system that can be stored in a memory element in the physical memory and executed by one or more of the physical processors . Still further a hypervisor can be stored in a memory element in the physical memory and can be executed by one or more of the physical processors . Executing on one or more of the physical processors can be one or more virtual machines A C generally . Each virtual machine can have a virtual disk A C and a virtual processor A C. In some embodiments a first virtual machine A can execute on a virtual processor A a control program that includes a tools stack . In other embodiments one or more virtual machines B C can executed on a virtual processor B C a guest operating system A B.

Further referring to and in more detail in one embodiment the virtualization environment described includes a Type 2 hypervisor or a hypervisor that executes within an operating system executing on the computing device . A Type 2 hypervisor in some embodiments executes within an operating system environment and virtual machines execute at a level above the hypervisor. In many embodiments the Type 2 hypervisor executes within the context of a user s operating system such that the Type 2 hypervisor interacts with the user s operating system.

In some embodiments the virtualization environment includes a computing device . The computing device can be any computing device and in some embodiments the computing device can be any computer device or computing machine described herein. While illustrates a single computing device in some embodiments the modules programs virtual machines and commands stored and executed by the computing device can be executed by more than one computing device . In still other embodiments the computing device can be a server farm.

In one embodiment the computing device can include a hardware layer that includes one or more pieces of hardware that communicates with the computing machine . In some embodiments the hardware layer can include any hardware included in the computing device . In other embodiments the hardware layer can include one or more physical disks one or more physical devices one or more physical processors and memory .

The hardware layer in some embodiments can include one or more physical disks . A physical disk can be any hard disk while in some embodiments a physical disk can be any hard disk described herein. In some embodiments the hardware layer can include one physical disk . In other embodiments the hardware layer can include more than one physical disk . The computing device in some embodiments can communicate with an external hard disk that is included in the hardware layer as a physical disk .

In other embodiments the hardware layer can include a processor . The processor in some embodiments can be any processor while in other embodiments the processor can be any processor described herein. The processor can include one or more processing cores. In other embodiments the computing device can include one or more processors . In some embodiments the computing device can include one or more different processors e.g. a processing unit a graphics processing unit or a physics engine.

Physical devices in some embodiments can be any device included in the computing device . In some embodiments physical devices can be any combination of devices included in the computing device and external devices that communicate with the computing device . The computing device in some embodiments can include one or more physical devices . A physical device can be any of the following a network interface card a video card a keyboard a mouse an input device a monitor a display device speakers an optical drive a storage device a universal serial bus connection any device connected to the computing device any device communicating with the computing device a printer a scanner or any other device or device described herein.

The hardware layer can further include physical memory that can include any type of memory. In some embodiments the physical memory can include any memory type described herein. The physical memory can store data and in some embodiments can store one or more programs or set of executable instructions. illustrates one embodiment where firmware is stored within the physical memory of the computing device . Programs or executable instructions stored in the physical memory can be executed by the one or more processors of the computing device .

Firmware in some embodiments can be any combination of executable instructions and hardware that controls hardware communicating with or included within the computing device . In some embodiments the firmware can control one or more pieces of hardware within the hardware layer . Firmware in many embodiments can be executed by one or more processors within the computing device . In some embodiments the firmware can be boot firmware such as the basic input output system BIOS. Additional firmware executing on the computing device can interface with the BIOS.

In one embodiment the computing device can include an operating system executed by one or more physical processors . In some embodiments the operating system is a user operating system that can directly access the hardware devices in the hardware layer . The operating system can be any operating system and in some embodiments the operating system can be any operating system described herein. illustrates one embodiment where the hypervisor executes within the context of the operating system executing on the computing device . In this embodiment the operating system can be referred to as a host operating system while the other operating systems can be referred to as guest operating systems. Guest operating systems can include the guest operating systems A B executing on the virtual machines and or the control program .

In some embodiments the computing device can include a hypervisor . A hypervisor in some embodiments can be a program that executed by processors on the computing device to manage any number of virtual machines. The hypervisor can be referred to as a virtual machine monitor or platform virtualization software. In some embodiments a hypervisor can be any combination of executable instructions and hardware that monitors virtual machines executing on a computing machine. While illustrates a virtualization environment that includes a Type 2 hypervisor the computing device can execute any other type of hypervisor. For example the computing device can execute a virtualization environment that includes a Type 1 hypervisor . In some embodiments the computing device can execute one or more hypervisors . These one or more hypervisors can be the same type of hypervisor or in other embodiments can be different hypervisor types.

The hypervisor in some embodiments can provide virtual resources to operating systems or control programs executing on virtual machines in any manner that simulates the operating systems or control programs having direct access to system resources. System resources can include physical devices physical disks physical processors physical memory and any other component included in the computing device hardware layer . In these embodiments the hypervisor may be used to emulate virtual hardware partition physical hardware virtualize physical hardware or execute virtual machines that provide access to computing environments. In still other embodiments the hypervisor controls processor scheduling and memory partitioning for a virtual machine executing on the computing device . Hypervisor may include those manufactured by VMWare Inc. of Palo Alto Calif. the XEN hypervisor an open source product whose development is overseen by the open source Xen.org community HyperV VirtualServer or virtual PC hypervisors provided by Microsoft or others. In some embodiments a computing device executes a hypervisor that creates a virtual machine platform on which guest operating systems may execute. In these embodiments the computing device can be referred to as a host server. An example of such a computing device is the XEN SERVER provided by Citrix Systems Inc. of Fort Lauderdale Fla.

In one embodiment the hypervisor can create a virtual machine A B generally in which an operating system executes. In one of these embodiments for example the hypervisor loads a virtual machine image to create a virtual machine . In another of these embodiments the hypervisor executes an operating system within the virtual machine . In still another of these embodiments the virtual machine executes an operating system .

In one embodiment the hypervisor controls the execution of at least one virtual machine . In another embodiment the hypervisor presents at least one virtual machine with an abstraction of at least one hardware resource provided by the computing device . The abstraction can further be referred to as a virtualization or virtual view of the hardware memory processor and other system resources available on the computing device . Hardware or hardware resources in some embodiments can be any hardware resource available within the hardware layer . In other embodiments the hypervisor controls the manner in which virtual machines access the physical processors available in the computing device . Controlling access to the physical processors can include determining whether a virtual machine should have access to a processor and how physical processor capabilities are presented to the virtual machine .

In some embodiments the computing device can host or execute one or more virtual machines . A virtual machine can be called a domain a guest and or a DOMAIN U. A virtual machine is a set of executable instructions that when executed by a processor imitate the operation of a physical computer such that the virtual machine can execute programs and processes much like a physical computing device. While illustrates an embodiment where a computing device hosts three virtual machines in other embodiments the computing device can host any number of virtual machines . The hypervisor in some embodiments provides each virtual machine with a unique virtual view of the physical hardware memory processor and other system resources available to that virtual machine . In some embodiments the unique virtual view can be based on any of the following virtual machine permissions application of a policy engine to one or more virtual machine identifiers the user accessing a virtual machine the applications executing on a virtual machine networks accessed by a virtual machine or any other similar criteria. The hypervisor in other embodiments provides each virtual machine with a substantially similar virtual view of the physical hardware memory processor and other system resources available to the virtual machines .

Each virtual machine can include a virtual disk A C generally and a virtual processor A C generally . The virtual disk in some embodiments is a virtualized view of one or more physical disks of the computing device or a portion of one or more physical disks of the computing device . The virtualized view of the physical disks can be generated provided and managed by the hypervisor . In some embodiments the hypervisor provides each virtual machine with a unique view of the physical disks . Thus in these embodiments the virtual disk included in each virtual machine can be unique when compared with the other virtual disks .

A virtual processor can be a virtualized view of one or more physical processors of the computing device . In some embodiments the virtualized view of the physical processors can be generated provided and managed by the hypervisor . In some embodiments the virtual processor has substantially all of the same characteristics of at least one physical processor . In other embodiments the virtual processor provides a modified view of the physical processors such that at least some of the characteristics of the virtual processor are different than the characteristics of the corresponding physical processor .

A control program may execute at least one application for managing and configuring the guest operating systems executing on the virtual machines and in some embodiments the computing device . In some embodiments the control program can be called a control operating system a control domain domain 0 or dom 0. The control program in some embodiments can be DOMAIN o or DOM0 of the XEN hypervisor. The control program can execute an administrative application or program that can further display a user interface which administrators can use to access the functionality of each virtual machine and or to manage the virtual machines . In some embodiments the user interface generated by the administrative program can be used to terminate the execution of virtual machines allocate resources to virtual machines assign permissions to virtual machines or manage security credentials associated with virtual machines . The control program in some embodiments can start new virtual machines or terminate execution of executing virtual machines . In other embodiments the control program can directly access hardware and or resources within the hardware layer . In still another embodiment the control program can interface with programs and applications executing on the computing device and outside of the context of a virtual machine . Similarly the control program can interface with programs and applications executing within the context of a virtual machine .

In one embodiment the hypervisor can execute the control program within a virtual machine . The hypervisor can create and start the virtual machine . In embodiments where the hypervisor executes the control program within a virtual machine that virtual machine can be referred to as the control virtual machine . In still another embodiment the control program executes within a virtual machine that is authorized to directly access physical resources on the computing device .

In some embodiments a control program A Not Shown on a first computing device A Not Shown may exchange data with a control program B Not Shown on a second computing device B Not Shown . In these embodiments the first computing device A may be located remote from the second computing device B. The control programs A B can exchange data via a communication link between a hypervisor A Not Shown executing on the first computing device A and a hypervisor B Not Shown executing on the second computing device B. Through this communication link the computing devices A B can exchange data regarding processors and other physical resources available in a pool of resources. Further through this connection between hypervisors A B the hypervisors A B can manage a pool of resources e.g. the resources available on the first computing device A and the second computing device B distributed across one or more computing devices A B. The hypervisors A B can further virtualize these resources and make them available to virtual machines executing on the computing devices A B. In another instance of this embodiment a single hypervisor can manage and control virtual machines executing on both computing devices A B.

In some embodiments the control program interacts with one or more guest operating systems A B generally . The control program can communicate with the guest operating systems through a hypervisor . Through the hypervisor the guest operating system can request access to physical disks physical processors memory physical devices and any other component in the hardware layer . In still other embodiments the guest operating systems can communicate with the control program via a communication channel established by the hypervisor such as for example via a plurality of shared memory pages made available by the hypervisor .

In some embodiments the control program includes a network back end driver for communicating directly with networking hardware provided by the computing device . In one of these embodiments the network back end driver processes at least one virtual machine request from at least one guest operating system . In other embodiments the control program includes a block back end driver for communicating with a storage element on the computing device . In one of these embodiments the block back end driver reads and writes data from the storage element based upon at least one request received from a guest operating system .

In another embodiment the control program includes a tools stack . In another embodiment a tools stack provides functionality for interacting with the hypervisor communicating with other control programs for example on a second computing device B or managing virtual machines on the computing device . In another embodiment the tools stack includes customized applications for providing improved management functionality to an administrator of a virtual machine farm. In some embodiments at least one of the tools stack and the control program include a management API that provides an interface for remotely configuring and controlling virtual machines running on a computing device . In other embodiments the control program communicates with the hypervisor through the tools stack .

In one embodiment the hypervisor executes a guest operating system within a virtual machine created by the hypervisor . In another embodiment the guest operating system provides a user of the computing device with access to resources within a computing environment. In still another embodiment a resource includes a program an application a document a file a plurality of applications a plurality of files an executable program file a desktop environment a computing environment or other resource made available to a user of the computing device . In yet another embodiment the resource may be delivered to the computing device via a plurality of access methods including but not limited to conventional installation directly on the computing device delivery to the computing device via a method for application streaming delivery to the computing device of output data generated by an execution of the resource on a second computing device and communicated to the computing device via a presentation layer protocol delivery to the computing device of output data generated by an execution of the resource via a virtual machine executing on a second computing device or execution from a removable storage device connected to the computing device such as a USB device or via a virtual machine executing on the computing device and generating output data. In some embodiments the computing device transmits output data generated by the execution of the resource to another computing device .

In one embodiment the guest operating system in conjunction with the virtual machine on which it executes forms a fully virtualized virtual machine that is not aware that it is a virtual machine such a machine may be referred to as a Domain U HVM Hardware Virtual Machine virtual machine . In another embodiment a fully virtualized machine includes software emulating a Basic Input Output System BIOS in order to execute an operating system within the fully virtualized machine. In still another embodiment a fully virtualized machine may include a driver that provides functionality by communicating with the hypervisor . In such an embodiment the driver is typically aware that it executes within a virtualized environment.

In another embodiment the guest operating system in conjunction with the virtual machine on which it executes forms a paravirtualized virtual machine which is aware that it is a virtual machine such a machine may be referred to as a Domain U PV virtual machine . In another embodiment a paravirtualized machine includes additional drivers that a fully virtualized machine does not include. In still another embodiment the paravirtualized machine includes the network back end driver and the block back end driver included in a control program as described above.

Illustrated in is another embodiment of a virtualization environment that illustrates a Type 1 hypervisor . Executing on the computing device is a hypervisor that can directly access the hardware and resources within the hardware layer . Virtual machines managed by the hypervisor can be an unsecure virtual machine B and or a secure virtual machine C. Whereas the virtualization environment depicted in illustrates a host operating system the virtualization environment embodiment in does not execute a host operating system.

Further referring to and in more detail the virtualization environment includes a Type 1 hypervisor . Type 1 hypervisors in some embodiments execute on bare metal such that the hypervisor has direct access to all applications and processes executing on the computing device all resources on the computing device and all hardware on the computing device or communicating with the computing device . While a Type 2 hypervisor accesses system resources through a host operating system a Type 1 hypervisor can directly access all system resources. The Type 1 hypervisor can execute directly on one or more physical processors of the computing device and can include program data stored in the physical memory .

In a virtualization environment that employs a Type 1 hypervisor configuration the host operating system can be executed by one or more virtual machines . Thus a user of the computing device can designate one or more virtual machines as the user s personal machine. This virtual machine can imitate the host operating system by allowing a user to interact with the computing device in substantially the same manner that the user would interact with the computing device via a host operating system .

Virtual machines can be unsecure virtual machines B and secure virtual machine C. While illustrates a secure and unsecure virtual machine sometimes they can be referred to as privileged and unprivileged virtual machines. In some embodiments a virtual machine s security can be determined based on a comparison of the virtual machine to other virtual machines executing within the same virtualization environment. For example were a first virtual machine to have access to a pool of resources and a second virtual machine not to have access to the same pool of resources the second virtual machine could be considered an unsecure virtual machine B while the first virtual machine could be considered a secure virtual machine A. In some embodiments a virtual machine s ability to access one or more system resources can be configured using a configuration interface generated by either the control program or the hypervisor . In other embodiments the level of access afforded to a virtual machine can be the result of a review of any of the following sets of criteria the user accessing the virtual machine one or more applications executing on the virtual machine the virtual machine identifier a risk level assigned to the virtual machine based on one or more factors or any other similar criteria.

In some embodiments unsecure virtual machines B may be prevented from accessing resources hardware memory locations and programs that secure virtual machines A may access. For example a secure virtual machine C may be able to access one or more company resources while the unsecure virtual machine B cannot access any company resources.

Illustrated in is one embodiment of a computing device where the control virtual machine A can further execute a memory manager that can reallocate memory to virtual machines executing within the virtualization environment . Each of the virtual machines can include a memory profile A N herein referred to generally as a memory profile and each virtual machine can execute a balloon driver A N herein generally referred to as a balloon driver . 

Further referring to and in more detail in one embodiment each virtual machine can include a memory profile . While does not illustrate the control virtual machine A as having a memory profile in some embodiments the control virtual machine A can include a memory profile . The memory profile in some embodiments can be any memory profile that dictates at least a maximum amount of physical memory available to a virtual machine and a minimum amount of physical memory available to a virtual machine . In other embodiments the memory profile can be any memory profile described herein.

The control program can execute a memory manager . While illustrates a memory manager executing within the control virtual machine A in other embodiments the memory manager can execute within the hypervisor or on a remote computer. While the memory manager can execute independent of the control program in some embodiments the memory manager can be a sub routine or sub function executing within the control program . The memory manager in some embodiments can manage the allocation of dynamic maximum and minimum memory values the calculation of target memory values the allocation and reallocation of memory amongst virtual machines in a virtualization environment and the general management of memory allocation in a virtualization environment . In some embodiments the memory manager can control the inflation and deflation of balloon drivers within the virtual machines . In still other embodiments the memory manager can issue inflation and deflation commands to balloon drivers within the virtual machines . The memory manager can execute on a control virtual machine A within the context of a control program within the hypervisor or on a remote computer.

The balloon driver in some embodiments can be any driver that causes an operating system executing on the computing device the memory manager or the control program to reclaim memory used by the virtual machine s executing on the computing device . In some embodiments the balloon driver can be a driver or other application that executes by or in conjunction with the hypervisor or control program to increase the amount of memory used by each virtual machine . Increasing the amount of memory used by each virtual machine can include allocating memory pages to one or more virtual machines executing on the computing device where the allocated memory pages correspond to a pinned or locked range of memory addresses on the physical disk s . By increasing the amount of memory used by each virtual machine the balloon driver effectively reduces the amount of memory available to the operating system executing on the computing device or the control operating system . Thus when the balloon driver continues to allocate memory to the virtual machines the memory manager or control program responsively reclaims used memory.

When a memory manager of the virtualization environment reclaims memory in some embodiments the balloon driver can retrieve or otherwise intercept the addresses of the memory pages reclaimed by the balloon driver and forward those page addresses to the control program the memory manager or another application or object executing within the control virtual machine . In other embodiments the balloon driver can forward the page addresses to the hypervisor or a memory manager executing within the hypervisor . In some embodiments the balloon driver can store the reclaimed memory page addresses in a table database or storage repository in the control virtual machine A so that the memory manager can access the memory addresses once the balloon driver deflates. In still other embodiments the memory manager can enumerate the memory locations e.g. memory addresses or memory page addresses of the reclaimed memory. The memory manager can then reallocate memory according to the enumerated memory locations or can store the enumerated memory locations in a table database or storage repository in the control virtual machine A.

A balloon driver can inflate to a predetermined size such that a predetermined amount of memory can be reclaimed. This predetermined size in some embodiments can be an amount of memory. For example the balloon driver can inflate to a size of 10 MB or another memory value amount. In some embodiments the predetermined size can be determined based on a calculated target memory value. For example a memory manager can determine a target memory value for a virtual machine e.g. 100 MB. The memory manager can then compare the calculated target memory value to an amount of memory actually used by the virtual machine e.g. compare 100 MB to 90 MB. The difference between the two values can be used to determine the predetermined inflation size e.g. the predetermined inflation size can be 10 MB. When the balloon driver inflates the balloon driver can inflate to the predetermined inflation size e.g. the balloon driver can inflate 10 MB. In other embodiments the balloon driver can continue to inflate until it reaches a predetermined threshold or until a process program or administrator commands the balloon driver to cease inflation. In still other embodiments the balloon driver can inflate until it reaches a threshold. For example the balloon driver can inflate until the amount of actual memory used by a virtual machine is substantially equal to a target memory value. Substantially equal can mean that the two numbers are mostly equal but may vary by an acceptable and minor amount or value.

Once the balloon driver reaches either a predetermined threshold or memory value the balloon driver can deflate by de allocating the memory pages allocated during inflation. De allocating the memory pages can include de allocating those memory pages reclaimed by the memory manager . In one embodiment the memory manager or control program can capture the memory addresses of the memory pages de allocated during deflation of the balloon driver . In other embodiments the memory manager or control program can retrieve the memory addresses of the reclaimed memory pages from a table list or other storage repository within the hypervisor layer. The reclaimed memory pages are effectively free or open for use once the balloon driver finishes deflating. Thus the control program memory manager or hypervisor can allocate memory associated with those reclaimed memory pages to virtual machines executing on the computing device .

Illustrated in is one embodiment of virtual machine having a memory profile . The memory profile in some embodiments can include one or more dynamic memory ranges that include each of a dynamic minimum memory value a dynamic maximum memory value and a target memory amount . The memory profile can also include a physical memory range that includes a physical minimum memory value and a physical maximum memory value .

Further referring to and in more detail in one embodiment each virtual machine executing on a computing device can have a memory profile which can be a configuration setting or can be a profile stored in a control virtual machine A. In some embodiments a memory profile for each virtual machine can be stored in a table or database accessible by the control virtual machine A the control program the memory manager or the hypervisor . In other embodiments the memory profile can be a setting of an interface within the virtual machine used to communicate and interact with the control virtual machine A. Still other embodiments include a memory profile that is a text file or other configuration file stored in the file system of a virtual machine .

In one embodiment the physical minimum memory value i.e. the static minimum memory value is less than or equal to the dynamic min value . The dynamic min value in many embodiments is less than the dynamic max value . The dynamic max value in many embodiments is less than the physical maximum memory value i.e. the static maximum memory value. In some embodiments the static min and the static max are fixed values that remain fixed during execution of the virtual machine on the computing device . In some embodiments the dynamic max and min can be configured or changed by an administrator user program or service at any time. The target memory value can be chosen such that the value is substantially always greater than or equal to the dynamic min and less than or equal to the dynamic max .

In one embodiment the memory profile can include a dynamic memory range that can include a dynamic minimum memory value and a maximum memory value . The dynamic minimum and maximum memory values can be chosen based on any of the following criteria the importance of the virtual machine a level of importance or criticality assigned to applications and or processes executing on the virtual machine an arbitrary risk score determined based on the importance of those processes and or services executing within the virtual machine when the virtual machine was created whether the virtual machine can control the operation of other virtual machines and any other relevant criteria. In some embodiments the minimum and maximum values can be based on the physical minimum and maximum memory value such that each value is a percentage of the maximum physical memory value . For example the minimum dynamic memory value can be twenty percent 20 of the maximum physical memory value while the maximum dynamic memory value can be eighty percent 80 of the maximum physical memory value .

The values chosen for the dynamic minimum and maximum values can in some embodiments reflect the importance of a particular virtual machine. For example a first virtual machine that has a dynamic minimum and maximum memory value which is 95 of the actual physical minimum and maximum memory value for that first virtual machine may be more important than a second virtual machine that has a dynamic minimum and maximum memory value that is 75 of the actual physical minimum and maximum memory value for that second virtual machine. In this example the first virtual machine may execute more critical or important services and or applications than the second virtual machine. In some embodiments the first virtual machine may be designated by the system as the control virtual machine A thereby making the first virtual machine more important than the second virtual machine.

In one embodiment the dynamic maximum and minimum memory values may be percentages of the physical maximum and minimum memory values while in other embodiments the dynamic maximum and minimum memory values can be hard coded values e.g. minimum 512 megabytes maximum 1 gigabyte. In still other embodiments the dynamic maximum and minimum memory values can be determined on a dynamic basis based on the types and number of applications and or services executed by the virtual machine. For example a first virtual machine may have an initial dynamic minimum memory value of 512 megabytes and an initial dynamic maximum memory value of 1 gigabyte. Upon instantiation of the first virtual machine a critical application requiring a large amount of resources begins executing on the first virtual machine. The control virtual machine A the control program or the memory manager can then in some embodiments modify the dynamic maximum memory value of the first virtual machine from 1 gigabyte to 10 gigabytes and the dynamic minimum memory value of the first virtual machine from 512 megabytes to 1 gigabyte.

The target memory amount can in some embodiments be a memory value determined by analyzing the maximum and minimum dynamic memory values. In some embodiments the target memory amount can be a number that is between the value range between the maximum and minimum values. Thus the target memory amount can be determined using the following equation Min Dynamic Mem. Max Dynamic Mem. Min Dynamic Mem. 2 where the Min Dynamic Mem. value is the minimum dynamic memory value and the Max Dynamic Mem. is the maximum dynamic memory value . In some embodiments the target memory amount can be calculated each time memory is reclaimed from a virtual machine or allocated to a virtual machine. In other embodiments the target memory amount can be stored in a table configuration file or other repository along with the dynamic minimum and maximum memory values . This table configuration file or other repository can reside within each virtual machine within the control virtual machine A or within a location accessible by the memory manager and or the control program . When the dynamic minimum and maximum memory values are altered a stored target memory amount can also be recalculated and altered.

The target memory amount or value in some embodiments can be calculated using a host compression ratio. The host compression ratio can represent the memory constraints of a particular virtual machine and can be calculated by the control program or another application anytime a virtual machine or domain is created or destroyed or anytime a dynamic memory value or dynamic memory constraint is changed. A dynamic memory constraint can be a range of memory values used to quantify a threshold that when crossed can cause severe performance degradation. A target memory value can be calculated using the host compression ratio for example the target memory value can be calculated using the following equation Host Compression Ratio Min Dynamic Mem. 1 Host Compression Ratio Max Dynamic Mem. 

While in many embodiments the target memory amount can be a value calculated according to the above mentioned equation in other embodiments the target memory amount can be any memory value within the range of memory values between the minimum and maximum memory values. In one embodiment this range can be dictated by the dynamic maximum and minimum memory values while in other embodiments this range can be dictated by the physical maximum and minimum memory values .

In some embodiments the memory profile can include a physical memory range that corresponds to the actual physical minimum memory value and physical maximum memory value of the physical disk s . These values in many embodiments are dictated by the memory included in the computing device while in other embodiments these values can include memory within the computing device as well as virtual memory and remote memory storages accessible and available to the computing device . While illustrates a memory profile that includes a physical memory range characterized by the actual physical memory max and min of the computing device in other embodiments the memory profile may not include a physical memory range . In these embodiments the physical minimum and maximum memory values can be intuited or otherwise determined by querying a control operating system that controls the physical memory available to virtual machines executing in a virtualization environment. In most embodiments the physical minimum memory value and the maximum memory value are static memory values which cannot change unless the physical memory available to the computing device changes.

In some embodiments the memory profile for a virtual machine can be altered or configured using an application programming interface provided by the control program or the hypervisor . While in some embodiments any aspect of the memory profile can be altered in other embodiments the physical memory range cannot be altered. In some embodiments when a static memory constraint in the memory profile is altered the change takes effect when the virtual machine is rebooted. In other embodiments when a dynamic memory constraint in the memory profile is altered the change takes effect substantially immediately. In some embodiments the memory profile can have a proportional mode within which the control program or memory manager can automatically assign a target memory amount based on the dynamic minimum memory value and the dynamic maximum memory value . The control program or the memory manager in some embodiments can communicate any aspect of the memory profile e.g. the target memory amount to the balloon drivers .

In some embodiments when a virtual machine is started the memory manager or control program can configure the memory profile for each virtual machine . For example the memory manager or control program can calculate a host compression ratio for each virtual machine and can use that compression ratio to determine a target memory amount for each virtual machine . Upon determining the target memory amount the memory manager or control program can assign the target amounts to each virtual machine . In some embodiments these target amounts can represent a minimized or reduced target amount . Thus when the virtual machine boots the memory manager can cause the balloon drivers to inflate. Upon inflation the memory manager can check to see if the reduced target amount was acquired. In situations where this amount was acquired the memory manager can do nothing. In situations where this amount was not acquired the memory manager can signal a failure and can reset the target memory amount to the previous target memory amount .

Illustrated in is an embodiment of a method for reallocating and reclaiming memory from virtual machines executing in a virtualization environment. In one instance a memory manager can identify the dynamic maximum and minimum memory values associated with substantially each virtual machine executing within the virtualization environment Step and can further calculate or determine a target memory amount associated with each virtual machine Step . Upon identifying these values the memory manager can then instruct a balloon driver within the virtualization environment to inflate which can then cause the memory manager the control virtual machine A or a control program to reclaim a predetermined number of memory pages e.g. amount of memory from one or more virtual machines. In some embodiments the memory manager can request memory from each virtual machine during the reclamation process and can then reclaim memory from those virtual machines that respond to the memory manager s request Step . The memory manager can then instruct the balloon driver to deflate obtain the memory addresses of those memory pages reclaimed during the inflation process and allocate the reclaimed memory pages to those virtual machines that did not respond to the memory manager s request Step .

Further referring to and in more detail any one of the steps of the process can be carried out by a memory manager a control program the control virtual machine A or any combination thereof. In other embodiments at least a portion of the process can be carried out by the hypervisor .

In some embodiments the memory manager can obtain the dynamic minimum and maximum memory values as well as the physical minimum and maximum memory values Step . In some embodiments the memory manager can identify the maximum and minimum memory values e.g. the dynamic and physical maximum and minimum values in response to detecting a virtual machine event. This virtual machine event can be any event while in some embodiments the event can be a reboot of a virtual machine a start of a virtual machine or a change made to a dynamic constraint such as the dynamic maximum and minimum memory values or the target memory value. In one embodiment the memory manager can obtain the maximum and minimum memory values for each virtual machine within the virtualization environment. In this embodiment the memory manager can further determine or calculate a target memory value for each virtual machine within the virtualization environment using the obtained or identified maximum and minimum memory values.

Upon determining each of the dynamic and physical max and min memory values the memory manager can then determine the target memory amount for each virtual machine and can further determine whether the actual memory available to a particular virtual machine is greater than less than or equal to the determined maximum and minimum memory values Step . In some embodiments when the memory manager determines that the actual memory allocated to or used by a particular virtual machine is less than the target memory amount of that particular virtual machine the memory manager can allocate additional memory to that virtual machine. Conversely when the memory manager determines that the actual memory allocated to or used by a particular virtual machine is greater than the target memory amount for that virtual machine the memory manager can reclaim additional memory from that virtual machine. In some embodiments the memory manager can identify at least one virtual machine that has an actual memory usage value less than the target memory value or amount assigned to that virtual machine. The actual memory usage value can be the amount of memory actually used by the virtual machine . In these embodiments the memory manager can allocate additional memory to the virtual machine de allocate the additional memory and reallocate the additional memory to another virtual machine .

Allocating additional memory to a virtual machine can be accomplished by inflating a balloon driver in that virtual machine . Inflation of a balloon driver causes the control program or a memory manager resident in the control virtual machine A or the hypervisor to allocate memory page tables or memory addresses to the virtual machine executing the balloon driver . This allocated memory is assigned to the virtual machine such that the memory is no longer available to other virtual machines executing within the virtualization environment. Memory can be allocated to a virtual machine until the amount of actual memory used by the virtual machine substantially equals the target memory value for that virtual machine. In some embodiments substantially equal can mean that the actual memory usage value equals the target memory value or is a value substantially close to the target memory value .

Upon inflation of the balloon driver the memory manager can track or otherwise store the memory addresses of the memory pages allocated to the virtual machine . The memory manager in some embodiments can enumerate the memory locations addresses or page table addresses of the allocated memory after the target memory value is reached or after the additional memory is de allocated from the virtual machine . In some embodiments the memory manager can execute in conjunction with the memory management module to reclaim memory from those virtual machines identified as having an actual memory usage value greater than the target memory value for those virtual machines Step . In other embodiments the memory manager can merely track an amount of memory reclaimed from each virtual machine.

In some embodiments once the target memory value for the virtual machine is reached the memory manager can de allocate the additional memory from the virtual machine by deflating the balloon driver . In some embodiments de allocation of memory occurs once the memory manager has allocated enough memory to a virtual machine or once the balloon driver inflates enough so that the actual amount of memory used by the virtual machine equals the target memory value for that virtual machine . Once the balloon driver deflates the memory manager can then go back and re allocate memory to those virtual machines that have an actual memory usage value less than the target memory value for those virtual machines while purposefully not re allocating memory to those virtual machine that have an actual allocated memory value greater than the target memory value . In some instances the memory allocated to the virtual machine can be reallocated to another virtual machine once the balloon driver deflates and the additional memory is de allocated. Reallocating the memory can include reallocating the enumerated memory addresses or locations to another virtual machine . In other embodiments reallocating the memory can include reallocating an amount of memory equal to the amount of de allocated memory to another virtual machine . While illustrates a method where memory is requested from each virtual machine in some embodiments the method may not include this step e.g. Step .

The memory manager in some embodiments can allocate memory reclaimed during the balloon driver inflation deflation process to those virtual machines from which the balloon driver was unable to reclaim memory Step . Thus the memory manager can track from which virtual machines memory was reclaimed and from which virtual machines the memory manager was unable to reclaim memory. As stated above the memory manager can allocate reclaimed memory to non responsive virtual machines from which the memory manager was unable to reclaim memory.

In some embodiments the memory manager can allocate memory to virtual machines subsequent to the balloon driver inflation deflation process and without regard to which virtual machines were responsive to the memory manager s request for memory. In these embodiments the memory manager can evaluate each virtual machine subsequent to the balloon driver s inflation deflation process to determine which virtual machines require additional memory and which virtual machines do not require additional memory. Virtual machines are identified as requiring additional memory when their actual memory usage is below the target memory amount for those virtual machines. Virtual machines are identified as not requiring additional memory when their actual memory usage is greater than or equal to the target memory amount for those virtual machines.

The memory manager in some embodiments can rank virtual machines according to their memory requirements. Thus those virtual machines identified as requiring a large amount of additional memory resources may receive additional memory reclaimed during the balloon driver inflation deflation process first and before other virtual machines identified as requiring a lesser amount of additional memory resources. In some embodiments the memory manager can take into account whether a particular virtual machine has been identified as a priority or mission critical virtual machine and may allocate memory to that virtual machine first and regardless of whether other virtual machines require a greater amount of memory.

The method illustrated in can execute spontaneously and may be triggered by any of the following events a page fault a determination that the actual memory allocated to a particular virtual machine has fallen below the target memory amount for that virtual machine or any other similar event. In some embodiments the method can execute each time a virtual machine boots or each time the computing device boots. In other embodiments the method can execute anytime there is a virtual machine event. In still other embodiments the method can execute anytime there is a dynamic constraint modification e.g. a modification of a dynamic memory range or target memory value.

The actions carried out in this example can be carried out by a control virtual machine A a control program a memory manager a hypervisor or any other platform or application that can manage memory allocation and disk partitioning.

In one embodiment the control program hypervisor or memory manager can dynamically re partition physical memory e.g. physical disk s in response to any number of virtual machine events. The virtual machine events in some embodiments can include the creation reboot and stopping of virtual machines. When a virtual machine is started memory can be de allocated from those virtual machines already executing on the computer and re allocated to the newly started virtual machine. When a virtual machine is stopped memory can be re allocated to those virtual machines still executing on the computer .

In some embodiments the hypervisor can automatically decrease the amount of memory available to those virtual machines already executing on a computer in response to an increase in the number of virtual machines executing on the computer . In other embodiments the hypervisor can automatically increase the amount of memory available to those virtual machines executing on a computer in response to a decrease in the number of virtual machines executing on the computer . The control program or memory manager in other embodiments can maintain the memory allocation targets for all virtual machines at a substantially similar distance from the dynamic max to the dynamic min while maintaining a high target memory value . In these embodiments the substantially similar distance can be referred to as a compression ratio. Other embodiments include maintaining memory allocation targets for all virtual machines in a pool at around the same proportional distance from the dynamic min to the dynamic max .

The control program memory manager or the control virtual machine A can respond to the instantiation of a new virtual machine by dynamically reducing the amount of memory allocated to virtual machines executing on the computer . This response can be achieved by entering an iterative memory de allocation cycle whenever a new virtual machine is started on a computer that does not have available memory to allocate to the new virtual machine. This iterative memory de allocation cycle progressively removes memory from virtual machines that respond to a memory de allocation request. The cycle in many embodiments can execute until enough memory is reclaimed for the new virtual machine. The hypervisor can then rebalance the target memory values for each virtual machine subsequent to successfully starting the new virtual machine.

In some embodiments the hypervisor can start each new virtual machine with a minimum projected compression ratio where the compression ratio is defined as a relative distance from dynamic max to dynamic min compression ratio dynamic max target dynamic max dynamic min 

While certain exemplary embodiments have been described and shown in the accompanying drawings it is to be understood that such embodiments are merely illustrative of and not restrictive on the methods and systems described herein. Additionally it is possible to implement the methods and systems described herein or some of its features in hardware programmable devices firmware software or a combination thereof. The methods and systems described herein or parts of the methods and systems described herein may also be embodied in a processor readable storage medium or machine readable medium such as a magnetic e.g. hard drive floppy drive optical e.g. compact disk digital versatile disk etc or semiconductor storage medium volatile and non volatile .

