---

title: Visual display of semantic information
abstract: Techniques involving visual display of information related to matching user utterances against graph patterns are described. In one or more implementations, an utterance of a user is obtained that has been indicated as corresponding to a graph pattern through linguistic analysis. The utterance is displayed in a user interface as a representation of the graph pattern.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09524291&OS=09524291&RS=09524291
owner: Virtuoz SA
number: 09524291
owner_city: Paris
owner_country: FR
publication_date: 20101006
---
Companies continue to develop an ever increasing variety of techniques to interact with customers. For example a company may provide a website that includes details about products and or services of the company. Additionally the website may include support information or functionality to purchase products and services from the company. A customer for instance may interact with the website to find information about a prospective purchase and later after the purchase to find information regarding use of the purchase. Consequently the amount of information that is made available via these techniques is ever increasing which may make it difficult for customers to locate desired information using traditional techniques.

One such traditional technique that has been employed by the companies involves the use of search technologies. For example the company may include search technologies on a website to allow customers to hunt for answers to their questions. This may work well for certain types of queries and issues but may fail as questions become increasingly complex as issue resolution may require personalized information and so on. As a result users may walk away from the website frustrated may make a time consuming call to a human customer service representative CSR and so on. Therefore traditional search techniques may have a negative impact on user experience with the website and consequently on the user s view of the company as a whole.

Techniques involving visual display of information related to matching user utterances against graph patterns are described. In one or more implementations an utterance of a user is obtained that has been indicated as corresponding to a graph pattern through linguistic analysis. The utterance is displayed in a user interface as a representation of the graph pattern.

In one or more implementations one or more utterances are obtained that have been indicated as not included in a lexicon used for linguistic analysis. The one or more utterances are displayed in an order of frequency in a user interface.

In one or more implementations a plurality of utterances is obtained that have been indicated as not included in a lexicon used for linguistic analysis. Each of the utterances is identified during the linguistic analysis that involves forming a user input that includes the utterance into a semantic graph and comparing the semantic graphic with one or more graph patterns of an intent to determine whether the utterance corresponds to the intent. The plurality of utterances are displayed each with a respective result of a spell check operation performed using the utterance.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

Users may have access to an ever increasing variety of information from an ever increasing variety of sources such as via a website mobile communications device email instant messaging and so on. Consequently it has become increasingly difficult for a user to locate desired information from within this variety of information which may lead to user frustration with the traditional techniques used to access the information as well as the provider of the information e.g. the company itself.

Conversational agent techniques are described which include linguistic analysis and other functionalities that are described in the following sections. In various implementations conversational agents are implemented using one or more modules to engage in an interactive natural language dialog with a user via a textual chat. Thus use of conversational agents may provide automated assistance to users to help them resolve issues without directly interacting with a human agent e.g. a customer support representative in a call center . This may help a company to efficiently utilize resources and provide additional functionality to a user that was not available via traditional search techniques. The textual chat may be inputted using a variety of mechanisms such as transcripts of spoken words such as telephone calls text inputs e.g. instant messages live chat email SMS blogging and micro blogging services and so on automatic speech recognition and so forth.

Through use of linguistic analysis techniques the conversational agent may map user inputs henceforth called utterances to semantic representations. Such representations may be graphs the nodes of which represent concepts and the edges of which represent semantic roles. Such graphs will henceforth be called semantic graphs .

The conversational agent may represent a user intent by an intent graph pattern or a plurality of intent graph patterns. Thus a user utterance may be formed into a semantic graph and compared with intent graph patterns henceforth called graph patterns or simply patterns . If there is a match then the utterance likely involves the intent represented by the graph pattern or plurality of graph patterns.

Identification of patterns that are matched to a too broad too specific or incorrect group of utterances may be used to improve a conversational agent. For example a pattern that is too specific will fail to match utterances to the correct intent whereas a pattern that is too general may result in an agent intent being activated in response to utterances that should not trigger that intent.

Traditional techniques that were employed to evaluate whether a pattern is correct however generally did not take into account the range of utterances that a user may submit to the conversational agent. In the following discussion techniques are described in which a pattern s correctness may be judged by viewing which utterances are actually matched to it.

Additionally traditional techniques that employed a matching system dependent on extensive knowledge of linguistics and semantic graphs to build and improve a conversational agent may be limited in terms of their ability to scale. Even for a trained reviewer for example it may be difficult to determine that a semantic graph will match appropriate utterances and not others. Using the visual representation techniques described herein however a reviewer who understands the conversational agent s business rules may detect patterns that do not behave as expected without an extensive knowledge of linguistics. Therefore a pattern that is not functioning as intended may be removed moved fixed and so on by a wider range of reviewers.

In the following discussion an example environment is described along with example procedures that may be implemented in the example environment as well as in other environments. Accordingly the example procedures are not limited to implementation in the example environments and the example environments are not limited to implementation of the example procedures.

Likewise the network may assume a variety of configurations. For example the network may include a wide area network WAN a local area network LAN a wireless network a public telephone network an intranet a telephone network and so on. Further although a single network is shown the network may be configured to include multiple networks. For instance the client device configured as a desktop computer and the service provider may be communicatively coupled via the Internet and the client device configured as a wireless phone may be communicatively coupled to the service provider via a telephone network. A wide variety of other instances are also contemplated.

The service provider is illustrated as being implemented by one or more servers or other computing devices that are accessible to the client devices via the network . Additionally the conversational agent is illustrated as a module that is implemented by the service provider . For example the conversational agent may include a user experience that is accessible via a webpage output by the service provider to the client device configured as a desktop computer. In another example the conversational agent may include a user experience that is accessible via a spoken input received by the client device configured as a wireless phone. Thus user experience of the conversational agent may be accessed through a wide variety of techniques. A variety of other examples are also contemplated such as instant messaging email user generated content in conjunction with a social network blogging and micro blogging services and so on.

Generally any of the functions described herein can be implemented using software firmware hardware e.g. fixed logic circuitry manual processing or a combination of these implementations. The terms module and functionality as used herein generally represent software firmware hardware or a combination thereof. In the case of a software implementation the module and or functionality represents instructions e.g. program code that perform specified tasks when executed on a processing system that may include one or more processors or other hardware. The program code can be stored in a wide variety of types and combinations of memory may be employed such as random access memory RAM hard disk memory removable medium memory and other types of computer readable media. The features of the semantic clustering techniques described below are platform independent meaning that the techniques may be implemented on a variety of commercial computing platforms having a variety of processors.

The conversational agent is configured to engage in an interactive natural language dialog with a human user via textual chat to complete a specific task for or on behalf of that user. For example text entered by a user through interaction with the client device configured as a desktop computer may be provided to the conversational agent . In another example a voice input provided by the client device configured as a wireless phone may be converted to text and processed by the conversational agent the response of the conversational agent can then be converted back to speech before being sent to the client device .

Tasks may include providing information to the user answering the user s questions helping the user solve a problem support agent proposing new products and services to the user sales and or marketing agent and so on.

The conversational agent may embed complex logic flows to aid interaction with the user using natural language. The conversational agent may also interact with various application programming interfaces APIs and backend systems of a company that offers use of the agent e.g. the service provider . For example the conversational agent may be offered as a visual avatar on a company web site or a specific section of the site but other interaction channels such as instant messaging systems mobile phones email social networking sites or blogging and micro blogging services are also contemplated. The conversational agent may respond to user questions and also drive the conversation to solicit specific information to better understand the user s situation.

Utterances that are received e.g. spoken or typed by a user are parsed by a linguistic analysis module of the conversational agent and may be matched by a comparison module against a number of possible intents that are part of one or more decision trees . Based on the identified intent the conversational agent may then generate a reply. A conversation between the user and the agent may include one or more of these interactions between the user and the conversational agent .

A user s intent can be expressed in a variety of ways. For example the user s intent may be configured as a single information request may include a set of several potential information requests and so on. In the latter case the conversational agent may ask for clarification until a specific information request is identifiable and may be satisfied.

In one or more implementations conversations are modeled as paths through a set of decision trees which may be configured as circuit like structures that describe possible conversation flows. The root of each decision tree may describe an initial state before a user intent has been identified. Leaves of the decision tree may be thought of as answers to a specific request. Accordingly a path from the root to a leaf of the decision tree may represent a sequence of utterances e.g. speech acts that may lead to identification of the information requested by the user and thus completion of the conversational agent s task. In addition to a simple traversal of the decision tree the conversational agent may offer increasingly complex dialog strategies that allow the user to switch between tasks or decision trees flexibly.

The set of intents that can be matched to user utterances at a particular point in time relates to a current position of a conversation in the decision tree . For example a customer of a telecommunications company might initiate a conversation by asking Can I access my voice mail from the web Upon recognizing the intent of the question the conversational agent moves from the decision tree s root node to one of the root s child nodes. Assuming that the company delivers phone services through a cellular network landlines and VOIP the conversational agent may consult the information that is relevant to proceed in the decision tree and respond with a clarifying question e.g. What type of phone service do you use for your voice mail 

Assuming the user answers with an utterance that includes sufficient information and is recognized by the agent the conversational agent has identified the user s intent and moves to a leaf node which contains an answer to the user s question. It should be noted that a user utterance such as VOIP may be associated with a different intent when produced at the beginning of the conversation at the root of the decision tree as opposed to later in the conversation at the node corresponding to web access to voicemail.

In addition to the current position in the decision tree the conversational agent may have knowledge of pieces of information that were obtained earlier during the conversation. For example this additional information may be represented as variable value pairs which may act to limit the user from asking a same question multiple times asking for information that was already provided by user and so on. Additionally the conversational agent may implement complex and sophisticated conversation strategies. For example the conversational agent may proactively ask questions and volunteer related pieces of information based on information known about the user from the conversation or other data collected about the user e.g. via an API provided by the service provider offering the conversational agent .

The main trait of a node is the concept it represents. In an implementation concept traits e.g. modify in are abstracted over lexical variations and spelling mistakes. For example replacing the word change by alter modify or even moddify sic in the user input does not affect the structure of the semantic graph shown in . Likewise representing my and I by the concept Interlocutor makes the interpretation of the semantic form insensitive to the form used in the user utterance. For example the utterance You would like to modify your order may be parsed by the linguistic analysis module to form the graph shown in . Similarly We would like to change our order may also be parsed by the linguistic analysis module into the graph shown in .

In implementations constructions such as would like to are represented by a modal trait on the modify node and not a concept trait. Additionally this particular value may be present on one or more of the utterances I d like to I want to I wanna and so on. In this way a single representation may be provided for a variety of synonymous constructions. On the other hand use of a dedicated modal trait rather than creating a node with a want to concept trait may help to simplify the semantic graphs and thus facilitate pattern matching further discussion of which may be found later in the Pattern Matching section of the description.

The graph edges that are drawn in may be referred to as function edges with the respective labels representing semantic roles. For example in Order is the theme of Modify i.e. the object acted upon. In this is denoted by the Theme label on the edges between the two nodes denoting the theme semantic role. The Theme label may still fulfill this role even if the same relation were expressed in the passive e.g. Has my order been modified where order is a syntactic subject. Thus semantic abstraction may be used to provide a straightforward identification of common ideas in different utterances which may increase the efficiency and accuracy of a pattern matching process to be discussed later.

In the semantic graph function edges and their incident nodes form a tree. In implementations the root of the tree may be used as a placeholder that does not represent a particular concept of the utterance. For example the concept trait may be set to a value Top which is representative of the most general concept.

It should be noted that parsing may focus on extracting dependencies between words which may then be mapped to dependencies between concepts. This approach known generically as a dependency grammar does not make assumptions on phrase structure. Therefore incomplete sentences and ungrammatical sentences may be handled and mapped to a semantic graph much in the way a human may extract meaning from ungrammatical or incomplete sentences. This approach allows a conversational agent to be robust and able to understand real user utterances which are often grammatically incorrect may contain typos and spelling mistakes and may use slang words or phrases.

Because there may be a variety of spelling suggestions for a word and a lexical entry may include several words for example credit card or bill of sale the lexical module of the conversational agent may map a word sequence of the user utterance to one or more flexion sequences. A flexion is a lexical entry that includes a lemma i.e. an uninflected form and possibly grammatical marks such as tense number person mood and so on. For example the lemma agent may have the flexions that include agent and agents. 

In an implementation the lexicon that is used to match words to flexions is language dependent. Additionally some of the entries contained therein may be specific to a business area a conversational agent and so on. For example lexical entries may include names of forms specific to a business area or commercial names specific to the conversational agent . Accordingly lexicon lookup may be filtered by word spaces where a word space characterizes a conversational agent or a business area.

At the syntactic module level information that is common to the flexions of a given lemma is stored in a dictionary . This information may include 1 construction information and 2 ontology information. Ontology information pertains to the semantic level and provides the concept traits which are further mentioned in the Parsing and semantic representations of input sentences Section and . Construction information includes possible part of speech assignments to a lemma. For example format may be assigned both verb and noun constructions. Construction information may also include syntactic patterns linking the dictionary item to other items. For example the construction for format as a verb may show that the item relates to a noun with a subject link and to another noun with an object link.

A unification based algorithm may be employed to unify available constructions of the lemmata i.e. a plurality of lemma in a sequence to yield one or more syntactic graphs. In addition to part of speech information linearity information e.g. in English a tendency of objects to occur after verbs and the confidence assigned to the recognition of particular constructions may be taken into account to score the graphs.

At the semantic module level a highest scoring syntactic graph is mapped to a semantic graph . As a result of this process a semantic graph having increased abstraction is obtained in which nodes represent ontology concepts and edges represent logical relations between the concepts.

Ontology may be represented as a language independent concept hierarchy. This hierarchy may be represented using a directed graph with two types of edges is a kind of and subsumes. In the example shown in for instance a password is a kind of certificate or credentials and is a kind of secret or arcanum . In turn secret or arcanum also subsumes esoterica and kabbalah while certificate or credentials subsumes login name identity card and diploma .

For illustration purposes suppose the conversational agent has been designed to help users change their password on the web site that embeds the conversational agent s user experience . A user may express this request in a variety of ways. Consider for example the user utterances How does one change one s password How to change password How should I go about changing my password Need to change my password. How do I do that and Would you be so kind as to tell me how to modify my password Each of these wordings contain the concepts how and change password with substantial variation in the exact way these two concepts are linked to each other as well as in the use or omission of pronouns.

One way to capture an intent common to these utterances is through use of semantic representations that contain graph fragments. depicts an example implementation of a graph pattern that includes graph fragments for 1 change password with password functioning as the theme of change and 2 how . These fragments form a graph pattern which for purposes of the discussion that follows may be simply referred to as a pattern . An utterance is considered as matching this pattern if each of the pattern fragments occurs in a semantic graph of the utterance. It should be noted that this is a condition that is considered sufficient for matching further discussion of this and other conditions may be found in relation to the following section.

For example semantic graphs for how to change password and need to change my password. How do I do that both contain these fragments examples of which are illustrated in the implementation of . In this implementation examples of semantic graphs that match the two graph fragments of are shown.

Suppose the conversational agent has been created to explain how to change credentials i.e. user ID and or password rather than a password specifically. Accordingly a pattern may be defined to match questions about how to change one s password as well as a user ID or other credentials. This is an example of a situation in which information to be provided by the conversational agent may be described by a general concept that subsumes a number of more specific concepts that are likely to occur in user utterances. For example the conversational agent may deliver generic information about connecting an Internet router but requests for this information are likely to mention specific router brands and models.

Concept subsumption may provide flexibility to the conversational agent . In implementations the conditions that are to be met for a match to be considered between a semantic graph and a pattern are stated as follows A pattern matches a semantic graph if and only if a subgraph of the semantic graph subsumes the pattern. Continuing with the previous example a simple example of graph subsumption would be the semantic graph for change credentials as subsuming the graph for change password an example of which is shown in the implementation of .

In given that ontology defines password as a child of credentials as previously discussed in relation to Graph subsumes Graph in this implementation . More generally a graph g subsumes a graph g if and only if g can be transformed into g by zero or more applications of the following operations 

Trait subsumption has been illustrated in for concept traits. However it should be noted that trait subsumption may be defined on a variety of traits including function labels on edges. Here are other examples 

Subsumption for modal values is based on sets of possible values. Either a trait takes its value in a hierarchy e.g. edge labels ontology concepts or in a collection of sets. For example the modal value MUST is really a singleton set that includes a single instance of MUST. 

In addition to capturing stylistic variations on a question matching also helps capture logically distinct but equivalent ways of expressing the same intent. For example a user might ask how she can change her password by typing How can I change my password or by typing Can you help me change my password Therefore a single intent is not usually captured by a single graph pattern. Accordingly several graph patterns may be used. This set of patterns forms a logical disjunction meaning that in order to match the intent a user utterance matches at least one of the patterns.

A set of possible intents may be associated with each position in a conversational agent s decision tree . This set is the union of the intents of the child nodes at that position in the decision tree . Each of the possible intents at the current decision tree position is represented by a set of graph patterns. The set of patterns collectively representing each of the possible intents at a current position are referred to as the active patterns in the following discussion.

Given an utterance and a current position in the conversational agent s decision tree the conversational agent may perform the following steps to determine user intent 

If no successful match can be found in step 2 above we say that the utterance is unmatched. In such a case the conversational agent may not have the linguistic knowledge to assign an intent to this utterance.

A number of metrics may be used to measure a distance between a graph of an utterance and a matching graph pattern in the conversational agent s knowledge. These metrics may combine one or more of the following quantities algebraically 

The matching distance between two trait values quantity henceforth called subsumption distance may be computed as a function of 

The conversational agent may also leverage indirect patterns that are assigned low confidence and may be used in cases when the conversational agent is not sure of the user s intent. Exclusive or direct patterns may take precedence over non exclusive or indirect patterns when identifying a user s intent by the conversational agent . If the user s utterance does not match one or more direct patterns each indirectly matching intent may be considered as potentially relevant. The conversational agent may then offer the user a list of question rewordings or a list of potentially relevant topics or questions. This may occur when a user has entered several keywords but not a full sentence or phrase that more fully describes what is being requested.

For example a user may type cashback which might mean How does cashback work or I never received my cash back. A designer of the conversational agent may address this situation in a variety of ways examples of which include the following 

The first method may be useful in specific situations for conversational agents where several keywords or ideas are used throughout by the agent in a wide variety of contexts. Therefore more precise information is to be gathered to differentiate between them. The second method that relies on indirect patterns makes it possible to deal with intent ambiguity with minimal demands on designer time.

As previously described identification of patterns that are matched to a too broad too specific or incorrect group of utterances may be used to improve a conversational agent. For example a pattern that is too specific will fail to match utterances to the correct intent whereas a pattern that is too general may result in an agent intent being activated in response to utterances that should not trigger that intent. Traditional techniques that were employed to evaluate whether a correct match was generated however generally did not take into account the range of utterances that a user may submit to the conversational agent because they were based on best practices rather than data driven. In the following discussion techniques are described in which a pattern s correctness may be judged by viewing which utterances are actually matched to the pattern.

Additionally traditional techniques that employed a matching system dependent on extensive knowledge of linguistics and semantic graphs to build and improve a conversational agent may be limited in terms of their ability to scale. Even for a trained reviewer for example it may be difficult to determine that a semantic graph will match appropriate utterances and not others. Using the visual representation techniques described herein however a reviewer who understands the conversational agent s business rules may detect patterns that do not behave as expected without an extensive knowledge of linguistics. Therefore a pattern that is not functioning as intended may be removed moved fixed and so on by a wider range of reviewers.

Further it may be difficult to understand why an utterance matched to a specific pattern in instances in which the mapping between semantic graphs and graph patterns cannot be easily understood. In one or more implementations the visualization techniques described herein may be used to visually indicate which parts of an utterance matched a pattern. This indication may therefore make it easier to understand why a pattern is matched to unexpected utterances.

Yet further when a pattern is added to a conversational agent it may be difficult to determine whether that pattern could be erroneously matched to utterances. In implementations visual representations that are based on real user utterances are utilized to show the effect of each particular pattern.

Users also generally expect that a conversational agent will address most if not all of the user s inputs when providing answers during a conversation. Therefore evaluation of whether a specific utterance triggered the correct agent intent may involve review of a conversation that includes the utterance. Information gained in this manner may be used to improve a pattern remove or alter the pattern if it is determined that the utterances should not trigger this agent intent and so on. Further discussion of these techniques may be found in relation to the following sections.

Use of inverse frequency as a specificity metric generally provides a sufficient approximation to measure the specificity of a concept i.e. its ability to characterize a specific topic. However topic selectivity may be measured in a more direct way namely by comparing a unigram distribution of concepts in a corpus with a conditional distribution of terms in utterances containing the concept to measure. For example a neutral concept like interlocutor typically occurs in a subcorpus whose concept distribution does not essentially differ from the distribution of terms in the whole corpus. Conversely a specialized concept like spark plug typically occurs in utterances forming an automotive subcorpus meaning that in this subcorpus automotive terms will be overrepresented and terms representative of other specialized topics e.g. cooking or finance are underrepresented with respect to the overall corpus. A variety of heuristics may be used to perform such a comparison between distributions examples of which include vector space sine and the Kullback Leibler divergence.

As shown in an example implementation of a conversational agent system in conversational agent bricks are illustrated as modules implemented via respective servers . The conversational agent bricks process user utterances by parsing the user utterance matching it to one or more patterns to determine the intent and applying logic that corresponds to that intent in order to generate an answer as previously described.

During the course of processing the user utterances a variety of different types of information may be logged by the conversational agent bricks to a respective log file . For example the logged information may include information about which direct or indirect pattern was activated as a result of the matching process for a user utterance a mapping between nodes of the pattern and the words of the user utterance that are captured and so on. Thus the mapping may be produced by the conversational agent bricks during a matching process and data that describes this mapping may be included in the log files .

In the illustrated example of data from the log files is communicated to a log repository and illustrated as communicated log files . Thus the log repository may act as a central collection point for the log files from the conversational agents .

A log extractor module is also illustrated as included on the log repository . The log extractor module is representative of functionality to process the log files and extract the information pertaining to the parsing and matching of user utterances which may be summarized in an input summary .

The input summary generated by the log extractor module may be periodically processed by a data mining module which is illustrated as part of a log processing service. For example the data mining module may update information in a pattern database such as a number of activations for each pattern contained in a conversational agent as well as a list of one or more sample user utterances that led to that pattern s activation.

In one or more implementations the pattern database includes the following information for each pattern 

The system is also illustrated as including a web application that is configured to allow a reviewer to use a web browser to display the information in the pattern database . Naturally other examples are also contemplated without departing from the spirit and scope thereof.

The list of matched utterances e.g. also referred to as input sentences in the following example but other utterances are also contemplated such as words abbreviations and so on may contain each user utterance encountered over a given time interval or a subset thereof. For a conversational agent that processes a large volume of conversations for instance the list of matched utterances may contain a subset of the user utterances in order to reduce the amount of memory consumed by the pattern database .

The utterances included in the subset may be chosen to represent which intent is captured by the pattern. For example the data mining module may keep user utterances that contain a minimum amount of information based on a specificity metric that was computed earlier when mining the data by the data mining module . This metric is computed based on each of the concepts found in the user utterances sent to the conversational agent bricks and associates a score to each concept. This score represents the specificity of a concept in the given context of the conversational agent as described above.

As the data mining module may perform the data mining periodically in an implementation a list of matched utterances containing a subset of user utterances may already exist in the pattern database when the data mining module updates the data associated to a given pattern . Accordingly when the data mining module processes an entry in the input summary file corresponding to a specific pattern pand user utterance i the data mining module may update the list of matched user utterances for pand select which user utterances will be kept in the subset. The following steps may be performed 

In an implementation by using a web browser connected to the web application shown in a reviewer can see which sentences have been captured by a given pattern . For example the web application may use the information in the pattern database to retrieve the list of matched user utterances associated to the given pattern . The matched words of each user utterance may be indicated e.g. highlighted to help the reviewer to understand why the user utterances resulted in the activation of the pattern examples of which may be found in the discussion below.

Further using the techniques described herein a reviewer may gain additional context about an input sentence e.g. to better understand either the behavior of the agent or what the user really meant. To do so for each user utterance displayed for a pattern the web application may allow the reviewer to navigate to a page that displays the entire conversation in which the utterance occurred. In an implementation the web application uses the unique identifier of the conversation which is stored in the pattern database as previously described to navigate to the conversation reading page of a web analytics application to display this conversation as further detailed below.

As shown in the communicated log files generated by the conversational agent bricks are also processed by an analytics pipeline. In the analytics pipeline each of the conversations are extracted from the logs by an analytics module and stored into a database called an analytics dialog store . In this database the conversations are indexed according to their conversation identifier which is taken from the logs and consequently is the same as the one used in the data mining pipeline described in relation to . The analytics dialog store is illustrated as being accessible by a web analytics application which in an implementation may also be accessed by a reviewer using a browser as previously described.

A conversational agent may not understand some of the words employed by a user in one or more user utterances. For example the conversational agent may be unable to find in its lexicon the word as it is spelled during lexical parsing of an input. In this case the conversational agent may employ spell checking functionality to produce suggestions for alternative spellings. For instance a spell checker may be able to produce an alternate spelling that is contained in the conversational agent s lexicon such as in an instance in which the user made a spelling mistake.

However in some cases the conversational agent s lexicon may lack a specific word. For instance the lexicon may not contain an entry for the word bump . If the word is significant in the context of the conversational agent for instance it is a brand or product name or a term used to describe a specific condition this lack may be indicated to a reviewer so that the missing word can be eventually added to the conversational agent s lexicon . Further techniques may be employed to prioritize the missing words that have been detected. Therefore a reviewer may focus on the words that have at least a certain amount of impact on the comprehension of the agent e.g. occur in a large number of user utterances.

To detect the missing words the data mining module described in relation to may collect input sentences from conversations and perform an additional function as shown in the example system of . The data mining module extracts user utterances ifrom the input summary and performs a lexical parse on the user utterances i. As described previously this lexical parse may map the word sequence to one or more flexion sequences. In the flexion in addition to the lemma and grammatical marks the parse adds the information provided by the spell checker if the latter was activated.

Using the parse results the data mining module extracts the words that do not have an entry in the lexicon and updates a missing word database . Each entry for a missing word in this database may contain the following information 

At this stage the missing words database contains information about which words are unknown in the lexicon and possible suggestions provided by the spell checker if any for the missing words. By a similar process as the one used to associate user utterances to patterns as described in the collecting user utterances from conversations section above a subset of user utterances may be kept as the list of user utterances to illustrate the user utterances where the missing word was found. For each missing word a count of occurrences may be maintained to help the reviewer gauge how important it may be to add the missing word to the lexicon.

Additionally the data mining module may also periodically check that each of the missing words currently stored in the missing words database are still missing i.e. have not been added to the agent lexicon yet. In an implementation if a missing word has been added and thus is no longer missing the missing word is not removed from the missing words database but is marked as recently added . This attribute is used to suppress display of the added missing words using the web application even if further input summary files are processed that were generated by a version of the conversational agent bricks that does not yet reflect the lexicon update.

As previously described direct manipulation of graph patterns is generally not practical for a broad group of reviewers. By using the techniques described herein however patterns can be manipulated by a wide variety of reviewers through use of a representation based on user utterances that matched to that pattern. Examples of which representations are described in the following sections.

As shown in an example user interface of a minimized representation may be used to show a single sample user utterance that is matched to a corresponding pattern and the pattern s popularity or status . Examples of this are illustrated for patterns using first second and third user utterances in the user interface . For example a pattern can be popular a pattern may be unpopular or a pattern may be unused . The minimized representation may also have a respective control to expand the respective representation to a maximized representation an example of which is shown in .

When the web application of is used to display patterns using the minimized representation it may use information stored in the pattern database as follows 

When the web application of displays a pattern using the maximized representation it may use the information stored in the pattern database and the missing word database as follows 

As previously described a conversational agent s intent may be associated with multiple patterns. Additionally direct patterns may be used to trigger the agent intent upon comparison. Indirect patterns may be used to add the intent to a list of reformulations of the user s question in an instance in which direct patterns are not activated.

The reviewer may use the web application of to display an agent s intent and its associated patterns an example of which is shown in the example implementation of a user interface in . As illustrated a reviewer may independently maximize or minimize the patterns for each conversational agent intent to view patterns of interest.

In some instances expansion of a conversational agent s lexicon may improve operation of the agent. To do this incoming user utterances may be scanned for words that are not already in the lexicon . To improve efficiency of the process the most commonly occurring missing words may be added first to the agent s lexicon thereby likely achieving a greater effect in comparison with missing words that are not as commonly used.

In some cases the missing words simply involve spelling errors that the spell checker was or was not able to correct. The missing words may also be relatively uncommon in the standard language. In other cases these missing words are the names of features products brands companies or other terms specific to that conversational agent. As a company introduces new products services and terms the conversational agent s lexicon can be enhanced.

To help a reviewer in deciding whether to add the missing word and what it means the user interface may display the word in the context of several input sentences containing that word. For example corresponding user conversations may be made available for the user utterances.

When the web application of displays missing words using the representation it may use the information stored in the missing word database as follows 

A result of activation of the control is illustrated in an example user interface of the example uses the missing word bidmaster for illustrative purposes . For each user utterance the reviewer may also view a full conversation containing this user utterance by selecting another control as previously described.

When the web application of displays the interface it may use the list of user utterances stored in the missing word database to display the list of sample user utterances corresponding to a missing word. Again although words were described in the missing word examples a wide variety of types of user utterances are contemplated such as phrases abbreviations short hand and so on.

Although the invention has been described in language specific to structural features and or methodological acts it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as example forms of implementing the claimed invention.

