---

title: Interface converter for unified view of multiple computer system simulations
abstract: Providing a unified view of multiple computer system simulations. A simulation process has a simulation thread that executes a plurality of computer system simulations. The simulation process also has a debug support thread that provides a unified view of the simulations. To provide the unified view, the debug support thread has an external interface, an internal interface to each of the simulations, and an interface converter that converts between the external interface and the internal interfaces. Thus, the external interface provides a unified view of the simulations. The external interface allows a single debugging platform to control and observe the simulations.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08793115&OS=08793115&RS=08793115
owner: Synopsys, Inc.
number: 08793115
owner_city: Mountain View
owner_country: US
publication_date: 20100511
---
This continuation application claims the benefit of the co pending commonly owned U.S. patent application Ser. No. 11 066 841 entitled INTERFACE CONVERTER FOR UNIFIED VIEW OF MULTIPLE COMPUTER SYSTEM SIMULATIONS with filing date Feb. 25 2005 and hereby incorporated by reference in its entirety.

This Application is related to U.S. patent application Ser. No. 11 066 945 by VanSpauwen et al. filed on Feb. 25 2005 entitled Method For Dynamically Adjusting Speed Versus Accuracy Of Computer Platform Simulation with and assigned to the assignee of the present invention.

Embodiments of the present invention relate to the field of software tools for debugging computer architectures using simulations such as processor software and hardware simulations. Specifically embodiments of the present invention relate to methods and systems that provide a single debugging platform with a unified view of multiple simulations.

Recently the evolution of embedded systems has shown a strong trend towards application specific single chip solutions. As a result application specific instruction set processors ASIP are more and more replacing off the shelf processors in such systems on chip SaC . One of the key factors for a successful design of application specific instruction set processors ASIP is an efficient architecture exploration phase. The objective of the architecture exploration is to reduce the huge design space in order to find the best suited architecture for a given application under a number of constraints such as performance power consumption chip size and flexibility. Although there are a number of analytical approaches large parts of the design space exploration still have to be carried out by simulating alternative architecture implementations. Therefore design methodology and simulation performance have a significant impact on the efficiency of the exploration process and hence on the quality of the architecture implementation and the design time.

One implication of this conventional environment is that the various debuggers are not synchronized. For example if the hardware simulation is halted e.g. hits a watchpoint the two processor core simulations are unaware of this event and are thus not synchronized with the hardware simulation. Furthermore the lack of synchronization prevents rewinding the simulations together to view a previous synchronized state of the simulations. Another drawback of the conventional environment is that because a debugger can only set a breakpoint or watchpoint for an event in a simulation that it controls breakpoints watchpoints involving multiple simulations are not possible.

Therefore it would be advantageous to provide a method and system that facilitates debugging a computer system platform using multiple simulations for different aspects of the platform. It would be further advantageous if the method and system allows a unified view of the multiple simulations to the platform developer. It would be still further advantageous if the method and system allowed the simulations to be rewound with synchronization of the simulations preserved. It would be still further advantageous for the method and system to allow breakpoints watchpoints involving events in multiple simulations.

Accordingly embodiments of the present invention provide methods and systems that provide a unified view of multiple simulations being used to simulate different aspects of a computer system platform. The unified view allows a single debugger to control and observe all simulations. The simulations may include a processor core simulation a hardware simulation or the like. Embodiments of the present invention allow the simulations to be rewound with synchronization of the simulations preserved. Embodiments of the present invention allow breakpoints watchpoints involving events in multiple simulations. Embodiments of the present invention provide these advantages and others not specifically mentioned above but described in the sections to follow.

One embodiment in accordance with the present invention is a computer readable medium having stored thereon instructions for implementing a method of providing a unified view of multiple computer system simulations. The instructions comprise a simulation process having a simulation thread that executes a plurality of computer system simulations. The simulation process also has a debug support thread that provides a unified view of the simulations. To provide the unified view the debug support thread has an external interface an internal interface to each of the simulations and an interface converter that converts between the external interface and the internal interfaces. Thus the external interface provides a unified view of the simulations. The external interface allows a single debugging platform to control and observe the simulations.

In another embodiment in addition to the above the instructions include a debugger process that is operable to communicate with the debug support thread via the external interface. Thus the single debugger has debug access to control and observe each of the simulations.

Another embodiment in accordance with the present invention is a computer implemented method of providing a unified view for debugging with multiple simulations such as processor core and hardware simulations. The method comprises receiving a request from a debugging process for debugging access to one of a plurality of simulations in a simulation process. The debugging access may be for controlling or observing a simulation. The simulations have different debugging interfaces from each other. The request is converted to a format that is compliant with the debugging interface of the simulation specified in the request. The converted request is passed on to the simulation via its debugging interface. Therefore the converting and passing the request provides the debugging process a unified view of the simulations.

In the following detailed description of embodiments of the present invention numerous specific details are set forth in order to provide a thorough understanding of the present invention. However it will be recognized by one skilled in the art that the present invention may be practiced without these specific details or with equivalents thereof. In other instances well known methods procedures and components have not been described in detail as not to unnecessarily obscure aspects of the present invention.

Some portions of the detailed descriptions that follow are presented in terms of procedures steps logic blocks processing and other symbolic representations of operations on data bits that can be performed on computer memory. These descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. A procedure computer executed step logic block process etc. is here and generally conceived to be a self consistent sequence of steps or instructions leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated in a computer system. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like.

It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussions it is appreciated that throughout the present invention discussions utilizing terms such as identifying or receiving or converting or processing or passing or computing or determining or maintaining or storing or constructing or accessing or selecting or forming or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

Embodiments of the present invention allow a computer system platform developer to have a unified view of the platform under development. Embodiments of the present invention provide a unified view of various simulations being used to simulate the computer platform. For example by allowing a unified view of multiple simulations embodiments of the present invention allow a user to observe and control one or more processor core simulations a hardware simulation etc. from a single debugging application. Embodiments of the present invention allow breakpoints and watchpoints to be set using a combination of events in different simulations.

The simulation kernel thread controls the execution of the various simulations. In one embodiment the simulation kernel thread invokes the various simulations wherein each simulation is allowed to execute for up to a pre determined number of clock cycles without stopping to for example synchronize with other simulations. The pre determined number of clock cycles is referred to herein as a quantum. The simulation may halt prior to the end of the quantum of clock cycles. For example if the simulation encounters a breakpoint or watchpoint it halts prior to completing the quantum of clock cycles.

The quantum is dynamically adjustable and may be based on simulation events. If the quantum is set relatively high the computer system platform simulation may be faster but possibly less accurate. If the quantum is set lower the platform simulation may be slower and possibly more accurate. For example a hardware designer may desire a very accurate simulation whereas a software developer may desire a faster simulation and be willing to trade some accuracy.

The platform debugger is a tool that allows a user to observe and control the simulations wherein the platform being simulated may be debugged. The debug support thread comprises an interface converter that allows the platform debugger to have a unified view of all of the simulations in the simulation kernel thread . The interface converter presents an external API to the platform debugger . Each of the simulations has a debug interface that allows observation and control of the actual simulation. The interface converter has API converter blocks that each convert from the external API to the respective debug APIs used by each of the simulations.

Thus the platform debugger has a uniform view to observe and control the simulations . For example the platform debugger may use an API call to inspect or to modify a simulation. In one embodiment to facilitate synchronization of the simulations API calls that modify a simulation are allowed only when the simulation is halted. The inter process communication between the platform debugger and the simulation process is implemented with the Common Object Request Broker Architecture CORBA in one embodiment. However inter process communication is not limited to CORBA. The platform debugger may execute on the same computer system as the simulation process . Alternatively the platform debugger executes on a different computer system than the simulation process . If desired stand alone debuggers not depicted in that control and observe only one simulation may be added to the debugging environment.

Some of the simulations may have a software wrapper in order to allow inter simulation communication. For example the CPU and CPU simulations each have their own software wrapper to allow communication with the hardware simulation . However the platform debugger does not need the software wrappers to control and observe the simulations .

Still referring to the simulation process comprises a control mechanism for halting and starting execution of the simulation kernel thread . Furthermore embodiments of the present invention synchronize the various simulations at various points in their execution. In other words the simulations are halted at a common point in execution. For example the simulations may execute sequentially and may be aware of a common clock such that each simulation can be halted at the same clock cycle e.g. a common point in their respective executions . In one embodiment the control mechanism comprises a semaphore although the present invention is not so limited.

The debug support thread allows continued viewing of the simulations when they are halted. When a breakpoint or watchpoint condition is detected the control mechanism is used to halt execution of all simulation processes. For example if the CPU simulation detects that a breakpoint is hit it may signal the control mechanism which halts the execution of the entire simulation kernel thread .

While the simulation kernel thread is halted the debug support thread continues to run wherein the platform debugger has continued visibility to the simulations. In order to wake up the simulation kernel thread the debug support thread may signal the control mechanism wherein the simulation kernel thread resumes execution.

As used herein the term thread may apply to an operating system process. However as used throughout this description the term thread is not limited to an operating system process. In some embodiments the thread may be a part of an application program process.

Embodiments of the present invention allow a user to set halt points in the simulations. Halt points may include breakpoints watchpoints and the like. A breakpoint typically refers to a location in code wherein the simulation halts and passes control of execution to the debugger when the code is hit. A watchpoint typically refers to a data access e.g. a read or write of memory hardware register etc. wherein a simulation halts and passes control of execution to the debugger when the data access occurs. Haltpoints are not limited to the examples herein and may be triggered by any event related to a simulation.

Furthermore embodiments of the present invention allow a user to set multi simulation halt points. As used throughout this description the term multi simulation halt point multi simulation breakpoint multi simulation watchpoint multi simulation breakpoint watchpoint or the like means that the halt point or the like is based on events in two different simulations. For example the events may be the combination of the program counter in the CPU simulation reaching a user defined value and an access to a register of a hardware simulation .

Step is converting the request to a format that is compliant with a debugging interface of the requested simulation. Step may be performed by one of the interface converter blocks .

Step is passing the converted request to the simulation via the debugging interface. Thus the debugging process e.g. platform debugger has debugging access to the simulations. Throughout this application the term debugging access with respect to a simulation means access that allows control and observation of the simulation. In one embodiment the request is for establishing multi simulation breakpoints.

Step is storing synchronized results of the simulations in a database. The database stores information that allows the results from each simulation to be compared at like points in time or execution. Embodiments of the present invention allow the simulations to be rewound such that stored values may be viewed by the debugger. Moreover the synchronization of the simulations is maintained. Moreover the debugger can step through the results wherein the results of all simulations are stepped together.

Step is rewinding the simulations. For example the results stored in the database are presented to the debugger wherein the debugger views the results synchronized by time as measured by clock cycles.

When the breakpoint is hit the processor core simulation sends a message to the control mechanism indicating the time at which the breakpoint occurred arrow . In order to facilitate synchronization of the various simulations the processor core simulation executes in a run ahead loop and allows other simulations to catch up after a breakpoint is hit in one embodiment. As previously discussed the simulations may be invoked by the simulation kernel thread to each execute up to a pre determined number of clock cycles. If a simulation hits a breakpoint while executing its quantum of clock cycles it notifies the simulation kernel thread of the time at which the breakpoint is hit such that the other simulations can execute up to that point in time rather than the entire quantum. Thus when the processor core simulation hits the breakpoint it breaks from its run ahead loop and tells the control mechanism to break at time T where T is the point where the breakpoint occurs arrow . The processor core simulation then waits until it is notified by the simulation kernel thread that the other simulations have caught up.

The simulation kernel thread will schedule other simulations e.g. other processor core simulations hardware simulation for execution which allows them to synchronize e.g. catch up with the core processor simulation that hit the breakpoint. The control mechanism may subscribe to a time advance callback of the simulation kernel thread arrow so that it is the first to be notified when time T is reached. When time T is reached the simulation kernel thread notifies the control mechanism arrow which then unsubscribes from the time advance notification arrow and waits on the control mechanism to suspend the simulation kernel thread arrow . Thus all simulations in the simulation kernel thread are suspended and are also synchronized. The debugger platform still has complete visibility of all the simulations through the debug support thread.

To re start the simulations the user inputs a command into the platform debugger arrow . In response to the command the platform debugger sends a message to the debug support thread to initiate re start of the simulation arrow . In response thereto the debug support thread signals the control mechanism to re start the simulation kernel thread arrow . The simulation kernel responds to the control mechanism by re starting execution of all simulations arrow .

A user may also wish to break at a certain simulation time or have complex breakpoint conditions that involve time . This can be implemented very similar to a breakpoint depicted in . In one embodiment an event is scheduled in the simulation at the time specified by the user. When this event is triggered by the simulation it sends a message to the control mechanism passing the current time as a parameter similar to arrow in . Then steps similar to arrows and of may be taken in order to help synchronize the simulations. When the control mechanism receives a callback from the simulation kernel similar to arrow of the simulation kernel thread will wait on the control mechanism similar to arrow of .

Watchpoints may be used to suspend the simulation when a hardware register is read or written in embodiments of the present invention. depicts a sequence diagram for implementing a watchpoint in accordance with an embodiment of the present invention. A user inputs the desired watchpoint to the platform debugger arrow . In response the platform debugger sends a message to the debug support thread indicating the watchpoint arrow . The debug support thread invokes the interface converter to send messages to a processor core simulation and to the hardware simulation indicating the watchpoint arrows and . In this case the watchpoint is an event e.g. memory or register access that the hardware simulation will detect. The processor core is made aware of the watchpoint for purposes of synchronizing the halting of the simulations which will be discussed herein below.

In one embodiment the processor core simulation runs ahead of time. If the processor core simulation model determines that it is about to access a part of the hardware that has a watchpoint associated with it the processor core simulation model will first synchronize with the other simulation models before doing the hardware access effectively allowing them to catch up. Thus the processor core simulation model may notify the control mechanism arrow and the simulation kernel arrow as if a breakpoint were hit. The simulation kernel may then schedule other simulation models to allow them to catch up to the processor core simulation model.

However instead of halting the simulation thereafter the processor core simulation model continues and executes the instruction that accesses the hardware simulation arrow . If the hardware simulation detects that the watchpoint is hit it notifies the simulation kernel of this fact arrow . As soon as the hardware access is over control is returned to the processor core simulation model which asks the simulation kernel to process any watchpoint that have been hit by the previously executed instruction arrow . If the simulation kernel determines the watchpoint was hit it waits on the control mechanism to suspend the simulation kernel thread arrows and .

To re start the simulations the user inputs a command into the platform debugger arrow . In response to the command the platform debugger sends a message to the debug support thread to initiate re start of the simulation arrow . In response thereto the debug support thread signals the control mechanism arrow . The simulation kernel responds to the control mechanism by re starting execution of all simulations arrow .

Computer system includes an address data bus for communicating information a central processor coupled with the bus for processing information and instructions a volatile memory e.g. random access memory RAM coupled with the bus for storing information and instructions for the central processor and a non volatile memory e.g. read only memory ROM coupled with the bus for storing static information and instructions for the processor . The instructions may include steps of process of or process of . Computer system also includes an optional data storage device e.g. a magnetic or optical disk and disk drive coupled with the bus for storing information and instructions. The simulation results may be stored optional data storage device or volatile memory .

With reference still to system may also include an alphanumeric input device including alphanumeric and function keys coupled to bus for communicating information and command selections to central processor unit . For example a user may input commands to the platform debugger via alphanumeric input device . System may also include a cursor control device coupled to bus for communicating user input information and command selections to central processor unit . System of the present embodiment may also include a display device coupled to bus for displaying information. For example the platform debugger may be a graphical debugger capable of displaying data and graphics from the simulations. In one embodiment the platform debugger executes on a device external to computer system . Computer system has a signal input output communication device coupled to bus providing communication with external devices for this and other purposes.

The simulation models are capable of cycle accurate simulation in one embodiment. However the simulation models may be executed in a mode that is less than cycle accurate while still achieving behaviorally correct simulation results. Embodiments of the present invention increase simulation speed without sacrificing accurate results by reducing the impact of simulation bottlenecks. An example of a bottleneck in the simulation is the communication between one of the CPU simulations and the memory simulation . Another example of a bottleneck is between one of the CPU simulations and one the hardware simulations which may be modeling a peripheral component. Moreover a bus simulation may be invoked in a cycle accurate simulation which provides greater simulation accuracy but may reduce the simulation efficiency.

For a cycle accurate simulation clock signals may be used to synchronize the different simulations as may be done in the architecture being simulated . A large portion of the work of the simulation engine is to manage and schedule clock signals. Embodiments of the present invention reduce the simulation engine s clock management workload by reducing the number of times that the simulations e.g. are synchronized. Instead of synchronizing the simulations each clock cycle embodiments of the present invention synchronize every quantum of execution units. The quantum is a number of clock cycles in one embodiment. However the quantum may be any convenient unit of execution.

Using a quantum allows a simulation to execute many clock cycles without having to stop to synchronize. For example a CPU simulation model may execute dozens hundreds thousands or more instructions in a row without having to stop to synchronize with the other simulation models. The CPU simulation may not be dependent upon an event in another simulation for a substantial time period. Thus the CPU simulation result may be behaviorally accurate without synchronizing even though the CPU simulation is not cycle accurate.

Referring to the simulations may be invoked by the simulation engine wherein each simulation is allowed to execute up to the quantum of execution units e.g. clock cycles without stopping for example to synchronize with another simulation. Thus simulation may execute its quantum block followed by simulation block then the rest of the simulations may be invoked blocks . At that point the simulations are synchronized Simulation Time Ti . It is not required that the simulations be executed one at a time. For example the simulation models could execute in parallel on different processors of a multi processor system. However the simulation models are allowed to execute a quantum of instructions without the need to stop and synchronize with another simulation.

It is not required that each of the simulations are actually invoked every time it has a chance to run. For example it is possible that a hardware simulation may not have any work to do for its quantum in which case it might not be invoked or invoked and shut down quickly. In some embodiments of the present invention the simulation models have an internal clock that is shut off when the simulation is asleep to save the overhead of the clock running. Thus the simulations can be written to be responsive as opposed to having autonomous behavior. As an example peripheral hardware may be modeled to be responsive or mostly responsive rather than autonomous. Furthermore the bus simulation model may also be written to be responsive. This allows a processor simulation to execute very large numbers of instructions while still providing a behaviorally accurate simulation.

To ensure behavioral correctness of the simulation the quantum may be dynamically adjusted so that a simulation does not run past an autonomous event scheduled in another simulation. Referring again to an autonomous event may be scheduled to occur in simulation at a known time. Simulation informs the simulation engine of this autonomous event and its simulation time at some convenient time prior to the autonomous event. The simulation engine stores this and other simulation events . The simulation engine dynamically adjusts the quantum such that other simulations do not run past this autonomous event.

In a typical scenario the autonomous event may be an event scheduled to take place in a hardware simulation. An embodiment of the present invention typically schedules a processor simulation prior to memory and hardware simulations. Thus in order to keep the processor simulation from running past the scheduled event in for example a hardware simulation the quantum is reduced in size prior to the processor simulation being invoked. If the frequency of events in memory bus or hardware simulations is too high the quantum can be negatively impacted. However as described below embodiments of the present invention provide for techniques to reduce the impact of such events wherein the quantum is not impacted by certain classes of events. These events are not necessarily autonomous events.

Thus referring again to each simulation executes for quantum . Simulation has an event scheduled at simulation time T. Therefore quantum is reduced to end at simulation time T. The reduction is done prior to simulation being invoked to execute its block such that all simulations execute for the reduced quantum and do not run past the autonomous event. After simulation returns control to the simulation engine simulation is then invoked to execute block . Simulations may then be invoked.

The size of the quantum may be based on a value input by the user. Typically the quantum should be given the highest possible value that still gives a behaviorally correct simulation result. Thus since there are no autonomous events scheduled between synchronization times T and T the quantum is increased back to it maximum possible value quantum . The simulation engine should not increase the quantum to a value larger than the user specified value.

In some cases a simulation is able to determine that it should halt prior to completion of its maximum quantum of execution units based on either an event in its simulation or one that it may trigger in another simulation model. Referring to initially the quantum is quantum ending at simulation time T and no known dependencies exist that would indicate the quantum should be shortened. However simulation stops its execution partway through its quantum of execution units block . This may occur because simulation determined that it has a dependency on another simulation at simulation time T such that it cannot continue behaviorally accurate simulation. Alternatively simulation may have hit a breakpoint or watchpoint. Or simulation may determine that it may cause an event in another simulation. For example simulation may determine that by writing to a register in another simulation it may cause a watchpoint in that other simulation to be hit. Simulation will inform the simulation engine of the stopping point Ti when returning control to the simulation engine.

The simulation engine then dynamically adjusts the quantum to quantum so that the rest of the simulations stay synchronized with simulation . The simulation engine then invokes simulations to execute up to the quantum which has been dynamically modified to quantum . Then the simulation engine may invoke simulations to execute to simulation time T by dynamically modifying the quantum to quantum . 

In some cases it is unknown that an event will occur in a simulation that would cause another simulation to get ahead in execution. Referring to initially the quantum is quantum and simulation executes its quantum of execution units entirely block . When simulation is invoked the quantum is still quantum because no known dependencies exist that would indicate the quantum should be shortened. However simulation stops its execution partway through its quantum of execution units block . This may occur because simulation determined that it has a dependency on another simulation at simulation time T such that it cannot continue behaviorally accurate simulation. Alternatively simulation may have hit a breakpoint or watchpoint. Simulation will inform the simulation engine of the stopping point T when returning control to the simulation engine.

The simulation engine then dynamically adjusts the quantum to quantum so that the rest of the simulations stay synchronized with simulation . The simulation engine then invokes simulations to execute up to the quantum which has been dynamically modified to quantum . Simulations will be synchronized at simulation time T. It is not required that simulation be synchronized with the rest of the simulations at this point If a user views simulation results at this point the user will be informed that simulation has run ahead of time and is stopped at simulation time . When the simulations are restarted the simulation engine may invoke simulations to execute to simulation time T by dynamically modifying the quantum to quantum . Then the quantum may be re set to a higher value for more efficient simulations quantum wherein simulations are invoked and allowed to execute up to simulation time T without any of the simulation models stopping to synchronize with another simulation model.

Step comprises the simulation engine invoking a first simulation for execution and informing the simulation of the current value of the quantum. Thus the simulation is aware of the maximum number of units of execution it is allowed to perform.

The simulation is not required to complete all of the execution units. For example if the simulation identifies a dependency on another simulation in step it halts in step . Moreover in step the simulation notifies the simulation engine of the time at which it halted. Thus in step the simulation engine modifies the dynamic quantum. Then the process returns to step wherein the simulation engine invokes the next simulation providing it with the current value of the dynamic quantum.

However in the typical case a simulation will complete the entire quantum of execution units. If the simulation is aware of an autonomous event in its simulation step it may inform the simulation of this in step . For example a hardware simulation may inform the simulation engine that it has an upcoming autonomous event so that it will be awoken to simulate the autonomous event. Moreover the simulation engine may modify the quantum to prevent other simulations from running ahead of this autonomous event. The simulation engine keeps track of this and other autonomous events such that it may modify the dynamic quantum at the appropriate time.

In step the simulation completes and returns control to the simulation engine. The process then returns to step wherein the simulation engine invokes the next simulation model.

As discussed above autonomous events can impact the quantum. However most hardware simulations may be modeled to be entirely responsive or at least mostly responsive e.g. they have none or little autonomous behavior. The real world hardware typically has a high frequency clock signal that may be used to guide a state machine. As a consequence conventional hardware simulation models typically include a high frequency clock signal and a state machine. However because the hardware is typically accessed infrequently this modeling style may cause substantial overhead because on the vast majority of clock cycles the hardware does no work. This modeling style can be achieved by the present invention if the dynamic quantum were set to one clock cycle since the simulation engine would interact with the hardware simulations every clock cycle.

However embodiments of the present invention provide a much more efficient hardware simulation model. These simulation modes may be described as functional models which simulate the function of the hardware instead of the actual hardware implementation. Thus the hardware simulation model normally sleeps and is woken up by incoming communication. The hardware simulation model then executes the needed behavior and goes to sleep again. If a hardware simulation model needs to execute behavior in the future it asks the simulation engine to wake it up again at that time in the future and goes to sleep again. The vast majority of hardware e.g. peripherals can be modeled in this fashion. Moreover busses and memory can be modeled in this functional fashion as well.

Because these functional simulations do not use clock signals this removes one of the bottlenecks. Moreover the quantum will only be limited dynamically whenever a processor simulation model actually accesses the hardware simulation which normally happens with a relatively low frequency meaning the dynamic quantum can often be equal to a maximum value specified by a user.

Another embodiment of the present invention provides for bypassing invocation of a simulation model to bypass a non autonomous simulation event when behavior of the non autonomous simulation event is not desired. In one embodiment backdoor memory accesses are used in order to improve simulation efficiency. The backdoor memory access can bypass a simulation event that might impact the quantum. The bypassed events may be non autonomous events. For example for every instruction that a real world processor executes there is at least one memory access e.g. the opcode fetch. Thus it is possible to simulate this by invoking the processor simulator and the memory simulator along with the bus simulator . Invoking the simulators in this fashion could cause the dynamic quantum to be very low typically two or three clock cycles.

However the memory and bus simulation models do not need to be invoked for correct and accurate behavior of a processor simulation memory access. Thus rather than invoking the memory and bus simulation models an embodiment of the present invention directly reads the memory in the memory simulation model. Referring to a memory simulation model may allocate a large array of bytes to model the memory. When a communication request comes into the memory simulation model the memory simulation indexes into the array and returns the proper value.

However rather than invoking the memory simulation as just described an embodiment of the present invention performs a backdoor access in which the memory simulation is not invoked. With a backdoor access instead of going over the bus the processor simulation uses a pointer to index the memory array . The simulation engine has pointer storage and receives pointers from the memory model and possibly other simulation models. Neither the bus simulation nor the memory simulation model need be invoked. Therefore the quantum is not impacted by this event. The user may be allowed to specify whether such backdoor accesses are permitted or not.

Backdoor memory accesses may reduce the accuracy of the simulation. One reason for reduced accuracy is that a backdoor access may take zero simulation time. Typically a real CPU to memory access over the bus would require several clock cycles. Thus an embodiment of the present invention allows a user to estimate the number of clock cycles that a backdoor access would take and input this as a simulation parameter. More than one estimate can be provided based on the type and or sequence of accesses e.g. read write write followed by read etc. The processor simulation factors in the estimated access time when it determines the number of instructions it can execute within its quantum. Thus the potential loss of simulation accuracy is reduced or eliminated by factoring in the estimate.

Backdoor accesses may apply to other than instruction fetches. In one embodiment the processor simulation model understands when it is safe to perform a backdoor access. That is the processor simulation model understands when a behavior that should be simulated is associated with the memory access. If there is such a behavior then the processor simulator does not perform a backdoor memory access.

Furthermore a backdoor access can apply to other than a memory simulation. This allows a more efficient simulation for pieces of hardware that may be frequently accessed. Thus the hardware simulation may also provide one or more pointers to the simulation engine.

In one embodiment the backdoor access does not use the bus simulation model or the memory or hardware simulation model. In this case the backdoor access does not trigger the behavior associated with the memory or hardware access. In another embodiment the backdoor access does not use the bus simulation model but does invoke the memory or hardware simulation model. In this case the backdoor access does trigger the behavior associated with the memory or hardware access.

The user is allowed to select backdoor accesses on the fly. For example a graphical user interface such as a debugging tool allows the user to specify which simulations may perform backdoor accesses. Furthermore the user may be allowed to specify under what conditions backdoor accesses are allowed. For example a user may specify that backdoor accesses are allowed for only instruction fetches. Further embodiments of the present invention allow selection of backdoor access on a per component basis within a given simulation model. For example the backdoor access may be specified on a register by register basis. The user can modify any of the backdoor access parameters without the need to re compile the simulation.

There may be cases in which dynamic adjustment of the quantum is insufficient to get correct behavioral simulation results. For example consider a dual processor system in which CPU monitors a piece of memory that is shared by both CPU and CPU. The software running on CPU will write data to the shared memory that CPU processes. A conventional way of communicating between the CPUs is by means of interrupt signals. By sending back and forth interrupts CPU knows that CPU has written to the shared memory and CPU knows that CPU has read the shared memory. If the simulation has knowledge of the interrupt then the simulation can stop execution prior to completing its quantum such that it will not run past the interrupt event.

However the software developer may avoid using an interrupt by exploiting the fact that it is known which software is running on both CPU s. For example if it is known that CPU will put a new element in the shared memory every 20 clock cycles then that knowledge can be exploited in CPU. If CPU is aware that CPU exploits that knowledge then CPU can know when it is safe to overwrite the shared memory based on the shared timing knowledge rather than using an interrupt.

However the simulation models may be unaware of this timing knowledge. For example if an interrupt is used the simulation may have explicit information regarding the interrupt. However if the aforementioned timing knowledge is used instead of interrupts the simulation may not contain explicit information about the timing of the shared memory accesses. An embodiment of the present invention prevents possible incorrect simulation results that may occur due to such dependencies that are not explicitly indicated in the simulations.

The following example will serve to illustrate a possible incorrect result which is avoided by an embodiment of the present invention. The software developer may program CPU to write to shared memory every 20 clock cycles and CPU to read the shared memory every 20 clock cycles. However this timing information may not be explicitly obtainable from the simulations. If the quantum were set to 100 clock cycles CPU could overwrite the shared memory before CPU would read the shared memory or vice versa . Thus the simulation results will likely be incorrect. An embodiment of the present invention allows the user to set a maximum value of the quantum. The simulation engine may only dynamically reduce the quantum in this embodiment. In this case the quantum might be limited by the user to 20 clock cycles e.g. the resolution of timing based communication between both CPUs .

In many systems the processor is the only real autonomous block and memory and hardware accesses are infrequent. More complex systems have one or more autonomous blocks besides the CPU or may have multiple CPUs. In one embodiment of the present invention each autonomous simulation model may have its own quantum. For example the dynamic quantum may be adapted to a specific simulation or it may be individually adapted to a plurality of autonomous simulations. Simulation models that are wholly or largely responsive e.g. non autonomous may have their quantum set to the lowest quantum in current use.

The preferred embodiment of the present invention are thus described. While the present invention has been described in particular embodiments it should be appreciated that the present invention should not be construed as limited by such embodiments but rather construed according to the below claims.

