---

title: Scalable and extensible framework for storing and analyzing sensor data
abstract: In a framework for acquiring and analyzing data from a network of sensors, plug-in software interfaces are used to provide scalability and flexibility. Data collection set-up data is exchanged through one or more first plug-in software interfaces with data collection devices, to configure the processor to collect measurement data from the data collection devices. Analysis set-up data is exchanged through one or more second plug-in software interfaces with one or more data analysis software packages, to configure the processor to provide a predefined subset of the measurement data to the data analysis software packages and to accept analysis results from the data analysis software packages. Measurement data and analysis results are subsequently exchanged through the plug-in interfaces.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08744807&OS=08744807&RS=08744807
owner: Siemens Aktiengesellschaft
number: 08744807
owner_city: Munich
owner_country: DE
publication_date: 20100518
---
This application claims the benefit of U.S. Provisional Application Ser. No. 61 232 593 entitled SensorMart Scalable and Extensible Framework for Storing Sensor Data filed on Aug. 10 2009 the contents of which are hereby incorporated by reference herein in their entirety.

The present invention relates generally to the field of data collection storage and analysis and more particularly to a scalable and flexible framework for acquiring and analyzing data.

The decreasing cost of sensor hardware and the availability of vast communications networks have permitted monitoring the conditions of remotely located assets over a long time period collecting enormous amounts of data. Examples of such monitoring systems abound and include systems for monitoring the condition of transportation infrastructure including bridges tunnels and highways communications and power distribution infrastructure such as cables and switches wind turbines waterways and equipment subsystems such as factory machines and agricultural equipment. In each case general or special purpose sensors produce measurement data that is collected by processors and analyzed using one or more data analysis algorithms.

A typical data monitoring system for long term monitoring is shown in . A data logger is typically used to gather data from simple sensors . As used herein the term sensor means any device that performs a measurement of its environment and transmits a signal representing that measurement. Examples of sensors include distance sensors temperature sensors pressure sensors strain gages color sensors liquid level sensors cameras microphones chemical sensors electrical sensors speed altitude or pitch sensors GPS receivers etc.

The data logger may perform one or more functions on signals received from the sensors . For example the data logger may condition and compensate a signal for offset and gain or may perform analog to digital conversion on a signal. The data logger may receive wireless signals from the sensors and convert them to terrestrial electrical or optical signals. The data logger may organize signals from multiple sensors and store data representing those signals in a temporary memory until the data is retrieved by a monitoring system. The data logger may associate sequential data from a sensor with timestamps to permit synchronization with data from other sources. The data logger may additionally calculate characteristics that are not directly measured by the sensors but are instead determined by combining or compensating signals received from the sensors. The data logger typically includes a processor that may be queried by a monitoring system to retrieve stored data.

Data from the data logger are collected by the monitoring system and stored into a measurement database . A system of measurement sensors such that described may generate a large volume of data the measurement database must therefore be capable of efficiently storing and accessing such data. In practice a column oriented database management system architecture is frequently used.

The data may be transmitted and stored in real time as it is measured or may be collected in small batches by the data logger and transmitted at regular time intervals or regular batch sizes to be stored by the monitoring system in the database . The stored data may include data from multiple sensors indexed according to a time line or according to some other indexing variable.

The stored data in the database are constantly analyzed through one or more analysis methods performed by one or more data analysis software packages . For example outlier detection may be performed on the data or a state estimation model may be used to detect deviations from a normal state. Results of those analyses are then used to generate labels that are indexed to the data . Each data analysis software package or algorithm typically generates a particular set of labels directed to a particular characteristic. The labels are stored in an event database as events and may include indexing data such as time data or unique IDs for aligning the labels with the corresponding measurement data . The labels annotate the data by marking intervals or points in the data where a certain error has been observed a certain threshold has been exceeded or some other event has occurred as determined by the data analysis software packages .

A data analysis software package utilizes a particular set of data from the data logger . Often that subset of data is only a small portion of the data generated by the logger over time. In a large system the various algorithms used in the data analysis software packages must parse through huge amounts of data generated by the data loggers to retrieve the data that is useful to a particular algorithm.

The monitoring system is often deployed in a long term setting IT framework that supports long term monitoring. In those cases it is desirable that the system be flexible enough to adapt over time to newly available sensing and logging technologies and new equipment models and vendors. The system should also adapt to new algorithmic developments. Currently available IT frameworks are vendor specific and not open for collecting data from sensing hardware of different providers. The frameworks are furthermore not sufficiently flexible to connect to sensing technologies not seen so far. In addition existing frameworks only allow the creation of very basic algorithms such as rule based or fuzzy logic based methods and are not open to the integration of more sophisticated custom made algorithms.

There is presently a need to overcome the above described limitations of existing IT solutions by facilitating the integration of a variety of different sensor types and data analysis methods. There is furthermore a need for the capability to extend the capabilities of a measurement system to function with new sensor inputs and new data analysis algorithms.

The present invention addresses the needs described above by providing a method for collecting and processing data. In a processor data collection set up data is exchanged through a first plug in software interface with a data collection device to configure the processor to collect measurement data from the data collection device. Measurement data is then collected from the data collection device. In the processor analysis set up data is also exchanged through a second plug in software interface with a data analysis software package to configure the processor to provide a predefined subset of the measurement data to the data analysis software package and to accept analysis results from the data analysis software package. The predefined subset of the measurement data is then providing to the data analysis software package for analysis.

Analysis results from the data analysis software package are then accepted and the measurement data is annotated with the analysis results.

In another embodiment of the invention a non transitory computer usable medium has computer readable instructions stored thereon for execution by a processor to perform a method as described above.

A system for collecting and processing data according to an exemplary embodiment of the present invention is illustrated in . In the system a computer performs steps of the disclosed method. While a single computer is shown one skilled in the art will recognize that the disclosed steps may be performed by a plurality of computers linked by a network or a bus.

The computer receives data from a plurality of sensors that may be connected to the computer through one or more data sources such as data loggers. The sensors are arranged to acquire data representing time related characteristics of a system. The sensor data is stored in a measurement database along with timestamps or other temporal identifiers or indexes.

The computer which may be a portable or laptop computer or a mainframe or other computer configuration includes a central processing unit CPU and a memory . The computer is connected to an input device and an output device . The CPU includes one or more data acquisition modules that are configured for performing one or more methods for monitoring collecting and storing sensor data as discussed herein.

The CPU additionally contains one or more data analysis modules containing algorithms for analyzing data collected from the sensors . The data analysis modules may be modules created by a third party for general use in sensor data analysis or may be created specifically for the present system. The data analysis modules determine the occurrence of events that may be indexed and stored in an event database .

The memory includes a random access memory RAM and a read only memory ROM . The memory may also include removable media such as a disk drive tape drive etc. or a combination thereof. The RAM functions as a data memory that stores data used during execution of programs in the CPU and is used as a work area. The ROM functions as a program memory for storing a program executed in the CPU . The program may reside on the ROM or on any other non volatile computer usable medium as computer readable instructions stored thereon for execution by the CPU or other processor to perform the methods of the invention. The ROM may also contain data for use by other programs.

The input may be a keyboard mouse network interface etc. and the output may be a liquid crystal display LCD cathode ray tube CRT display printer etc. The computer may be connected to a network with all commands input output and data being passed via the network. The computer can be configured to operate and display information by using e.g. the input and output devices to execute certain tasks.

Presently disclosed is architecture of a system shown in that overcomes the limitations of current frameworks discussed above. To provide increased system flexibility and adaptability two plug in interfaces are provided a data acquisition plug in interface and a data analysis plug in interface . Those plug in interfaces are interconnected as described below. Databases are provided for storing measurement data and events respectively. A user interface including a data display and event labeling are also provided through the events framework.

The plug in interface on the data acquisition side of the system provides a flexible and easily extendible data gathering mechanism. The interface supports fetching data from data sources . Data sources are devices or locations that acquire and or temporarily store measurement data. The data sources are frequently vendor specific such as vendor specific data loggers that interface with sensors. The data sources acquire raw in field measurement data condition and combine the measurement data and store the results for later batch retrieval. The interface connects to those diverse data sources as described below and transfers the data to the presently described system.

The plug in interface facilitates adding new data sources to the system. Preferably the data acquisition plug in interface comprises an application programming interface API that provides a standard interface allowing third party data source designers to create code for data sources having a plug in feature that interacts with the host application in the interface . It is contemplated that manufacturers of data loggers and other data sources may agree on such an interfacing standard making the coding of an adapter unnecessary for introducing new data sources. Data sources may furthermore incorporate a plug and play type feature to facilitate the discovery of the data source hardware component in the system without the need for physical device configuration or user intervention.

Alternatively if a data source to be added to the system has no provision for using an API and has previously not been used with the system then a simple adapter is written for defining the necessary components and for translating data formats data types and commands. The adapter permits exchanges between a particular data source type and the plug in interface . Once an adapter is written for a particular data source type no additional special code need be written for later uses of that data source type.

A new data source is registered with the system through a protocol including several commands. The following are examples of commands that may be used to register a new data source 

connect passes initial details necessary for a connection to be established between the data sources and the data acquisition plug in interface . Those details may include an initial handshaking protocol for physically establishing a communications channel.

disconnect tears down a previously established channel between a data source and the data acquisition plug in interface.

getSensors is transmitted to the data source to request a list of sensors connected to that data source. In response to the getSensors command the data source sends a table including information about each sensor connected to the data source. That information may include for example a sensor identifier a sensor hardware type a sensor location sensor measurement units and a sensor data format.

setReadingInterval The data acquisition plug in interface supports the periodic uploading of data from the data sources. The setReadingInterval command defines a time interval between transfers of data from a particular data source to the data acquisition plug in interface . In one example a setReadingInterval command is sent from the interface to a data logger . The command includes arguments establishing a time period between data uploads. Thereafter as each time interval equal to the time period elapses the data logger collects data from all sensors identified in previous the getSensors command and transmits the collected data to the data acquisition plug in interface . A corresponding getReadingInterval command may be used to check the interval currently in use by the data source.

Thus different types of data sources from different vendors can coexist and run efficiently in the presently described infrastructure. The plug in features of the system enable third party data source developers to create unique capabilities for their devices without the need to specifically integrate those capabilities into a data monitoring and acquisition system such as that presently described. The size and complexity of the data monitoring and acquisition system is maintained at a manageable level while permitting data source capabilities to be expanded. Because the two systems remain separate problems with incompatible software licenses are reduced.

The data analysis plug in interface depicted on the right hand side of enables users to conveniently plug customized data analysis tools into the system thus extending the algorithmic power of the system without changing the underlying framework or code base. As with the data source plug in interface the data analysis plug in interface facilitates adding new units to the system. An API provides a standard interface allowing third party data analysis package designers to create code that interacts with the host application in the interface .

The customized data analysis tools contemplated by the present disclosure may perform a broad variety of tasks. General purpose tools may perform statistical analysis on time series data including the calculation of data trends the detection of anomalies and abnormal conditions and the production of summary data for storage.

Specialized tools may be created specifically for certain types of data. For example a data analysis tool for weather data may receive data from certain sensors at geographically distributed stations and make weather predictions and prepare summaries for archiving based on that data. A data analysis tool for structural analysis may receive data from strain gages located throughout a structure and calculate stress estimates based on those readings.

A new data analysis package may be registered with the system through a protocol including several commands. The following are examples of commands that may be used to register a new data analysis software package 

subscribe identifies data that is to be transmitted to the data analysis software package. The command may for example contain arguments identifying the data by sensor type by data type by the time the data was acquired by the identity of the data source from which the data comes or by the locations of the sensors of interest. If a data analysis package subscribes to data of a certain type or data from a certain type of sensor then all available data fitting that description is sent by the data monitoring system to the analysis package as it becomes available. By subscribing only to data that is of interest in performing the needed calculations a data analysis software package avoids the necessity of parsing through the huge amounts of data that are otherwise available from the system.

consume triggers the data monitoring system to transmit all data identified in previous subscribe commands minus data identified in unsubscribe commands to the sending data analysis package.

Using the presently described infrastructure each of the data analysis components receives only a predefined subset of the measurement data. Specifically the data analysis components receive only the data they are interested in i.e. subscribed to thus the quantity of data to be analyzed is reduced significantly. As noted above the data analysis components may define the subscribed data in several ways. In one example the subscribe command defines a data type such as all temperature data in a system that monitors weather. In that case all temperature data produced by the sensors in the system will be transmitted to the requesting data analysis component. The data analysis component may use all received temperature data or may filter the data according to parameters such as location time or measuring sensor using only a portion of the data received.

In another example a data analysis component may define data from particular data sources identified in the subscribe command. That may be the case for specialized algorithms designed to identify events that are uniquely associated with a specific set of sensors.

With the above described infrastructure users can easily register the components to be implemented in the system including data sources and data analysis packages.

The flow of data in the system of the invention is illustrated in a functional block diagram of the system shown in . Data from sensors is gathered by a data source such as a data logger. The data is conditioned combined and otherwise prepared by modules of the data source such as the data conditioning module .

The data source communicates with a data acquisition manager of the system through a pluggable interface . While the pluggable interface may be implemented in a number of ways one technique is to define an API in the data acquisition manager and provide an adapter implementing the API in the data source . In object oriented languages for example the adapter code of the data source implements a set of class definitions set forth in the API of the data acquisition manager . The definitions describe how objects derived from a particular class will behave in a given circumstance. Other data sources may then easily be added by adding code implementing the API of the data acquisition manager .

As described above at intervals the data acquisition manager receives all available data from the data source through the plug in interface . The data acquisition manager may be connected to a large number of data sources which may in turn be connected to large numbers of sensors. The potentially large volume of data transmitted to the data acquisition manager is handled for example using a rule based filter residing in a data management module .

Requested measurement data that is subscribed to by one or more data analysis packages through data subscriptions as described above is transmitted to a data analysis manager for distribution to the subscribing data analysis package s . Other measurement data may be identified for archiving in a measurement database . For example weather summary data may be stored in the database for future retrieval.

Other measurement data may be identified as data to be displayed in a user interface together with events determined by various data analysis packages connected to the data analysis manager . The user interface provides real time information to operators of the system. For example the user interface may indicate events such as outliers or state changes in the data or may identify predefined occurrences such as the attainment of a goal.

Rules defining which data is stored in the measurement database which data is displayed in the user interface and which data is forwarded to the data analysis manager may be stored in the data management module . Rules for routing the data may depend on the data type and or the type of source from which the data is received as well as on whether the data is used by one or more of the data analysis packages as defined by the subscribe commands. Measurement data from a particular data source may be transmitted by the data acquisition manager to each of the measurement database the user interface and the data analysis manager to any combination or subset of the three or to none. In the case where no data from a particular data source is to be routed to any of measurement database the user interface or the data analysis manager the data acquisition manager may close the connection with that data source.

As described above the data analysis manager is connected through one or more plug in interfaces to one or more data analysis packages . Each data analysis package may have adapter code implementing an API defined in the data analysis manager . A data analysis module in each data analysis package calculates events from data received through the plug in interface .

An event manager distributes events received from the data analysis packages to an event database and to the user interface . The event manager may contain rules for determining events to be displayed and events to be stored based on event types or based on manual input through the user interface .

A method for collecting and processing data in accordance with one embodiment of the invention shown in may be executed by a processor in communication with the various components described above. Data collection set up data is initially exchanged through a first plug in software interface. The data is exchanged with a data collection device to configure the processor to collect measurement data from the data collection device. Measurement data is thereafter collected from the data collection device.

Analysis set up data is exchanged through a second plug in software interface with a data analysis software package. The analysis set up data is used to configure the processor to provide a predefined subset of the measurement data to the data analysis software package and to accept analysis results from the data analysis software package.

The predefined subset of the measurement data is provided to the data analysis software package for analysis. Analysis results from the data analysis software package are accepted and the measurement data is annotated with those analysis results.

The presently described method and system may also implement an efficient pull based user notification mechanism for users that initiate an interest in a particular pattern of measurement data. Using this notification mechanism the users are only notified when their interest pattern occurs in the incoming data. In such a system network usage and data transfer is minimized and the processing load is shifted onto the powerful servers rather than the users enabling the users to use thin clients such as PDAs etc.

The foregoing Detailed Description is to be understood as being in every respect illustrative and exemplary but not restrictive and the scope of the invention disclosed herein is not to be determined from the Description of the Invention but rather from the Claims as interpreted according to the full breadth permitted by the patent laws. For example the techniques described herein may be applied to any repository of temporal data including for example machine or process condition monitoring structural health monitoring transportation or other infrastructure monitoring etc. while remaining within the scope of the invention. It is to be understood that the embodiments shown and described herein are only illustrative of the principles of the present invention and that various modifications may be implemented by those skilled in the art without departing from the scope and spirit of the invention.

