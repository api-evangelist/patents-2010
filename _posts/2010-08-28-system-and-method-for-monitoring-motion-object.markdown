---

title: System and method for monitoring motion object
abstract: A motion object monitoring system captures an image of a scene and distance data between points in the scene and a time-of-flight (TOF) camera by the TOF camera. A 3D model of the scene is built according to the image of the scene and the distance data. The motion object monitoring system gives numbers to the monitored objects according to specific features of the monitored objects. The specific features of the monitored objects are obtained by detecting the built 3D model of the scene. Only one of the numbers of each of the monitored objects is stored, instead of repeatedly storing the numbers of same motion objects. The motion object monitoring system analyzes the stored numbers, and displays an analysis result. The motion object monitoring system also determines a movement of each of the motion objects according to corresponding numbers of the motion objects.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08270705&OS=08270705&RS=08270705
owner: Hon Hai Precision Industry Co., Ltd.
number: 08270705
owner_city: Tu-Cheng, New Taipei
owner_country: TW
publication_date: 20100828
---
The present application is related to a co pending U.S. patent application titled SYSTEM AND METHOD FOR MONITORING MOTION OBJECT with the application Ser. No. 12 507 092 and another co pending U.S. patent application Ser. No. 12 868 194 titled SYSTEM AND METHOD FOR MONITORING SUBJECTS OF INTEREST assigned to the same assignee as the present application and the disclosure of which is incorporated herein by reference.

The present disclosure relates to monitoring systems and methods and more particularly to a system and a method for monitoring motion objects.

Nowadays video monitoring technology is prevalent in many public spaces such as banks stores and parking lots. Moving objects may be detected during video monitoring and recorded data may be obtained for analysis. For example video monitoring technology has been proposed to measure traffic flow on highways by recording the number of vehicles passing through the monitored areas of the highways. In addition video monitoring technology is helpful to compile consumer demographics in shopping malls and amusement parks by detecting and counting consumers who traverse into a monitored area during a predetermined time period. However there are times that users may not want to repeatedly record or count the same motion objects which appear in a monitored area many times during a given period of time.

The disclosure including the accompanying drawings is illustrated by way of example and not by way of limitation. It should be noted that references to an or one embodiment in this disclosure are not necessarily to the same embodiment and such references mean at least one.

Referring to an embodiment of a motion object monitoring system includes a time of flight TOF camera a processor and a storage device . The TOF camera captures a scene to get images of the scene and distance data between every point in the scene and the TOF camera . The storage device and the processor receive the image and the distance data to obtain a three dimensional 3D model of the scene.

The TOF camera is a camera system that creates distance data between every point in the scene and the TOF camera . When the TOF camera surveys the scene the TOF camera sends electrical signals frequency throughout the scene. The electrical signals bounce back to the TOF camera when they meet an object such as a wall in the scene. As a result the distance data can be obtained according to time differences between the TOF camera sending and receiving the electrical signals frequency.

The storage device includes a three dimensional 3D model building module an information gathering module a storing and comparing module and a processing module . The 3D model building module the information gathering module the storing and comparing module and the processing module may include one or more computerized instructions and are executed by the processor . The motion object monitoring system is operable to detect monitored objects in a monitored area give numbers about the monitored objects and analyze the given numbers of the monitored objects. In this embodiment the monitored objects are subjects of interest. In other embodiments the monitored objects may be vehicles or other motion objects.

Referring to the information gathering module includes a key portion locating unit a feature obtaining unit and a numbering unit . The processing module includes a data analyzing unit a data storing unit an object tracking unit and a displaying unit .

The 3D model building module builds a 3D model of the scene according to the image of the scene and the distance data between every point in the scene and the TOF camera . In the embodiment according to the distance data between every point in the scene and the TOF camera every point in the scene has coordinates relative to the TOF camera . The 3D model building module can obtain a curved surface that is a true representation of the scene according to the coordinates of every point in the image. The curved surface can be regarded as the 3D model of the scene.

The key portion locating unit of the information gathering module locates key portions of each of the 3D model of the scene. The key portions of the 3D model of the scene may have specific features of the monitored objects such as license plates of vehicles or facial features of subjects of interest. In this embodiment the key portions of each of the 3D model of the scene may include faces of the subjects of interest. The feature obtaining unit obtains facial features of each of the subjects by detecting faces of the subjects in the 3D model of the scene. The facial features may include face shapes complexions and individual features such as the ears eyes lips and noses of the subjects. The numbering unit gives a number to each of the features of the subjects according to their individual features. Each of the numbers may include a feature portion representing individual facial features of the subject a position portion representing a coordinate position of the subject in the monitored area and a time portion representing a time when the subject appears at the coordinate position. Therefore a plurality of numbers may be given to the same subject when the subject appears at different coordinate positions or different times in the monitored area during a time period. During the time period the feature portions numbers of a subject are the same.

The given numbers of the subjects are received by the storing and comparing module . When a new number is received by the storing and comparing module the feature portion of the new number is compared with the feature portions of the stored numbers in the storing and comparing module . The storing and comparing module stores the new number when the feature portion of the new number is different from the feature portion of each of the stored numbers. The new number is not stored by the storing and comparing module when the feature portion of the new number is the same to a feature portion of a stored number. Therefore only one of given numbers of a same subject appears in the monitored area in the time period can be stored by the storing and comparing module .

The time period can be predetermined according to the need such as 10 minutes or 5 hours for example. The stored numbers are transmitted to the data analyzing unit for analysis. For example the stored numbers may be counted by the data analyzing unit to obtain the number of customers which enter into a supermarket from 9 00 a.m. to 5 00 p.m. of a day so each of the customers are not counted more than once. An analysis result of the stored numbers may be transmitted to the displaying unit from the data analyzing unit . The displaying unit displays the analysis result.

The position portion of the given number of each of the subjects is formed in coordinate information representing the coordinate position of each of the subjects in the monitored area. All of the given numbers are transmitted to the data storing unit by the numbering unit . The data storing unit stores the given numbers of the subjects. Each of the subjects can be tracked by the object tracking unit . The object tracking unit may read the position portions and the time portions of given numbers which include same feature portions from the data storing unit and sequence the position portions of the given numbers of each of the subjects according to the time portions. The position portions of each of the subjects are displayed on the displaying unit . Therefore the displaying unit can display the coordinate positions of a subject in sequence of times. Thus the movement of a subject can be surveyed from the displaying unit .

In step S the TOF camera captures the scene to obtain the image of the scene and the distance data between every point in the scene and the TOF camera .

In step S the 3D model building module builds the 3D model of the scene according to the image and the distance data between every point in the scene and the TOF camera .

In step S the information gathering module obtains the specific features of each of the monitored subjects by detecting the key portions of the 3D model of the scene. As mentioned above the key portions of the 3D model of the scene are located by the key portion locating unit and detected by the feature obtaining unit . The key portions of each of the 3D model of the scene may include a face or a license plate. The specific features of the monitored objects may be facial features such as face shape and skin tone.

In step S the information gathering module gives a number to each of the monitored objects according to the specific features of the monitored subjects. Each of the numbers includes the feature portion the time portion and the position portion. The feature portions of the numbers of subjects are the same. The numbers of the monitored objects are generated by the numbering unit .

In step S the storing and comparing module receives the given numbers and stores only one of the given numbers of each of the monitored subjects. In this embodiment the storing and comparing module stores a new number when the feature portion of the new number is different from the feature portion of each of the stored numbers. The new number is not stored by the storing and comparing module when the feature portion of the new number is the same to the feature portion of one of the stored numbers.

In step S the stored numbers and all of the given numbers are received by the processing module to be analyzed respectively. In this step the stored numbers are received by the data analyzing unit from the storing and comparing module . The stored numbers may be counted by the data analyzing unit and an analysis result of the stored numbers may be displayed by the displaying unit . The given numbers are received by the data storing unit from the numbering unit . The feature portions the time portions and the position portions of the given numbers are helpful to survey the movement of the monitored subjects. The displaying unit can display the coordinate positions of each of the subjects in sequence of times.

The foregoing description of the exemplary embodiments of the disclosure has been presented only for the purposes of illustration and description and is not intended to be exhaustive or to limit the disclosure to the precise forms disclosed. Many modifications and variations are possible in light of the above everything. The embodiments were chosen and described in order to explain the principles of the disclosure and their practical application so as to enable others of ordinary skill in the art to utilize the disclosure and various embodiments and with various modifications as are suited to the particular use contemplated. Alternative embodiments will become apparent to those of ordinary skills in the art to which the present disclosure pertains without departing from its spirit and scope. Accordingly the scope of the present disclosure is defined by the appended claims rather than the foregoing description and the exemplary embodiments described therein.

