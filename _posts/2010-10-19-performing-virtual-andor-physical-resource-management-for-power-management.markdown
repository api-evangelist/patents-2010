---

title: Performing virtual and/or physical resource management for power management
abstract: A mechanism is provided for directed resource folding for power management. The mechanism receives a set of static platform characteristics and a set of dynamic platform characteristics for a set of resources associated with the data processing system thereby forming characteristic information. The mechanism determines whether one or more conditions have been met for each resource in the set of resources using the characteristic information. Responsive to the one or more conditions being met, the mechanism performs a resource optimization to determine at least one of a first subset of resources in the set of resources to keep active and a second subset of resources in the set of resources to dynamically fold. Based on the resource optimization, the mechanism performs either a virtual resource optimization to optimally schedule the first subset of resources or a physical resource optimization to dynamically fold the second subset of resources.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08448006&OS=08448006&RS=08448006
owner: International Business Machines Corporation
number: 08448006
owner_city: Armonk
owner_country: US
publication_date: 20101019
---
This invention was made with Government support under DARPA HR0011 07 9 0002. THE GOVERNMENT HAS CERTAIN RIGHTS IN THIS INVENTION.

The present application relates generally to an improved data processing apparatus and method and more specifically to mechanisms for directed resource folding i.e. freeing resources by limiting the set of resources between which tasks are distributed in order to provide more efficient power management.

Many modern data processing system architectures utilize operating system and virtualization mechanisms e.g. hypervisors to perform resource management. Operating systems and hypervisors are in band resource managers on data processing systems that manage the allocation of virtual and physical resources to processes tasks. They determine when and what physical resources get used by which tasks executing in the data processing system. In the most prevalent mode of operation the resource scheduler dispatcher manager of the operating system or hypervisor has a load balancing component that distributes the tasks evenly among the available resources to ensure good performance.

Known mechanisms for performing this load balancing do so independent of any considerations from the platform i.e. hardware and firmware such as the basic input output system BIOS service firmware and the like. To the contrary the load balancing mechanisms use only information available at the resource scheduling layer such as resource utilization task priority static resource organization information such as core topology in terms of which cores map to a socket etc. There is no runtime feedback from a lower platform layer that is used to optimize the implementations of these load balancing mechanisms.

In one illustrative embodiment a method in a data processing system is provided for directed resource folding for power management. The illustrative embodiment receives at least one of a set of static platform characteristics that identifies operation parameters of a set of resources under no load and a set of dynamic platform characteristics that identifies operation parameters of the set of resources under load associated with the data processing system thereby forming characteristic information. The illustrative embodiment determines whether one or more conditions have been met for each resource in the set of resources using the characteristic information. In the illustrative embodiment the resource usage conditions identify one or more conditions under which a configuration of one or more resources in the set of resources needs to be modified. The illustrative embodiment performs a resource optimization to determine at least one of a first subset of resources in the set of resources to keep active and a second subset of resources in the set of resources to dynamically fold in response to the one or more conditions being met. The illustrative embodiment performs at least one of a virtual resource optimization in order to optimally schedule the first subset of resources by consolidation of at least one of resource activities task or workload or a physical resource optimization in order to dynamically fold the second subset of resources based on the resource optimization.

In other illustrative embodiments a computer program product comprising a computer usable or readable medium having a computer readable program is provided. The computer readable program when executed on a computing device causes the computing device to perform various ones and combinations of the operations outlined above with regard to the method illustrative embodiment.

In yet another illustrative embodiment a system apparatus is provided. The system apparatus may comprise one or more processors and a memory coupled to the one or more processors. The memory may comprise instructions which when executed by the one or more processors cause the one or more processors to perform various ones and combinations of the operations outlined above with regard to the method illustrative embodiment.

These and other features and advantages of the present invention will be described in or will become apparent to those of ordinary skill in the art in view of the following detailed description of the example embodiments of the present invention.

The illustrative embodiments provide mechanisms for directed resource folding i.e. freeing resources by limiting the set of resources between which tasks are distributed in order to provide more efficient power management. Power and thermal management in data processing systems is of increasing concern in modern data processing system architectures. Data processing systems are being designed to operate in a more power efficient manner e.g. to be green machines. Moreover it is desirable to implement in such data processing systems an ability to set policies that perform trade off decision making with regard to power and performance in order to meet particular objectives. For example it is often desirable to be able to over provision installations relative to the nominal maximum power and temperature values of the data processing systems that are installed but be able to take advantage of the variability in workloads and utilization to ensure that the data processing systems operate correctly and within the limits of the available power and cooling.

One mechanism that provides an ability to perform such trade off decision making and implement the results of such decisions is the ability to fold resources. The concept of folding resources involves the freeing up of resources by limiting the set of resources between which the tasks are distributed. This is done by limiting the set of resources to only a subset of the available resources. By folding the resources the distribution of the current set of tasks by the operating system and or hypervisor are made to the freed resources that are not within the subset of resources selected for the folded set of resources. Thus the freed resources are made available for 1 additional tasks thereby providing spare capacity 2 donation to other resource pool managers e.g. donate to a different partition of the data processing system and or 3 to be put into a lower power idle mode to reduce power consumption.

As an example operating systems in charge of partitions running in virtualized environments may be associated with virtualized processors assigned by a hypervisor with the operating systems then scheduling tasks workloads on these virtualized processors. When the aggregate load seen by the operating system is low an operating system may fold or release a virtual processor to the hypervisor thereby enabling the hypervisor to put the corresponding physical processor upon which the virtual processor is executing into a low power mode if the net demand for physical processors is also low or utilize it for other partitions. There may be a one to one correspondence between virtual processors and physical processors for dedicated partitions while for shared pool partitions the hypervisor manages a dynamic mapping between virtual processors and physical processors. In either case the released processor resources may subsequently be unfolded or reclaimed by a partition s operating system from the hypervisor when a load on the partition increases.

The decision on which specific virtual physical resource to fold unfold in power thermal constrained environments may have significant impact on the energy efficiency and or performance of the partition and the data processing system as a whole. Relevant information for deciding on the right resource to fold unfold resides primarily with physical resource state management firmware. This information may be used both at the operating systems layer as well as the hypervisor layer to make energy efficient resource folding unfolding decisions.

The illustrative embodiments provide an improved mechanism for directed resource folding for power management. The mechanism uses runtime feedback and or communication between the platform such as firmware hardware or the like and resource scheduling layers such as operation systems virtualization mechanisms e.g. hypervisors or the like for optimal management of resources by either an operating system a virtualization mechanism e.g. hypervisor or the like. Some examples of runtime feedback information that may be communicated from a platform to a resource scheduling layer for better power management may include power thermal information related to specific resources constraints favoring freeing one resource entity over another e.g. core A is hotter than core B and so is a better candidate to be put into lower power idle constraints that assist in determining how many resource entities need to be freed or the like. It should be noted that the term freeing with regard to resources is a term that is generally known in the art and is used herein as referring to the ability to identify a resources as being available for allocation to another task or process. By using runtime feedback and or communication between the platform such as firmware hardware or the like and resource scheduling layers such as operation systems virtualization mechanisms or the like the illustrative embodiments provide for an optimal management of resources by either the operating system the virtualization mechanism or the like.

The mechanisms of the illustrative embodiments may be utilized by and implemented in many different types of data processing environments. In order to provide a context for the description of the specific elements and functionality of the illustrative embodiments are provided hereafter as example environments in which aspects of the illustrative embodiments may be implemented. While the description following will focus primarily on a single data processing device implementation for directed resource folding for power management this is only an example and is not intended to state or imply any limitation with regard to the features of the present invention.

With reference now to the figures and in particular with reference to example diagrams of data processing environments are provided in which illustrative embodiments of the present invention may be implemented. It should be appreciated that are only examples and are not intended to assert or imply any limitation with regard to the environments in which aspects or embodiments of the present invention may be implemented. Many modifications to the depicted environments may be made without departing from the spirit and scope of the present invention.

In the illustrative embodiments a computer architecture is implemented as a combination of hardware and software. The software part of the computer architecture may be referred to as microcode or millicode. The combination of hardware and software creates an instruction set and system architecture that the rest of the computer s software operates on such as Basic Input Output System BIOS Virtual Machine Monitors VMM Hypervisors applications etc. The computer architecture created by the initial combination is immutable to the computer software BIOS etc except through defined interfaces which may be few.

Referring now to the drawings and in particular to there is depicted a block diagram of a data processing system with which aspects of the illustrative embodiments may advantageously be utilized. As shown data processing system includes processor units . Each of processor units includes a processor and a cache memory. For example processor unit contains processor and cache memory and processor unit contains processor and cache memory

Processor units are connected to main bus . Main bus supports system planar that contains processor units and memory cards . System planar also contains data switch and memory controller cache . Memory controller cache supports memory cards that include local memory having multiple dual in line memory modules DIMMs .

Data switch connects to bus bridge and bus bridge located within native I O NIO planar . As shown bus bridge connects to peripheral components interconnect PCI bridges and via system bus . PCI bridge connects to a variety of I O devices via PCI bus . As shown hard disk may be connected to PCI bus via small computer system interface SCSI host adapter . Graphics adapter may be directly or indirectly connected to PCI bus . PCI bridge provides connections for external data streams through network adapter and adapter card slots via PCI bus .

Industry standard architecture ISA bus connects to PCI bus via ISA bridge . ISA bridge provides interconnection capabilities through NIO controller having serial connections Serial and Serial . A floppy drive connection keyboard connection and mouse connection are provided by NIO controller to allow data processing system to accept data input from a user via a corresponding input device. In addition non volatile RAM NVRAM connected to ISA bus provides a non volatile memory for preserving certain types of data from system disruptions or system failures such as power supply problems. System firmware is also connected to ISA bus for implementing the initial Basic Input Output System BIOS functions. Service processor connects to ISA bus to provide functionality for system diagnostics or system servicing.

The operating system OS is stored on hard disk which may also provide storage for additional application software for execution by a data processing system. NVRAM is used to store system variables and error information for field replaceable unit FRU isolation. During system startup the bootstrap program loads the operating system and initiates execution of the operating system. To load the operating system the bootstrap program first locates an operating system kernel image on hard disk loads the OS kernel image into memory and jumps to an initial address provided by the operating system kernel. Typically the operating system is loaded into random access memory RAM within the data processing system. Once loaded and initialized the operating system controls the execution of programs and may provide services such as resource allocation scheduling input output control and data management.

The illustrative embodiment may be embodied in a variety of data processing systems utilizing a number of different hardware configurations and software such as bootstrap programs and operating systems. The data processing system may be for example a stand alone system or part of a network such as a local area network LAN or a wide area network WAN . As stated above is intended as an example not as an architectural limitation for different embodiments of the present invention and therefore the particular elements shown in should not be considered limiting with regard to the environments in which the illustrative embodiments of the present invention may be implemented.

While the illustrative embodiments may be implemented in any type of data processing system the following description is directed to a logically portioned system where resources such as processors memory or the like are apportioned by a virtualization mechanism based upon requests from operating systems in various partitions. By using runtime feedback and or communication between the partitioned hardware such as processor units or memory cards of and resource scheduling layers such as operation systems or virtual machine monitor of the illustrative embodiments provide for an optimal management of resources by the resource scheduling layers.

With reference now to a block diagram of an exemplary logically partitioned platform is depicted in which the illustrative embodiments may be implemented. The hardware in logically partitioned platform may be implemented for example using the hardware of data processing system in .

Logically partitioned platform includes partitioned hardware logical partitions and operating systems and virtual machine monitor . Operating systems and may be multiple copies of a single operating system or multiple heterogeneous operating systems simultaneously run on logically partitioned platform . These operating systems may be implemented for example using OS which is designed to interface with a virtualization mechanism such as virtual machine monitor e.g. a hypervisor. OS is used only as an example in these illustrative embodiments. Of course other types of operating systems such as AIX and Linux may be used depending on the particular implementation. Operating systems and are located in logical partitions and respectively.

Each of operating systems and may interface with a set of application programming interfaces APIs and one or more applications. While logically partitioned platform illustrates only logical partitions and the illustrative embodiments are not limited to such. Rather any number of logical partitions may be utilized with the mechanisms of the illustrative embodiments without departing from the spirit and scope of the present invention.

Hypervisor software is an example of software that may be used to implement platform in this example virtual machine monitor and is available from International Business Machines Corporation. Firmware is software stored in a memory chip that holds its content without electrical power such as for example a read only memory ROM a programmable ROM PROM an erasable programmable ROM EPROM and an electrically erasable programmable ROM EEPROM .

Logically partitioned platform may also make use of IBM s PowerVM Active Memory Sharing AMS which is an IBM PowerVM advanced memory virtualization technology that provides system memory virtualization capabilities to IBM Power Systems allowing multiple logical partitions to share a common pool of physical memory. The physical memory of IBM Power Systems may be assigned to multiple logical partitions either in a dedicated or shared mode. A system administrator has the capability to assign some physical memory to a logical partition and some physical memory to a pool that is shared by other logical partitions. A single partition may have either dedicated or shared memory. Active Memory Sharing may be exploited to increase memory utilization on the system either by decreasing the system memory requirement or by allowing the creation of additional logical partitions on an existing system.

Logical partitions and also include partition firmware loader and . Partition firmware loader and may be implemented using IPL or initial boot strap code IEEE 1275 Standard Open Firmware and runtime abstraction software RTAS which is available from International Business Machines Corporation.

When logical partitions and are instantiated a copy of the boot strap code is loaded into logical partitions and by virtual machine monitor . Thereafter control is transferred to the boot strap code with the boot strap code then loading the open firmware and RTAS. The processors associated or assigned to logical partitions and are then dispatched to the logical partition s memory to execute the logical partition firmware.

Partitioned hardware includes a plurality of processors a plurality of system memory units a plurality of input output I O adapters and storage unit . Each of the processors memory units NVRAM storage and I O adapters may be assigned to one of multiple logical partitions and within logically partitioned platform each of which corresponds to one of operating systems and .

Virtual machine monitor performs a number of functions and services for logical partitions and to generate and enforce the partitioning of logical partitioned platform . Virtual machine monitor is a firmware implemented virtual machine identical to the underlying hardware. Thus virtual machine monitor allows the simultaneous execution of independent OS images and by virtualizing all the hardware resources of logical partitioned platform .

Service processor may be used to provide various services such as processing of platform errors in logical partitions and . Service processor may also act as a service agent to report errors back to a vendor such as International Business Machines Corporation. Operations of the different logical partitions may be controlled through a hardware system console . Hardware system console is a separate data processing system from which a system administrator may perform various functions including reallocation of resources to different logical partitions.

Those of ordinary skill in the art will appreciate that the hardware in may vary depending on the implementation. Other internal hardware or peripheral devices such as flash memory equivalent non volatile memory or optical disk drives and the like may be used in addition to or in place of the hardware depicted in . Also the processes of the illustrative embodiments may be applied to a multiprocessor data processing system without departing from the spirit and scope of the present invention.

On a logically partitioned system such as logically partitioned platform of the allocation of processor and memory resources is highly dependent on the partition configuration. In general multiple partitions have processor and memory resources allocated from a single processor chip cores on the processor chip and the memory behind the memory controllers on the chip . It is also possible that a partition may have resources allocated from multiple chips in the system. In general the processor and memory allocation policies are geared towards optimal system performance. The processor and memory resources are allocated so that there is good affinity between a partition s processors and memory. However these allocation policies may conflict with the power savings policies with regard to packing processor and memory resources. It should be noted that the term packing with regard to resources is a term that is generally known in the art and is used herein as referring to the ability optimally schedule a resource so that the resource is performing at optimal power and performance but within the limits of the available power and cooling for the resource and the data processing system.

Operating systems and virtualization mechanisms such as operating systems and and virtual machine monitor of are in band resource managers on computer systems that manage the allocation of virtual and physical resources to processes tasks. These operating systems and virtualization mechanisms determine not only when a when physical resources are used for tasks but also what physical resources are used by which tasks. In the most prevalent mode of operation a resource scheduler dispatcher manager at each level has a load balancing component that distributes the tasks evenly among the available resources to ensure good performance.

The operating systems and virtualization mechanisms implement the concept of folding resources which is discussed above. As mentioned above the folding of resources frees resources by limiting the set of resources between which the tasks are distributed to only a subset of the available resources. That is folding is a technique used by an operating system to steer work away from one or more of its allocated resources. As the utilization of a resource by a logical partition decreases below a threshold the operating system will fold an allocated resource such that no work is dispatched and no interrupts are directed to the folded resource. By folding resources such that the distribution of current set of tasks is made to only a subset of resources the freed resources are then available for additional tasks spare capacity for donation to other resource pool managers e.g. donate to a different partition and or to be put into lower power idle modes to reduce power consumption.

Platform service and state management firmware may obtain these static and or dynamic platform resource utilization characteristics either through solicited or unsolicited means. That is platform service and state management firmware may poll each of resources for their specific platform resource utilization characteristics or platform service and state management firmware may receive the specific platform resource utilization characteristics from each of resources based on data observed by the resource and periodically sent by the resource. Once platform service and state management firmware receives the platform resource utilization characteristic information for one or more of resources platform service and state management firmware either sends this platform resource utilization characteristic information to virtualization mechanism based on a predetermined setting which may indicate immediately at predetermined time intervals or when polled such as by a virtualization mechanism one of the operating systems or one of the workload system management mechanisms or the like.

Virtualization mechanism may then relay the platform resource utilization characteristic information to operating systems and or workload system management mechanism which may manage the workload associated with one or more of operating systems on logical partitions as well as the resources controlled by virtualization mechanism . Virtualization mechanism may also send other physical resource management characteristics associated with resources to operating systems and or workload system management mechanism . That is since virtualization mechanism allocates each of resources to one or more of logical partitions virtualization mechanism retains state information such as voltage setting frequency settings or the like associated with each of resources that may be used by platform aware folding and resource management mechanism within the operating system platform aware folding and resource management mechanism within virtualization mechanism and or by workload system management mechanism .

Platform aware folding and resource management mechanisms and and workload system management mechanism may use the platform resource utilization characteristic information to identify resource allocation resource scheduling dynamic folding decisions or the like by determining whether one or more of the following resource usage properties conditions that identify one or more conditions under which a configuration of the one or more resources needs to be modified have been met 

Different methods may be adopted to resolve the status with respect each of the different properties conditions into a folding decision for a resource. The following presents one high level approach to combining the different properties conditions for a single folding decision. At every periodic folding decision instant platform aware folding and resource management mechanism platform aware folding and resource management mechanism and or workload system management mechanism compute the number of resource entities e.g. processor cores that are needed to sustain the aggregate resource load e.g. total cpu utilization across the system . If the number of active resource entities exceeds the required number then platform aware folding and resource management mechanism and or platform aware folding and resource management mechanism identify one or more of resources to fold. Folding is the process of releasing a virtual resource to virtualization mechanism . The determination of which resource to fold may be determined based on a least loaded resource a set priority to the resources a random selection or the like. If the number of active resource entities is below the required number platform aware folding and resource management mechanism platform aware folding and resource management mechanism and or workload system management mechanism identifies one or more of resources that should be activated. The determination of which resource to activate may be determined based on a least folded resource a set priority to the resources a random selection or the like.

In order to choose the right resource of resources to fold unfold platform aware folding and resource management mechanism platform aware folding and resource management mechanism and or workload system management mechanism may establish a special metric with a value associated with each of resources referred to as the Folding Desirability Metric FDM where the value is computed from the conditions associated with each of resources such as those conditions described above. For example FDM could be a linear combination of the observations for different platform resource utilization characteristics of each of resources such as PropertyScale Func PropertyValue Threshold where PropertyScaleis a precedence priority of one property over another PropertyValueis a number of active cores in same socket as the icore entity and Thresholdis a threshold at which a resource should be folded or activated.

A set of resources in resources with higher FDM values may be preferred for folding over other resources in resources with lower values and vice versa for unfolding. The PropertyScalemultiplicant may be used to establish the precedence priority of one property over another. For example if resource sub system energy efficiency is considered more important than average resource thermal environment then the PropertyScalefactor for Energy efficiency property may be set much higher than the factor for Temperature such that temperature becomes a factor for folding consideration only when energy efficiency of all possible candidate resources are identical. An alternative to using the PropertyScaleto establish priority among the properties is to explicitly consider higher priority platform resource utilization characteristics first and consider lower priority platform resource utilization characteristics only when all fold able entities are on par for values with the higher priority platform resource utilization characteristics.

In addition to PropertyScalethe function Funcmay be customized to each property to convert it to a comparable quantitative measure. For example desirability is generally higher to fold the last remaining processor cores on a socket as opposed to one of many active cores on a socket in a multi socket system. This is because the former would then free up an entire socket to be put into a lower power idle mode from reducing voltage down to retention as opposed to using higher voltages and power on sockets where there are still some active cores . Here Funcmay be 1 PropertyValue Number of active cores in same socket as the icore entity Threshold 1 Number of usable cores in the same socket . With this the contribution to FDM of a core which is the lone active core on a socket will be much higher than for a core which is one among many active cores in its socket.

Note that it is also possible for platform aware folding and resource management mechanism platform aware folding and resource management mechanism and or workload system management mechanism to use the FDM measure or the like thereof to not just choose when to fold not fold ones of resources but even to decide which ones of resources to use for any scheduling. For example those ones of resources whose FDM measure or like thereof exceed a certain threshold may be eliminated temporarily from the resource pool i.e. folded and added back i.e. unfolded only when their measures fall below the given threshold or vice versa.

Optionally workload system management mechanism may also examine the above conditions across the full or a partial set of logical partitions in logically partitioned platform to evaluate more global resource optimization opportunities. Depending on the partition environment e.g. dedicated or shared resource type virtual processor physical memory and optimization scope within partition entire system or across pool of partitions used for a single job each of platform aware folding and resource management mechanism platform aware folding and resource management mechanism or workload system management mechanism may each serve as the primary decision making entity with optional additional input from the others.

In one embodiment when a partition is a dedicated partition then platform aware folding and resource management mechanism may be the primary decision making entity. That is if a partition is a dedicated partition platform aware folding and resource management mechanism determines whether one or more conditions have been met for each dedicated resource assigned to the dedicated partition. Platform aware folding and resource management mechanism then determines for each dedicated resource that meets one or more of the conditions whether the dedicated resource needs to be optimally scheduled or dynamically folded. Based on the determination platform aware folding and resource management mechanism either performs a virtual resource management action or sends platform directed resource management commands to platform aware resource management mechanism in virtualization mechanism to perform a physical resource management action.

In another illustrative embodiment when a partition is a shared partition then platform aware folding and resource management mechanism may be the primary decision making entity. That is if a partition is a shared partition and thus its resources are controlled by virtualization mechanism then platform aware folding and resource management mechanism determines whether one or more conditions have been met for each shared resource controlled by virtualization mechanism . Platform aware folding and resource management mechanism then determines for each shared resource that meets one or more of the conditions whether the shared resource needs to be optimally scheduled or dynamically folded. Based on the determination platform aware folding and resource management mechanism either sends platform directed resource management commands to platform aware resource management mechanism in operating system to perform a virtual resource management or performs a physical resource management.

In still another illustrative embodiment when the workload system management mechanism is managing multiple one of logical partitions in order to enact the resource optimization workload system management mechanism may send platform directed resource management commands to platform aware folding and resource management mechanism in operating system and or platform aware folding and resource management mechanism in virtualization mechanism . Platform aware folding and resource management mechanism may perform those ones of the platform directed resource management commands that are directed to virtual resource management such as consolidation of resource activities task or workload allocation and or reallocation virtual processor folding or the like. Platform aware folding and resource management mechanism may perform those ones of the platform directed resource management commands that are directed to physical resource management such as physical processor folding for a shared pool memory interleaving aware allocation memory folding or the like.

By implementing resource optimization using runtime communication of platform attributes and environmental information from the platform firmware and or hardware the illustrative embodiments provide superior energy efficiency improved performance on active resources and an increased reliability of operation which in turn may enables more intelligent system stack with improved overall infrastructure efficiencies and more competitive systems and computing solutions.

As will be appreciated by one skilled in the art the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in any one or more computer readable medium s having computer usable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CDROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in a baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Computer code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable radio frequency RF etc. or any suitable combination thereof.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to the illustrative embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions that implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

Referring now to these figures provide flowcharts outlining example operations of directed resource folding for power management. depicts a flowchart outlining example operations of directed resource folding for power management for a dedicated partition in accordance with an illustrative embodiment. As the operation begins platform service and state management firmware monitors a set of resources in partitioned hardware for static and or dynamic platform resource utilization characteristics step . The platform service and state management firmware may obtain these static and or dynamic platform resource utilization characteristics either through solicited or unsolicited means. Once the platform service and state management firmware receives the platform resource utilization characteristic information for one or more resources the platform service and state management firmware sends the platform resource utilization characteristic information to a virtualization mechanism based on a predetermined setting step .

The virtualization mechanism then relays the platform resource utilization characteristic information to a platform aware folding and resource management mechanism in an operating system of the dedicated partition step . The virtualization mechanism may also send other physical resource management characteristics associated with the one or more resources to the platform aware folding and resource management mechanism in the operating system step . The platform aware resource management mechanism in the operating system uses the platform resource utilization characteristic information to identify resource allocation resource scheduling dynamic folding decisions or the like for dedicated resources by determining whether one or more conditions have been met for each dedicated resource in the set of resources step .

Once the platform aware resource management mechanism in the operating system has determined whether one or more of the following conditions have been met for each dedicated resource in the set of resources the platform aware resource management mechanism in the operating system may perform a resource optimization such that only the required number of dedicated resources for current aggregate load are kept active and additional dedicated resources are folded with targets for specific resources to be folded based on the condition of each resource with respect to the monitored platform resource utilization characteristics. The monitored platform resource utilization characteristics are used to facilitate enforce that those resources determined as excess for current load are specifically selected based on the monitored platform resource utilization characteristics to boost energy efficiency reliability and other desired operational properties step . These explicitly targeted resources are then dynamically folded. The resources determined as necessary are then optimally scheduled. For each resource if at step the decision is to optimize the schedule for that dedicated resource then platform aware resource management mechanism in the operating system performs virtual resource management such as consolidation of resource activities task or workload allocation and or reallocation or the like step .

If at step the decision is to dynamically fold that dedicated resource then the platform aware resource management mechanism in the operating system temporarily releases the resource to the virtualization mechanism and sends platform directed resource management commands to a platform aware folding and resource management mechanism in the virtualization mechanism to perform those ones of the platform directed resource management commands that are directed to physical resource management such as processor folding using an appropriate low power mode memory interleaving aware de allocation memory folding or the like step . From steps or the platform aware resource management mechanism in the operating system determines whether there is another resource in the set of resources to analyze step . If at step there is another resource then the operation returns to step . If at step there is not another resource then the operation terminates.

The entire flow from Begin to End in is repeated for each distinct resource type managed with directed resource folding technology for example performed once for compute resources such as processors then over storage resources such as main memory and so on.

The virtualization mechanism then relays the platform resource utilization characteristic information to an operating system and optionally to a workload system management mechanism within the operating system or outside step . The virtualization mechanism may also send other physical resource management characteristics associated with the one or more resources to the operating system step . The platform aware resource management mechanism in the virtualization mechanism uses the platform resource utilization characteristic information to identify resource allocation resource scheduling dynamic folding decisions or the like for shared resources by determining whether one or more conditions have been met for each shared resource in the set of resources step .

Once the platform aware resource management mechanism in the virtualization mechanism has determined whether one or more of the following conditions have been met for each shared resource in the set of resources the platform aware resource management mechanism in the virtualization mechanism may perform a resource optimization such that only the required number of shared resources for current aggregate load are kept active and additional shared resources are folded with targets for specific resources to be folded based on the condition of each resource with respect to the monitored platform resource utilization characteristics. The monitored platform resource utilization characteristics are used to facilitate enforce that only those resources that are necessary are optimally scheduled and any non optimally used resources are dynamically folded step . For each resource if at step the decision is to optimize the schedule for that shared resource then the platform aware resource management mechanism in the virtualization mechanism sends platform directed resource management commands to a platform aware folding and resource management mechanism in the operating system to perform virtual resource management such as consolidation of resource activities task or workload allocation and or reallocation or the like step .

If at step the decision is to dynamically fold that resource then the platform aware resource management mechanism in the virtualization mechanism perform those ones of the platform directed resource management commands that are directed to physical resource management such as processor folding memory interleaving aware allocation memory folding or the like step . From steps or the workload system management mechanism determines whether there is another resource in the set of resources to analyze step . If at step there is another resource then the operation returns to step . If at step there is not another resource then the operation terminates.

The entire flow from Begin to End in is repeated for each distinct resource type managed with directed resource folding technology for example performed once for compute resources such as processors then over storage resources such as main memory and so on.

The virtualization mechanism then relays the platform resource utilization characteristic information to a workload system management mechanism associated with the plurality of logical partitions step . The virtualization mechanism may also send other physical resource management characteristics associated with the one or more resources to the workload system management mechanism step . The workload system management mechanism uses the platform resource utilization characteristic information to identify resource allocation resource scheduling dynamic folding decisions or the like by determining whether one or more conditions have been met for each resource in the set of resources step .

Once the workload system management mechanism has determined whether one or more of the following conditions have been met for each resource in the set of resources the workload system management mechanism may perform a resource optimization such that only the required number of resources for current aggregate load are kept active and additional resources are folded with targets for specific resources to be folded are based on the condition of each resource with respect to the monitored platform resource utilization characteristics. The monitored platform resource utilization characteristics are used to facilitate enforce that only those resources that are necessary are optimally scheduled and any non optimally used resources are dynamically folded step . For each resource if at step the decision is to optimize the schedule for that resource then the workload system management mechanism sends platform directed resource management commands to a platform aware folding and resource management mechanism in operating system to perform virtual resource management such as consolidation of resource activities task or workload allocation and or reallocation or the like step .

If at step the decision is to dynamically fold that resource then for a physical resource the workload system management mechanism sends platform directed resource management commands to a platform aware folding and resource management mechanism in the virtualization mechanism to perform those ones of the platform directed resource management commands that are directed to physical resource management such as processor folding memory interleaving aware allocation memory folding or the like step . For a virtual resource the workload system management mechanism sends platform directed resource management commands to a platform aware folding and resource management mechanism in the operating system to carry out the appropriate virtual resource folding operations. From steps or the workload system management mechanism determines whether there is another resource in the set of resources to analyze step . If at step there is another resource then the operation returns to step . If at step there is not another resource then the operation terminates.

The entire flow from Begin to End in is repeated for each distinct resource type managed with directed resource folding technology for example performed once for compute resources such as processors then over storage resources such as main memory and so on.

The flowcharts and block diagrams in the figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

Thus the illustrative embodiments provide mechanisms for using runtime feedback and or communication between the platform such as firmware hardware or the like and resource scheduling layers such as operation systems virtualization mechanisms or the like for optimal management of resources by either an operating system a virtualization mechanism or the like.

As noted above it should be appreciated that the illustrative embodiments may take the form of an entirely hardware embodiment an entirely software embodiment or an embodiment containing both hardware and software elements. In one example embodiment the mechanisms of the illustrative embodiments are implemented in software or program code which includes but is not limited to firmware resident software microcode etc.

A data processing system suitable for storing and or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus. The memory elements can include local memory employed during actual execution of the program code bulk storage and cache memories which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.

Input output or I O devices including but not limited to keyboards displays pointing devices etc. can be coupled to the system either directly or through intervening I O controllers. Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems cable modems and Ethernet cards are just a few of the currently available types of network adapters.

The description of the present invention has been presented for purposes of illustration and description and is not intended to be exhaustive or limited to the invention in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. The embodiment was chosen and described in order to best explain the principles of the invention the practical application and to enable others of ordinary skill in the art to understand the invention for various embodiments with various modifications as are suited to the particular use contemplated.

