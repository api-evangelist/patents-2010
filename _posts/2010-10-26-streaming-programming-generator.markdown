---

title: Streaming programming generator
abstract: A device receives input that includes definitions of components of a computational pipeline, where the components include one or more buffers, one or more kernels, and one or more stages within a control graph. The device generates, based on the input, kernel signatures for a graphics processor, where the kernel signatures compile into an executable streaming program for the computational pipeline. The device also generates, based on the input, host-side runtime code to execute the streaming program.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08856760&OS=08856760&RS=08856760
owner: Advanced Micro Devices, Inc.
number: 08856760
owner_city: Sunnyvale
owner_country: US
publication_date: 20101026
---
Graphics or graphical processing units GPUs have evolved from fixed function pipelines used primarily for graphics acceleration to programmable parallel processing units that are suitable for general purpose computations. Improved GPU performance has made GPUs increasingly popular for general purpose computations on GPUs referred to as GPGPU . GPGPU generally uses a GPU to perform computations in applications traditionally handled by a central processing unit CPU . GPGPU is made possible by the addition of programmable stages and higher precision arithmetic to computational pipelines allowing developers to use streaming programming languages on non graphics data. Graphics processors include discrete GPUs e.g. separate devices primarily dedicated to the processing of graphics integrated GPUs e.g. integrated into another device such as a north bridge CPUs capable of processing graphics accelerated or fused processing units e.g. a GPU integrated into another processor such as a CPU digital signal processors DSPs application processors and the like.

Several GPU programming languages target GPGPU such as OpenCL from the Khronos Group DirectCompute from Microsoft Corporation CUDA from NVIDIA Corporation . These programming languages are typically based on the C programming language. These streaming programming languages describe computational kernels and data buffers but do not describe higher level constructs that result from their composition.

According to one embodiment a computing device implemented method may include receiving by the computing device input that defines components of a computational pipeline where the components include one or more buffers one or more kernels and one or more stages within a control graph. The method may further includes generating by the computing device and based on the input kernel signatures for a graphics processor where the kernel signatures compile into an executable streaming program for the computational pipeline and generating by the computing device and based on the input host side runtime code to execute the streaming program.

According to one aspect the input may include one or more application programming interface calls or a text file supplied by a user.

According to another aspect the method may further include providing a graphical user interface to accept from the user definitions for the one or more buffers the one or more kernels and the one or more stages within the control graph and generating based on the definitions an input file.

According to still another aspect the host side runtime code may include a file of external pipeline stages and a unit test framework.

According to another embodiment a device may include a memory to store a plurality of instructions and a processor. The processor may execute instructions in the memory to receive from a user definitions of components of a computational pipeline where the components include multiple buffers multiple kernels and multiple stages within a control graph generate based on the input file kernel signatures for a graphics processor where the kernel signatures compile into an executable streaming program for the computational pipeline and generate based on the definitions host side runtime code to execute the streaming program.

According to a further embodiment a computer readable memory device may store one or more computer executable instructions and may include one or more instructions to receive user input that includes definitions of components of a computational pipeline where the components include one or more buffers one or more kernels and one or more stages within a control graph. The computer readable memory device may also include one or more instructions to generate based on the input file kernel signatures for a graphics processor where the kernel signatures compile into an executable streaming program for the computational pipeline and one or more instructions to generate based on the user input host side runtime code to execute the streaming program.

The following detailed description refers to the accompanying drawings. The same reference numbers in different drawings may identify the same or similar elements. Also the following detailed description does not limit the invention.

Systems and or methods described herein may provide a toolkit for developing computational pipelines in streaming programming languages such as OpenCL and DirectCompute. In an embodiment described herein computational pipelines may be described by a control graph with associated stages buffers and kernels. The toolkit may automatically generate a working streaming program e.g. an OpenCL DirectCompute or CUDA program from the control graph description and may provide additional features to test document and profile the resulting streaming program. In embodiments described herein programs can be executed on a graphics processor such as a single GPU multiple GPUs multicore CPUs etc.

Systems and or methods described herein may reduce effort required of programmers by automating tedious and repetitive software chores. For example the systems and or methods may allow a novice streaming programming language programmer to specify and construct a working program with significantly less time than would be required using conventional programming techniques. The systems and or methods may allow a software architect to design at the pipeline level rather than being bogged down in the details of the streaming programming language constructs. Additionally the systems and or methods may allow an application developer to estimate throughput and performance of a design based on parameters

The terms component and device as used herein are intended to be broadly construed to include hardware e.g. a processor a microprocessor an application specific integrated circuit ASIC a field programmable gate array FPGA a chip a memory device e.g. a read only memory ROM a random access memory RAM etc. etc. or a combination of hardware and software e.g. a processor microprocessor ASIC etc. executing software contained in a memory device .

Program generator may include a compiler component to transform input file to an alternative form. For example program generator may generate code e.g. executable streaming program that corresponds to a format e.g. OpenCL DirectCompute CUDA etc. identified in high level abstractions of input file . Program generator may perform various operations to generate the code. For example program generator may prepare data structures evaluate parameters determine entity connectivity determine signal compatibility etc. associated with the high level abstractions of input file . Given the expansive nature of existing compilers it will be appreciated that this description is not intended to be construed as an exhaustive treatment of compilers code generators translators and the like. Generally compilers may convert or translate a source language to a target language. Thus for purposes of discussion program generator may be described as a compiler that converts the high level abstractions of input file into an executable form which may then be executed to evaluate a computational pipeline.

Input file may include for example a pipeline specification in the form of a text file. In one embodiment input file may define components of a computational pipeline. For example input file may describe the relationships among buffers kernels uniforms and invariants of a streaming program. Control flow may be specified by one or more control graphs or execution graphs that consist of stages. Stages may typically invoke kernels although some stages may execute on a host CPU such as stages that make branching decisions. Input file may also define code sections of a resulting executable streaming program.

Executable streaming program may include for example an executable streaming program compiled based on input file . Executable streaming program may use a streaming programming language identified in input file such as OpenCL DirectCompute CUDA or another selected streaming programming language. Executable streaming program may include multiple control graphs from a single input file . The control graphs may execute on one or more graphics processors and or on graphics processors distributed across nodes of a Message Passing Interface MPI computing cluster.

Runtime code may include for example code to execute executable streaming program for efficiency for unit testing for debugging and or for performance measurement and prediction. For example the runtime code may simulate the memory access patterns of the kernels so that memory bandwidth requirements can be estimated based on input file .

As illustrated in device may include a bus a processing unit a main memory a ROM a storage device an input device an output device and or a communication interface . Bus may include a path that permits communication among the components of device .

Processing unit may include one or more processors e.g. multi core processors microprocessors or other types of processing units that may interpret and execute instructions. In one embodiment processing unit may include a single processor that includes multiple cores. Main memory may include a RAM a dynamic RAM DRAM and or another type of dynamic storage device that may store information and instructions for execution by processing unit . ROM may include a ROM device or another type of static storage device that may store static information and or instructions for use by processing unit . Storage device may include a magnetic and or optical recording medium and its corresponding drive.

Input device may include a mechanism that permits an operator to input information to device such as a keyboard a mouse a pen a microphone voice recognition and or biometric mechanisms a touch screen etc. Output device may include a mechanism that outputs information to the operator including a display a printer a speaker etc. Communication interface may include any transceiver like mechanism that enables device to communicate with other devices and or systems. For example communication interface may include mechanisms for communicating with another device or system via a network.

As described herein device may perform certain operations in response to processing unit executing software instructions contained in a computer readable medium such as main memory . A computer readable medium may be defined as a physical or logical memory device. A logical memory device may include memory space within a single physical memory device or spread across multiple physical memory devices. The software instructions may be read into main memory from another computer readable medium such as storage device or from another device via communication interface . The software instructions contained in main memory may cause processing unit to perform processes described herein. Alternatively hardwired circuitry may be used in place of or in combination with software instructions to implement processes described herein. Thus embodiments described herein are not limited to any specific combination of hardware circuitry and software.

Although shows example components of device in other embodiments device may include fewer components different components differently arranged components or additional components than depicted in . Alternatively or additionally one or more components of device may perform one or more other tasks described as being performed by one or more other components of device .

Parameters may include top level attributes for the computational pipeline. Some top level attributes may be defined to set defaults for kernel invocation and the program generator target e.g. OpenCL DirectCompute CUDA etc. . Generally one pipeline declaration may be included per input file . Input file may begin for example with Pipeline . One of the attributes can be target where is a supported streaming programming language such as OpenCL or DirectCompute. Other attributes may include for example range and workgroup size. After the top level attributes input file may include a list of objects e.g. invariant objects buffer objects uniform objects kernel objects stage objects and control graph object s that define the computational pipeline. Any top level attributes that are defined in parameters may be inherited by relevant objects. However the top level attributes may be overridden in a declaration for later objects.

Invariant objects may support standard binary operators. Invariant object types may include for example integers e.g. and floating points e.g. . If an expression is provided for an invariant object the equation can be true whenever the generated class invokes kernels. This makes it possible to preserve invariants at runtime that can be passed into a kernel as a uniform object or used to control kernel invocation for example by controlling the range . The generated class may contain accessor and mutator functions e.g. of the form getX and setX y for each variable X named on the left hand side of an invariant object. The invariant equation can be respected so long as the application uses these mutator functions to change the values of the relevant variables. If no expression is provided then a variable may be reserved that may be used in other invariant objects. An example syntax for invariant object may include 

where may include or may include an identifier for the invariant object and may include an invariant equation.

Buffer objects may describe a memory component that may receive information from and or provide information to a kernel. In one embodiment buffer object may declare a buffer of a specified type such as a primitive type in OpenCL or DirectCompute. An example syntax for buffer object may include 

where Buffer may include an identifier for the buffer object  global  local may include alternative attribute declarations may include a primitive type in OpenCL or DirectCompute and may include an expression of the buffer size.

Uniform objects may declares scalar quantities that can be passed into kernels e.g. kernel objects as arguments. As with invariant objects uniform object types may include integers e.g. and floating points e.g. . These quantities may exist as class members and may be directly accessed or modified. Unlike invariant objects uniform objects may not have a corresponding expression. An example syntax for invariant object may include 

Kernel objects may declare a kernel with a list of input parameters and output parameters. In one embodiment a kernel declaration may be similar to a function prototype in the C programming language. The input and output parameters of kernel objects may be matched with arguments provided in stage objects . An example syntax for kernel object may include 

Kernel . . . . . . where Kernel may include an identifier for the kernel object may define for example arguments for consuming buffers and may define for example arguments for producing buffers.

Stage objects may declare an invocation of a kernel as a stage of a control graph. In one embodiment a stage object may be similar to a function invocation in the C programming language. Named arguments may be provided to the kernel and should agree in type with parameters declared for that kernel. In one implementation stage objects may include barriers and or fences to synchronize multi GPU processing. An example syntax for stage object may include 

where Stage may include an identifier for the stage object and kernelId may include an identifier for a kernel object.

Control graph object s may define a control graph that determines a sequence in which stage objects may execute. In one embodiment multiple control graphs may be defined and selected at runtime. Each control graph may have a starting stage object specified by the attribute start. Control graph object may be defined by a list of edges where each edge may be defined by a pair of stages. That is a stage object pair may correspond to an edge in the control graph while each stage object may correspond to a vertex in the control graph. In one embodiment control graph object may contain cycles. Any stage object that has multiple descendents may be defined as a branch selector stage e.g. declaring the attribute branchSelector . An example syntax for control graph object may include 

Although shows example elements of input file in other embodiments input file may include fewer elements different elements differently arranged elements or additional elements than depicted in . Alternatively or additionally one or more elements of input file include assignments for one or more other tasks described as being assigned by one or more other elements of input file . Alternatively the elements may be provided by making API calls rather than providing a textual input file.

Stages may invoke a kernel e.g. defined by one of kernel objects for a particular graphics processor or one of multiple graphics processors. In some embodiments stages may alternatively invoke host side CPU resources that do not invoke a kernel on a graphics processor. The kernels may produce e.g. write to and or consume e.g. read from buffers . Terminology used within stages and buffers of is for illustrative purposes. The terminology may relate to for example a smoothed particle hydrodynamics simulation. Thus stages may include representative kernel object names such as clear buffers hash particles sort sort postpass index integrate and compute. 

As shown in stages may form a linear sequence with each stage being connected to a subsequent stage via one of edges . Particularly the linear sequence may start with clear buffers followed by hash particles sort sort postpass and index. After the index stage other stages not shown may eventually lead to the integrate stage and the final compute stage. In other embodiments control graph portion may include a non linear sequence of stages including for example branches and or loops.

A kernel executed at each stage may write to and or read from a buffer to perform a task. Data flows to from buffers are indicated in control graph portion via dotted lines. Arrows from buffers leading into stages may represent that stages consume those buffers and arrows leading out of stages may represent that stages produce those buffers .

In an embodiment herein a user may arrange re arrange stages by revising input file e.g. by changing the stage sequence in control graph object . In another embodiment a user may employ a graphical user interface e.g. presented on a display such as output device to arrange stages . Thus a streaming programmer may design at the stage pipeline level without being delayed in the details of the streaming programming language constructs.

Although shows example elements control graph portion in other embodiments control graph portion may include fewer objects different objects differently arranged objects or additional objects than depicted in .

Input interface module may include hardware or a combination of hardware and software that may collect user input to define elements of a computational pipeline. For example input interface module may provide a menu driven interface to solicit definitions of buffers kernels and stages. In one embodiment input interface module may instruct a user to provide an input that includes optional code sections invariants buffers uniforms kernels stages and control graphs in that order. In another embodiment input interface module may take the form of one or more templates. In still another embodiment input interface module may include a graphical user interface that allows a user to define for example invariants buffers uniforms kernels and stages. The graphical user interface may visually present the invariants buffers uniforms kernels and or stages within a control graph e.g. similar to control graph portion that may be arranged and or modified by a user at a high level of abstraction e.g. via buffers kernels stages etc. . Input interface module may collect assemble the user input into a file e.g. input file with a format e.g. a pipeline description language that may be converted by program generator into a streaming programming language.

Compiler may include hardware or a combination of hardware and software that may perform a source to source translation from a pipeline description language of input file to a C based programming language. For example compiler may read input file and generate a pipeline class e.g. OpenCL DirectCompute etc. in a C file with a .hpp extension.

Runtime environment may include hardware or a combination of hardware and software that may generate and execute runtime code. For example runtime environment may also generate a file of external pipeline stages e.g. a C source code file with a .ext.cpp extension and a unit test framework e.g. a C source code file with a .test.cpp extension . In an embodiment the runtime code can execute the streaming program for high efficiency for unit testing for debugging and for performance measurement and prediction. For example runtime environment may produce code that simulates the memory access patterns of the kernels so that memory bandwidth requirements can be estimated from the description of the pipeline. In another embodiment memory access patterns of the kernels may be combined with feedback from for example an integrated runtime profiler e.g. that gathers performance data from the GPU as the streaming program application executes to build a model of program performance at different problem scales. The runtime code may be executed when frames are served e.g. for each stage of a control graph . The runtime code may be executed on every frame requested and only for that specific frame in an event driven fashion.

Although shows example functional components of program generator in other embodiments program generator may include fewer functional components different functional components differently arranged functional components or additional functional components than depicted in . Alternatively or additionally one or more functional components of program generator may perform one or more other tasks described as being performed by one or more other functional components of program generator .

As illustrated in process may include providing a user interface to receive from a user input such as definitions for buffers kernels and stages within a control graph block and generating an input file based on the user input block . For example in embodiments described above in connection with program generator e.g. input interface module may provide a menu driven interface to solicit definitions of buffers kernels and stages. In one embodiment input interface module may instruct a user to provide an input that includes optional code sections invariants buffers uniforms kernels stages and control graphs in that order. In another embodiment input interface module may take the form of one or more templates. In still another embodiment input interface module may include a graphical user interface that allows a user to define for example invariants buffers uniforms kernels and stages. The graphical user interface may visually present the invariants buffers uniforms kernels and or stages within a control graph e.g. similar to control graph portion that may be arranged and or modified by a user at a high level of abstraction e.g. via buffers kernels stages etc. . Input interface module may collect assemble the user input into a file e.g. input file with a format e.g. a pipeline description language that may be converted by program generator into a streaming programming language.

As further shown in process may include generating based on the input file kernel signatures for a graphics processor where kernel signatures compile into an executable streaming program for the computational pipeline block . For example in embodiments described above in connection with program generator e.g. compiler may read input file and generate kernel signatures in an OpenCL programming language file.

Returning to process may include generating based on the input file host side runtime code to execute the streaming program block . For example in embodiments described above in connection with runtime environment may generate a pipeline class e.g. a C file with an .hpp extension a file of external pipeline stages e.g. a C source code file with a .ext.cpp extension and a unit test framework e.g. a C source code file with a .test.cpp extension . In an embodiment the runtime code can execute the streaming program for high efficiency for unit testing for debugging and for performance measurement and prediction. For example runtime environment may produce code that simulates the memory access patterns of the kernels so that memory bandwidth requirements can be estimated from the description of the pipeline. In another embodiment memory access patterns of the kernels may be combined with feedback from for example an integrated runtime profiler e.g. that gathers performance data from the graphics processor as the streaming program application runs to build a model of program performance at different problem scales.

Systems and or methods described herein may receive an input file that includes definitions of components of a computational pipeline where the components include one or more buffers one or more kernels and one or more stages within a control graph. The systems and or methods may generate based on the input file kernel signatures for a graphics processor where the kernel signatures compile into an executable streaming program for the computational pipeline and may generate based on the input file host side runtime code to execute the streaming program.

The foregoing description of embodiments provides illustration and description but is not intended to be exhaustive or to limit the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practice of the invention.

For example while a series of blocks has been described with regard to the order of the blocks may be modified in other embodiments. Further non dependent blocks may be performed in parallel. In another example the number of different applications and threads described herein were provided for explanatory purposes only.

It will be apparent that aspects as described above may be implemented in many different forms of software firmware and hardware in the embodiments illustrated in the figures. The actual software code or specialized control hardware used to implement these aspects should not be construed as limiting. Thus the operation and behavior of the aspects were described without reference to the specific software code it being understood that software and control hardware could be designed to implement the aspects based on the description herein.

Further certain embodiments described herein may be implemented as a component or as logic that performs one or more functions. This component or logic may include hardware such as a processor an ASIC or a FPGA or a combination of hardware and software.

Even though particular combinations of features are recited in the claims and or disclosed in the specification these combinations are not intended to limit the disclosure of the invention. In fact many of these features may be combined in ways not specifically recited in the claims and or disclosed in the specification. Although each dependent claim listed below may directly depend on only one other claim the disclosure of the invention includes each dependent claim n combination with every other claim n the claim set.

No element block or instruction used in the present application should be construed as critical or essential to the invention unless explicitly described as such. Also as used herein the article a is intended to include one or more items. Where only one item is intended the term one or similar language is used. Further the phrase based on is intended to mean based at least in part on unless explicitly stated otherwise.

