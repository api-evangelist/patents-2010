---

title: Distributed publish/subscribe system
abstract: In one embodiment, a first one of a plurality of message processors receives a request with respect to a topic, and determines whether the first message processor itself is currently responsible for the topic. If so, then the first message processor services the request. If not, then the first message processor determines whether any of the other ones of the message processors is currently responsible for the topic. If so, then the request is redirected to another message processor to be serviced. If not, then the first message processor selects one of the message processors to be responsible for the topic and to service the request.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08489674&OS=08489674&RS=08489674
owner: Yahoo! Inc.
number: 08489674
owner_city: Sunnyvale
owner_country: US
publication_date: 20100311
---
The present disclosure generally relates to a publish subscribe system and more specifically relates to a topic based distributed publish subscribe system including multiple data centers each of which serving a number of publishers and subscribers.

Publish Subscribe or simply pub sub is an asynchronous messaging paradigm. There may be any number of publishers and subscribers. Each publisher may publish any number of messages. However a publisher is not programmed to send its messages to specific subscribers. Instead the messages are grouped into any number of classes often called topics . That is each message published by a publisher may belong to one or more of the topics. Each subscriber may express interest in one or more of the topics and receive messages belonging to those specific topics. In this sense a subscriber subscribes to the specific topics of interest and receives only the messages belonging to those topics it subscribes. Alternatively each subscriber may specify one or more content filters and receive messages that match to those content filters. Of course an entity may be both a publisher and a subscriber as the same entity may both publish messages and subscribe to topics.

The present disclosure generally relates to a publish subscribe system and more specifically relates to a topic based distributed publish subscribe system including multiple data centers each of which serving a number of publishers and subscribers.

In particular embodiments a first one of a plurality of data centers of a publish subscribe system comprises a message store operable to store one or more messages belonging to one or more topics a metadata store operable to store information concerning the first data center a cross data center component operable to exchange one or more of the messages with other ones of the data centers and a plurality of message processors.

In particular embodiments a first one of the message processors is operable to receive a request with respect to a first one of the topics from a client device associated with a user and connected with the first message processor determine whether the first message processor itself is currently responsible for the first topic if the first message processor itself is currently responsible for the first topic then service the request and if the first message processor itself is not currently responsible for the first topic then determine whether any of other ones of the message processors is currently responsible for the first topic based on the information stored in the metadata store if a second one of the message processors is currently responsible for the first topic then redirect the request to the second message processor to be serviced and if none of the other ones of the message processors is currently responsible for the first topic then select one of the message processors to be responsible for the first topic if the selected one of the message processors is the first message processor then service the request and if the selected one of the message processors is not the first message processor then redirect the request to the selected one of the message processors to be serviced.

These and other features aspects and advantages of the disclosure are described in more detail below in the detailed description and in conjunction with the following figures.

The present disclosure is now described in detail with reference to a few embodiments thereof as illustrated in the accompanying drawings. In the following description numerous specific details are set forth in order to provide a thorough understanding of the present disclosure. It is apparent however to one skilled in the art that the present disclosure may be practiced without some or all of these specific details. In other instances well known process steps and or structures have not been described in detail in order not to unnecessarily obscure the present disclosure. In addition while the disclosure is described in conjunction with the particular embodiments it should be understood that this description is not intended to limit the disclosure to the described embodiments. To the contrary the description is intended to cover alternatives modifications and equivalents as may be included within the spirit and scope of the disclosure as defined by the appended claims.

Typically in a publish subscribe system there may be one or more publishers and one or more subscribers. Each publisher may publish one or more messages. A message may have any format such as for example and without limitation text audio video graphic or executable. The present disclosure contemplates any suitable message format. The publish subscribe system may be topic based. In this case the messages may be grouped into one or more topics. In particular embodiments each topic may have a unique topic name such as for example and without limitation music travel sports entertainment education or finance. The present disclosure contemplates any suitable topic name. A message may belong to one or more of the topics. Each subscriber may subscribe to one or more of the topics. When a subscriber subscribes to a specific topic it receives all messages published to that topic until the subscriber stops its subscription to the topic. Alternatively the publish subscribe system may be content based. In this case each subscriber may specify one or more content filters and receive all messages that match each of the content filters from any publisher. An entity may be both a publisher and a subscriber. Because the messages are grouped according to topics and the subscribers subscribe to specific topics such a publish subscribe system may be referred to as a topic based publish subscribe system.

In particular embodiments a publish subscribe system may provide a number of guarantees to its users i.e. publishers and subscribers . First some publish subscribe systems may guarantee the delivery of the messages. That is if a subscriber subscribes to a particular topic it is guaranteed that the subscriber receives all the messages published to that topic after its subscription of the topic by all the publishers until the subscriber stops its subscription of the topic. For example with a topic based publish subscribe system suppose that a subscriber u subscribes to a topic T at a certain time t. With guaranteed delivery of the messages uis guaranteed to receive all messages published to Tafter t regardless of which publisher has actually published which message. However uis not guaranteed and in practice is not likely to receive any message published to Tbefore t. Further suppose that uun subscribes to Tat a later time t. Then no message published to Tafter tis delivered to u.

Second some publish subscribe systems may guarantee the order of the messages when delivered. That is if a subscriber subscribes to a particular topic it is guaranteed that the subscriber receives the messages published to that topic in the same order as they are published. For example again suppose that uhas subscribed to T. Further suppose that after t there are three messages M M and M published to T with Mpublished after M and Mpublished after M. With guaranteed order of the messages when the three messages are delivered to u they are delivered in the order as they are published Mfollowed by Mfollowed by M.

These guarantees bring various benefits to the publish subscribe systems. For example the guaranteed delivery messaging is a powerful primitive it allows distributed system components to communicate with each other without worrying about each others failures. With respect to a publish subscribe system a guaranteed delivery messaging system allows a publisher to submit a message for asynchronous delivery to any interested subscriber. Asynchrony allows the publisher to move on to other tasks without waiting for the subscribers to actually receive the message. Guaranteed delivery ensures that every subscriber eventually receives the message even if it happens to be temporarily unavailable. Such a guaranteed delivery primitive greatly simplifies building a distributed system since failures of individual system components may now be decoupled.

On the other hand they also add to design or implementation complexities. For example many existing publish subscribe systems achieve their guaranteed delivery of the messages through the use of a shared disk which requires a significant upfront investment cannot be incrementally scaled and is problematic to share between major properties. More specifically when using a shared disk messages are handled by soft state or stateless hubs which persist messages to a shared disk before acknowledging the publish. If a hub fails another hub may attach to the same shared disk and restart message delivery from the log of persisted messages. Consequently this shared disk must be highly reliable so that it can survive failures which means that in practice a Network Attached Storage NAS device is often used. Deploying any of these solutions in production requires a significant investment in hardware and software and offers limited opportunity for elastic growth much of the capacity especially hardware capacity needs to be provisioned and paid for up front. Moreover since different properties need predictable performance they cannot easily share certain hardware components in their deployment since certain components can become a bottleneck and cause one property s performance spikes to degrade performance for another property. Both of these properties inelasticity and inability to share increase cost for equipment and operations and in general hinder progress towards cloud computing.

To remedy some of these limitations particular embodiments provide a distributed guaranteed delivery messaging system that requires only inexpensive commodity machines to run and has low operational complexity but can still provide stringent fault tolerance guarantees. In particular embodiments the guaranteed delivery messaging system may be run on a collection of shared nothing commodity servers. The system is highly scalable as capacity may be added on the fly by adding new machines.

In particular embodiments publish subscribe system is topic based and provides guaranteed delivery of the messages. Publish subscribe system may have any number of users which are the publishers and subscribers. Note that a user is not necessarily a human but may be any entity. In particular embodiments there may be any number of named topics and the publishers publish to and the subscribers subscribe to the individual topics. New topics may be created by publish subscribe system or by individual users when needed. When a publisher publishes a message the message is associated with one or more topics. If a subscriber subscribes to a topic it is guaranteed to receive all messages published to that topic by any publisher during the period of its subscription. To achieve guaranteed delivery of the messages in particular embodiments publish subscribe system delivers and if necessary redelivers every message of a topic to every current subscriber of that topic until all current subscribers acknowledge receipt of the message.

In particular embodiments publish subscribe system guarantees delivery of the messages while a user is serviced by a particular data center . For example suppose a user uis serviced by a data center dcand subscribes to a topic T. While uis serviced by dc even though umay be disconnected from dcfrom time to time it is guaranteed that ueventually receives all messages published to T including those message published while uis disconnected from dc. On the other hand if umoves to another data center dc in particular embodiments once uis connected to dc umay need to re subscribe to T. In this case it is guaranteed that ueventually receives all messages published to Tafter the re subscription through dc. However there may be some messages published before u s re subscription at dc e.g. messages published while umoves from dcto dc that may not be delivered to u.

In particular embodiments publish subscribe system may further guarantee that when the messages are delivered to a subscriber they are delivered in the same order as the messages are originally published within each data center . However publish subscribe system does not guarantee a global ordering of all the messages among all data centers . For example suppose a first data center dc services two users uand u a second data center dc services three users u u and u and a third data center dcservices three users u u and u. Further suppose that to a particular topic T uhas published three messages M M and M in that order uhas published two messages Mand M in that order and uand utogether have published three messages M M and M in that order with Mand Mpublished by uand Mpublished by u. Then dcis the data center to which M M and Mare first published dcis the data center to which Mand Mare first published and dcis the data center to which M M and Mare first published. If uhas subscribed to T then when delivering the eight messages to u the three messages first published to dcare guaranteed to be delivered in the order of their publication among themselves the two messages first published to dcare guaranteed to be delivered in the order of their publication among themselves and the three messages first published to dcare guaranteed to be delivered in the order of their publication among themselves. However in particular embodiments publish subscribe system does not guarantee that all eight messages are delivered to uaccording to the global order of their publication. Thus the eight messages may be delivered as M M M M M M M and M even though according to publication times Mmay have been published before M or Mmay have been published before M. Such an ordering may be referred to as a data center based partial ordering.

In particular embodiments publish subscribe system does not use the publication timestamps of the messages to achieve the partial ordering of the messages because data centers may be physically located in different parts of the world and it is difficult to reconcile the time differences around the world. Instead each data center may maintain a counter for the messages published by those users connected to that data center . When a user publishes a new message through a client device connected with a data center the data center may assign the current message counter to that new message and then increment the message counter by one. The messages are then delivered according to their associated counters such that a message with a lower counter is delivered before a message with a higher counter. In addition each message when first published may be associated with a unique identifier of the data center to which its publisher is connected while publishing the message i.e. the original data center where the message is first published . When the messages are shared among multiple data centers each data center may determine which message is originally published at which data center based on the associated data center identifier. When delivering messages to a subscriber to ensure data center based partial ordering a message s counter is compared against the counters of the other messages originally published in the same data center as the message.

In particular embodiments each data center may have a similar or substantially the same architecture as the other data centers . illustrates an example architecture of a data center of publish subscribe system .

In particular embodiments data center may include a message store for storing the messages published by the publishers of publish subscribe system . In particular embodiments message store is a persistent store that stores the messages durably despite failures. In particular embodiments message store may include one or more storage units and new storage units may be added to message store when needed thus achieving scalability.

In particular embodiments message store may be implemented using Yahoo Bookkeeper which is a distributed logging service developed by Yahoo Research. In particular embodiments Bookkeeper operates multiple servers called bookies that receive log messages and append them to log files called ledgers . Depending on the number of failures to be tolerated e.g. n each log message is written in parallel to n 1 bookies e.g. two bookies to tolerate one failure and is considered committed when all bookies persist the message. If a bookie fails the lost data is available at the other bookies. To ensure high throughput the bookies first persist messages to a common sequential log and then lazily write to ledger files using the file system cache. Bookkeeper may be scaled by adding new bookies.

In particular embodiments data center may include a metadata store for storing information relating to the publication and subscription service such as which subscribers subscribe to which topics which messages have been delivered and acknowledged by which subscribers which message processors described below are responsible for which topics which message processors are currently functional and so on. In particular embodiments metadata store may include one or more storage units and new storage units may be added to metadata store when needed thus achieving scalability.

In particular embodiments metadata store may be implemented using Apache Zookeeper which is a distributed consistency service. Zookeeper is a centralized service for maintaining configuration information naming providing distributed synchronization and providing group services. When a client writes some data in Zookeeper the update is atomically committed to multiple Zookeeper servers so that the data can survive a failure. To provide high throughput Zookeeper maintains its data in memory and thus is more appropriate as a metadata store rather than a data store.

Although in metadata store and message store are illustrated as two separate components in practice the same hardware component e.g. a database server in connection with a number of hard drives may host both metadata store and message store or different hardware components may host metadata store and message store separately.

In particular embodiments data center may include one or more message processors mpto mp where n may be any positive integer for receiving messages from the publishers updating message store and metadata store and delivering messages to the subscribers. Each message processor may also be called a hub and may be implemented as a server. In particular embodiments new message processors may be added to data center when needed thus achieving scalability. In particular embodiments each message processor may be responsible for one or more topics and each topic is assigned to one message processor at any given time.

In particular embodiments data center may service one or more users associated with one or more client devices and a user may be a publisher or a subscriber or both. Each message processor may service one or more of clients . In particular embodiments clients may connect to message processors through a virtual IP address or DNS round robin. Note that unless the virtual IP address scheme is used virtual IP address component is not required. In particular embodiments each message processor may be responsible for accepting published messages on a topic and persisting those messages to message store . Each message processor may also accept subscription requests for topics and record the subscriptions in metadata store . In particular embodiments each message processor may retrieve messages out of message store and deliver them to the subscribers and record in metadata store which subscribers have acknowledged which messages. This may also indicate the last message that has been delivered to and received by a subscriber as the publication order of the messages within data center may be determined based on the counters assigned to the individual messages.

For example suppose that a user u is connected to a data center dc via its client device. The Virtual IP address of dcmay select one of the message processors mp to service u or more precisely to service the client device used by u. Further suppose that upublishes a message M that belongs to a topic T. Since each topic is assigned to one of the message processors of dcat any given time Tmay or may not be assigned to mpat this time. If mpis currently responsible for T then mpmay persistently store Min the message store of dcand update the relevant information in the metadata store e.g. metadata relating to T M or u of dc. On the other hand if mpis not currently responsible for T then mpmay determine from the metadata store of dc which message processor is responsible for Tat the present. Suppose that another message processor mp is currently responsible for T. Then mpmay forward Mto mpto be processed e.g. for persistent store . Alternatively mpmay redirect u s client device together with Mto mpso that mpmay handle u s publication request.

As another example suppose that another user u is connected to dcvia its client device. The Virtual IP address of dcmay select another one of the message processors mp to service u or more precisely to service the client device used by u. Further suppose that usubscribes to a topic T. Again since each topic is assigned to one of the message processors of dcat any given time Tmay or may not be assigned to mpat this time. If mpis currently responsible for T then mpmay retrieve all the messages belonging to Tthat have not yet been delivered to ufrom the message store of dcbased on the relevant information stored in the metadata store of dcand deliver the messages to u. On the other hand if mpis not currently responsible for T then mpmay determine from the metadata store of dc which message processor is responsible for Tat the present. Suppose that another message processor mp is currently responsible for T. Then mpmay send a request to mp which in turn retrieve the messages belonging to Tthat have not yet been delivered to ufrom the message store of dcbased on the relevant information stored in the metadata store of dcand deliver the messages to mp which in turn deliver the messages to u. Alternatively mpmay redirect u s client device to mpso that mpmay handle u s subscription request.

In particular embodiments an automatic failover scheme is applied to message processors . In particular embodiments each message processor is responsible for a number of topics at any given time and information stored in metadata store indicates which message processor is currently responsible for which topics and which message processor is currently functional. If any one of message processors has failed due to any cause i.e. that message processor is no longer functional then the topics for which the failed message processor has been responsible are automatically assigned to the other message processors that are still functional. In particular embodiments the metadata stored in metadata store indicates which message processors are currently functioning correctly and which message processors have failed as well as which message processors are currently responsible for which specific topics.

Using the above example suppose that uis connected to mpof dcand that usubscribes to T. Further suppose that another message processor mp has been responsible for T. Since mpof is not currently responsible for T upon receiving a request for messages belonging to Tfrom u mpmay determine from the metadata store of dc which message processor is currently responsible for T. If at this time mphas failed due to some problem then the information stored in the metadata store of dcmay indicate that none of the functional message processors is currently responsible for T. In particular embodiments mpmay select another functional message processor e.g. mp to be responsible for T. The information stored in the metadata store of dcmay be updated accordingly to reflect that mpis now responsible T and mpmay be notified so that it begins handling the messages belonging to T e.g. publishing and subscribing requests from the users . The same message processor selection process may be repeated when individual users publish or subscribe to other topics for which the failed mphas been responsible and one by one these topics may be automatically assigned to other functional message processors.

The message processor selection process may be applied when a new topic is first requested by a user in connection with publication or subscription as well. Using the above example suppose that in addition to T ualso wishes to subscribe to another topic T. Further supposed that no user connected to dchas previously published or subscribed to T. Thus Tis a new topic with respect to dc and no message processor is currently responsible for T. Similarly mpmay select another functional message processor e.g. mp to be responsible for T. The information stored in the metadata store of dcmay be updated accordingly to reflect that mpis now responsible T and mpmay be notified so that it begins handling the messages belonging to T e.g. publishing and subscribing requests from the users .

In particular embodiments a load balancing scheme may be applied when selecting a message processor to be responsible for a topic either when another message processor has failed or when a new topic has been requested. In particular embodiments each message processor may store its current load information in metadata store and the load information may be updated when needed. When it is necessary to select a message processor for a topic the message processor with the least load may be selected. Of course other load balancing schemes may be used and the present disclosure contemplates any suitable load balancing scheme.

In connection with balancing the workloads among message processors when a new message processor is added to data center some of the topics may be moved from certain existing message processors e.g. existing message processors responsible for relatively large number of topics to the new message processor thus lightening the workloads of these existing message processors . Similarly some of the topics currently assigned to a message processor having a relatively higher workload may be reassigned to another message processor having a relatively lower workload. In this sense the workloads may be continuously balanced among message processors by moving selected topics from message processors having relatively higher workloads to message processors having relatively lower workloads.

The following illustrates the processing logic of a message processor when receiving a request in connection with a topic from user.

Although in cross data center component is illustrated as a separate component from message processors in particular embodiments the functionalities of cross data center component may be implemented in each message processor so that each message processor directly sends and receives messages to and from other data centers .

Using the above example suppose that uis connected to mpof dcand that usubscribes to T. Since any publisher may publish messages that belong to a topic there may be publishers connected to other data centers e.g. dcand dc that have also published messages to T which have not been delivered to u. To obtain these messages dcmay through its cross data center component subscribe to Tfrom dcand dc. In this sense dcbecomes a subscriber of Twith respect to dcand dc and may receive messages belonging to Tfrom dcand dcsimilarly as a user subscriber connected to dcor dcreceiving messages belonging to Tfrom dcor dc. Once that dc through its cross data center component has received messages from the other data centers the messages may be persistently stored in the message store of dc and delivered to subscribers of T such as u.

To avoid sending duplicate messages among the data centers in particular embodiments when sending messages to other data centers each data center may only send the messages published by those publishers connected to the data center itself. Thus the messages a first data center has received from a second data center as a subscriber of the second data center are not resend to a third data center when the third data center subscribes messages from the first data center. On the other hand the messages that are first published to the first data center are send to the third data center. To distinguish a data center subscriber from a user subscriber in particular embodiments a indicator e.g. a flag may be associated with each data center subscriber.

In particular embodiments cross data center component of a data center may handle subscription requests from cross data center components of the other data centers. That is message processors may handle user requests while cross data center component may handle requests originated from other data centers. Thus cross data center component of each data center may avoid sending duplicate messages among the data centers .

In particular embodiments each data center may implement a garbage collection scheme for deleting old messages from message store . A message is needed for as long as it is necessary to deliver it to all of its subscribers. When a subscriber receives a message it may acknowledge that the message has been received. Thus when all subscribers that subscribe to a message have acknowledged that the message has been received that message may be deleted from message store as the message is no longer needed. In particular embodiments it is not necessary that each subscribes acknowledges the receipt of each and every message. If a subscriber acknowledges the receipt of a particular message it may be assumed that all the messages sent to that subscriber prior to the particular message have also been received by the subscriber. For example if a subscriber has acknowledged that it has received a message having a counter of 10 then it may be assumed that this subscriber has received all messages having counters less than 10.

Publish subscribe system is designed to be horizontally scalable. For each data center if more message processing capacity is needed more message processors may be added and the topics may be automatically redistributed to the new message processors . If more I O input output capacity for message persistence is needed more servers may be added to message store . In practice metadata store may not likely to be a bottleneck of a data center as updates to the metadata are relatively infrequent in comparison to updates to the messages stored in message store . Nevertheless if needed more servers may be added to metadata store as well.

On the other hand if the message processor is not currently responsible for the topic step NO then in particular embodiments the message processor determines if another message processor is currently responsible for the topic step . If so step YES the message processor redirects the publication request to the other message processor to be handled step . If not step NO that is no message processor is currently responsible for the topic the message processor may select one of the message processors to be responsible for the topic step . Here there are two possibilities with respect to the selection of one of the message processors to be responsible for the topic first the message processor may select another message processor i.e. other than itself and second the message processor may select itself. In either case the message processor updates the metadata relevant to the selection step such as indicating which one of the message processors i.e. itself or another message processor has been selected to be responsible for the topic. If another message processor has been selected the message processor may notify the other selected message processor and redirect the publication request to the other message processor to be handled step . On the other hand if the message processor itself has been selected the message processor may handle the publication request in an appropriate manner e.g. proceeding to step .

In particular embodiments a client device may maintain a persistent connection with a particular message processor once the client device has been directed to the message processor currently responsible for a particular topic with which the user of the client device publishes messages. In this case subsequent message publication in that topic does not result in the client device being redirected again and again since the client device has already been connected with the particular message processor that is currently responsible for the topic in question.

In particular embodiments the message processor may obtain all the messages belonging to the topic that has not been delivered to the user step . Whether a message belonging to a topic has been delivered to a user may be determined based on the metadata stored at the data center. The message processor may obtain these messages locally from among the messages stored at the data center or remotely from other data centers via subscription requests to the other data centers. The message processor then delivers the messages to the user step and updates the metadata relevant to the subscription request step such as indicating which messages have been delivered to the user.

On the other hand if the message processor is not currently responsible for the topic step NO then in particular embodiments the message processor determines if another message processor is currently responsible for the topic step . If so step YES the message processor redirects the subscription request to the other message processor to be handled step . If not step NO that is no message processor is currently responsible for the topic the message processor may select one of the message processors to be responsible for the topic step . Again there are two possibilities with respect to the selection of one of the message processors to be responsible for the topic first the message processor may select another message processor i.e. other than itself and second the message processor may select itself. In either case the message processor updates the metadata relevant to the selection step such as indicating which one of the message processors i.e. itself or another message processor has been selected to be responsible for the topic. If another message processor has been selected the message processor may notify the other selected message processor and redirect the subscription request to the other message processor to be handled step . On the other hand if the message processor itself has been selected the message processor may handle the subscription request in an appropriate manner e.g. proceeding to step .

In particular embodiments a client device may maintain a persistent connection with a particular message processor once the client device has been directed to the message processor currently responsible for a particular topic with which the user of the client device subscribes messages. In this case subsequent message subscription in that topic does not result in the client device being redirected again and again since the client device has already been connected with the particular message processor that is currently responsible for the topic in question.

In particular embodiments a client device may maintain a persistent connection with a particular message processor once the client device has been directed to the message processor currently responsible for a particular topic with which the user of the client device publishes or subscribes messages. In this case subsequent message publication or subscription in that topic does not result in the client device being redirected again and again since the client device has already been connected with the particular message processor that is currently responsible for the topic in question.

Particular embodiments may be implemented in a network environment. illustrates an example network environment . Network environment includes a network coupling one or more servers and one or more clients to each other. In particular embodiments network is an intranet an extranet a virtual private network VPN a local area network LAN a wireless LAN WLAN a wide area network WAN a metropolitan area network MAN a communications network a satellite network a portion of the Internet or another network or a combination of two or more such networks . The present disclosure contemplates any suitable network .

One or more links couple servers or clients to network . In particular embodiments one or more links each includes one or more wired wireless or optical links . In particular embodiments one or more links each includes an intranet an extranet a VPN a LAN a WLAN a WAN a MAN a communications network a satellite network a portion of the Internet or another link or a combination of two or more such links . The present disclosure contemplates any suitable links coupling servers and clients to network .

In particular embodiments each server may be a unitary server or may be a distributed server spanning multiple computers or multiple datacenters. Servers may be of various types such as for example and without limitation web server news server mail server message server advertising server file server application server exchange server database server or proxy server. In particular embodiments each server may include hardware software or embedded logic components or a combination of two or more such components for carrying out the appropriate functionalities implemented or supported by server . For example a web server is generally capable of hosting websites containing web pages or particular elements of web pages. More specifically a web server may host HTML files or other file types or may dynamically create or constitute files upon a request and communicate them to clients in response to HTTP or other requests from clients . A mail server is generally capable of providing electronic mail services to various clients . A database server is generally capable of providing an interface for managing data stored in one or more data stores.

In particular embodiments each client may be an electronic device including hardware software or embedded logic components or a combination of two or more such components and capable of carrying out the appropriate functionalities implemented or supported by client . For example and without limitation a client may be a desktop computer system a notebook computer system a netbook computer system a handheld electronic device or a mobile telephone. A client may enable a network user at client to access network . A client may have a web browser such as Microsoft Internet Explorer or Mozilla Firefox and may have one or more add ons plug ins or other extensions such as Google Toolbar or Yahoo Toolbar. A client may enable its user to communicate with other users at other clients . The present disclosure contemplates any suitable clients .

In particular embodiments one or more data storages may be communicatively linked to one or more servers via one or more links . In particular embodiments data storages may be used to store various types of information. In particular embodiments the information stored in data storages may be organized according to specific data structures. Particular embodiments may provide interfaces that enable servers or clients to manage e.g. retrieve modify add or delete the information stored in data storage .

Particular embodiments may be implemented on one or more computer systems. illustrates an example computer system . In particular embodiments one or more computer systems perform one or more steps of one or more methods described or illustrated herein. In particular embodiments one or more computer systems provide functionality described or illustrated herein. In particular embodiments software running on one or more computer systems performs one or more steps of one or more methods described or illustrated herein or provides functionality described or illustrated herein. Particular embodiments include one or more portions of one or more computer systems .

This disclosure contemplates any suitable number of computer systems . This disclosure contemplates computer system taking any suitable physical form. As example and not by way of limitation computer system may be an embedded computer system a system on chip SOC a single board computer system SBC such as for example a computer on module COM or system on module SOM a desktop computer system a laptop or notebook computer system an interactive kiosk a mainframe a mesh of computer systems a mobile telephone a personal digital assistant PDA a server or a combination of two or more of these. Where appropriate computer system may include one or more computer systems be unitary or distributed span multiple locations span multiple machines or reside in a cloud which may include one or more cloud components in one or more networks. Where appropriate one or more computer systems may perform without substantial spatial or temporal limitation one or more steps of one or more methods described or illustrated herein. As an example and not by way of limitation one or more computer systems may perform in real time or in batch mode one or more steps of one or more methods described or illustrated herein. One or more computer systems may perform at different times or at different locations one or more steps of one or more methods described or illustrated herein where appropriate.

In particular embodiments computer system includes a processor memory storage an input output I O interface a communication interface and a bus . Although this disclosure describes and illustrates a particular computer system having a particular number of particular components in a particular arrangement this disclosure contemplates any suitable computer system having any suitable number of any suitable components in any suitable arrangement.

In particular embodiments processor includes hardware for executing instructions such as those making up a computer program. As an example and not by way of limitation to execute instructions processor may retrieve or fetch the instructions from an internal register an internal cache memory or storage decode and execute them and then write one or more results to an internal register an internal cache memory or storage . In particular embodiments processor may include one or more internal caches for data instructions or addresses. The present disclosure contemplates processor including any suitable number of any suitable internal caches where appropriate. As an example and not by way of limitation processor may include one or more instruction caches one or more data caches and one or more translation lookaside buffers TLBs . Instructions in the instruction caches may be copies of instructions in memory or storage and the instruction caches may speed up retrieval of those instructions by processor . Data in the data caches may be copies of data in memory or storage for instructions executing at processor to operate on the results of previous instructions executed at processor for access by subsequent instructions executing at processor or for writing to memory or storage or other suitable data. The data caches may speed up read or write operations by processor . The TLBs may speed up virtual address translation for processor . In particular embodiments processor may include one or more internal registers for data instructions or addresses. The present disclosure contemplates processor including any suitable number of any suitable internal registers where appropriate. Where appropriate processor may include one or more arithmetic logic units ALUs be a multi core processor or include one or more processors . Although this disclosure describes and illustrates a particular processor this disclosure contemplates any suitable processor.

In particular embodiments memory includes main memory for storing instructions for processor to execute or data for processor to operate on. As an example and not by way of limitation computer system may load instructions from storage or another source such as for example another computer system to memory . Processor may then load the instructions from memory to an internal register or internal cache. To execute the instructions processor may retrieve the instructions from the internal register or internal cache and decode them. During or after execution of the instructions processor may write one or more results which may be intermediate or final results to the internal register or internal cache. Processor may then write one or more of those results to memory . In particular embodiments processor executes only instructions in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere and operates only on data in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere . One or more memory buses which may each include an address bus and a data bus may couple processor to memory . Bus may include one or more memory buses as described below. In particular embodiments one or more memory management units MMUs reside between processor and memory and facilitate accesses to memory requested by processor . In particular embodiments memory includes random access memory RAM . This RAM may be volatile memory where appropriate Where appropriate this RAM may be dynamic RAM DRAM or static RAM SRAM . Moreover where appropriate this RAM may be single ported or multi ported RAM. The present disclosure contemplates any suitable RAM. Memory may include one or more memories where appropriate. Although this disclosure describes and illustrates particular memory this disclosure contemplates any suitable memory.

In particular embodiments storage includes mass storage for data or instructions. As an example and not by way of limitation storage may include an HDD a floppy disk drive flash memory an optical disc a magneto optical disc magnetic tape or a Universal Serial Bus USB drive or a combination of two or more of these. Storage may include removable or non removable or fixed media where appropriate. Storage may be internal or external to computer system where appropriate. In particular embodiments storage is non volatile solid state memory. In particular embodiments storage includes read only memory ROM . Where appropriate this ROM may be mask programmed ROM programmable ROM PROM erasable PROM EPROM electrically erasable PROM EEPROM electrically alterable ROM EAROM or flash memory or a combination of two or more of these. This disclosure contemplates mass storage taking any suitable physical form. Storage may include one or more storage control units facilitating communication between processor and storage where appropriate. Where appropriate storage may include one or more storages . Although this disclosure describes and illustrates particular storage this disclosure contemplates any suitable storage.

In particular embodiments I O interface includes hardware software or both providing one or more interfaces for communication between computer system and one or more I O devices. Computer system may include one or more of these I O devices where appropriate. One or more of these I O devices may enable communication between a person and computer system . As an example and not by way of limitation an I O device may include a keyboard keypad microphone monitor mouse printer scanner speaker still camera stylus tablet touchscreen trackball video camera another suitable I O device or a combination of two or more of these. An I O device may include one or more sensors. This disclosure contemplates any suitable I O devices and any suitable I O interfaces for them. Where appropriate I O interface may include one or more device or software drivers enabling processor to drive one or more of these I O devices. I O interface may include one or more I O interfaces where appropriate. Although this disclosure describes and illustrates a particular I O interface this disclosure contemplates any suitable I O interface.

In particular embodiments communication interface includes hardware software or both providing one or more interfaces for communication such as for example packet based communication between computer system and one or more other computer systems or one or more networks. As an example and not by way of limitation communication interface may include a network interface controller NIC or network adapter for communicating with an Ethernet or other wire based network or a wireless NIC WNIC or wireless adapter for communicating with a wireless network such as a WI FI network. This disclosure contemplates any suitable network and any suitable communication interface for it. As an example and not by way of limitation computer system may communicate with an ad hoc network a personal area network PAN a local area network LAN a wide area network WAN a metropolitan area network MAN or one or more portions of the Internet or a combination of two or more of these. One or more portions of one or more of these networks may be wired or wireless. As an example computer system may communicate with a wireless PAN WPAN such as for example a BLUETOOTH WPAN a WI FI network a WI MAX network a cellular telephone network such as for example a Global System for Mobile Communications GSM network or other suitable wireless network or a combination of two or more of these. Computer system may include any suitable communication interface for any of these networks where appropriate. Communication interface may include one or more communication interfaces where appropriate. Although this disclosure describes and illustrates a particular communication interface this disclosure contemplates any suitable communication interface.

In particular embodiments bus includes hardware software or both coupling components of computer system to each other. As an example and not by way of limitation bus may include an Accelerated Graphics Port AGP or other graphics bus an Enhanced Industry Standard Architecture EISA bus a front side bus FSB a HYPERTRANSPORT HT interconnect an Industry Standard Architecture ISA bus an INFINIBAND interconnect a low pin count LPC bus a memory bus a Micro Channel Architecture MCA bus a Peripheral Component Interconnect PCI bus a PCI Express PCI X bus a serial advanced technology attachment SATA bus a Video Electronics Standards Association local VLB bus or another suitable bus or a combination of two or more of these. Bus may include one or more buses where appropriate. Although this disclosure describes and illustrates a particular bus this disclosure contemplates any suitable bus or interconnect.

Herein reference to a computer readable storage medium encompasses one or more non transitory tangible computer readable storage media possessing structure. As an example and not by way of limitation a computer readable storage medium may include a semiconductor based or other integrated circuit IC such as for example a field programmable gate array FPGA or an application specific IC ASIC a hard disk an HDD a hybrid hard drive HHD an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive a floppy disk a floppy disk drive FDD magnetic tape a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive or another suitable computer readable storage medium or a combination of two or more of these where appropriate. Herein reference to a computer readable storage medium excludes any medium that is not eligible for patent protection under 35 U.S.C. 101. Herein reference to a computer readable storage medium excludes transitory forms of signal transmission such as a propagating electrical or electromagnetic signal per se to the extent that they are not eligible for patent protection under 35 U.S.C. 101.

This disclosure contemplates one or more computer readable storage media implementing any suitable storage. In particular embodiments a computer readable storage medium implements one or more portions of processor such as for example one or more internal registers or caches one or more portions of memory one or more portions of storage or a combination of these where appropriate. In particular embodiments a computer readable storage medium implements RAM or ROM. In particular embodiments a computer readable storage medium implements volatile or persistent memory. In particular embodiments one or more computer readable storage media embody software. Herein reference to software may encompass one or more applications bytecode one or more computer programs one or more executables one or more instructions logic machine code one or more scripts or source code and vice versa where appropriate. In particular embodiments software includes one or more application programming interfaces APIs . This disclosure contemplates any suitable software written or otherwise expressed in any suitable programming language or combination of programming languages. In particular embodiments software is expressed as source code or object code. In particular embodiments software is expressed in a higher level programming language such as for example C Perl or a suitable extension thereof. In particular embodiments software is expressed in a lower level programming language such as assembly language or machine code . In particular embodiments software is expressed in JAVA. In particular embodiments software is expressed in Hyper Text Markup Language HTML Extensible Markup Language XML or other suitable markup language.

The present disclosure encompasses all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend. Similarly where appropriate the appended claims encompass all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend.

