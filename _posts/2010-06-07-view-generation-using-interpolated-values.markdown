---

title: View generation using interpolated values
abstract: Images provide rich information regarding what they depict. For example, an image may have additional information, such as depth and/or 3D location values, for some points within the image. It may be advantageous to extrapolate the values from the valued points to the entire image because a new view of the image may be generated based upon values of points. Accordingly, an interpolated image may be generated by interpolating values for unvalued points based upon values of valued points. In particular, a set of valued points having desired cost paths may be determined for an unvalued point. A model may be applied to the set of valued points to interpolate a value for the unvalued point. One or more interpolated images may be projected onto a new view. In particular, points within an interpolated image may be projected onto locations within the new view based upon values of the points.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08633942&OS=08633942&RS=08633942
owner: Microsoft Corporation
number: 08633942
owner_city: Redmond
owner_country: US
publication_date: 20100607
---
Digital images play a prevalent role in current computing applications. For example users may upload alter and share digital photos advertising companies may generate digital images for online advertisements mapping applications may comprise satellite images of various locations on earth etc. In some instances digital images may be generated where specific points of the image have known values. In one example a camera may capture a dense sampling of a scene. A stereo process may recover depth information at some but not all of the points within the image. In another example color information of an image may be known at a few specific points within the image e.g. a user provides brush strokes of color on various regions of objects such as a brown stroke near a chair and a red stroke near an apple . However some information may still be missing from such images.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

Among other things one or more systems and or techniques for generating a new view are disclosed herein. An image may comprise points representing pixels. Valued points may comprise values representing depth position and or 3D location data. Values of valued points may have been determined based upon manual user entry a stereo process a frame bundling process etc. It may be appreciated that values may be used to determine locations of points within an image and or a new view of an image. Typically not all points within the image will have known values. That is an image may comprise valued points and unvalued points where an unvalued point lacks a value. For example some pixels may be valued points while the majority of pixels are unvalued points.

Values for unvalued points may be interpolated based upon values of valued points within the image. In particular for respective unvalued points a set of valued points may be determined for an unvalued point. It may be appreciated that values may relate to depth position and or 3D location data. The set of valued points may comprise valued points having desired cost paths. It may be appreciated that a cost may represent a difference between two points such as a color difference a texture difference a gradient difference a reflectance etc. A cost path may represent a cost to travel from an unvalued point to a valued point based upon traveling through a path of adjacent points within the image e.g. a cost path from A to C may be a cost from unvalued point A to unvalued point B a cost from unvalued point B to valued point C . For example a desired cost path may be path of points from an unvalued point to a valued point where the sum of costs between points along the path is small e.g. a small change in color between points along a path from an unvalued point to a valued point .

It may be appreciated that there may be an increased probability that an unvalued point may have a value similar to a valued point where there is a desired low cost path between the unvalued point and the valued point. For example if there is a desired low cost path of points between a green colored unvalued point and a green colored valued point of depth 50 cm e.g. points along the desired low cost path have a small change in the color green then there may be an increased probability that both points are part of a similar object and that the green colored unvalued point has a depth similar to the 50 cm depth of the green colored valued point. In this way the set of valued points may comprise a predetermined number k of valued points having a desired cost path represented by a desired e.g. small change in color texture gradient reflectance and or other similarity measurements between points along a path from the unvalued point to the valued point.

A model may be applied to a set of valued points associated with an unvalued point to interpolate a value for the unvalued point. In one example an average of the values for the valued points within the set of valued points may be interpolated as the value for the unvalued point. In another example a plane intersecting the valued points within the set of valued points may be used to interpolate the value for the unvalued point. It may be appreciated that a variety of models are contemplated as falling within the scope of the claimed subject matter e.g. a variety of geometric shapes . In this way an interpolated image comprising valued points having values and unvalued points having values interpolated based upon one or more valued points within the image may be generated.

A new view may be generated based upon projecting points from within the interpolated image to locations within the new view. A point may be project to a location based upon a value of the point e.g. a depth and or 3D location value . In one example forward mapping assignment of color values may be used to project points. In another example backward mapping assignment of depth values may be used to project points. It may be appreciated that feature recognition techniques may be utilizes to determine features between the interpolated image and the new view which may aid in determining locations within the new view of projected points. Additional information may be used to determine locations. For example a desired camera viewing angle for the new view may be used in determining locations within the new view to project points.

It may be appreciated that one or more images may be utilized in generating a new view. That is a fused new view may be generated based upon independently projecting interpolated images onto a new view. It may be appreciated that a z buffer relevance measure a time measure a quality measure and or other image information may be used to generate the fused new view. For example a weight may be assigned to interpolated images and or points therein to determine how much values of the interpolated images and or points therein contribute to the projection of points to locations within the fused new view.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are illustrated in block diagram form in order to facilitate describing the claimed subject matter.

Many images contain rich information regarding what the images depict. For example texture color depth and or a variety of other data may be known. Unfortunately this additional image information may be sparse. That is depth values may be known for some but not all pixels and or objects within an image. If enough additional information is known or determinable then images with additional information may be used to generate new views of what is depicted by the images. That is the additional image information such as depth may be used to project points from the image into locations within a new view of the image. In one example an image may depict a scene of a room. A new view depicting the room from a different angle may be derived from the image e.g. depth 3D location and or color data may be used to determine where objects belong in the new view . In another example five sequential images depicting a person walking down a crowded sidewalk may be used to determine additional new views of the sidewalk scene. The five sequential views and the new views may be used to generate motion of the person walking down the sidewalk. In another example a few images of a car may be used to generate new views of the car. In this way a real time virtual walk around tour of the car may be generated from the original few images and the new views.

One current technique for new view generation is to generate a new view directly from the input images without generating a 3D model as an intermediate stage. The technique may specify how pixels within the new view should be colored based upon the input image. Some pixels may be easy to match. However the challenge is to spread the matched information to unmatched pixels. Another current technique may attempt to generate a model based upon the input images. For example a stereo reconstruction may be used to determine geometry such that textures may be project onto the geometry. However generating a good model may be a difficult because points may be hard to match e.g. untextured points and or invisible due to occlusion. For example artifacts may be generated where pixels have unknown data.

Accordingly one or more systems and or techniques for generating a new view based upon one or more input images are provided herein. An input image may lack a complete set of information regarding a particular feature of the image. For example depth position and or 3D location information may be known for some but not all pixels within the image. Geodesic affinity may be leveraged to fill in the missing values. In particular values of valued points within an image may be used to interpolate values for unvalued points. In this way values may be used to determine locations of points within an image and or a new view of an image.

Geodesic affinity of an unvalued point may be interpreted as a difference measurement defined by a cost between adjacent points along a path from the unvalued point and a valued point. It may be appreciated that geodesic affinity may be referred to as desired cost paths. In particular a set of valued points having low geodesic affinity desired low cost paths may be determined for the unvalued point. A desired low cost path between an unvalued point and a valued point may indicate that there is an increased probability that the unvalued point and the valued point share a similar value because the low cost e.g. a small change in color to travel from the unvalued point to the valued point may indicate that both points are part of a similar object within the image. For example a valued point may have a depth value of 100 cm. A low desired cost path between an unvalued point and the valued point may be determined based upon a small change in color between points along a path between valued point and the unvalued point e.g. the valued pixel may be green the unvalued pixel may be dark green and adjacent pixels along a path from the valued pixel to the unvalued pixel may be greenish color thus it may be determined that the valued pixel and the unvalued pixel are part of a green object having a uniform depth . It may be appreciated that geodesic affinity e.g. a desired cost path between points may not be based upon an actual distance between the points but rather may be based upon difference measurements between points.

One embodiment of generating a new view is illustrated by an exemplary method in . At the method begins. At an interpolated image may be generated by interpolating values for unvalued points within an image based upon values of valued points within the image. In particular at for respective unvalued points a set of valued points for an unvalued point may be determined at . That is a first set of valued points may be determined for a first unvalued point a second set of valued points may be determined for a second unvalued point etc. A set of valued points may comprise one or more valued points e.g. the image may comprise 50 valued points while 5 valued points may be determined as the set of valued points . A valued point may be included within the set of valued points based upon the valued point having a desired cost path. For example a desired low cost path may be a path of points having a low cost to travel from the unvalued point to the valued point where the cost may be defined based upon difference measurements between points along the path e.g. a change in color or texture between points .

In one example the set of valued points may comprise a predetermined number k of valued points having desired low cost paths from the unvalued point to the respective valued points. A desired low cost path may correspond to a small change in color texture gradient reflectance and or other difference measurements along a path of points between the unvalued point and the valued point. In this way a set of valued points having desired cost paths may be determined for an unvalued point such that there may be an increased probability that the unvalued point may have a similar value e.g. a depth position and or 3D location as values of the valued points within the set of valued points as opposed to valued points not included within the set of valued points. It may be appreciated that in one example values of valued points may be determined based upon user entered values values from a stereo process values from a frame bundling process and or values derived from a variety of techniques. It may be appreciated that additional techniques such as facial detection may be utilized in determining values for unvalued points.

It may be appreciated that cost paths may be determined based upon comparing unvalued points with neighboring unvalued points e.g. it may be cheaper to travel through a first neighboring point to a first valued point rather than traveling through a second neighboring point to the first valued point and or a second valued point . In one example of interpolation a dimensional array of points within an image may be generated. The dimensional array may be traversed e.g. forward loops and or backward loops to generate an interpolation table comprising predetermined number k of valued points for respective unvalued points within the dimensional array. To determine k valued points having desired cost paths the dimensional array may be traversed one or more times to compare cost paths of valued points within a set of valued points for a current point with cost paths of valued points within a set of valued points for a neighboring point. In this way a set of valued points for a current point may be determined and or updated based upon comparing cost paths of the current point and neighboring points.

At for respective unvalued points a model may be applied to a set of valued points associated with an unvalued point to interpolate a value for the unvalued point. It may be appreciated that a model may be a technique for deriving a single value based upon values of valued points. In one example an average of the values for the valued points within the set of valued points may be used as the interpolated value for the unvalued point. In another example a plane and or a variety of geometric shapes intersecting the valued points within the set of valued points may be used to interpolate a value for the unvalued point.

One or more values of valued points within the set of valued points may be determined as outliers. In one example valued points having outlier values may be removed from the set of valued points before applying the model. In this way interpolated values may be assigned to unvalued points based upon relevant values to generate an interpolated image. In particular the image may be interpreted as an interpolated image comprising valued points having values and unvalued points having interpolated values.

At for respective points within the interpolated image a point may be projected to a location within a new view based upon a value of the point. For example values of unvalued points and valued points may correspond to depth position and or 3D location data of the respective points. A depth value of a point may be used to determine a location of the point within the new view. In one example a forward mapping assignment may be performed where a color value associated the point may assigned as a color value for the location within the new view. In another example a backward mapping assignment may be performed where a depth value associated with the point may be assigned as the depth value for the location within the new view. It may be appreciated that a variety of projection techniques may be utilized to project points within the interpolated image to locations within the new view based upon values of the points. Additional information may be used to determine locations. For example a desired camera viewing angle for the new view may be used in determining locations within the new view to project points.

It may be appreciated that a fused new view may be generated based upon multiple interpolated images. In one example a second interpolated image may be projected onto the new view to generate a fused new view. That is interpolated images may be project onto the new view independently to create the fused new view. For example points within a second interpolated image may be projected to locations within a new view to generate a fused new view. In another example a first interpolated image and a second interpolate image may be reconciled with one another such that a single projection is performed onto a fused new view without the creation of an intermediate new view.

Weights may be assigned to interpolated images and or points therein. A weight may correspond to a relevance measurement e.g. how relevant an interpolated image is to a new view a time measurement e.g. how close in time an interpolate image is to a new view a quality measurement e.g. a confidence measurement regarding an accuracy or quality of an interpolated image a z buffer and or other metrics. The weight may be taken into account when generating a fused new view. For example a first interpolated image may have a weight of 1 because the first interpolated image is close in time and or is highly relevant to a new view. A second interpolated image may have a weight of 0.04 because the second interpolated image may be farther in time and or less relevant than the first interpolated image. In this way values of points within the first interpolated image may contribute more than values of points within the second interpolated image when determining locations of points within the new view. At the method ends.

In one example of generating a fused new view three or more images may be received where an image comprises unvalued points without values and valued points having 3D location values. For respective images sets of valued points may be determined for unvalued points within an image where respective valued points within a set of valued points have desired low cost paths. An interpolated image may be generated based upon applying a model to the sets of valued points associated with the image. In particular interpolated 3D location values may be interpolated for an unvalued point based upon applying a model to a set of valued points associated with the unvalued point. In this way interpolated images may be generated for respective images. The interpolated images may be projected onto a fused new view based upon 3D location values of valued points and interpolated 3D location values of unvalued points within respective interpolated images.

The interpolator may be configured to determine sets of valued points for respective unvalued points within the image . A set of valued points may comprise one or more valued points having desired cost paths. For example a desired cost path may be a path having a desired low cumulative cost between points along a path from an unvalued point to a valued point e.g. a cost path between unvalued point and valued point may comprise a cost from unvalued point to unvalued point a cost from unvalued point to unvalued point a cost from unvalued point to valued point . In this way valued points having desired geodesic affinity with the unvalued point may be retained while other valued points e.g. a valued point having a high cost path to the unvalued point because many of the points along the path have large changes in color texture and or some other measurement may be excluded from the set of valued points. In one example the interpolator may be configured to determine a predetermined number k of valued points as a set of valued points where a valued point has a desired low cost path corresponding to a small change in color texture gradient and or reflectance along a path of points between the unvalued point and the valued point. It may be appreciated that desired cost paths may be determined based upon comparing current cost paths of an unvalued point with cost paths of neighboring unvalued points such that valued points having desired cost paths are retained for the unvalued point.

The interpolator may be configured to apply a model to a set of valued points to interpolate a value for a corresponding unvalued point. In one example the interpolator may be configured to apply a model comprising an average function. The average function may be used to interpolate the value for the unvalued point based upon an average value of valued points within the set of valued points. In another example the interpolator may be configured to apply a model comprising a geometric shape intersection function and or a plane intersection function that intersects the valued points within the set of valued points. In this way a value may be interpolated for the unvalued point based upon the location of the unvalued point with respect to the geometric shape or plane. The interpolator may be configured to remove outlier values to increase accuracy when interpolating values.

The interpolator may be configured to generate the interpolated image based upon values of valued points and values of unvalued points. That is the interpolated image may comprise valued points having depth position and or 3D location data and unvalued points having interpolated depth position and or 3D location data. It may be appreciated that the interpolator may be configured to generate one or more interpolated images.

The projector may be configured to project points within the interpolated image to locations within the new view based upon values of points within the interpolated image . In particular depth position and or 3D location values may be used to determine where to project points pixels from the interpolated image onto the new view . It may be appreciated that additional information such as matching features e.g. a corner an object within the image a person within the image etc. between the image image and or interpolated image and the new view may be used to determine projection locations. In another example matching features between a first image input image and or interpolated image and a second image input image and or interpolated image may be used to determine projection locations. In another example additional information such as a desired camera viewing angle for the new view may be used to determine projection locations.

Interpolated images and or points therein may be assigned weights by the projector based upon a relevance measure a time measure a quality measure a z buffer and or metrics. In this way the projector may generate a fused new view based upon the assigned weight. For example a second interpolated image having a larger weight than a first interpolated image may be taken into greater consideration when projecting points to locations within the fused new view.

In one example the projector may be configured to merge new views e.g. projections of interpolated images into the fused new view . In this way new views may be independently projected onto the fused new view . In another example a first interpolated image may be projected onto the fused new view and then a second interpolated image may be project onto the fused new view etc. while utilizing a z buffer to determine final locations of points within the fused new view based upon depth. It may be appreciated that a variety of projection techniques may be employed by the projector .

It may be appreciated that unvalued points within the image may be traversed one or more times to determine and or update sets of valued points associated with unvalued points. In particular a current unvalued point may be compared with neighboring points to determine and or update a set of valued points having desired low cost paths. For example a current unvalued point may be associated with a set of valued points comprising 4 valued points having respective cost paths. However the 4 valued points may be updated with new valued points and or cost paths e.g. a valued point may be replaced with a different valued point a cost path of a valued point may be updated with a more desirable cost path based upon traveling through a different neighboring point to the valued point etc. . In this way the set of valued points for the current unvalued points may be updated to comprise valued points having desired low cost paths.

It will be appreciated that a particular naming convention is applied to some points in to facilitate a description of a following example but that the same points may have different designations in another example. That is the names of points illustrated in may change when another point is examined. In this example certain points are referred to as unvalued point unvalued point unvalued point unvalued point neighboring unvalued point neighboring unvalued point valued point valued point valued point valued point valued point and valued point . These designations allow various aspects e.g. traversal through different paths points to be discussed.

In one example unvalued point may be associated with a set of 3 valued points. Example may illustrate a comparison of the unvalued point with neighboring points during an iteration of traversing the image e.g. a second iteration after a first iteration from which the initial set of valued points were determined . It may be appreciated that new valued points and or cost paths may be discovered while traversing the image because the unvalued point may be compared with neighboring points to update the set of valued points e.g. a lower cost path to a valued point may be discovered .

The set of valued points associated with the unvalued point may be determined and or updated based upon comparing the set of valued points associated with the unvalued point with sets of valued points of neighboring points. In one example the unvalued point may be compared with neighboring unvalued point . The neighboring unvalued point may have 3 valued points within a set of valued points. For example the set of valued points for the neighboring unvalued point may comprise a valued point having a cost path of 3 a valued point having a cost path of 17 and another valued point having a cost path from the neighboring unvalued point to the valued point. A comparison between the cost paths of valued points associated with the unvalued point and cost paths associated with the neighboring unvalued point may be performed. It may be determined that a cost path from the unvalued point through the neighboring unvalued point to the valued point may have a desired cost path e.g. a cost path smaller than at least one cost path of valued points within the set of valued points associated with the unvalued point . In this way the set of valued points associated with the unvalued point may be updated to comprise the valued point having a total cost of 5 2 3 .

The unvalued point may be compared with another neighboring point such as valued point . A cost of 50 may be associated with traveling from unvalued point to valued point . For example the unvalued point may have a color of white while the valued point may have a color of black thus there is a high cost between the points. In this way the set of valued points for the unvalued point may not be updated because the valued points within the set of valued points may have more desired cost paths e.g. costs below 50 .

The unvalued point may be compared with neighboring unvalued point . Neighboring unvalued point may be associated with a set of valued points comprising a valued point having a cost path of 8 1 5 2 a valued point having a cost path of 10 1 3 6 and another valued point having a cost from the neighboring unvalued point to the valued point. A comparison between the cost paths of valued points associated with the unvalued point and cost paths associated with the neighboring unvalued point may be performed. It may be determined that a cost path from the unvalued point through the neighboring unvalued point to valued point may have a desired cost path of 12 4 1 5 2 . In particular the desired cost path of 12 may be derived from a cost between unvalued point and neighboring unvalued point a cost between neighboring unvalued point and unvalued point a cost between unvalued point and unvalued point a cost between unvalued point and valued point . The set of valued points for the unvalued point may be updated with valued point because the cost path of 12 may be more desired e.g. smaller than a cost path of a valued point within the set of valued points for the unvalued point .

Additionally a cost path from the unvalued point through the neighboring unvalued point to valued point may be determined as a desired cost path because the cost path may be more desired e.g. smaller than a cost path of a valued point within the set of valued points for the unvalued point . For example there may be a low cost based upon a small change in color between points along the path from the unvalued point through the neighboring unvalued point to the valued point . The cost path may be a cost between unvalued point and neighboring unvalued point a cost between neighboring unvalued point and unvalued point a cost between unvalued point and unvalued point a cost between unvalued point and valued point .

In this way the unvalued point may be compared with neighboring points during one or more traversals of the image to determine a final set of valued points having desired cost paths. In one example the set of valued points for unvalued point may comprise the valued point having a cost path of 5 the valued point having a cost path of 12 and the valued point having a cost path of 14. The set of valued points may exclude valued points valued point valued point and or other valued points having less desired cost paths e.g. cost paths greater than 14 .

The projector may be configured to project points from the interpolated image to locations within the new view . In particular values e.g. depth position and or 3D location data of points may be used to determine projection locations within the new view . Additional information such as a desired camera viewing angle may be used to determine projection locations. In one example the new view may be a view of the person near the lake and three trees at a new viewing angle. The new view may be a view of the scene where the person has walked north from the original location. For example the new view may depict the person closer to the lake but further from the southwest tree. Additionally the new view may be depicted the scene from a different angle as though a viewing camera was tilted counterclockwise. Thus points from the interpolated image may be projected onto the new view to depict a view of the scene where the person has walked slightly north towards a lake and the camera view is slightly tilted counterclockwise.

In one example of fusing the second interpolated image with the new view points within the second interpolated image may be projected onto locations within the new view based upon values of the points within the second interpolated image . For example a cloud may be depicted within the second interpolated image by one or more points. However the cloud may be absent from the new view . The projector may project a shrunken version of the cloud onto the new view based upon values of the points corresponding to the cloud and or additional information regarding desired attributes of the fused new view e.g. a desired viewing angle .

A northeast most tree may be depicted within the second interpolated image in a location closer to the camera view point than the northeast most tree s location within the new view . That is the northeast most tree is depicted further down in the second interpolated image than in the new view . The projector may project the points associated with the tree onto the new view based upon values of the tree and or additional information regarding desired attributes of the fused new view . In this way the fused new view may depict the tree at a location between the location of the tree within the second interpolated image and the new view .

Additionally the viewing angle of the second interpolated image is tilted more counterclockwise than the new view . The fused new view may have a viewing angle corresponding to the second interpolated image based upon a desired attribute of the fused new view to have a more counterclockwise view. In this way the fused new view may be generated based upon projecting points from the second interpolated image onto locations within the new view to generate the fused new view .

In one example a first value of a point within the first interpolated image and a second value of the point within the second interpolated image may be used to determine a location to project the point within the new fused view . Thus a single projection of the point is performed by considering the first value and the second value when performing the projection.

In another example a point within the first interpolated image may be project onto a location within the fused new view based upon a first value of the point. A second independent projection of the point may be performed based upon a second value of the point within the second interpolated image . Thus points within the first interpolated image may be project onto the fused new view and then points within the second interpolated image may be projected onto the fused new view . In this way the projector may merge the two projections to generate the final version of the fused new view .

The projector may take into account weights assigned to the first interpolated image and the second interpolated image . For example a weight of 1 may be assigned to the first interpolated image because the fused new view may be highly relevant e.g. close in time to the view of the scene depicted by the first interpolated image . A weight of 0.56 may be assigned to the second interpolated image because the fused new view may be less relevant e.g. further in time to the view of the scene depicted by the second interpolated image . In this way the projector may give greater consideration of values of the first interpolated image than values of the second interpolated image . For example the entire cloud from the first interpolated image may be projected into the fused new view even though the cloud is absent from the second interpolated image . In this way the fused new view may be generated based upon values of points within interpolated images where interpolated images and or points therein have assigned weights.

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to implement one or more of the techniques presented herein. An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable medium e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions configured to operate according to one or more of the principles set forth herein. In one such embodiment the processor executable computer instructions may be configured to perform a method such as the exemplary method of for example. In another such embodiment the processor executable instructions may be configured to implement a system such as the exemplary system of and or exemplary system of for example. Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB firewire IEEE 13114 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via a network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

