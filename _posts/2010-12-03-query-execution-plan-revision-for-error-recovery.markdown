---

title: Query execution plan revision for error recovery
abstract: A computer-implemented method, apparatus and article of manufacture for performing an automatic error recovery in a database system. Automatic error recovery is performed for a query execution plan, following errors, problems or failures that occur during execution, by automatically or manually deactivating and/or activating components, features or code paths, and then re-submitting the query execution plan for execution in the computer system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08938644&OS=08938644&RS=08938644
owner: Teradata US, Inc.
number: 08938644
owner_city: Dayton
owner_country: US
publication_date: 20101203
---
The invention relates generally to computer implemented database systems and specifically to an automatic error recovery mechanism for a database system.

During the processing of queries in a database system a substantial number of errors problems or failures may cause the system to cancel the query. In today s environment i.e. from a user s point of view such failures are a constant source of frustration and delay.

Problems get reported to the vendor s customer service personnel who investigate each instance and for many instances create incident reports. Such incident reports are then forwarded to the vendor s development personnel who may take some time to respond to the incident report and resolve the customer s problem. Indeed some incidents may not get responded to and some problems may not get resolved for extended periods of time.

Often a workaround is available e.g. by deactivating or activating certain components features or code paths but it may take a substantial period of time to communicate the workaround from the vendor to the customer so that the workaround can be implemented. Indeed there may be situations where the workaround could be automatically implemented by the database system itself in a real time environment and without the intervention of a user database administrator DBA or other personnel. Such workarounds can be used for long periods of time even across several releases or updates of the system thereby allowing the system to provide for better query plans i.e. query plans that execute without faults . Moreover workarounds could be manually or automatically disabled once a fix is implemented thereby avoiding having the components features or code paths being deactivated or activated for long periods of time.

What is needed then is a database system that can automatically or manually activate and or deactivate components features and code paths through the analysis of diagnostics which may result in errors problems or failures being bypassed.

The present invention provides such a system wherein an active system management capability can resubmit a query following its execution failure but using a different set of components features or code paths than the previous set of components features or code paths that resulted in the failure. Moreover this active system management capability can be used to alert users DBAs and other personnel including vendor personnel of potential problems or potential issues in components features or code paths and communicate ways to avoid those problems or issues.

To overcome the limitations in the prior art described above and to overcome other limitations that will become apparent upon reading and understanding the present specification the present invention discloses a computer implemented method apparatus and article of manufacture for performing an automatic error recovery in a database system.

The automatic error recovery is performed during execution of database queries in the database system. First a query execution plan is generated for a query request wherein the query execution plan accesses data from a database stored on the computer system. The query execution plan is then executed to access the data in the database.

Automatic error recovery is performed for the query execution plan following errors problems or failures that occur during the execution of the query execution plan. The automatic error recovery is performed following an analysis of diagnostics generated by the computer system. The automatic error recovery may also alert users DBAs or other personnel to the errors problems or failures that cause the query execution plan to stop executing.

Automatic error recovery is performed by deactivating and or activating components features or code paths in the computer system and then re submitting the query execution plan for execution in the computer system. The components features or code paths in the computer system may be automatically or manually deactivated or activated. The specifics for deactivating or activating the specified components features or code paths are described in more detail below.

Upon a first attempt to execute the query execution plan a retry attempt number RAN is initialized. The RAN is used to determine how many times the query execution plan is retried following errors problems or failures before the query execution plan is flagged as having failed.

Upon the execution of a first set of components features or code paths which is initiated by the execution of the query execution plan a Unique Identifying Code UIC is pushed onto an Autonomic Error Recovery Stack AERS stored in memory. The UIC is popped from the AERS when the execution of the first set of components features or code paths is completed successfully. Otherwise the UIC remains at the top of the AERS.

When errors problems or failures occur during the execution of the first set of components features or code paths an error code is generated and an error handler is invoked to access a table using both the UIC at the top of the AERS and the error code. The error handler retrieves one or more matching rows from the table that contain the UIC and the error code wherein the matching rows also contain diagnostic codes optional parameters for the diagnostic codes and a retry order. The error handler then selects one or more of the matching rows with a retry order based on the RAN. Each of the matching rows may include a different set of diagnostic commands and optional parameters that may deactivate the first set of components features or code paths and or activate a second set of components features or code paths in an attempt to avoid the errors problems and failures.

The error handler also determines a maximum number of attempts MNA to re submit the query execution plan and the RAN is incremented. The query execution plan is not re submitted when the RAN is greater than the MNA.

Otherwise the error handler re submits the query execution plan with the diagnostic codes and optional parameters from the selected matching row wherein the diagnostic codes and optional parameters may deactivate the first set of components features or code paths and or activate a second set of components features or code paths during the subsequent re execution the query execution plan in an attempt to avoid the errors problems and failures.

In the following description of the preferred embodiment reference is made to the accompanying drawings which form a part hereof and in which is shown by way of illustration a specific embodiment in which the invention may be practiced. It is to be understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the present invention.

The DBS is comprised of one or more nodes connected by a network interconnect or bus . The DBS may include multiple nodes in addition to the node illustrated in which are connected by extending the network .

Each node of the DBS includes one or more processing modules connected by the network that manage the storage and retrieval of data in data storage facilities . Each of the processing modules may be one or more physical processors or each may be a virtual processor with one or more virtual processors running on one or more physical processors.

For the case in which one or more virtual processors are running on a single physical processor the single physical processor swaps between the set of N virtual processors. Each virtual processor is generally termed an Access Module Processor AMP in the Teradata Active Data Warehousing System.

For the case in which N virtual processors are running on an M processor node the node s operating system schedules the N virtual processors to run on its set of M physical processors. If there are 4 virtual processors and 4 physical processors then typically each virtual processor would run on its own physical processor. If there are 8 virtual processors and 4 physical processors the operating system would schedule the 8 virtual processors against the 4 physical processors in which case swapping of the virtual processors would occur.

Each of the processing modules manages a portion of a database that is stored in a corresponding one of the data storage facilities . Each of the data storage facilities includes one or more disk drives.

The system stores data in one or more tables in the data storage facilities . The rows of the tables may be stored across multiple data storage facilities to ensure that the system workload is distributed evenly across the processing modules .

A Parsing Engine PE organizes the storage of data and the distribution of table rows among the processing modules . The PE also coordinates the retrieval of data from the data storage facilities in response to queries received from a user at a mainframe or a client computer . The DBS usually receives queries in a standard format such as SQL.

As illustrated in the session control provides the logon and logoff function. It accepts a request for authorization to access the database verifies it and then either allows or disallows the access.

Once the session control allows a session to begin a user may submit an SQL request that is routed to the parser . As illustrated in the flowchart of the parser interprets the SQL request block checks it for proper SQL syntax block evaluates it semantically block and consults a data dictionary to ensure that all of the objects specified in the SQL request actually exist and that the user has the authority to perform the request block .

Finally the parser runs an Optimizer block that generates and selects an optimal query execution plan e.g. the least expensive plan comprised of one or more steps to perform the request. In one embodiment of the present invention the Optimizer includes performance information such as actual cost information or intermediate results when developing an optimal plan to perform the request.

Referring again to once a query execution plan is selected it is scheduled for execution by the Dispatch function . The Dispatch function accepts performance goals for each workload as inputs and dynamically adjusts system resources such as by allocating DBS resources and controlling the flow of workloads. For example adjusting how weights are assigned to resources modifies the way access to the CPU disk and memory are allocated among requests. Given performance objectives for each workload and the fact that the workloads may interfere with each other s performance through competition for shared resources the DBS may find a performance setting that achieves one workload s goal but makes it difficult to achieve another workload s goal.

The performance goals for each workload will vary widely as well and may or may not be related to their resource demands. For example two workloads that execute the same application and DBS code could have differing performance goals simply because they were submitted from different departments in an organization. Conversely even though two workloads have similar performance objectives they may have very different resource demands.

The DBS includes a closed loop workload management architecture which is capable of satisfying a set of workload specific goals and responding to errors problems and failures. In other words the system is a goal oriented workload management system capable of supporting complex workloads and capable of self adjusting to various types of workloads errors problems and failures. The workload management system is generally referred to as the Teradata Active System Management TASM .

The system s operation has four major phases 1 assigning a set of incoming request characteristics to workload groups assigning the workload groups to priority classes and assigning goals called Service Level Goals or SLGs to the workload groups 2 monitoring the execution of the workload 3 regulating adjusting and managing the workload flow and 4 correlating the results of the workload and taking action to improve execution.

Execution improvement can be accomplished in several ways 1 through performance tuning recommendations such as the creation or change in index definitions or other supplements to table data or to recollect statistics or other performance tuning actions 2 through capacity planning recommendations for example increasing system power 3 through utilization of results to enable optimizer self learning 4 through recommending adjustments to SLGs of one workload to better complement the SLGs of another workload that it might be impacting and 5 by activating and or deactivating components features and code paths in response to errors problems and failures. These can be performed automatically by the DBS itself or manually by a user DBA or other personnel.

1 Administrator block This component provides a GUI to define workloads SLGs other workload management requirements and to activate and or deactivate components features and code paths in response to errors problems and failures. The administrator accesses data in logs associated with the system including a database query log DBQL . The administrator is a primary interface for the DBA. The administrator also establishes workload rules which are accessed and used by other elements of the system.

2 Monitor block This component provides a top level dashboard view and the ability to drill down to various details of workload performance. Such data is stored in the query log and other logs available to the monitor. The monitor also includes processes that initiate the execution improvement mechanisms listed above and processes that provide long term trend reporting which may including providing execution improvement recommendations. Some of the monitor functionality may be performed by the regulator which is described in the next paragraph.

3 Regulator block This component dynamically adjusts system settings and or addresses execution issues and either alerts the DBA or user to take action for example by communication through the monitor which is capable of providing alerts or through the exception log providing a way for applications and their users to become aware of and take action on regulator actions. Alternatively the regulator can automatically take action itself by deferring requests or executing requests with the appropriate priority to yield the best solution given requirements defined by the administrator block or by deactivating or activating components features and code paths in response to errors problems and failures. The regulator may also use a set of open application programming interfaces APIs to access and monitor these functions.

The workload management administrator block or administrator is responsible for determining i.e. recommending and or executing the appropriate application settings. Such activities as setting weights managing active work tasks and changes to any and all options will be automatic and taken out of the hands of the DBA. The user will be masked from all complexity involved in setting up the DBS .

As shown in the workload management administrator block allows the DBA to establish workload rules including SLGs which are stored in a storage facility accessible to the other components of the system. The DBA has access to a query log which stores the steps performed by the DBS in executing a request along with database statistics associated with the various steps and an exception log queue which contains records of the system s errors problems and failures as well as deviations from the SLGs established by the administrator. With these resources the DBA can examine past performance establish SLGs that are reasonable in light of the available system resources and deactivate and or activate components features and code paths in response to errors problems and failures. In addition the system provides a guide for creation of workload rules which guides the DBA in establishing the workload rules . The guide accesses the query log and the exception log queue in providing its guidance to the DBA.

a Establishing rules for dividing requests into candidate workload groups and creating workload group definitions. Requests with similar characteristics users application table resource requirement etc are assigned to the same workload group. The system supports the possibility of having more than one workload group with similar system response requirements.

b Refining the workload group definitions and defining SLGs for each workload group. The system provides guidance to the DBA for response time and or arrival rate threshold setting by summarizing response time and arrival rate history per workload group definition versus resource utilization levels which it extracts from the query log from data stored by the regulator allowing the DBA to know the current response time and arrival rate patterns. The DBA can then cross compare those patterns to satisfaction levels or business requirements if known to derive an appropriate response time and arrival rate threshold setting i.e. an appropriate SLG. After the administrator specifies the SLGs the system automatically generates the appropriate resource allocation settings. These SLG requirements are distributed to the rest of the system as workload rules.

c Optionally establishing priority classes and assigning workload groups to the classes. Workload groups with similar performance requirements are assigned to the same class.

d Providing proactive feedback i.e. validation to the DBA regarding the workload groups and their SLG assignments prior to execution to better assure that the current assignments can be met i.e. that the SLG assignments as defined and potentially modified by the DBA represent realistic goals. The DBA has the option to refine workload group definitions and SLG assignments as a result of that feedback.

The internal monitoring and regulating component regulator illustrated in more detail in accomplishes its objective by dynamically monitoring the workload characteristics defined by the administrator using workload rules or other heuristics based on past and current performance of the system that guide feedback mechanisms. It does this before the request begins execution and at periodic intervals during query execution. Prior to query execution an incoming request is examined to determine in which workload group it belongs based on criteria as described in more detail below.

Query execution requests currently being executed are monitored to determine if errors problems or failures have occurred. If so actions can be taken to activate and or deactivate components features and code paths in response to the errors problems and failures. In addition query execution requests may be aborted and or alerts may be generated and logged with the potential for follow up actions as a result of detecting these situations.

As shown in the regulator receives one or more requests each of which is assigned by an assignment process block to a workload group and optionally a priority class in accordance with the workload rules . The assigned requests are passed to a workload query delay manager . The regulator includes an exception monitor for detecting workload exceptions which are recorded in a log .

In general the workload query delay manager monitors the workload performance from the exception monitor as compared to the workload rules and either allows the request to be executed immediately or places it in a queue for later execution when predetermined conditions are met.

If the request is to be executed immediately the workload query delay manager places the requests in buckets corresponding to the priority classes to which the requests were assigned by the administrator . A request processor function performed under control of a priority scheduler facility PSF selects queries from the priority class buckets in an order determined by the priority associated with each of the buckets and executes it as represented by the processing block on .

The PSF also monitors the request processing and reports throughput information for example for each request and for each workgroup to the exception monitor . Also included is a system condition monitor which is provided to detect system conditions such as errors problems and failures that occur during the execution of query execution plans. The system condition monitor provides the ability to dynamically monitor and regulate the DBS globally. The exception monitor and system monitor collectively define an exception attribute monitor .

The exception monitor compares the throughput with the workload rules and stores any exceptions e.g. throughput deviations from the workload rules in the exception log queue . In addition the exception monitor provides system resource allocation adjustments to the PSF which adjusts system resource allocation accordingly e.g. by adjusting the priority scheduler weights. Further the exception monitor provides data regarding the workgroup performance against workload rules to the workload query delay manager which uses the data to determine whether to delay incoming requests depending on the workload group to which the request is assigned.

As can be seen in the system provides a plurality of feedback loops. A first feedback loop includes the PSF and the exception monitor . In this first feedback loop the system monitors on a short term basis the execution of requests to detect deviations greater than a short term threshold from the defined service level for the workload group to which the requests were defined. If such deviations are detected the DBS is adjusted e.g. by adjusting the assignment of system resources to workload groups.

A second feedback loop includes the workload query delay manager the PSF and the exception monitor . In this second feedback loop the DBS monitors on a long term basis to detect deviations from the expected level of service greater than a long term threshold. If it does the DBS adjusts the execution of requests e.g. by delaying swapping out or aborting requests to better provide the expected level of service.

In one embodiment the DBS implements an automatic error recovery mechanism using the administrator monitor and regulator working together in an attempt to address errors problems or failures that occur during the processing of queries in the DBS especially where those errors problems or failures cause the DBS to cancel execution of the query.

Specifically a workaround may be available in the DBS i.e. by deactivating and or activating components features or code paths that can be manually implemented on the DBS through the intervention of a user DBA or other personnel or that can be automatically implemented by the DBS without the intervention of a user DBA or other personnel. Such workarounds can remain in place for long periods of time even across several releases or updates to the DBS thus allowing the DBS to provide for better execution of query plans namely execution without errors problems or failures. Moreover workarounds can be manually or automatically disabled in the DBS i.e. by activating and or deactivating components features or code paths once a fix is implemented in the DBS thereby avoiding having the workarounds implemented for long periods of time.

Specifically components features and code paths of the DBS can be manually or automatically deactivated and or activated through the analysis of diagnostics which may result in the errors problems and failures being avoided. The query can be resubmitted for execution but using a different set of components features or code paths of the DBS than the set of components features or code paths that resulted in the errors problems and failures. Moreover users DBAs and other personnel including vendor personnel can be alerted to the errors problems and failures.

Often these errors problems and failures results from PE errors such as Parser or Optimizer errors. A large number of PE errors such as lack of memory and or other internal failures may cause the PE to cancel execution of the query execution plan. However the PE has a large number of options that can be automatically deactivated and or activated through the use of diagnostics which may result in the errors problems and failures being bypassed. The present invention enhances TASM Workload Management with the ability to identify a scenario where a query execution plan can be resubmitted using a different set of components features or code paths. In other words a query execution plan can be re submitted without invoking the components features and code paths that resulted in the errors problems or failures.

For example assume that an error is discovered in the code path of the Hash Join algorithm performed by the Optimizer that causes an out of memory condition. Diagnostic codes can instruct the Optimizer to disable the code path of the Hash Join algorithm until a fix can be installed on the system thereby allowing the user s query to execute without causing the error at the cost of eliminating optimization for that portion of the query. In this way the present invention allows the DBS to detect and disable and or enable certain components features and code paths without causing a major disruption to the operation of the DBS .

In the present invention the PE is instrumented in such a way that when execution of a first set of components features or code paths is initiated by a query execution plan it pushes a Unique Identifying Code UIC onto an Autonomic Error Recovery Stack AERS stored in memory. When execution of the first set of components features or code paths is completed successfully it pops the UIC from the AERS.

However should errors problems or failures occur during the execution of the first set of components features or code paths the UIC is at the top of the AERS when an error handler is invoked by the PE . In addition the errors problems or failures that occurred during the execution of the first set of components features or code paths will have generated an associated error code.

The error handler accesses a table stored in the data storage facilities which in one embodiment is named DBC.AERCodes that contains all UICs their associated error codes diagnostic codes optional parameters for the diagnostic codes and retry order. Workload classification rules can also include a retry order so that a dynamic limit for retry attempts can be specified.

The error handler performs a lookup into the DBC.AERCodes table using the UIC and the error code in order to retrieve one or more matching rows containing in addition to the UIC and the error code the diagnostic codes optional parameters and retry order. Upon successfully retrieving one or more matching rows the error hander performs the following steps or functions 

 a Sort the matching rows by their retry order and select one or more of the matching rows with a retry order based on the current RAN. As noted above a retry attempt number RAN for the query execution plan is initialized to 0 when the query is executed for the first time. The RAN is used to determine the number of times the query execution plan is retried before the query execution plan is flagged as failing.

 b Use a set of heuristics that take into account the current work load and the classification rules related to this specific query to determine the maximum number of attempts MNA to re submit the query execution plan.

 c Instruct the Dispatcher function to resubmit or restart the query execution plan with the diagnostic codes and optional parameters from the selected matching row. The diagnostic codes and optional parameters instruct the PE to implement a workaround which is expected to avoid the errors problems or failures that occurred. In this regard the diagnostic codes and optional parameters may deactivate the first set of components features or code paths and or activate a second set of components features or code paths.

Note that in the present invention each retry attempt may be executed with a different set of diagnostic commands and optional parameters that instruct the PE to implement different workarounds i.e. that deactivate and or activate different components features or code paths in an attempt to avoid the errors problems and failures.

Note also that. before a query execution plan is resubmitted it is marked as such and the RAN for the query execution plan is incremented. When the error handler determines that the RAN is greater than the MNA the error handler does not resubmit the query execution plan but instead flags the query execution plan as completed and failed .

In addition it is anticipated that each time that the query execution plan fails all information related to the errors problems and failures as well as the UICs error codes diagnostic codes and optional parameters may be sent to the vendor for further investigation of the causes. It is possible to have multiple causes especially when there have been retry multiple attempts using different diagnostic codes and optional parameters.

The main advantage of the present invention is that it automatically reduces the number of requests that cannot be performed by the DBS due to PE faults such as low memory bugs etc. The PE has a large number of diagnostics that enable a large number of opportunities to dynamically perform query requests without causing crashes faults etc. in the PE . In other words the present invention can dynamically provide a workaround until a fix can be applied to the DBS . With the present invention substantial time is saved and features are not deactivated for long periods of time thus allowing for customers to keep using most of the components features and code paths available in the DBS . In addition it means that the PE fails with less frequency.

Block represents the DBS generating a query execution plan for a request wherein the query execution plan accesses data from a database stored on the DBS .

Blocks generally represent the DBS executing the query execution plan to access the data in the database wherein automatic error recovery is performed for the query execution plan following errors problems or failures that occur during execution of the query execution plan by deactivating or activating components features or code paths in the computer system and then re submitting the query execution plan for execution in the computer system. The specifics of these steps are described below.

Block represents the DBS initializing a retry attempt number RAN for the request upon the first attempt to execute the query execution plan. The RAN is used to determine how many times the query execution plan is retried before being flagged as failed.

Block is decision block the represents the DBS determining whether diagnostic codes and their optional parameters accompany the query execution plan. The diagnostics codes may have been automatically or manually included with the query execution plan. If so control transfers to Block otherwise control transfers to Block .

Block represents the DBS initiating execution of the diagnostics codes including their optional parameters. The diagnostics codes may manually or automatically deactivate activate and or re activate components features or code paths in the DBS .

Block represents the DBS executing one or more components features or code paths for the query execution plan. Note that this Block may represent the deactivation of a first set of components features or code paths in the DBS and or the activation of a second set of alternative components features or code paths in the DBS . Note also that this Block includes a Unique Identifying Code UIC being pushed onto an Autonomic Error Recovery Stack AERS stored in the memory of the DBS .

Block is decision block the represents the DBS determining whether any errors problems or failures occurred during the execution of the components features or code paths in Block . If not control transfers to Block otherwise control transfers to Block .

Block represents the DBS popping the UIC from the AERS when the execution of the components features or code paths for the query execution plan has completed successfully. Thereafter the logic terminates as the query request has been completed successfully and no automatic error recovery mechanism is performed.

Block represents the DBS generating an error code when the execution of the components features or code paths in the DBS for the query execution plan results in errors problems or failures.

Block represents the DBS optionally invoking an automatic error recovery mechanism following an analysis of diagnostics generated by the DBS as a result of the errors problems or failures. Specifically this Block may represent the PE invoking an error handler to process the UIC and error code as described below. This Block may also alert users DBAs or other personnel including vendor personnel to the errors problems or failures resulting from the execution of the query execution plan.

Block represents the error handler accessing the table stored in the data storage facilities that contains all UICs their associated error codes diagnostic codes optional parameters for the diagnostic codes and retry order. Specifically the error handler performs a lookup into the table using the UIC and the error code in order to retrieve one or more matching rows containing in addition to the UIC and the error code the diagnostic codes optional parameters and retry order. Upon successfully retrieving one or more matching rows Block also represents the error handler sorting the matching rows by their retry order and then selecting one or more of the matching rows with retry orders based on the current RAN.

Block represents the DBS using a set of heuristics that take into account the current work load and the classification rules related to this specific query determining a maximum number of attempts MNA to re submit the query execution plan.

Block is decision block that represents the DBS determining whether the retry attempt number RAN is greater than the maximum number of attempts MNA . If not control transfers to Block otherwise the logic terminates as the query request has been completed unsuccessfully and the query execution plan is flagged as failed.

Block represents the DBS re submitting the query execution plan with the diagnostic codes and optional parameters from the selected matching rows. Thereafter control is transferred back to Block to re execute the query execution plan using the diagnostic codes and optional parameters. The diagnostic codes and optional parameters instruct the PE to implement a workaround which is expected to avoid the errors problems or failures that occurred. In this regard as noted above the diagnostic codes and optional parameters may deactivate a first set of components features or code paths and or activate a second set of components features or code paths.

Thus the present invention provides a number of advantages over the prior art. First the present invention maximizes the overall effectiveness of query execution. Moreover the present invention minimizes the amount of down time resulting from errors in the execution of queries. Finally the present invention leverages and co exists with existing solutions to solve the problem at hand.

Consequently the present invention provides a major step forward in improving the quality of query execution. In addition the present invention provides greater run time and real time awareness in errors problems and failures during query execution as compared to prior art query execution techniques.

This concludes the description of the preferred embodiment of the present invention. The foregoing description of one or more embodiments of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. It is intended that the scope of the invention be limited not by this detailed description but rather by the claims appended hereto.

