---

title: Zooming and panning widget for internet browsers
abstract: In one aspect, a widget mechanism for zooming and panning a content item is provided. The widget mechanism includes a first region including a miniaturized and complete version the content item. The widget mechanism further includes a second region including a displayed version of the content item. The displayed version represents a portion of the content item currently displayed on a display. The widget mechanism further includes a third region including a to be displayed version of the content item. The to be displayed version represents a portion of the content item to be displayed on the display upon actuation. The second region is smaller than and within the first region when the content item is zoomed and the second region is coextensive or substantially coextensive with the first region when the content item is fully not zoomed. The third region is adjustable within the first region.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09459783&OS=09459783&RS=09459783
owner: HILLCREST LABORATORIES, INC.
number: 09459783
owner_city: Rockville
owner_country: US
publication_date: 20100106
---
This application claims priority from U.S. Provisional Application Ser. No. 61 143 633 entitled ZOOMING AND PANNING WIDGET FOR INTERNET BROWSERS filed Jan. 9 2009 which is herein incorporated by reference in its entirety.

Technologies associated with the communication of information have evolved rapidly over the last several decades. Television cellular telephony the Internet and optical communication techniques to name just a few things combine to inundate consumers with available information and entertainment options. Taking television as an example the last three decades have seen the introduction of cable television service satellite television service pay per view movies and video on demand. Whereas television viewers of the 1960s could typically receive perhaps four or five over the air TV channels on their television sets today s TV watchers have the opportunity to select from hundreds thousands and potentially millions of channels of shows and information. Video on demand technology currently used primarily in hotels and the like provides the potential for in home entertainment selection from among thousands of movie titles.

The technological ability to provide so much information and content to end users provides both opportunities and challenges to system designers and service providers. One challenge is that while end users typically prefer having more choices rather than fewer this preference is counterweighted by their desire that the selection process be both fast and simple. Unfortunately the development of the systems and interfaces by which end users access media items has resulted in selection processes which are neither fast nor simple. Consider again the example of television programs. When television was in its infancy determining which program to watch was a relatively simple process primarily due to the small number of choices. One would consult a printed guide which was formatted for example as series of columns and rows which showed the correspondence between 1 nearby television channels 2 programs being transmitted on those channels and 3 date and time. The television was tuned to the desired channel by adjusting a tuner knob and the viewer watched the selected program. Later remote control devices were introduced that permitted viewers to tune the television from a distance. This addition to the user television interface created the phenomenon known as channel surfing whereby a viewer could rapidly view short segments being broadcast on a number of channels to quickly learn what programs were available at any given time.

Despite the fact that the number of channels and amount of viewable content has dramatically increased the generally available user interface control device options and frameworks for televisions has not changed much over the last 30 years. Printed guides are still the most prevalent mechanism for conveying programming information. The multiple button remote control with up and down arrows is still the most prevalent channel content selection mechanism. The reaction of those who design and implement the TV user interface to the increase in available media content has been a straightforward extension of the existing selection procedures and interface objects. Thus the number of rows in the printed guides has been increased to accommodate more channels. The number of buttons on the remote control devices has been increased to support additional functionality and content handling e.g. as shown in . However this approach has significantly increased both the time required for a viewer to review the available information and the complexity of actions required to implement a selection. Arguably the cumbersome nature of the existing interface has hampered commercial implementation of some services e.g. video on demand since consumers are resistant to new services that will add complexity to an interface that they view as already too slow and complex.

In addition to increases in bandwidth and content the user interface bottleneck problem is being exacerbated by the aggregation of technologies. Consumers are reacting positively to having the option of buying integrated systems rather than a number of segregable components. An example of this trend is the combination television VCR DVD in which three previously independent components are frequently sold today as an integrated unit. This trend is likely to continue potentially with an end result that most if not all of the communication devices currently found in the household will be packaged together as an integrated unit e.g. a television VCR DVD internet access radio stereo unit. Even those who continue to buy separate components will likely desire seamless control of and interworking between the separate components. With this increased aggregation comes the potential for more complexity in the user interface. For example when so called universal remote units were introduced e.g. to combine the functionality of TV remote units and VCR remote units the number of buttons on these universal remote units was typically more than the number of buttons on either the TV remote unit or VCR remote unit individually. This added number of buttons and functionality makes it very difficult to control anything but the simplest aspects of a TV or VCR without hunting for exactly the right button on the remote. Many times these universal remotes do not provide enough buttons to access many levels of control or features unique to certain TVs. In these cases the original device remote unit is still needed and the original hassle of handling multiple remotes remains due to user interface issues arising from the complexity of aggregation. Some remote units have addressed this problem by adding soft buttons that can be programmed with the expert commands. These soft buttons sometimes have accompanying LCD displays to indicate their action. These too have the flaw that they are difficult to use without looking away from the TV to the remote control. Yet another flaw in these remote units is the use of modes in an attempt to reduce the number of buttons. In these moded universal remote units a special button exists to select whether the remote should communicate with the TV DVD player cable set top box VCR etc. This causes many usability issues including sending commands to the wrong device forcing the user to look at the remote to make sure that it is in the right mode and it does not provide any simplification to the integration of multiple devices. The most advanced of these universal remote units provide some integration by allowing the user to program sequences of commands to multiple devices into the remote. This is such a difficult task that many users hire professional installers to program their universal remote units.

Some attempts have also been made to modernize the screen interface between end users and media systems. However these attempts typically suffer from among other drawbacks an inability to easily scale between large collections of media items and small collections of media items. For example interfaces which rely on lists of items may work well for small collections of media items but are tedious to browse for large collections of media items. Interfaces which rely on hierarchical navigation e.g. tree structures may be speedier to traverse than list interfaces for large collections of media items but are not readily adaptable to small collections of media items. Additionally users tend to lose interest in selection processes wherein the user has to move through three or more layers in a tree structure. For all of these cases current remote units make this selection process even more tedious by forcing the user to repeatedly depress the up and down buttons to navigate the list or hierarchies. When selection skipping controls are available such as page up and page down the user usually has to look at the remote to find these special buttons or be trained to know that they even exist. Accordingly organizing frameworks techniques and systems which simplify the control and screen interface between users and media systems as well as accelerate the selection process while at the same time permitting service providers to take advantage of the increases in available bandwidth to end user equipment by facilitating the supply of a large number of media items and new services to the user have been proposed in U.S. patent application Ser. No. 10 768 432 filed on Jan. 30 2004 entitled A Control Framework with a Zoomable Graphical User Interface for Organizing Selecting and Launching Media Items the disclosure of which is incorporated here by reference.

Of particular interest for this specification are the remote devices usable to interact with such frameworks as well as other applications systems and methods for these remote devices for interacting with such frameworks. As mentioned in the above incorporated application various different types of remote devices can be used with such frameworks including for example trackballs mouse type pointing devices light pens etc. However another category of remote devices which can be used with such frameworks and other applications is 3D pointing devices with scroll wheels. The phrase 3D pointing is used in this specification to refer to the ability of an input device to move in three or more dimensions in the air in front of e.g. a display screen and the corresponding ability of the user interface to translate those motions directly into user interface commands e.g. movement of a cursor on the display screen. The transfer of data between the 3D pointing device may be performed wirelessly or via a wire connecting the 3D pointing device to another device. Thus 3D pointing differs from e.g. conventional computer mouse pointing techniques which use a surface e.g. a desk surface or mousepad as a proxy surface from which relative movement of the mouse is translated into cursor movement on the computer display screen. An example of a 3D pointing device can be found in U.S. patent application Ser. No. 11 119 663 the disclosure of which is incorporated here by reference.

According to one exemplary embodiment a widget mechanism for zooming and panning a content item includes a first region including a miniaturized and complete version of the content item a second region including a displayed version of the content item the displayed version representing a portion of the content item currently displayed on a display and a third region including a to be displayed version of the content item the to be displayed version representing a portion of the content item to be displayed on the display upon actuation wherein the second region is smaller than and within the first region when the content item is zoomed and the second region is coextensive or substantially coextensive with the first region when the content item is fully not zoomed and wherein the third region is adjustable within the first region.

According to another exemplary embodiment an Internet browser for displaying a content item includes a display displaying at least a portion of the content item a widget mechanism the widget mechanism overlaying the at least a portion of the content item and including a first region including a miniaturized and complete version of the content item a second region including a displayed version of the content item the displayed version representing the at least a portion of the content item currently displayed on the display and a third region including a to be displayed version of the content item the to be displayed version representing at least a portion of the content item to be displayed on the display upon actuation wherein the third region is adjustable within the first region by making smaller the third region relative to the first region thereby zooming in the to be displayed version of the content item by making the third region coextensive or substantially coextensive with the first region when fully zoomed out thereby zooming out the to be displayed version of the content item and by panning the third region within the first region.

The following detailed description of the invention refers to the accompanying drawings. The same reference numbers in different drawings identify the same or similar elements. Also the following detailed description does not limit the invention. Instead the scope of the invention is defined by the appended claims.

In order to provide some context for this discussion an exemplary aggregated media system in which the present invention can be implemented will first be described with respect to . Those skilled in the art will appreciate however that the present invention is not restricted to implementation in this type of media system and that more or fewer components can be included therein. Therein an input output I O bus connects the system components in the media system together. The I O bus represents any of a number of different of mechanisms and techniques for routing signals between the media system components. For example the I O bus may include an appropriate number of independent audio patch cables that route audio signals coaxial cables that route video signals two wire serial lines or infrared or radio frequency transceivers that route control signals optical fiber or any other routing mechanisms that route other types of signals.

In this exemplary embodiment the media system includes a television monitor a video cassette recorder VCR digital video disk DVD recorder playback device audio video tuner and compact disk player coupled to the I O bus . The VCR DVD and compact disk player may be single disk or single cassette devices or alternatively may be multiple disk or multiple cassette devices. They may be independent units or integrated together. In addition the media system includes a microphone speaker system video camera and a wireless I O control device . According to exemplary embodiments of the present invention the wireless I O control device is a 3D pointing device. The wireless I O control device can communicate with the entertainment system using e.g. an IR or RF transmitter or transceiver. Alternatively the I O control device can be connected to the entertainment system via a wire.

The entertainment system also includes a system controller . According to one exemplary embodiment of the present invention the system controller operates to store and display entertainment system data available from a plurality of entertainment system data sources and to control a wide variety of features associated with each of the system components. As shown in system controller is coupled either directly or indirectly to each of the system components as necessary through I O bus . In one exemplary embodiment in addition to or in place of I O bus system controller is configured with a wireless communication transmitter or transceiver which is capable of communicating with the system components via IR signals or RF signals. Regardless of the control medium the system controller is configured to control the media components of the media system via a graphical user interface described below.

As further illustrated in media system may be configured to receive media items from various media sources and service providers. In this exemplary embodiment media system receives media input from and optionally sends information to any or all of the following sources cable broadcast satellite broadcast e.g. via a satellite dish very high frequency VHF or ultra high frequency UHF radio frequency communication of the broadcast television networks e.g. via an aerial antenna telephone network and cable modem or another source of Internet content . Those skilled in the art will appreciate that the media components and media sources illustrated and described with respect to are purely exemplary and that media system may include more or fewer of both. For example other types of inputs to the system include AM FM radio and satellite radio.

More details regarding this exemplary entertainment system and frameworks associated therewith can be found in the above incorporated by reference U.S. patent application A Control Framework with a Zoomable Graphical User Interface for Organizing Selecting and Launching Media Items . Alternatively remote devices and interaction techniques between remote devices and user interfaces in accordance with the present invention can be used in conjunction with other types of systems for example computer systems including e.g. a display a processor and a memory system or with various other systems and applications.

As mentioned in the Background section remote devices which operate as 3D pointers are of particular interest for the present specification although the present invention is not limited to systems including 3D pointers. Such devices enable the translation of movement of the device e.g. linear movement rotational movement acceleration or any combination thereof into commands to a user interface. An exemplary loop shaped 3D pointing device is depicted in however the present invention is not limited to loop shaped devices. In this exemplary embodiment the 3D pointing device includes two buttons and as well as a scroll wheel scroll wheel can also act as a button by depressing the scroll wheel although other exemplary embodiments will include other physical configurations. User movement of the 3D pointing device can be defined for example in terms of rotation about one or more of an x axis attitude roll a y axis elevation pitch or a z axis heading yaw . In addition some exemplary embodiments of the present invention can additionally or alternatively measure linear movement of the 3D pointing device along the x y and or z axes to generate cursor movement or other user interface commands. An example is provided below. A number of permutations and variations relating to 3D pointing devices can be implemented in systems according to exemplary embodiments of the present invention. The interested reader is referred to U.S. patent application Ser. No. 11 119 663 entitled as amended 3D Pointing Devices and Methods filed on May 2 2005 U.S. patent application Ser. No. 11 119 719 entitled as amended 3D Pointing Devices with Tilt Compensation and Improved Usability also filed on May 2 2005 U.S. patent application Ser. No. 11 119 987 entitled as amended Methods and Devices for Removing Unintentional Movement in 3D Pointing Devices also filed on May 2 2005 and U.S. patent application Ser. No. 11 119 688 entitled Methods and Devices for Identifying Users Based on Tremor also filed on May 2 2005 the disclosures of which are incorporated here by reference for more details regarding exemplary 3D pointing devices which can be used in conjunction with exemplary embodiments of the present invention.

According to exemplary embodiments of the present invention it is anticipated that 3D pointing devices will be held by a user in front of a display and that motion of the 3D pointing device will be translated by the 3D pointing device into output which is usable to interact with the information displayed on display e.g. to move the cursor on the display . For example such 3D pointing devices and their associated user interfaces can be used to make media selections on a television as shown in which will be described in more detail below. Aspects of exemplary embodiments of the present invention can be optimized to enhance the user s experience of the so called 10 foot interface i.e. a typical distance between a user and his or her television in a living room. For example interactions between pointing scrolling zooming and panning e.g. using a 3D pointing device and associated user interface can be optimized for this environment as will be described below although the present invention is not limited thereto.

Referring again to an exemplary relationship between movement of the 3D pointing device and corresponding cursor movement on a user interface will now be described. Rotation of the 3D pointing device about the y axis can be sensed by the 3D pointing device and translated into an output usable by the system to move cursor along the yaxis of the display . Likewise rotation of the 3D pointing device about the z axis can be sensed by the 3D pointing device and translated into an output usable by the system to move cursor along the xaxis of the display . It will be appreciated that the output of 3D pointing device can be used to interact with the display in a number of ways other than or in addition to cursor movement for example it can control cursor fading volume or media transport play pause fast forward and rewind . Additionally the system can be programmed to recognize gestures e.g. predetermined movement patterns to convey commands in addition to cursor movement. Moreover other input commands e.g. a zoom in or zoom out on a particular region of a display e.g. actuated by pressing button to zoom in or button to zoom out may also be available to the user.

Returning now to the application illustrated in the GUI screen also referred to herein as a UI view which terms refer to a currently displayed set of UI objects seen on television is a home view. In this particular exemplary embodiment the home view displays a plurality of applications e.g. Photos Music Recorded Guide Live TV On Demand and Settings which are selectable by the user by way of interaction with the user interface via the 3D pointing device . Such user interactions can include for example pointing scrolling clicking or various combinations thereof. For more details regarding exemplary pointing scrolling and clicking interactions which can be used in conjunction with exemplary embodiments of the present invention the interested reader is directed to U.S. patent application Ser. No. 11 417 764 entitled METHODS AND SYSTEMS FOR SCROLLING AND POINTING IN USER INTERFACE to Frank J. Wroblewski filed on May 4 2006 the disclosure of which is incorporated here by reference.

Of particular interest for exemplary embodiments of the present invention are the global navigation objects displayed above the UI objects that are associated with various media applications. Global navigation objects provide short cuts to significant applications frequently used UI views or the like without cluttering up the interface and in a manner which is consistent with other aspects of the particular user interface in which they are implemented. Initially some functional examples will be described below followed by some more general characteristics of global navigation objects according to exemplary embodiments of the present invention.

Although the global navigation objects are displayed in simply as small circles in actual implementations they will typically convey information regarding their functionality to a user by including an icon image text or some combination thereof as part of their individual object displays on the user interface. A purely illustrative example is shown in . Therein four global navigation objects are illustrated. The leftmost global navigation object operates to provide the user with a shortcut to quickly reach a home UI view main menu . For example the user can move the 3D pointing device in a manner which will position a cursor not shown over the global navigation object . Then by selecting the global navigation object the user interface will immediately display the home view e.g. the view shown in . Other mechanisms can be used to select and actuate the global navigation object as well as the other global navigation objects generally referenced by . For example as described in the above identified patent application entitled METHODS AND SYSTEMS FOR SCROLLING AND POINTING IN USER INTERFACE to Frank J. Wroblewski each of the global navigation objects can also be reached by scrolling according to one exemplary embodiment of the present invention.

The other global navigation objects through similarly provide shortcut access to various UI views and or functionality. For example global navigation object is an up global navigation object. Actuation of this global navigation object will result in the user interface displaying a next highest user interface view relative to the currently displayed user interface view. The relationship between a currently displayed user interface view and its next highest user interface view will depend upon the particular user interface implementation. According to exemplary embodiments of the present invention user interfaces may use at least in part zooming techniques for moving between user interface views. In the context of such user interfaces the next highest user interface view that will be reached by actuating global navigation object is the UI view which is one zoom level higher than the currently displayed UI view. Thus actuation of the global navigation object will result in a transition from a currently displayed UI view to a zoomed out UI view which can be displayed along with a zooming transition effect. The zooming transition effect can be performed by progressive scaling and displaying of at least some of the UI objects displayed on the current UI view to provide a visual impression of movement of those UI objects away from an observer. In another functional aspect of the present invention user interfaces may zoom in in response to user interaction with the user interface which will likewise result in the progressive scaling and display of UI objects that provide the visual impression of movement toward an observer. More information relating to zoomable user interfaces can be found in U.S. patent application Ser. No. 10 768 432 filed on Jan. 30 2004 entitled A Control Framework with a Zoomable Graphical User Interface for Organizing Selecting and Launching Media Items and U.S. patent application Ser. No. 09 829 263 filed on Apr. 9 2001 entitled Interactive Content Guide for Television Programming the disclosures of which are incorporated here by reference.

Movement within the user interface between different user interface views is not limited to zooming. Other non zooming techniques can be used to transition between user interface views. For example panning can be performed by progressive translation and display of at least some of the user interface objects which are currently displayed in a user interface view. This provides the visual impression of lateral movement of those user interface objects to an observer.

Regardless of the different techniques which are employed in a particular user interface implementation to transition between user interface views the provision of a global navigation object which provides an up function may be particularly beneficial for user interfaces in which there are multiple paths available for a user to reach the same UI view. For example consider the UI view shown in . This view illustrates a number of on demand movie selections categorized by genre which view can be reached by for example zooming in on the On Demand application object shown in the home view of . By pressing the zoom in button on the 3D pointing device one more time while the current focus e.g. selection highlighting is on the UI object associated with Genre A in the UI view the user interface will zoom in on this object to display a new UI view . The UI view will display a number of sub genre media selection objects which can for example be implemented as DVD movie cover images. However this same UI view could also have been reached by following a different path through the user interface e.g. by actuating a hyperlink from another UI view. Under this scenario actuating the up global navigation object from UI view will always result in the user interface displaying UI view regardless of which path the user employed to navigate to UI view in the first place. By way of contrast if the user actuates the zoom out or back button from UI view the user interface will display the previous UI view along the path taken by the user to reach UI view . Thus according to this exemplary embodiment of the present invention the up global navigation object provides a consistent mechanism for the user to move to a next highest level of the interface while the zoom out or back button on the 3D pointing device provides a consistent mechanism for the user to retrace his or her path through the interface.

Returning to global navigation object provides a search function when activated by a user. As a purely illustrative example the search tool depicted in can be displayed when a user actuates the global navigation object from any of the UI views within the user interface on which global navigation object is displayed. The exemplary UI view depicted in contains a text entry widget including a plurality of control elements with at least some of the control elements being drawn as keys or buttons having alphanumeric characters thereon and other control elements being drawn on the interface as having non alphanumeric characters which can be e.g. used to control character entry. In this example the control elements are laid out in two horizontal rows across the interface although other configurations may be used.

Upon actuating a control element e.g. by clicking a button on a the 3D pointing device when a particular element has the focus the corresponding alphanumeric input is displayed in the textbox disposed above the text entry widget and one or more groups of displayed items related to the alphanumeric input provided via the control element s can be displayed on the interface e.g. below the text entry widget. Thus the GUI screen depicted in according to one exemplary embodiment of the present invention can be used to search for selectable media items and graphically display the results of the search on a GUI screen in a manner that is useful efficient and pleasing to the user. Note that in the illustrated example of although the letter g is illustrated as being displayed in the text box the displayed movie cover images below the text entry widget simply represent a test pattern of DVD movie covers and are not necessarily related to the input letter g as they could be in an implementation e.g. the displayed movie covers could be only those whose movie titles start with the letter g . This type of search tool enables a user to employ both keyword searching and visual browsing in a powerful combination that expedites a search across potentially thousands of selectable media items. By selecting one of the DVD movie covers e.g. UI object the user interface can for example display a more detailed UI view associated with that movie along with an option for a user to purchase and view that on demand movie. As those skilled in the art will appreciate given a potentially very large number of selectable media items quick and easy access to a search tool made possible by the provision of global navigation object on most if not all of the UI views provided by the user interface provides the user with convenient access thereto.

Returning again to the fourth global navigation object displayed in this exemplary embodiment is a live TV global navigation object. Actuation of the global navigation object results in the user interface immediately displaying a live TV UI view that enables a user to quickly view television programming from virtually any UI view within the interface. An example of a live TV UI view is shown in wherein it can be seen that the entire interface area has been cleared out of UI objects so that the user has an unimpeded view of the live television programming. A channel selection control overlay can be displayed and used to change channels in response to movement of the cursor proximate to the leftmost region of the user interface. Similarly a volume control overlay can be displayed and used to change the output volume of the television in response to movement of the cursor proximate to the rightmost region of the user interface. More information relating to the operation of the channel selection control overlay and volume control overlay can be found in the above incorporated by reference U.S. patent application entitled METHODS AND SYSTEMS FOR SCROLLING AND POINTING IN USER INTERFACE to Frank J. Wroblewski.

Comparing reveals that the global navigation objects are visible in the UI view but not in the UI views and . This visual comparison introduces the different display states of global navigation objects according to exemplary embodiments of the present invention. More specifically according to one exemplary embodiment of the present invention the global navigation objects can be displayed in one of three display states a watermark state an over state and a non displayed state. In their watermark partially visible state which is a default display state each of the global navigation are displayed in a manner so as to be substantially transparent or faintly filled in relative to the rest of the UI objects in a given UI view. For example the global navigation objects can be displayed only as a faint outline of their corresponding icons when in their watermark state. As the default display state this enables the global navigation objects to be sufficiently visible for the user to be aware of their location and functionality but without taking the focus away from the substantially opaque UI objects which represent selectable media items.

In their over display state which is triggered by the presence of a cursor proximate and or over one of the global navigation objects that global navigation object has its outline filled in to become opaque. Once in its over display state the corresponding global navigation object can be actuated e.g. by a button click of the 3D pointing device .

Lastly for at least some UI views the global navigation objects can also have a non displayed state wherein the global navigation objects become completely invisible. This non displayed state can be used for example in UI views such as the live TV view where it is desirable for the UI objects which operate as controls to overlay the live TV feed only when the user wants to use those controls. This can be implemented by for example having the global navigation objects move from their watermark display state to their non displayed state after a predetermined amount of time has elapsed without input to the user interface from the user while a predetermined UI view is currently being displayed. Thus if the live TV view is currently being displayed on the television and the user interface does not receive any input e.g. motion of the 3D pointing device for more than 3 or 5 seconds then the global navigation objects can be removed from the display.

Global navigation objects may have other attributes according to exemplary embodiments of the present invention including the number of global navigation objects their location as a group on the display their location as individual objects within the group and their effects. Regarding the former attribute the total number of global navigation objects should be minimized to provide needed short cut functionality but without obscuring the primary objectives of the user interface e.g. access to media items or overly complicating the interface so that the user can learn the interface and form navigation habits which facilitate quick and easy navigation among the media items. Thus according to various exemplary embodiments of the present invention the number of global navigation objects provided on any one UI view may be 1 2 3 4 5 6 or 7 but preferably not more than 7 global navigation objects will be provided to any given user interface. The previously discussed and illustrated exemplary embodiments illustrate the global navigation objects being generally centered along a horizontal axis of the user interface and proximate a top portion thereof however other exemplary embodiments of the present invention may render the global navigation objects in other locations e.g. the upper righthand or lefthand corners of the user interface. Whichever portion of the user interface is designated for display of the global navigation buttons that portion of the user interface should be reserved for such use i.e. such that the other UI objects are not selectable within the portion of the user interface which is reserved for the global navigation objects .

Additionally location of individual global navigation objects within the group of global navigation objects regardless of where the group as a whole is positioned on the display can be specified based on e.g. frequency of usage. For example it may be easier for users to accurately point to global navigation objects at the beginning or end of a row that those global navigation objects in the middle of the row. Thus the global navigation objects which are anticipated to be most frequently used e.g. the home and live TV global navigation objects in the above described examples can be placed at the beginning and end of the row of global navigation objects in the exemplary embodiment of .

According to some exemplary embodiments of the present invention global navigation objects can have other characteristics regarding their placement throughout the user interface. According to one exemplary embodiment the entire set of global navigation objects are displayed at least initially on each and every UI view which is available in a user interface albeit the global navigation objects may acquire their non displayed state on at least some of those UI views as described above . This provides a consistency to the user interface which facilitates navigation through large collections of UI objects. On the other hand according to other exemplary embodiments there may be some UI views on which global navigation objects are not displayed at all such that the user interface as a whole will only have global navigation objects displayed on substantially every UI view in the user interface.

Likewise it is generally preferable that for each UI view in which the global navigation objects are displayed they be displayed in an identical manner e.g. the same group of global navigation objects the same images text icons used to represent each global navigation function the same group location the same order within the group etc. However there may be some circumstances wherein for example the functional nature of the user interface suggests a slight variance to this rule e.g. wherein one or more global navigation objects are permitted to vary based on a context of the UI view in which it is displayed. For example for a UI view where direct access to live TV is already available the live TV global navigation object can be replaced or removed completely. In the above described exemplary embodiment this can occur when for example a user zooms in on the application entitled Guide in . This action results in the user interface displaying an electronic program guide such as that shown in on the television or other display device . Note that from the UI view of a user can directly reach a live TV UI view in a number of different ways e.g. by positioning a cursor over the scaled down live video display and zooming in or by positioning a cursor over a program listing within the grid guide itself and zooming in. Since the user already has direct access to live TV from the UI view of the live TV global navigation object can be replaced by a DVR global navigation object which enables a user to have direct access to a DVR UI view. Similarly the live TV global navigation object for the live TV UI views e.g. that of can be replaced by a guide global navigation object which provides the user with a short cut to the electronic program guide. For those exemplary embodiments of the present invention wherein one or more global navigation objects are permitted to vary from UI view to UI view based on context it is envisioned that there still will be a subset of the global navigation objects which will be the same for each UI view on which global navigation objects are displayed. In the foregoing examples a subset of three of the global navigation objects e.g. those associated with home up and search functions are displayed identically or substantially identically and provide an identical function on each of the UI views on which they are displayed while one of the global navigation objects i.e. the live TV global navigation object is permitted to change for some UI views.

Still another feature of global navigation objects according to some exemplary embodiments of the present invention is the manner in which they are handled during transition from one UI view to another UI view. For example as mentioned above some user interfaces according to exemplary embodiments of the present invention employ zooming and or panning animations to convey a sense of position change within a Zuiverse of UI objects as a user navigates between UI views. However according to some exemplary embodiments of the present invention the global navigation objects are exempt from these transition effects. That is the global navigation objects do not zoom pan or translate and are instead fixed in their originally displayed position while the remaining UI objects shift from e.g. a zoomed out view to a zoomed in view. This enables user interfaces to on the one hand provide the global navigation objects as visual anchors while on the other hand not detract from conveying the desired sense of movement within the user interface by virtue of having the global navigation buttons in their default watermark transparent state.

Although not shown in applications may also include an Internet browser to permit a user of the system to surf the Web on his or her television. Additionally a zooming and panning widget as shown in can be provided as an overlay to the displayed web page s to enable easy generic browsing on the TV. illustrates the zooming and panning widget itself. The widget can include for example three rectangular regions. However the number and shape of the regions may vary. The first region defined by border contains a complete version albeit miniaturized of the content e.g. a web page or image which can be displayed on the television based on the current target being browsed. That is the first region may include a miniaturized and complete version of a content item. The complete version of the content may fill the border completely or not e.g. depending upon the aspect ratio of the content. The second region defined by border displays the portion of the content which is currently displayed on the television. That is the second region may include a displayed version of the content item. If the user has opted to zoom into the content then the rectangle will be smaller than rectangle . If no zooming is currently selected then the rectangle will be coextensive with or be displayed just inside of rectangle . The portion of the content displayed within rectangle may be displayed more brightly than the remainder of the content which is outside of rectangle but within rectangle to indicate to the user that rectangle indicates the portion of the content which is currently being viewed. The portion of the content displayed within the rectangle may otherwise be displayed in contrast to the remainder of the content which is outside of rectangle but within rectangle .

The third region defined by border is indicative of the portion of the content which will be displayed if the user actuates a user control to display the content associated with rectangle e.g. by panning to that portion of the entire web page or image shown in rectangle . That is the third region may include a to be displayed version of the content item. This rectangle is movable within rectangle like a cursor based on movement of an input device such as the 3D pointing device described above. Each of the borders associated with the three rectangles and may be displayed with different colors to further distinguish their respective functions.

Systems and methods for processing data according to exemplary embodiments of the present invention can be performed by one or more processors executing sequences of instructions contained in a memory device. Such instructions may be read into the memory device from other computer readable mediums such as secondary data storage device s . Execution of the sequences of instructions contained in the memory device causes the processor to operate for example as described above. In alternative embodiments hard wire circuitry may be used in place of or in combination with software instructions to implement the present invention.

Numerous variations of the afore described exemplary embodiments are contemplated. The above described exemplary embodiments are intended to be illustrative in all respects rather than restrictive of the present invention. Thus the present invention is capable of many variations in detailed implementation that can be derived from the description contained herein by a person skilled in the art. All such variations and modifications are considered to be within the scope and spirit of the present invention as defined by the following claims. No element act or instruction used in the description of the present application should be construed as critical or essential to the invention unless explicitly described as such. Also used herein the article a is intended to include one or more items.

