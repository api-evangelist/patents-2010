---

title: Method and apparatus for providing user interface of portable device
abstract: A method includes displaying a user interface for displaying a graphic and a hidden graphic in a first area; displaying a set of contents corresponding to the graphic in a second area distinguishable from the first area; detecting a user's gesture for selecting a part of the first area; enlarging the first area to include a part of the second area; displaying a plurality of graphics including the graphic and the hidden graphic in the extended first area in response to the user's gesture; detecting a user's additional gesture for moving a first graphic among the plurality of graphics; and moving the first graphic to a part of the extended first area in response to the user's additional gesture, and moving a second graphic of the plurality of graphics to an area from which the first graphic is moved out.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09652145&OS=09652145&RS=09652145
owner: SAMSUNG ELECTRONICS CO., LTD.
number: 09652145
owner_city: Suwon-si
owner_country: KR
publication_date: 20101202
---
This application claims priority from U.S. Provisional Applications No. 61 265 923 and No. 61 265 939 filed Dec. 2 2009 and Korean Patent Application No. 10 2010 0119922 filed on Nov. 29 2010 in the Korean Intellectual Property Office the disclosures of which are incorporated herein by reference in their entireties.

Apparatuses and methods consistent with exemplary embodiments relate to a method and an apparatus for providing a user interface and more particularly to a method and an apparatus for providing a more efficient user interface by using a screen configuration.

A user interface UI may provide a temporary or continuous access to enable a communication between a user and an object a system a device or a program. The UI may include a physical or virtual medium. Generally the UI may be divided into an input by which a user manipulates a system and an output by which a response or result of the input to the system is displayed.

Input needs an input device to move a cursor on a screen or to receive a user s manipulation to select a particular object. For example the input device may include a button a key a mouse a track ball a touch pad a joy stick or a touch screen. Output needs an output device to identify a response to the input by using user s sense of sight hearing or touch. For example the output device may include a display apparatus a touch screen a speaker or an oscillator.

The touch screen may provide both input and output through a screen. Users may touch the screen by using their fingers or a stylus. A computer may recognize the touch on the touch screen analyze the touch and perform a corresponding operation based on the touch.

Exemplary embodiments address at least the above problems and or disadvantages and other disadvantages not described above. Also an exemplary embodiment is not required to overcome the disadvantages described above and an exemplary embodiment may not overcome any of the problems described above.

According to an aspect of an exemplary embodiment there is provided a method for providing a user interface of a portable device the method including displaying a user interface for displaying at least one graphic and a hidden graphic in a first area displaying a set of contents corresponding to one of the at least one graphic in a second area distinguishable from the first area detecting a user s gesture for selecting a part of the first area enlarging the first area up to a part of the second area and displaying a plurality of graphics including the at least one graphic and the hidden graphic in the extended first area in response to the user s gesture detecting a user s additional gesture for moving at least one among the plurality of graphics and moving at least one among the plurality of graphics to a part of the extended first area in response to the user s additional gesture and moving at least one of the graphics other than the at least one graphic to an area from which the at least one graphic is moved out.

The displaying the plurality of graphics including the at least one graphic and the hidden graphic in the extended first area may include displaying at least a part of the hidden graphic in an area converted from the second area to the first area.

The displaying a user interface for displaying at least one graphic and a hidden graphic in the first area may include detecting the user s gesture for selecting the user interface and displaying the hidden graphic in response to the user s gesture.

The hidden graphic may be positioned in a front direction or a back direction of the at least one graphic and the detecting the user s gesture for selecting the user interface may include detecting a contact position and a contact released position of the user on the user interface determining a direction of the gesture on the basis of the contact position and the contact released position and displaying the hidden graphic corresponding to the direction of the gesture among the graphics positioned in the front or back direction.

The hidden graphic may be positioned in a front direction or a back direction of the at least one graphic and the displaying the user interface for displaying the at least one graphic and the hidden graphic in the first area may include displaying an identifier which shows a direction where the hidden graphic is positioned at one side of the first area corresponding to the first or back direction.

The displaying the user interface for displaying the at least one graphic and the hidden graphic in the first area may include giving a visible feedback to one of the at least one graphic and the displaying a set of contents corresponding to one of the at least one graphic in the second area includes displaying the set of contents corresponding to the graphic to which the visible feedback is given in the second area.

The displaying a plurality of graphics including the at least one graphic and the hidden graphic in the extended first area may include removing the visible feedback given to one graphic of the at least one graphic.

The displaying a plurality of graphics including the at least one graphic and the hidden graphic in the extended first area may include inactivating the set of the at least one content displayed in the second area.

The plurality of graphics may be divided into a first group of graphics and a second group of graphic in accordance with respective positions of the plurality of graphics in the first area and the displaying a plurality of graphics including the at least one graphic and the hidden graphic in the extended first area may include detecting a user s gesture for selecting a part of the second area and downsizing the extended first area into an original area in response to the user s gesture and displaying the first group of graphics in the downsized first area.

The moving at least one among the plurality of graphics within the extended first area and moving at least one of the graphics other than the at least one graphic to an area from which the at least one graphic is moved out may include moving a first graphic among the plurality of graphics to an area for a second graphic among the plurality of graphics and moving the second graphic to an area from which the first graphic is moved out if the first graphic is not moved any more for a predetermined period of time.

According to another aspect of an exemplary embodiment there is provided a portable device providing a user interface the portable device including a touch screen which includes a first area to display a user interface for displaying at least one graphic and a hidden graphic and a second area to display a set of contents corresponding to one of the at least one graphic which is distinguishable from the first area a processor and a memory the processor detecting a user s gesture for selecting a part of the first area enlarging the first area up to a part of the second area and displaying a plurality of graphics including the at least one graphic and the hidden graphic in the extended first area in response to the user s gesture detecting a user s additional gesture for moving at least one among the plurality of graphics and moving at least one among the plurality of graphics to a part of the extended first area in response to the user s additional gesture and moving at least one of the graphics other than the at least one graphic to an area from which the at least one graphic is moved out.

In the case of displaying the plurality of graphics including the at least one graphic and the hidden graphic in the extended first area the processor may display at least a part of the hidden graphic in an area converted from the second area to the first area.

The processor may detect the user s gesture for selecting the user interface and display the hidden graphic in the first area in response to the user s gesture.

In the case of displaying a plurality of graphics including the at least one graphic and the hidden graphic in the extended first area the processor may remove a visible feedback given to one graphic of the at least one graphic.

In the case of displaying a plurality of graphics including the at least one graphic and the hidden graphic in the extended first area the processor may inactivate the set of the at least one content displayed in the second area.

The plurality of graphics may be divided into a first group of graphics and a second group of graphic in accordance with respective positions of the plurality of graphics in the first area and in the case of displaying a plurality of graphics including the at least one graphic and the hidden graphic in the extended first area the processor may detect a user s gesture for selecting a part of the second area and downsize the extended first area into an original area in response to the user s gesture and displays the first group of graphics in the downsized first area.

In the case of moving at least one among the plurality of graphics within the extended first area and moving at least one of the graphics other than the at least one graphic to an area from which the at least one graphic is moved out the processor may move a first graphic among the plurality of graphics to an area for a second graphic among the plurality of graphics and move the second graphic to an area from which the first graphic is moved out if the first graphic is not moved any more for a predetermined period of time.

According to another aspect of an exemplary embodiment there is provided a computer readable medium in which a program is recorded to execute a method for providing a user interface in a portable device the method including displaying a user interface for displaying at least one graphic and a hidden graphic in a first area displaying a set of contents corresponding to one of the at least one graphic in a second area distinguishable from the first area detecting a user s gesture for selecting a part of the first area enlarging the first area up to a part of the second area and displaying a plurality of graphics including the at least one graphic and the hidden graphic in the extended first area in response to the user s gesture detecting a user s additional gesture for moving at least one among the plurality of graphics and moving at least one among the plurality of graphics to a part of the extended first area in response to the user s additional gesture and moving at least one of the graphics other than the at least one graphic to an area from which the at least one graphic is moved out.

Certain exemplary embodiments are described in greater detail below with reference to accompanying drawings.

In the following description like drawing reference numerals are used for like elements even in different drawings. The matters defined in the description such as detailed construction and elements are provided to assist in a comprehensive understanding of exemplary embodiments. However exemplary embodiments can be practiced without those specifically defined matters.

A computer system is used as a reference to explain exemplary embodiments. The skilled in the art may fully understand that the system and methods as described below are applicable to a voluntary display system including a user interface.

 Exemplary embodiment example aspect and exemplification used herein shall not be construed that the discretionary aspect or design explained herein are better or more advantageous than other aspects or designs.

 Component module system and interface used hereinbelow means a computer related entity in general and e.g. may mean hardware a combination of hardware and software or software.

 Or means an inclusive or rather than exclusive or . That is unless otherwise stated or explicit in the context the expression x uses a or b means one of natural inclusive permutations.

The singular used herein should be interpreted as including one or more unless otherwise stated or explicit in the context regarding the singular type.

 And or used herein should be understood as referring to and including all of available combinations of at least one item of listed relevant items.

 Include and or including means that the concerned property step operation module elements and or components exist but does not exclude that one or more of other properties steps operations modules elements and component and or a group thereof exist or are added.

 First Second etc. may be used herein to explain various elements but the elements are not limited to such terms. The terms are used only to distinguish two or more elements and there is no order or order of priority between the elements.

Hereinafter an apparatus according to an exemplary embodiment will be described. In an exemplary embodiment the apparatus a user interface UI for the apparatus and a relevant process for using the apparatus will be described. Such apparatus may include a device which further includes a PDA function a music playing or calling function and other functions. However all or part of the apparatus the user interface and the relevant process according to an exemplary embodiment which will be described below are applicable to digital devices such as a personal computer a laptop computer a digital TV etc.

The apparatus may support at least one of a telephone application a video conference application an e mail application an instant messaging application a blogging application a photo managing application a digital camera application a digital video camera application a web browsing application a digital music playing application and a digital video playing application.

The various applications above may use e.g. a physical or virtual UI. For example a user may change or move information displayed on a touch screen within a single application or to another application through the physical or virtual UI. The apparatus may support various applications by using a physical or virtual UI that is intuitive and clear and uses a common physical or virtual architecture.

The apparatus may include at least one processor a memory a peripheral interface an input output I O subsystem a touch screen a sensor another I O device a radio frequency RF circuit an audio circuit a power circuit and an external port . Such components may communicate with each other through at least one communication bus or signal line.

The memory may include e.g. a high speed random access memory a magnetic disk an SRAM a DRAM a ROM a flash memory or a non volatile memory. The memory may include a software module an instruction set or other various data. An access to the memory by other components such as the processor and the peripheral interface may be controlled by the processor .

The peripheral interface may integrate the input and or output peripheral device of the apparatus to at least one processor and memory . The processor may perform various functions and process data by executing the software module or the instruction set stored in the memory .

The RF circuit may transmit and receive an RF signal which is also known as an electromagnetic signal. The RF circuit may convert an electric signal into an electromagnetic signal convert an electromagnetic signal into an electric signal and communicate with a communication network or other communication devices through an electromagnetic signal. The RF circuit may include a known circuit to perform the foregoing function. The known circuit may include an antenna system an RF transmitter receiver at least one amplifier a tuner at least one oscillator a digital signal processor a codec chipset a subscriber identification module SIM card and a memory but not limited thereto. The RF circuit may communicate in a wireless communication with a cellular phone network a wireless network such as wireless local area network LAN and or metropolitan area network MAN a network such as an intranet and or the Internet also called the World Wide Web WWW and other devices. Such wireless communication may include an e mail protocol such as Global System for Mobile Communications GSM Enhanced Data GSM Environment EDGE Wideband Code Division Multiple Access W CDMA Code Division Multiple Access CDMA Time Division Multiple Access TDMA Bluetooth Wireless Fidelity Wi Fi for IEEE 802.11a IEEE 802.11b IEEE 802.11g and or IEEE 802.11n Voice over Internet Protocol VoIP Wi MAX Long Term Evolution LIE Internet Message Access Protocol IMAP and or Post Office Protocol POP an instant messaging protocol such as eXtensible Messaging and Presence Protocol XMPP Session Initiation Protocol for Instant Messaging and Presence Leveraging Extensions SIMPLE Instant Messaging and Presence Service IMPS or Short Message Service SMS or communication protocols which are not developed at the time of the application date of the present application. In addition to the foregoing wireless communication other communication standards protocols and technology may be used.

The audio circuit may provide an audio interface between a user and the apparatus by using a speaker and or a microphone. The audio circuit may receive audio data from the peripheral interface convert audio data into electric signals and transmit electric signals to the speaker. The speaker may convert the electric signal into a human audible sound wave. The audio circuit may receive an electric signal converted from a sound wave by a microphone. The audio circuit may convert an electric signal into audio data and transmit the audio data to the peripheral interface to process the audio data. The audio data may be searched from or transmitted to the memory or the RF circuit by the peripheral interface . According to an aspect the audio circuit may further include a headset jack. The headset jack may provide an interface between a headset including input and output devices or a portable audio I O peripheral device such as an output headphone.

The power circuit may supply power to all or part of the components of the apparatus . For example the power circuit may include a power management system at least one power source such as a battery or alternating current AC power source a charging system a power failure detection circuit a power transformer or inverter a power indicator and other voluntary components for generating managing and distributing power.

The I O subsystem may integrate an I O peripheral device such as the touch screen the sensor or the another input control device to the peripheral interface . The I O subsystem may include a display controller a sensor controller or at least one I O controller . According to another aspect the touch screen the sensor or the input control device may be integrated directly to the peripheral interface instead of through the I O subsystem .

According to another aspect at least one of the processor the peripheral interface and the I O subsystem may be provided in a single chip. Otherwise a part of at least one of the processor the peripheral interface and the I O subsystem may be provided in a single chip.

The display controller may receive an electric signal from the touch screen including a touch detection area transmit an electric signal to the touch screen or transmit and receive an electric signal to from the touch screen . By a control of the display controller the touch screen may display thereon a visual output for a user. The visual output may include a graphic a text an icon a video and a combination of the foregoing elements collectively the graphic . According to an aspect a part or all of the visual output may correspond to a user interface which will be described later in more detail.

The touch screen may include a liquid crystal display LCD a light emitting polymer display LPD an organic light emitting diode OLED an active matrix organic light emitting diode AMOLED or other displays. The touch screen and the display controller may employ capacitive technology resistive technology infrared technology and surface acoustic wave technology but not limited thereto and may further include other known technologies or touch detection technology which will be developed in the future. The touch screen and the display controller may detect a contact point its movement or release by using a proximity sensor array or other elements to determine at least one contact address with the touch screen .

The display controller may be coupled with a screen which does not include a touch detection area. The touch detection area excluding screen may receive an electric signal from the display controller and display a visual output for a user. The touch detection area excluding screen may include a plasma display panel PDP an electronic paper display EPD a liquid crystal display LCD a light emitting polymer display LPD an organic light emitting diode OLED an active matrix organic light emitting diode AMOLED and other displays. The apparatus which employs the screen excluding the touch detection area may provide an I O device such as a keyboard a mouse or a physical button as a user interface.

The at least one another I O controller may receive an electric signal from the another I O device or transmit an electric signal to the another I O device . The another I O control device may include e.g. a button a keyboard a touch pad a dial a slider switch or a joy stick. The another I O controller may be integrated to any of an infrared port a USB port and a mouse.

According to an aspect the another I O control device may include at least one physical or virtual button. In the case of the virtual button the button and a button controller may be a part of the touch screen and the display controller respectively. According to an aspect the button may include an up down button a locker button or a push button to adjust a volume of the speaker or the microphone . For example if a user presses the push button briefly the touch screen is unlocked and an unlocking process may be initiated by applying a gesture to the touch screen. Otherwise a user may press the push button long to turn on or turn off power to the apparatus .

According to another aspect the another I O control device may include at least one physical keyboard or virtual soft keyboard. As an example of the keyboard Qwerty and or non Qwerty may be used. In the virtual soft keyboard the soft keyboard and the soft keyboard controller may be a part of the touch screen and the display controller respectively. The soft keyboard according to an exemplary embodiment may include a fewer number of graphics or soft keys than the physical keyboard. Then a user may select at least one graphic of the soft keyboard and display at least one corresponding symbol on the touch screen .

According to another aspect the another I O control device may include a touch pad to enable or disable a particular function. According to another aspect the touch pad may include a touch detection area which does not display thereon the visual output unlike the touch screen. The touch pad may include a touch detection surface separated from the touch screen or a part of the touch detection surface formed and extended from the touch screen .

The sensor controller may receive an electric signal from the sensor transmit an electric signal to the sensor or transmit and receive an electric signal to from the sensor . The sensor may include an optical sensor a proximity sensor an accelerometer a GPS sensor a magnetic sensor a tilt sensor an ambient sensor and a weather sensor but not limited thereto.

According to an aspect the sensor may include at least one optical sensor . illustrates the optical sensor which is integrated to the sensor controller of the I O subsystem . The optical sensor may be integrated to the peripheral interface . The optical sensor may include a charge coupled device CCD or complementary metal oxide semiconductor CMOS photo transistor. The optical sensor may receive light emitted through at least one lens from the environment and convert such light into image data. Together with an image module a so called camera module the optical sensor may capture a still image or video. According to another aspect to use the touch screen display as a view finder to acquire at least one of a still image and a video the optical sensor may be provided in a rear side or a front side of the apparatus . According to an aspect to acquire an image of a user for a video conference while a user views other video conference attendees on the touch screen display the optical sensor may be provided in the front side of the apparatus . According to another aspect a user may rotate a lens and a sensor of the apparatus housing to change a location of the optical sensor so that the single optical sensor acquires a still image or a video for the video conference. Further the apparatus may detect the light amount from the optical sensor adjust a brightness of a particular area of the touch screen by using a value corresponding to the light amount or adjust a brightness of a graphic on the touch screen .

According to an aspect the sensor may include at least one proximity sensor . illustrates the proximity sensor which is connected to the sensor controller of the I O subsystem . Otherwise the proximity sensor may be connected to the peripheral interface . The proximity sensor may detect whether any object is proximate to the apparatus . For example the proximity sensor may provide an on or off value with respect to a detection non detection of the object. According to an aspect when the apparatus is proximate to a user s ear like talking over the phone the proximity sensor may turn off the touch screen to thereby prevent unnecessary battery consumption.

According to another aspect the sensor may further include at least one of accelerometers . illustrates the accelerometer which is connected to the sensor controller of the I O subsystem . Otherwise the accelerometer may be connected to the peripheral interface . The accelerometer may detect a change of speed of the apparatus or a direction of the apparatus . For example the accelerometer may measure an accelerating vector value of the apparatus in three axes of X Y and Z. The accelerometer may provide a displacement value per hour corresponding to the three axes. According to an aspect information may be displayed on the touch screen vertically or transversely on the basis of the analysis of data transmitted from the at least one accelerometer

According to another aspect the sensor may further include at least one GPS sensor . FIG. illustrates the GPS sensor which is connected to the sensor controller of the I O subsystem . Otherwise the GPS sensor may be connected to the peripheral interface . The GPS sensor may receive at least one satellite signal process the received signal and detect a location of the apparatus on earth. For example the GPS sensor may provide latitude longitude and altitude values of the apparatus based on the detected value. For example the GPS sensor may provide the latitude value of 90 up to 90 degrees and the longitude value of 180 up to 180 degrees. According to an aspect the location of the apparatus on earth may be displayed on the touch screen on the basis of the analysis of data transmitted from the GPS sensor

According to another aspect the sensor may further include at least one magnetic sensor . illustrates the magnetic sensor which is connected to the sensor controller of the I O subsystem . Otherwise the magnetic sensor may be connected to the peripheral interface . For example the magnetic sensor may detect an intensity or a change of a magnetic field generated on earth process the detected signal and determine a direction value of the apparatus . For example the magnetic sensor may provide the intensity and change of the magnetic field as values of three axes of X Y and Z based on the detected value. According to an aspect the apparatus may change a rotation of a predetermined icon on the touch screen by using the value provided by the magnetic sensor

According to another aspect the sensor may further include at least one tilt sensor . illustrates the tilt sensor which is connected to the sensor controller of the I O subsystem . Otherwise the tilt sensor may be connected to the peripheral interface . The tilt sensor may include at least one accelerometer and at least one magnetic sensor. The tilt sensor may provide e.g. azimuth pitch and roll values by using the values of three axes of X Y and Z detected from the sensors. For example the tilt sensor may provide the value ranging from zero to 360 degrees as an azimuth value the value ranging from 180 to 180 degrees as a pitch value and the value ranging from 90 to 90 degrees as a roll value. The apparatus according to an aspect may detect a user s gesture gripping and moving the apparatus by using the tilt sensor

According to another aspect the sensor may further include at least one ambient sensor . illustrates the ambient sensor which is connected to the sensor controller of the I O subsystem . Otherwise the ambient sensor may be connected to the peripheral interface . The ambient sensor may detect temperature humidity and intensity of illumination of the ambient environment of the apparatus . The ambient sensor may acquire the detected value per hour. For example the ambient sensor may provide humidity values ranging from zero to 100 and temperature in Fahrenheit or Celsius and the intensity of illumination from level zero to 10. According to an aspect the apparatus may display on the touch screen the value of the ambient environment of the apparatus acquired through the ambient sensor

According to another aspect the sensor may further include at least one weather sensor . illustrates the weather sensor which is connected to the sensor controller of the I O subsystem . Otherwise the weather sensor may be connected to the peripheral interface . The weather sensor may provide information on humidity temperature or weather. The weather information relating to a particular day or time may be acquired from an external server. The server may provide weather information based on information of a user s location. According to an aspect the apparatus may transmit to the server an http request signal including location information. The server may search the weather information on the location based on the location information of the apparatus and provide the apparatus with the searched information as an eXtensible Markup Language XML document. For example the weather sensor may provide the value of humidity ranging from zero to 100 and the temperature in Fahrenheit or Celsius and the condition relating to weather as an integer.

Returning back to the apparatus may perform an operation combining a predetermined function through a screen including a touch detection area such as the touch screen or touch pad . In this case a basic input control is available on the touch screen for the operation of the apparatus and the number of a physical input output device such as a push button keyboard and dial of the apparatus may be reduced.

To perform the operation combining the predetermined function through the touch screen a UI may be displayed on the touch screen for navigation. According to an aspect if a user touches the touch screen the touch screen may provide a UI such as a main menu or root menu. According to another aspect the apparatus may provide a physical push button or other physical input and control devices as a UI.

According to an aspect the apparatus may perform the operation combining the predetermined function through a screen excluding the touch detection area. The apparatus may use a UI such as a physical keyboard a mouse and a physical button as a basic input control device. According to an aspect if a user manipulates a physical UI the apparatus may display a visual output on the screen excluding the touch detection area corresponding to a user s manipulation.

According to another aspect the apparatus may perform the operation combining the predetermined function through both the touch screen or touch pad including the touch detection area and the screen excluding the touch detection area. The apparatus may use at least one of a physical UI and a virtual UI as a basic input control device. According to an aspect if a user touches the physical UI or manipulates the virtual UI the apparatus may interact with the physical or virtual UI and display the result of a user s touch or manipulation on at least one of the touch screen including the touch detection area and the screen excluding the touch detection area.

The touch screen may provide a UI between the apparatus and a user. For example the touch screen may include a touch detection surface a sensor or a sensor set which detects a user s input based on a haptic contact or a tactile contact. The touch screen and the display controller may detect a contact a movement of such contact or a release of contact on the touch screen and convert such detected contact into an interaction with the UI graphic at least one soft key icon web page or image displayed on the touch screen . According to an aspect a contact address between the touch screen and a user may correspond to a user s finger a voluntary object such as a stylus or an appendage. According to an aspect the UI is designed to operate by a contact mainly based on a user s finger and gesture which is less accurate than the input by the stylus since the former has a larger contact area on the touch screen . In this case the apparatus may analyze a finger based rough input as a location or command of an accurate pointer or cursor to perform a desired operation.

The touch screen may display at least one graphic as a UI. According to an aspect a user may contact touch and select at least one graphic by using at least one of his her fingers. According to another aspect if a user releases the contact of the at least one graphic the at least one graphic may be selected. According to an aspect a user s gesture may include a touch to select a graphic or an area relating to the graphic a tap which is a gesture touching and releasing the touch to execute a graphic application or receive another graphic a double tap increasing or decreasing the graphic a hold maintaining a touch for predetermined time to receive a detailed menu relating to the graphic a touch and move touching and moving left to right right to left or up and down and down and up or releasing such touch to scroll an item list a flick or swipe touching moving and releasing such touch within short time to move to a superior or subordinate list relating to the graphic or to execute other useful functions and a drag and drop to move the graphic to a desired location. According to an aspect an accidental contact of the graphic may not select the graphic. For example if the gesture corresponding to the selection is a tap a predetermined application may not be selected by a swipe going over the graphic relating to such application. According to another aspect the apparatus may employ a heuristic method to determine a user s gesture accurately. According to an aspect cumulative data of a user s gesture user s characteristics and pattern may be detected and analyzed by the heuristic method and the apparatus may determine the intent of such user s gesture by using the analyzed data characteristic and pattern.

According to an aspect the touch screen may display a virtual soft keyboard as a UI. A user may select at least one graphic or soft key of the soft keyboard and display at least one symbol on the touch screen . The soft keyboard according to an exemplary embodiment may be adaptive. For example the displayed graphic may be adjusted by a user s action selecting at least one graphic or at least one symbol. At least one application of the apparatus may employ a common keyboard or different keyboards. Accordingly the used soft keyboard may be customized for at least a part of the applications or for each user. For example the at least one soft keyboard according to an exemplary embodiment may be customized for each user on the basis of a word usage record of such user. The soft keyboard may be adjusted to reduce a user s mistake when he she selects at least one graphic and at least one corresponding symbol.

Hereinafter an example of a configuration of the memory which is included in the apparatus will be described in more detail with reference to .

According to an aspect a software component which is stored in the memory may include an operating system OS a communication module or an instruction set a social networking module or an instruction set a commerce service module or an instruction set a location based service LBS module or an instruction set an interaction module or an instruction set a sensor module or an instruction set a graphic module or an instruction set a text input module or an instruction set and an application or an instruction set .

According to an aspect the communication module the social networking module the commerce service module the LBS module the interaction module the sensor module the graphic module or the text input module may be included in the OS . For example the communication module the social networking module the commerce service module the LBS module the interaction module the sensor module the graphic module or the text input module may provide an interface for the application to access hardware or software components or control a system task relating to the application .

According to another aspect the communication module the social networking module the commerce service module the LBS module the interaction module the sensor module the graphic module or the text input module may be included in the application . For example the communication module the social networking module the commerce service module the LBS module the interaction module the sensor module the graphic module or the text input module may include a driver of a software component and or hardware component or perform an operation of the software component and or hardware component in association with the OS .

Like an embedded OS such as Darwin Linux Unix OSX Windows bada one of mobile OSs provided by Samsung Electronics a Korean company or VxWorks the OS includes various software components and or drivers to control and manage general system tasks including memory management storage device control and power control and enables a communication between the various hardware and software components.

The OS according to an exemplary embodiment may include layers of a kernel a device a service and a framework .

The device may include platform functions of the apparatus provided by a device OS a graphic and multimedia function and communication components. For example the platform functions may include telephony security graphics or events and window management.

The service may include service oriented functions which are provided by application engines and server assisted components. By the service which includes contact or messaging engines the application engines may be provided. For example the server assisted functions may be provided by web service components which are connected to service components of the bada server. As above the applications may manage data stored in remote servers including geographical information or user presence information through the server assisted functions. The server assisted functions may be accessed by an Application Programming Interface API of the framework .

The framework may include an open API framework of bada. The framework may include an application framework as well as interfaces and classes accessing functions of lower layers. The application framework may provide application life cycle management event handling or an application control function. The interfaces may be provided by the open API framework. The open API framework may include basic interfaces which are necessary for data handling utilities basic functions and application status or application generating a graphic user interface. The API framework may include not only interfaces enabling access to services provided by lower layers but also user interface or multimedia communication internationalization location security commerce or web browsing interfaces.

The communication module enables a communication with other devices through at least one external port and may include various software components to process data received by the RF circuit and or the external port . The external port such as a universal serial bus USB or FireWire may be directly connected to other devices or indirectly connected thereto through a network such as the Internet or wireless LAN .

The social networking module enables a communication with other devices or a network server through the at least one external port and may include various software components to process data received by the RF circuit and or the external port . The social networking module may share user presence information and the like with other application users or manage user profiles in association with the communication module . The social networking module may provide an interface for the application to share user presence information with other application users or manage user profiles. Also the social networking module or an interface of the social networking module may include a mechanism through which application users gather and use a social networking service on the Internet.

The commerce service module enables a communication with other devices or a network server through at least one external port and may include various software components to process data received from the RF circuit and or the external port . The commerce service module may be in association with the communication module . The commerce service module may operate for a user to sell or purchase goods e.g. game items or applications through a communication network or provide an interface which supports such operation to the application .

The LBS module enables a communication with other devices or a network server through at least one external port and may include various software components to process data received from the RF circuit and or the external port . The LBS module may be in association with the communication module . The LBS module may transmit or receive geographical information e.g. major landmarks stores map data or geographical coding services through a communication network or process geographical information to be provided to a user or a network server. The LBS module may provide the application with an interface including functions using geographical information.

The interaction module may provide a user with a visual auditory or tactile feedback as a response to a user s motion or touch or touch gesture a response to a detect of a user s shape face or body or a response to a preset event.

For example upon receiving a touch from the touch screen the interaction module may include a software component which provides a user with various vibrations patterns as a haptic function to feedback a tactile response depending on contact by touch release of contact size of a contact point speed acceleration direction change of size or change of direction through the another I O controller and or a vibration device not shown included in the another I O device . The interaction module may provide an effect as if the screen is shaking together with the graphic module or the display controller to increase the vibration. Upon receiving a new message from the instant messaging module as a preset event the interaction module may provide a vibration or a visual feedback together with the another I O controller a vibration device not shown the graphic module or the display controller .

If the interaction module together with the sensor controller the optical sensor included in the sensor and or the sensor module recognizes a user s shape and determines that the recognized user is a user registered with the apparatus it may provide a feedback including a preset sound voice or preset visual stimulus in association with the audio circuit the graphic module or the display controller . The interaction module may provide an interface to enable the application to use the feedback.

The sensor module may process data acquired from the optical sensor the proximity sensor the accelerometer the GPS sensor the magnetic sensor the tilt sensor the ambient sensor or the weather sensor or provide an interface to enable the application to use the foregoing data.

For example the sensor module may acquire location information of the apparatus by using data received through the GPS sensor and provide various applications with the location information. The sensor module may provide the telephone module with the location information acquired through the GPS sensor for a location based call or provide the camera module and or blogging module with the information as metadata such as photo video. The sensor module may provide the map module or an application providing a location based service such as navigation and or the LBS module with the location information acquired through the GPS sensor

The sensor module may provide the weather module with data acquired from the ambient sensor or the weather sensor . The sensor module may provide the graphic module or the display controller with data acquired from the optical sensor to change a brightness of a graphic or adjust a brightness of a backlight of the screen.

The graphic module includes various known software components to render and display a graphic on the touch screen including a component to change a brightness of the displayed graphic. Graphic used herein means any voluntary object which is displayed including a text a web page an icon such as a user interface object including a soft key a digital image a video and animation.

The text input module may be a component of the graphic module . The text input module may provide a soft keyboard to various applications e.g. a contact address module an e mail client module an instant messaging module the blogging module the browser module or other voluntary applications which need a text input to input a text or an interface which activates an input module of a physical keyboard e.g. Qwerty keyboard .

The application may include the following module or an instruction set or a subset or superset thereof the contact address module also referred to as address book or contact point the telephone module the video conference module the e mail client module the instant messaging IM module the blogging module the camera module for still and or video images an image management module a video player module a music player module or a video music player module integrating the video player module and the music player module a note module the browsing module a map module a calendar module the weather module a stock module a calculator module an alarm clock module a dictionary module a search module or a news module.

The memory may include a word processing module a JAVA module an encoding module a digital authority management module a voice recognition module or a voice replication module as the application .

The contact address module may be used to manage an address book or contact address together with the touch screen the display controller the interaction module the graphic module and or the text input module . For example the contact address module may add names on the address book delete names from the address book connect telephone number e mail address physical address or other information with names connect name and image classify or sort names initiate communication by the telephone module the video conference module the e mail client module or the IM module or provide telephone number or e mail address to enable the initiation of communication.

The telephone module may operate together with the RF circuit the audio circuit the touch screen the display controller the interaction module the graphic module and or the text input module . For example the telephone module may input characters corresponding to telephone number access at least one of telephone numbers of the contact address module revise the input telephone number dial each telephone number perform dialog or release connection or hang up if the dialog is over. As described above wireless communication may employ any of a plurality of communication standards protocols and technologies.

The video conference module may initiate perform and end a video conference between a user and at least one conference attendee together with the RF circuit the audio circuit the touch screen the display controller the optical sensor the sensor controller the interaction module the graphic module the text input module the contact address module and or the telephone module .

The e mail client module may generate transmit receive and manage e mail together with the RF circuit the touch screen the display controller the interaction module the graphic module and or the text input module . The email client module may generate transmit and receive e mail including still or video images acquired through the image management module and or the camera module .

The IM module may operate together with the RF circuit the touch screen the display controller the interaction module the graphic module and or the text input module . For example the IM module may input characters corresponding to an instant message revise the input character transmit and receive each instant message. The transmitted and or received instant message may include a graphic a photo an audio file a video file and or other attachment supported by an MMS and or Enhanced Messaging Service EMS . Instant messaging used herein may refer to both a telephone based message such as a message transmitted through SMS or MMS and an Internet based message such as a message transmitted through XMPP SIMPLE or IMPS.

The blogging module may transmit to or receive from a blog e.g. a user s blog a text a still image a video and or other graphics together with the RF circuit the touch screen the display controller the interaction module the graphic module the text input module the image management module the browsing module and or the social networking module .

The camera module may operate together with the touch screen the display controller the optical sensor the sensor controller the interaction module the graphic module and or the image management module . For example the camera module may capture a video including a still image or a video stream to store them in the memory modify the property of the still image or the video or delete such still image or video from the memory .

The image management module may operate together with the touch screen the display controller the interaction module the graphic module the text input module and or the camera module . For example the image management module may arrange modify manipulate label or delete a still image and or video image or display and store such still image and or video image as a digital slide show or an album.

The video music player module may include a video player module. The video player module may display a video on the touch screen or an external display connected through the external port or play such video together with the touch screen the display controller the interaction module the graphic module the RF circuit and or the audio circuit .

The video music player module may include a music player module. The music player module may play music stored and recorded in at least one file format including MP3 wma and AAC file and other sound files together with the touch screen the display controller the interaction module the graphic module the audio circuit the RF circuit and or the browsing module .

The note module may generate and manage a note or a to do list together with the touch screen the display controller the interaction module the graphic module and or the text input module .

The browsing module may perform the Internet browsing including searching linking receiving and displaying a web page or a part of the web page and an attachment linked to the web page and other files together with the RF circuit the touch screen the display controller the interaction module the graphic module and or the text input module .

The map module may receive display modify or store data on e.g. driving direction stores in a particular location or adjacent stores and relevant sites location based data and other map related data and maps together with the RF circuit the touch screen the display controller the interaction module the graphic module the text input module the sensor module the LBS module and or the browsing module .

The calendar module may generate display and store a calendar and relevant data e.g. calendar entry and a to do list together with the RF circuit the touch screen the display controller the interaction module the graphic module and or the text input module .

The weather module the stock module the calculator module the alarm clock module and or the dictionary module may operate together with the RF circuit the touch screen the display controller the interaction module the graphic module the text input module the communication module the sensor module and or the browsing module . The foregoing modules may be applications which provide weather information stock information or calculator alarm clock or dictionary function.

The search module may search a text music sound image video and or other files stored in the memory and matching at least one search condition such as at least one search word designated by a user together with the touch screen the display controller the interaction module the graphic module and or the text input module .

The news module may operate together with the touch screen the display controller the interaction module the graphic module the RF circuit the communication module the social networking module and or the text input module . For example the news module may receive a web address designated by a user a network address an html xml RSS file including news channel articles or a text about a blog or images or Digital Rights Management DRM files and other data in the network or of an external device or download such data from the network or the external device to the memory and provide a user with such data.

The foregoing modules and applications may correspond to an instruction set to perform at least one of the functions described above. Such modules i.e. an instruction set do not need to be realized as an individual software program procedure or module and various subsets of such modules may be integrated or rearranged according to various exemplary embodiments. For example the video music player module may be a single module or may be classified into a video player module and a music player module. According to some exemplary embodiments the memory may store therein the foregoing modules and the subset of a data configuration. The memory may further store modules and data configuration which are not described above.

According to an aspect an area of the screen may include a status area a main area and a command area .

The status area may be provided in an upper part of the touch screen and provide information relating the status of the apparatus . For example the status information may include connection information and system event information. The connection information may include an icon or graphic relating to a signal intensity Wi Fi connection Bluetooth connection and call connection. The system event information may include an icon or graphic relating to time a residual amount level of a battery applications on execution execution of music or radio reception of message profile and alarm setting. Such icons may have priority and may be sequentially provided in a left or right side on the status area according to the priority. According to an aspect an icon which has a lower priority may be hidden while an icon which has a higher priority may be displayed always.

On the main area at least one content which accounts for most of the touch screen and provided by the apparatus may be displayed. In an upper part of the main area information relating to at least one content or a UI relating to at least one content may be provided. For example the content related information may include a title of a content a command name which is executed in a previous screen a name or location of a category which includes a currently displayed content. The content related UI may include a tab or folder to move to another content at the same level as the content. According to an aspect if at least one content is scrolled on the main area the content related information or content related UI provided in an upper side of the main area may hold its location on the main area regardless of a scroll gesture.

The command area may be provided in a lower part of the touch screen and provide e.g. a UI such as at least one of soft keys and and an option menu . According to an aspect the command area may be used as a part of the main area usually and provide the soft keys and or the option menu depending on circumstances e.g. when a user contacts moves or releases such contact . The soft keys and may be provided to perform useful functions relating to an application on execution. For example the soft keys and may include a search function a function returning to a previous screen a function canceling an operation being executed and a function adding a new category. The soft keys and may be provided in a left side or right side of the command area and include at least one key in proportion to the number of available functions. The soft keys and may include various graphics e.g. icons and texts which are intuitive and easy to understand. The option menu may provide an option with respect to a content displayed on the main area or to an application being executed. For example if a user selects the option menu the option menu may provide a soft keyboard having at least one symbol displayed on the main area or at least one available function or detailed information of contents on the main area .

The apparatus may include at least one physical UI together with the virtual UI. According to an aspect the apparatus may include a power lock button a home button a volume up button and a volume down button. The power lock button may lock or unlock the apparatus or turn on or off the apparatus when pressed long. The home button may be navigated by a voluntary application of an application set executable in the apparatus e.g. main page application . The volume up button and the volume down button may increase and decrease volume respectively. According to another exemplary embodiment the apparatus may further include a send button a camera button and an end button. The send button may display a telephone log or connect the latest received telephone call when pressed long. The camera button may photograph by executing a camera application or using the optical sensor of the apparatus . The end button may end a currently executed application and return to the main page or end a call connection when a user is on the phone. A set of functions corresponding to the foregoing button may be performed by using the same physical button or functions corresponding to a single button may be distributed and performed by different physical buttons. The function of the physical button may be realized as a virtual button on the touch screen . According to another exemplary embodiment the apparatus may receive a verbal input through the audio circuit as a physical UI to enable or disable some functions.

Hereinafter exemplary embodiments of a user interface and its related process to be implemented on the apparatus will be described.

The user interface of may be included in the main area of . may include a first area and a second area . The first area may provide information related to at least one of contents or a user interface related to at least one of contents. For example if a plurality of graphics to are provided in the first area and a user selects one among the plurality of graphics to a set of contents corresponding to the selected graphic may be displayed on the second area . At this time the graphic may be a tab menu.

When the set of contents corresponding to one graphic among the plurality of graphics to is displayed on the second area the one graphic may be provided with a visible feedback. For example the whole or a part of the graphic may be changed in color the circumference of the graphic may be highlighted or the position of the graphic may be moved.

According to an exemplary embodiment a reference numeral of represents a plurality of items as a set of contents corresponding to a graphic . Here the plurality items may be provided by executing the contact address module the telephone module etc.

According to another exemplary embodiment a reference numeral of represents a web page as a set of contents corresponding to a graphic . Here the web page may be provided by executing the browsing module etc.

According to still another exemplary embodiment a reference numeral of represents a plurality of thumbnails as a set of contents corresponding to a graphic . For example the plurality of thumbnails may be providing by executing the camera module the image management module or etc. The plurality of items the web page or the thumbnails as described above may be moved in a direction corresponding to a predetermined direction e.g. a up or down direction in which a user s gesture moves.

Reference numerals and of illustrate user interface screens for displaying at least one graphic and a hidden graphic on the first area according to an exemplary embodiment. For example the user interface for displaying the hidden graphic may be the whole or a part of the first area . The apparatus can detect a user s gesture for selecting the user interface and display the whole or a part of the hidden graphic in response to the user s gesture.

The at least one graphic and the hidden graphic may follow a predetermined order. A reference numeral of shows an order in which the at least one graphic and the hidden graphic are positioned. For example the order of the at least one graphic and the hidden graphic may be achieved in the form of a stack a queue a linked list etc. and stored in the memory of the apparatus .

Each of the first areas in the screens and of and C may include an identifier for showing a direction where the hidden graphic is positioned.

According to an exemplary embodiment an identifier showing that the hidden graphics and will be displayed from the back of the at least one graphic and may be provided at one side of the first area in the screen of . According to another exemplary embodiment identifiers and showing that the hidden graphics and and respectively will be displayed from at least one of the front or the back of the at least one graphic and may be provided at one side of the first area in the screen of . According to still another exemplary embodiment an identifier showing that the hidden graphics to will be displayed from the front of the at least one graphic to may be provided at one side of the first area in the screen of . The identifiers and may have various shapes such as a triangle a star a heart a finger an arrow etc. but not limited thereto. Also if a user selects the identifier the identifiers may be provided with various visible feedbacks. For example the identifiers may be changed in shape or color or be highlighted.

The first area in the screens and of may include a user interface for displaying the hidden graphics. The apparatus detects a user s contact position and a contact released position on the user interface and determines a direction of the gesture on the basis of the contact position and the contact released position. Further the apparatus can display the hidden graphic corresponding to the direction of the gesture in accordance with the determination.

According to an aspect if a user contacts a part of the first area reference numeral moves the contact frontward keeping the contact reference numeral and releases the contact reference numeral in the screen of the hidden graphics to may be displayed from the back. According to another aspect if a user contacts parts of the first area reference numerals moves the contacts backward or frontward keeping the contacts reference numeral and releases the contacts reference numerals in the screen of the hidden graphics and and may be displayed from the front or the back respectively. According to still another aspect if a user contacts a part of the first area reference numeral moves the contact backward keeping the contact reference numeral and releases the contact reference numeral in the screen of the hidden graphics to may be displayed from the front. The user s gesture for displaying the hidden graphic from the front or the back may include flick touch and move swipe drag and drop etc. but not limited thereto.

In the screen of the apparatus can detect a user s gesture for selecting a part of a first area . For example a user s gesture may include touch and hold for selecting a part of the first area .

In the screen of the apparatus may extend the first area to a part of a second area in response to a user s gesture and display a plurality of graphics including at least one graphic and and hidden graphics and on the extended first area . In this case the whole or a part of the hidden graphics to may be displayed on an area converted from the second area to the first area. At this time the hidden graphics to may be displayed from the bottom of the at least one graphic to .

When the apparatus detects the user s gesture for selecting a part of the first area a set of contents displayed within the second area may be inactivated. For example The apparatus may not provide an operation or a visible feedback related to the at least one content in the state that a user selects at least one among the sets of contents in the second area . Also at this time the sets of contents in the second area may move downward or some sets of contents may be covered with the extended first area . Further the visible feedback provided to at least one graphic within the first area may be removed. For example if the visible feedback changes the color of the at least one graphic from first color to second color the color of the graphic may be returned to the first color.

In the screen of the apparatus selects at least one graphic among a plurality of graphics and within an extended first area where the plurality of graphics to is displayed and detects a user s additional gesture for moving the selected graphic . In response to the user s additional gesture the apparatus may move at least one graphic among the plurality of graphics to to an area of the extended first area . For example the apparatus may move a first graphic among the plurality of graphics to to an area for a second graphic among the plurality of graphics to . At this time the second graphic may be one of the displayed graphics on the screen of and the first graphic may be one of the hidden graphics in the screen of .

In the screen of if the at least one graphic among the plurality of graphics to is moved to an area of the first area in response to the user s additional gesture the apparatus may move at least one among the graphics other than the at least one graphic to an area from which the at least one graphic is moved out. For example if the first graphic among the plurality of graphics to is moved to an area of the first area and does not move for a predetermined period of time the apparatus may move the second graphic to an area from which the first graphic is moved out. At this time the case where the first graphic is not moved any longer may include that a user moves the first graphic while keeping the contact and keeps or releases the contact on one position for a certain period of time.

In the screen of the apparatus may detect a user s additional gesture for selecting at least one graphic among the plurality of graphics and within the extended first area and moving the selected graphic .

In the screen of the apparatus may move at least one graphic among the plurality of graphics to an area of the first area in response to a user s additional gesture and move a graphic adjacent to the at lest one graphic to an area from which the at least one graphic is moved out. Again another adjacent graphic is pushed in and moved to an area from which the adjacent graphic is moved out. For example when the first graphic among the plurality of graphic to is moved to an area of the first area the apparatus moves an adjacent third graphic to an area from which the first graphic is moved out and moves an adjacent second graphic again to an area from which the third graphic is moved out.

In a screen of the apparatus can sense a user s gesture for selecting a part of a second area in the state that a plurality of graphics and is provided in an extended first area . At this time the plurality of graphics may be divided into a first group of graphics and a second group of graphics in accordance with positions within the extended first area . Here the first group of graphics may be positioned in a higher rank than the second group of graphics . Meanwhile for example the user s gesture for selecting a part of the second area may include a tap a contact or etc. for selecting the second area .

In the screen of the apparatus downsizes an extended first area to an original area in response to the user s gesture and displays the first group of graphics in the downsized first area . At this time the second group of graphics is hidden and an identifier for representing that the second group of graphics can be provided may be placed at one side of the downsized first area . Meanwhile the first group of graphics may include a second graphic moved to an area for the first graphic in accordance with a user s gesture in and the second group of graphics may include a first group of graphics moved to an area for the second graphic.

In the screens and of when the first area of the apparatus is downsized to the original area a visible feedback may be given to at least one among the plurality of graphics to and contents corresponding to one graphic may be activated. For example if the visible feedback of the graphic is removed when the first area is enlarged to the extended first area the visible feedback may be given again to the graphic the feedback of which is removed as the first area is downsized to the original area . Also if a set of contents in the second area related to the graphic is inactivated as the first area is enlarged to the extended first area the set of contents related to the graphic may be activated again to receive a user s input as the first area is downsized to the original area .

At operation the apparatus may display a user interface for displaying at least one graphic and a hidden graphic in the first area. At operation the apparatus may display a set of contents corresponding to one of the at least one graphic in the second area distinguishable from the first area. Also the apparatus may display an identifier for showing a direction where the hidden graphic is disposed at one side of the first area.

In the case that the apparatus detects a user s gesture for selecting the user interface the apparatus may detect a user s contact position and a contact released position on the user interface. Further the apparatus may determines a direction of the gesture on the basis of the contact position and the contact released position and thus display the hidden graphic corresponding to the direction of the gesture.

At operation the apparatus may detect a user s gesture for selecting a part of the first area. At operation the apparatus enlarges the first area up to a part of the second area in response to a user s gesture and display at least one graphic and a plurality of graphics including a hidden graphic in the enlarged first area. At this time the apparatus may display at least a part of the graphic hidden in an area converted from the second area to the first area. Also the apparatus may remove the visible feedback given to one graphic of the at least one graphic. Also the apparatus may inactivate at least one set of contents displayed in the second area.

At operation the apparatus may detect a user s additional gesture for moving at least one among the plurality of graphics. At operation the apparatus may move at least one among the plurality of graphics to a part of the enlarged first area in response to the user s additional gesture and move at least one among the graphics other than the at least one moved graphic to an area from which the at least one graphic is moved out. For example the apparatus may move a first graphic among the plurality of graphics to an area for a second graphic among the plurality of graphics. Further if the first graphic is not moved any more for a predetermined period of time the apparatus moves the second graphic to an area from which the first graphic is moved out.

The apparatus divides the plurality of graphics into a first group of graphics and a second group of graphics in accordance with respective positions of the plurality of graphics. If the apparatus detects a user s gesture for selecting a part of the second area at operation the apparatus may downsize the enlarged first area into an original area and display the first group of graphics on the downsized first area at operation .

As described above disclosed are a method and an apparatus in which functions corresponding to respective areas where a user s gesture is received are performed when the user s gesture is received in different areas through a user interface on a screen so that a user s input can be more effectively acquired.

The foregoing exemplary embodiments may be realized as a program command to be executed through various computer means and recorded in a medium read by a computer. The medium read by the computer may solely or collectively include a program command a data file and a data configuration. The program command which is recorded in the medium is specifically designed and configured for an exemplary embodiment but may be known and accessible by a person skilled in computer software.

The foregoing exemplary embodiments and advantages are merely exemplary and are not to be construed as limiting. The present teaching can be readily applied to other types of apparatuses. Also the description of exemplary embodiments is intended to be illustrative and not to limit the scope of the claims and many alternatives modifications and variations will be apparent to those skilled in the art.

