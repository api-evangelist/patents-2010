---

title: Multiprocessor system and multigrain parallelizing compiler
abstract: Provided is a multiprocessor system and a compiler used in the system for automatically extracting tasks having parallelism from an input program to be processed, performing scheduling to efficiently operate processor units by arranging the tasks according to characteristics of the processor units, and generating codes for optimizing a system frequency and a power supply voltage by estimating a processing amount of the processor units.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08812880&OS=08812880&RS=08812880
owner: Waseda University
number: 08812880
owner_city: Tokyo
owner_country: JP
publication_date: 20100111
---
This application is a Divisional application of U.S. application Ser. No. 11 660 104 filed on Feb. 13 2007 now U.S. Pat. No. 7 895 453 which is a national stage application of PCT JP2006 308161 filed on Apr. 12 2006 the disclosures of which are hereby incorporated by reference. The present application claims priority from U.S. application Ser. No. 11 660 104 filed on Feb. 13 2007 which claims priority from National Stage Application PCT JP2006 308161 filed on Apr. 12 2006 which claims priority from Japanese Application 2005 114842 filed on Apr. 12 2005 the content of which is hereby incorporated by reference into this application.

This invention relates to a hardware configuration that can be adopted for a multiprocessor system constituted of a plurality of processor units for enabling efficient operation of the plurality of processor units in the multiprocessor system and to a compiler for generating programs used in the multiprocessor system.

Device miniaturization due to a progress in a semiconductor manufacturing technology has enabled integration of a huge number of transistors. Simultaneously a progress has been made in achieving higher operation frequencies of a processor. However an increase of operation power and an increase of standby power caused by a leakage current the limit has begun to be seen in performance improvement of a processor which has been achieved conventionally by increasing operation frequency and improving a logical system.

Therefore at present as means for improving performance and attaining lower power consumption a multiprocessor system i.e. a single chip multiprocessor system appears promising. In the multiprocessor system a plurality of processor units hereinafter referred to as PU such as conventional CPU and digital signal processor are mounted on a chip and operated in parallel to thereby obtain high arithmetic operation performance without increasing an operation frequency processes in parallel. In the future it is expected that a further progress in miniaturization will enable 100 to 1000 PUs to be mounted on a chip.

In such a multiprocessor system to obtain arithmetic operation performance proportional to the number of PUs the mounted PUs must be simultaneously operated to process programs. However descriptions of program manipulation are generally made in time sequence which hinders to attain the arithmetic operation performance expected to be in proportion to the number of PUs despite the plurality of mounted PUs.

In order to solve the above mentioned problem there is a method in which a program developer himself rewrites original programs by adding parallelization codes to the programs with consideration given to parallelism of the programs for executing the programs on the plurality of PUs based on the configuration of the multiprocessor system in which the programs are to be executed. This method is useful for a system which includes only a few PUs however this method is not practical in a case of a future system which has several tens to several thousands of PUs mounted therein especially when the PUs are of different types in terms of development time or effective performance.

Accordingly studies have already been made on an automatic parallelization compiler for use in a multiprocessor system constituted of a plurality of PUs similar in configuration and arithmetic operation performance which analyzes input programs extracts parallely operable parts from the programs and allocates these parts to a plurality of PUs for simultaneous execution. For example JP 2004 252728 A discloses a compilation system in which an input source program is analyzed for dividing the program into blocks i.e. tasks of various grain sizes such as subroutines or loops to analyze parallelism among the plurality of tasks and the tasks and data to be accessed by the tasks are divided into sizes suited to a cache or local memory to optimally allocate the tasks to the PUs to thereby generate an object program for efficiently operating the multiprocessor system. An architecture of a chip multiprocessor for supporting the multigrain parallel processing function is disclosed in JP 2001 175619 A.

In the multiprocessor system a reduction of power consumption in each PU is essential to reduce power consumption and exhaust heat. Various proposals have been made regarding methods for reducing power of the individual processors. For example a method for reducing power by dynamically controlling a frequency voltage i.e. reducing a system clock of a processor within real time processing restrictions and supplying a voltage according to the system frequency to the processor is disclosed in JP 3138737 B and JP 2004 2341126 A.

In addition according to a method disclosed in JP 2004 252900 A a plurality of different kinds of processors such as CPU or digital signal processor are combined according to characteristics of each processing whose processing time and power consumption on the processors are measured and provided as information beforehand thereby dynamically allocating a series of processes to the processors based on the information.

Currently new applications are being generated for use in an automobile navigation system a portable telephone a digital television or the like for simultaneously treating variety of data such as an image voice and database information. Under the circumstances it is expected that the processor will have plural types of PUs mounted thereon to simultaneously process various kinds of input data by the method optimal for each kind of data. As disclosed in JP 2004 252728 A a conventional multiprocessor system is a homogeneous processor system which includes a plurality of similarly configured PUs mounted thereon.

However in a future heterogeneous multiprocessor system for simultaneously processing various applications on a variety of PUs there is a problem that processing efficiency in proportion to the types and the number of PUs to be mounted cannot be attained unless programs are paralleled and arranged with consideration given to the types of PUs.

Up to now for efficient execution of programs on the plurality of PUs in a case where a small program or a processing sequence can always be executed in a fixed manner it is necessary that the program first be executed in the system to measure processing time and the like and that the developer manually generate the schedule information based on the measured value in order to obtain schedule information such as execution time for scheduling which consumes a large amount of labor and time.

In this case in a case of a general program whose processing contents or sequence cannot be confirmed beforehand or in a case of a program especially large it is difficult to manually generate the information beforehand. Similarly in a case where the types or the number of PUs increase it is also difficult to manually generate the information.

In the system including many PUs mounted thereon there is a fear that power consumption of the entire processor will increase. Accordingly in applying the system especially to a mobile device such as a portable telephone or a digital television used at home power supply management or system frequency control need to be more precisely performed depending on a processing state of each PU by software in each application program in addition to the conventional frequency and voltage i.e. system frequency and driving voltage control by the operating system.

In particular it is necessary to reduce power consumption without degrading processing performance. In executing a program requiring real time processing it is also necessary to reduce power consumption while complying with time restrictions.

It is therefore an object of this invention to provide a multiprocessor system including various types of PUs mounted thereon and a compiler used in the system for efficiently operating the PUs by automatically extracting parallel tasks from an input program to be processed and by arranging the tasks according to characteristics of the PUs and further for generating codes for optimizing a system frequency a power supply voltage or the like by estimating a processing amount of the PUs and adding the codes to an object program the multiprocessor system enabling optimization thereof.

Therefore according to this invention due to the compiler used in the multiprocessor system which integrates various processor units the programs are divided and arranged for efficiently operating the processor units and control codes i.e. execution codes are generated which minimizes processing time and makes a process to be carried out at low power while making maximum use of performance of the processor system. Moreover a software developer can efficiently create programs within a short time without giving consideration to a configuration of the processor unit.

When the input program is compiled the compiler estimates processing time beforehand based on the processor unit configuration and schedules tasks whose processing order is decided beforehand at compiling stage to each processor. In case processing order cannot be determined at compiling time the compiler generates dynamic scheduling codes which assign such tasks to processors at runtime based on processing information containing execution time. Accordingly a general program can be efficiently processed by the multiprocessor system constituted of various processor units.

The compiler analyzes the input program estimates processing time after task scheduling and precisely executes power supply management and frequency control for each processor unit with giving consideration to a margin of the processing time with respect to time restrictions. Hence power consumption can be greatly reduced.

In the multiprocessor constituted of processing units of different types input programs are parallelized and scheduled to minimize execution time and system frequency control and power supply management are precisely executed for each processor unit. Therefore power consumption can be optimized without degrading performance.

This embodiment shows an example in which types and numbers of PUs are constituted of two general purpose processors hereinafter referred to as CPU and two digital signal processors hereinafter referred to as DSP and two dynamically reconfigurable processors hereinafter referred to as DRP and and two bit manipulation processor hereinafter referred to as BMP and . The types and the numbers of PUs are not limited to those shown in this embodiment but various configurations can be employed. A conventional configuration of only the same type of PU e.g. constituted of four CPUs only may be employed. According to this embodiment the DSPs and and the DRPs and and and the BMPs and and are accelerator units while the CPUs and and are general purpose processor unit.

The DRPs Dynamically Reconfigurable Processors and are processors which can dynamically reconfigure a processing circuit configuration and therefore a processing function so that specific processing determined by the configuration can be executed in a more highly efficient manner than CPUs.

Each of the PUs to includes a local memory or cache LM for temporarily storing a program or data to be processed by the PU and a system control register R for executing frequency power supply voltage FV control to decide a supply voltage VL and a system frequency FL to be supplied to the PU and synchronous control among the PUs. The local memory LM is divided into an area in which a global address to be accessed from the other PU and the original PU having the LM is mapped and an area in which a private address to be accessed from the original PU only is mapped. The shared memory SM connected to the LBUS has a global address mapped therein and can be accessed from the plurality of PUs. The application configuration of this invention is only an example and this embodiment is in no way limitative. For example though not shown in peripheral circuits such as input output processing interruption processing a timer and a debug circuit are to be connected to the LBUS when necessary. Similar or different types of buses may be connected in a tiered manner though a bus bridge.

The SM shared by the PUs to includes a system control register R for setting a supply voltage VL and a system frequency FL to be supplied to the SM to execute frequency and voltage FV control. The local bus LBUS for interconnecting the PU and the SM includes a system control register R for setting VL and FL to be supplied to the LBUS to execute frequency and voltage control. In place of this system control register R a frequency and voltage control register of the SM and the LBUS may be disposed in each of the system control registers R of the PUs to . The system control register R is set by one of the PUs to .

The PUs to are configured on one chip LSI . However a plurality of LSIs constituting PUs to may be connected to configure one chip or module.

The SM may be shared by each processor type CPU DSP DRP or BMP . For example as described below with reference to to an area of the SM is divided into banks and each bank can be shared by each processor type. Alternatively a part of the SM may be shared by the plurality of PUs.

Next configurations of the power supply voltage generation circuit DCGEN and the clock generation circuit CLKGEN connected to each PU will be described.

The step down or boosting circuit DCCNV includes a plurality of voltage step down units. For example as shown in it includes a circuit for directly supplying a power supply voltage VD a step down circuit LVCNV for stepping down the power supply voltage to and a step down circuit LVCNV for stepping down the power supply voltage VD to .

For the PUs to the supply voltage selection circuit VDSEL is controlled via a control line DCCL by a FV driving frequency and driving voltage mode set in the frequency and voltage control register in the system control register R of each PU to select one of a plurality of voltages generated by the step down circuit DCCNV and the selected supply voltage VL is supplied to corresponding one of the PUs to . The frequency and voltage control register is to be set in a predetermined area in the system control register .

An output voltage VCNV of the step down circuit LVCNV is decided by the number of stages of an nMOSFET in the reference voltage generation circuit VREF for deciding a reference voltage and a configuration of the LVCNV is decided to supply a voltage designated by the frequency and voltage control register. A voltage designated via the control line from the PU is selected from a plurality of voltages stepped down by the above mentioned circuit to be output to each of the PUs to .

By inserting an nMOSFET of a high threshold value into the source voltage supply unit of the PU a leakage current flowing during the power cutoff of the PU can be reduced. Each of the configurations of is only one configuration for realizing a function of the step down circuit LVCNV and other various power supply voltage generation circuit may be applied.

Next referring to an example of a configuration of the clock generation circuit CLKGEN will be described. The CLKGEN includes frequency division circuits and for reducing an internal clock FC to an integral submultiple such as or of the internal clock and a clock pulse selector CLKSEL for selecting a clock FL to be supplied to the PU from a plurality of frequency divided clocks. The internal clock FC is generated by multiplying a system clock input from the outside by a designated multiplication rate at a phase locked loop PLL circuit .

In addition to the configuration of as shown in a configuration may be employed in which each circuit DCCNV and CLKCV for converting power supply voltages and clock pulses is added to the plurality of PUs or entire PU and circuits VDSEL and CLKSEL for selecting plural types of power supply voltages and clock pulses generated on the PU sides are added. The example of shows a case in which two sets of power supply voltage generation circuits and clock generation circuits supply power and clocks to four PUs.

Accordingly the circuits for generating power supply voltages and clock pulses can employ various configurations and the configurations are not limited to the above. For example a configuration can be employed in which one circuit DCCNV for converting a power supply voltage is added to the plurality of PUs or entire PU and a circuit CLKCNV for generating a clock pulse is added to the PU side for each PU. Alternatively for example a configuration can be employed in which one circuit CLKCNV for generating a clock pulse is added to the plurality of PUs or entire PU and a circuit DCCNV for converting a power supply voltage is added to the PU side for each PU. Alternatively for example a configuration may be employed in which a DCCNV is not mounted in the chip plural types of power supply voltages generated outside the chip are input and a desired supply voltage VL is selected and supplied by the VDSEL.

As means for setting the frequency and voltage control mode in addition to the configuration of or in which each PU has the frequency and voltage control register system control register R for executing frequency and voltage control of the PU a configuration may be employed in which a frequency and voltage control table FVTBL for holding the frequency and voltage control modes of the PUs to in block is connected to the LBUS as shown in . In the frequency and voltage control register included in the system control register of is integrated as the frequency and voltage control table connected to the local bus LBUS .

The frequency and voltage control table FVTBL can be accessed from each of the PUs to and may be set in a part of the shared memory SM or constituted of a memory or register independent from the shared memory SM.

As described above since the power supply voltages can be individually set for the PUs to a signal voltage level varies between the PUs and the LBUS connected to the PUs. Accordingly the bus interface BIF connected between the PUs to and the LBUS includes a signal level conversion circuit not shown to convert a signal level between the bus LBUS and the PUs to .

Next a hardware mechanism for deciding a power supply voltage VL and a system clock FL generated by the power supply voltage generation circuit DCGEN and the clock generation circuit CLKGEN will be described.

Operation modes VL and FL values to be supplied of the power supply voltage generation circuit DCGNE and the clock generation circuit CLKGEN are decided beforehand during designing and each PU designates the circuit via a control line DCCL or CKCL based on a value of the frequency and voltage control register of the PU. A setting method of VL and FL will be described below in detail. The compiler generates a control code for setting a frequency and voltage control register and the general purpose processor CPU or the CPU for executing the code accesses the memory mapped frequency and voltage control register to rewrite the value.

According to this embodiment the FV mode of the PUs to is set by four stages of VL and FL combinations 2 bits in frequency and voltage control register . shows an operation mode list of the PUs to . An OFF mode voltage frequency cutoff of VL 0 and FL 0 is set when a value of 2 bits of the frequency and voltage control register is 00 and a FULL mode equal to a power supply voltage at VL VD and equal to a system frequency at FL FC is set when a value of the register is 11 .

A LOW mode of VL VD and FL FC is set when a register value is 01 . A MIDDLE mode of VL VD and FL F is set when a register value is 10 . The number of VL FL modes and a VL value FL value are decided based on a form or an application of a system to be built a process technology to be used or the like.

It has been described the case where all the PUs are targeted for the frequency and voltage control and the frequency and voltage control mode is set for the PUs altogether. However different frequency and voltage control modes may be set for the local memories LM and the frequency and voltage control registers to be mounted in the PUs to and other peripheral circuits to the processor. This can be realized by expanding the bit fields of the frequency and voltage control registers and providing fields to set frequency and voltage control modes corresponding to parts to be subjected to frequency and voltage control. For example a mechanism of independently setting FL and VL may be employed for circuits such as a local memory LM and a system control register R whose data must be held. In other words by executing frequency and voltage control for the local memory LM and the frequency and voltage control register independently the data of the LM and the R are held even when the FV of the PU is cut off and the LM of the PU can be accessed from another PU even when the target PU is cut off.

A plurality of frequency and voltage control targets can be set due to the configuration of the local memory LM. Each of to shows a frequency and voltage control system for the local memory LM.

For example as shown in a bank configuration is employed for the local memory LM and frequency and voltage control is carried out for each bank i.e. banks to . Accordingly a supply voltage selection circuit VDSEL is connected to each of the banks to .

In other words a normal voltage or a minimum voltage necessary for holding data is supplied to a bank whose data must be held while power supplies to the banks other than the bank are cut off to thereby save the power. At the same time since it is not necessary to save data return from the PU power cut off time to the normal operation time can be made at a high speed.

As shown in the address space of the local memory LM is divided into certain continuous address spaces i.e. areas to and frequency and voltage control is carried out by the space units. Accordingly power consumption can be reduced by cutting off power supplies to unnecessary address spaces i.e. storage areas .

Therefore the supply voltage selection circuit VDSEL is connected for each of the address spaces i.e. areas to of the local memory LM.

As shown in in the case of the bank configuration of the local memory LM frequency and voltage control is carried out for each unit of the local memory LM divided by certain continuous address spaces i.e. areas to across the banks i.e. banks to .

Accordingly the supply voltage selection circuit VDSEL is connected for each of the address spaces i.e. areas to over the banks to of the local memory LM. With this configuration low power consumption can be realized while utilizing the bank configuration to realize memory interleaving for achieving a high speed of memory access.

The local memory LM may be divided into a part to be accessed from the PU alone having the LM functionally mounted thereon i.e. unshared memory and a part to be accessed from not only the PU but the other PUs i.e. distributed shared memory to be mounted and frequency and voltage control may be carried out for each of the above two memory function units. Accordingly though not shown the supply voltage selection circuit VDSEL is connected for each of the unshared memory and the distributed shared memory areas.

The memory division methods shown in to can similarly be applied for various memories or functional part units such as the memory function units and the shared memory SM mounted in the system. For example a configuration of a plurality of banks may be employed for the shared memory SM arranged outside of the PU and frequency and voltage control may be separately carried out corresponding to access frequencies to the banks and a system state e.g. standby or sleep state .

For example the configuration of is applied to the shared memory SM in place of the local memory LM in which the shared memory SM is divided into banks i.e. banks to and the supply voltage selection circuit VDSEL is connected to each bank to thereby execute power control for each bank units. Alternatively the configuration of is applied to the shared memory SM in place of the local memory LM in which the address space of the shared memory SM is divided into certain continuous address spaces i.e. areas to and frequency and voltage control is executed for each space units to cut off power supplied to the unnecessary address spaces to thereby reduce power consumption. Also the configuration of is applied to the shared memory SM in place of the local memory LM in which frequency and voltage control i.e. power control can be carried for each unit of the shared memory SM divided by certain continuous address spaces areas to across the banks i.e. bank to . It should be noted that the structure shown in to are applied to the shared memory SM LM shown shall be interpreted as SM .

As an example where frequency and voltage control targets are a plurality of parts i.e. functional parts in the PU a method of executing frequency and voltage control for the local memory LM independently of the PU will be described below. According to the example the local memory LM is constituted of four banks i.e. banks to as shown in and the PU and each LM bank are targeted for frequency and voltage control.

A frequency and voltage control mode of the PU is as shown in . shows a list of frequency and voltage control modes of the local memory LM. As a memory is targeted for the operation mode of LM according to this embodiment three operation modes provided as the operation modes of LM i.e. a normal operation mode in which VL VD FL FC and register value is 11 capable of normal memory accessing and data holding a data holding mode in which VL VD FL 0 and register value is 01 inhibited from accessing the memory but permitted to hold data and a power supply cutoff mode in which VL 0 FL 0 and register value is 00 for completely cutting off power without holding data.

In addition a configuration may be employed where an address is allocated to the frequency and voltage control register for each control target. For example shows a format of the frequency and voltage control register where a register is mapped in a memory address for each frequency and voltage control target. In PUFV and LMOFV to LMFV indicating the control frequency and voltage control modes of the PU and the LM are stored in order of addresses.

As shown in when the frequency and voltage control mode of the control target is switched by a bit field of the frequency and voltage control register bit calculation is necessary to set a value of the field. In the configuration of however it is only necessary to directly access the address where the control target register is directly mapped and thus the number of commands regarding frequency and voltage control register setting can be reduced. On the other hand more address resources are necessary as compared with

Described above is the example where the frequency and voltage control modes of the PU and the LM are set by setting the frequency and voltage control register of each PU. However as described above referring to when the frequency and voltage control registers indicating the frequency and voltage control modes of the PUs to are provided as the frequency and voltage control tables FVTBL connected to the local bus LBUS the FVTBL is configured as shown in .

Then the CPU or the like reads the frequency and voltage control table FVTBL to decide frequency and voltage control modes of the PU the local memory LM for each bank and the local bus for each of the PUs to and controls the voltage generation circuit DCGEN and the clock generation circuit CLKGEN .

For the local bus LBUS interconnecting the PUs to a power supply can be partially controlled i.e. power supply can be cut off as frequency and voltage control for the functional part units of the multiprocessing system.

For example when power is cut off during non operation of one of the PUs to the bus interface BIF of the PU is not accessed. Accordingly power of the BIF can be cut off with the result that a leakage current is reduced. When a bus configuration is a cross bar power of the switch for deciding a bus to be connected to the PU can be controlled and cut off.

Therefore it is possible to reduce power consumption of the switch group of the DSP set in an unoperated state.

The network control unit NWCRL includes an SHCTL for deciding priority of packet processing by analyzing the packets sent from the PUs to a selector SELC that selects the packets for which priority has been decided by the SHCTL a queue for temporarily holding the packets and an SWCTL for controlling selector switches to for connecting the network of the sending destination and the sending source by analyzing the packets.

The network switch NWSW includes the selector switches SEL to for connecting the network among the PUs.

The PUs to and the network control unit NWCRL each include switch DSCEL disposed to be selectively connected to the power supply generation circuit DCGEN. Power is supplied from the switches DCSEL to the PUs to and to the selector switches to to which the PU is connected.

For example presuming that the DSP is set in a power cutoff state and no communication traffic occurs in the DSP the switch DCSEL added to the DSP cuts off power supply not only to the DSP but also to the BIF connected to the DSP and the selector switch SEL for selecting the network to the DSP. Accordingly it is possible to further reduce power consumption by cutting off power supply not only to the DSP of the power cutoff state but also to the peripheral circuits. When the entire network is set in a standby state i.e. in a power cutoff state power supply to the NWCRL is also cut off by the switch DCSEL for supplying power to the NWCRL.

Next a specific method of setting the frequency and voltage control register will be described. The description will be made by configuring the register format as shown in

A global address to be uniquely accessed from all the PUs is allocated to the frequency and voltage control register of each PU. A task management PU i.e. PU for an executing scheduler or an operating system predetermined by the compiler accesses the address and sets a frequency and voltage control mode by changing a value of the register.

Frequency and voltage control register setting is carried out by executing a register access object code through the task management PU decided by the compiler and by accessing the frequency and voltage control register of a control destination PU via the local bus LBUS . A specific method by which the compiler generates the object code will be described later. To simply explain in allocating tasks to the plurality of PUs the compiler groups the plurality of PU groups and determines a task management PU for starting the tasks of the group or executing synchronous processing. The compiler generates a code for executing frequency and voltage control in the management PU and the management PU executes the code to carry out frequency and voltage control of the PU in the group. The compiler is executed by a computer not shown .

According to the FV setting method the object code by which the task management PU directly accesses the register is executed. Alternatively as shown in when the operating system hereinafter referred to as OS manages the FV operation mode of each PU by calling a frequency and voltage control API of the OS frequency and voltage control mode setting of the PU can be carried out under control of the OS.

It is also possible to provide a mechanism in which a frequency and voltage control register is set in the entire system and registers for setting frequency and voltage control modes of all the PUs to are set in the register such that FV modes are set to all the PUs to once modes are set in the registers. For example as shown in the frequency and voltage control table of a register shared by all the PUs to are provided such that the frequency and voltage control modes of all the PUs to can be changed by updating the register.

A plurality of frequency and voltage control registers may be provided in the control register of the entire system to set an FV mode for each type of PU in synchronization depending on the types of processors such as a general purpose processing PU group CPU or a dedicated processing PU group DSP DRP and BMP . In this case frequency and voltage control registers are provided for each type of processors in the frequency and voltage control table of and the frequency and voltage control register is shared among the CPU the DSP the DRP and the BMP thereby making it possible to change the frequency and voltage control mode for each type of processor by changing one register.

Next the broadcast BC area disposed in the head area of the memory map of will be described. The BC area is a write only area. When one PU writes data in one address of the BC area the data is simultaneously written in LM entries of all the PUs correlated beforehand to the address via the local bus LBUS . Accordingly the data shared by all the PUs is simultaneously held by the local memories LM of the PUs and the PUs to can access the data of the LM at a high speed without accessing the shared memory SM.

Even in the case of executing system control such as frequency and voltage control the broadcasting is carried out thereby making it possible to simultaneously transmit control information to all the PUs. At this time broadcasting mask information for designating a PU range may be transmitted together to thereby realize a broadcast function of transmitting data or control information by limiting the PU range. As a result for example when the compiler defines a PU group constituted of a plurality of PUs to process tasks in parallel task processing can be simultaneously started or frequency and voltage control can be executed in the PU group thereby improving throughput of the entire system.

Next referring to to a concept of a power supply voltage and system frequency FV control method during task processing at the PUs to will be described. A task program executed at each PU is generated from an input program by a compiler described below. In other words in the input program a structure of the program is first analyzed by the compile described below and divided as macrotasks MT statement blocks of large grain sizes such as a basic block BB a repetition block RB and a subroutine SB which are constituted of assignment statements alone. According to the example the structure is divided into three macrotasks MT to MT . The macrotask is obtained by dividing the input program i.e. source code into a plurality of grain size unit blocks. In other words through the division into the macrotasks a multigrain parallel process is carried out to execute parallel processing by combining macrodata flow processing using parallel processing among rough grain size tasks such as subroutines and middle grain size parallel processing which is loop level parallel processing with near fine grain size parallel processing using statement level parallelism in the basic block in a tiered manner. According to this embodiment program components and macrotask components are allocated to the PUs to as macrotasks and tasks respectively.

Subsequently by calculating characteristic information on calculation costs or the like at an optional PU of the macrotask MT a PU in which the macrotask MT should be executed is decided and data dependency and control dependency among the macrotasks MTs are analyzed to decide execution order of tasks.

In as the macrotasks MT and MT can be executed in parallel the MT and the MT are simultaneously started to be processed by the CPU i.e. CPU and the BMP i.e. BMP respectively. During normal processing voltages supplied to the CPU and the BMP are both normal VD and a normal FC is supplied as a system frequency. According to the example as the number of processing cycles of the macrotask MT at the CPU is smaller than that of the macrotask MT at the BMP the processing of the macrotask MT at the CPU is finished before the processing of the macrotask MT at the BMP is finished.

The CPU which has finished the processing of the macrotask MT next processes the macrotask MT . However because of a dependency relation among the macrotasks MTs the macrotask MT to be processed next at the CPU cannot be executed until the end of the processing of the MT at the BMP. Therefore the CPU is set in an idle state until the processing of the macrotask MT is finished at the BMP. Even during the idle state the normal power supply voltage VD and the clock FC is being supplied to the CPU which leads to extra power consumption.

As one method for solving the problem when the CPU executes the macrotask MT the CPU is driven in a LOW mode i.e. mode of supplying FC of for reducing a system frequency of the CPU from that of a normal time i.e. FULL mode so as to make time necessary for the BMP to process the macrotask MT equal to the processing time of the macrotask MT executed by the CPU. In other words while the BMP is driven in the frequency and voltage control mode at FULL of the normal time the frequency and voltage control mode of the CPU is set to a LOW mode a system frequency of the PU whose processing is finished first is reduced and a frequency and voltage control register is set so that different frequency and voltage control modes are set among the PUs which execute parallel processing. is a Gantt chart when the frequency and voltage control of this method is applied. The compiler estimates the number of processing cycles of the macrotask MT at the CPU CPU and the number of processing cycles of the macrotask MT at the BMP BMP to decide system frequency of the CPU so that processing times of both can be equal. As a result since the system frequency of the CPU is reduced a power supply voltage VL to the PU can also be reduced thereby optimizing power consumption.

In other words according to this example for the macrotask MT the frequency and voltage control mode of the CPU is set to the LOW mode of and the frequency and voltage control mode of the BMP which executes parallel processing is set to FULL .

As another method of solving the idle state of the CPU of at the end time of the processing of the macrotask MT at the CPU the supply of the power supply voltage and the system clock of the CPU are cut off to set a standby state . In other words when the CPU completes the processing of the macrotask MT the frequency and voltage control mode of the CPU is set to OFF of . Then at the start time of the macrotask MT the frequency and voltage control mode is set to FULL to resume the processing. is a Gantt chart when the frequency and voltage control of this method is applied.

In the processing of the macrotask MT of the CPU is finished before the macrotask MT of the BMP is finished. However at the end time the CPU is set in a standby state OFF a normal power supply voltage and a normal system clock are supplied to return the CPU to the normal state when the BMP finishes the processing of the macrotask MT and processing of the macrotask MT is started. As a result as the operation is stopped without setting the CPU to be idle power consumption can be reduced.

Accordingly when the programs i.e. tasks are compiled the compiler estimates processing times beforehand based on the configuration of the PU decides processing order beforehand regarding parts whose processing order can be statically decided during compiling and executes precise system frequency control and power management for each PU. Hence power consumption can be optimized without reducing performance of the multiprocessing system.

The FC control method in the case where execution conditions of the macrotask MT depends on the other macrotasks MTs has been described. It is also possible to provide another frequency and voltage control method targeting a real time processing task having restrictions to be processed within a certain time i.e. a processing time limit i.e. allowance time of the task is predetermined as shown in

When a macrotask MT of is processed in the FULL mode in other words when processed by a CPU operated by a normal power supply voltage and a normal system frequency the processing is finished prior to a processing time limit i.e. deadline . In this case as there is still allowance for the original processing time limit while the CPU is set in an idle state at the end time of the processing a system frequency of the CPU can be reduced within the processing time limit .

Similarly by cutting off the power supply and the system clock of the CPU at the end time of the processing of the macrotask MT power consumption may be reduced. is a Gantt chart when the frequency and voltage control of this method is applied. In this case the CPU processes the macrotask MT in the FULL mode and completes the processing within the processing time limit. However the operation mode is set to OFF when the macrotask MT is completed to thereby save useless power consumption.

Next a compiling method for generating codes to execute scheduling according to characteristics of the processor unit PU and power consumption optimization control based on a dynamic voltage frequency change in the aforementioned multiprocessor architecture and processing of the compiler employing the method will sequentially be described. shows a processing flow of the compiler employing the method.

An input program of a sequential structure described in high level language such as C or Fortran first analyzes the program structure to be divided into three kinds of coarse grain macrotasks MT of a repetition block RB a subroutine SB and a block of pseudo assignment statements BPA to generate macrotasks . The RB is a loop block and an outermost loop in each tier the BPA is a block obtained by combining or dividing a plurality of basic blocks constituted of assignment statements with consideration given to scheduling overhead or parallelism. shows an example of the input program i.e. source program .

In the source program PU allocation can be described beforehand. For example allocation of a given subroutine to the DSP and a given subroutine to the CPU can be explicitly designated. As a result the DSP subroutine is subjected to further parallelism analysis by the compiler and when there are four DSPs for example the compiler executes parallelization scheduling for the four DSPs.

Subsequently a control flow and data dependency among the divided and generated tasks is analyzed and an execution order relation of the macrotasks MTs is extracted . As the input program of is sequentially described execution codes generated by the normal compiler are executed in sequential order as in the case of the structure of the program. However in many cases it is not always necessary to execute the codes in the described order in terms of the relationship among the macrotasks MTs.

In other words when there is no dependency of control or data reference among the macrotasks MTs especially in the multiprocessor system it is important to execute scheduling simultaneously or changing the order by arranging a plurality of macrotasks MTs in a plurality of PUs to shorten the overall execution time.

To execute such scheduling parallelism among the MTs must be analyzed. As a preparation for this analysis an execution order relation among the macrotasks MTs is extracted by a data dependence control flow analysis process .

Subsequently as middle grain size level parallelism analysis in the macrotask MT loop level parallelization is carried out . In the loop level parallelization data dependency among loop repetition i.e. iteration units is analyzed to determine whether each iteration can be independently processed or not. If each iteration can be independently processed iterations are allocated to the plurality of PUs to be subjected to parallel processing.

Loop parallelization is realized by various methods e.g. dividing a single loop into a plurality of loops to increase parallelism copying data or expanding arrangement variables to delete data dependency among the loops thereby realizing parallelization and combining a plurality of loops into a single loop to reduce overhead necessary for loop control.

Next processing cost analysis is carried out to estimate a processing cycle necessary when the generated macrotask MT is executed at each PU . For a method of estimating processing costs i.e. calculation costs for example regarding the CPU the following can be adopted. That is the number of cycles necessary at a command level such as multiplication or addition is held as profiling information in a processing cost table and the number of sequential processing cycles when the macrotask MT is executed at the PU is estimated with reference to the table .

When it is difficult to estimate the number of cycles at an object code level in such devices as the DRP or the DSP which handles multiple amount of data with one command each local compiler generating an object code of the device is called by the compiler and estimates execution cycles on the converted execution codes by the local compiler . The local compiler is preset corresponding to a type of a PU. For example DSP local compiler profiling information is used in the case of the DSP and DRP local compiler profiling information is used in the case of the DRP.

When a branch is included or when a size of a loop or a size of an array cannot be determined before the execution of the macrotask MT profiling may be once executed on supposed execution environment to calculate processing costs with increased accuracy. When this profiling is not executed but the macrotask MT includes a branch cost calculation is carried out with a branch probability of 50 . Similarly when the profiling is not executed and the number of loop iterations cannot be determined a method in which the loop iteration number is set to a fixed number of times or the defined size of an array used in the loop is applied.

The processing costs have been defined as the number of processing cycles time . However it is also possible to define costs as power consumption and carry out scheduling such that power consumption can be reduced to minimum. For example an operation mode capable of reducing power consumption to minimum within the processing time limit is selected from among frequency and voltage control modes frequency and system voltage to be set based on the number of processing cycles and the processing time limit to complete the macrotask MT. Alternatively as power consumption of the PU can be estimated by the following equation power consumption system voltage to the power of 2 driving frequency a combination of frequency and voltage control modes capable of reducing power consumption to minimum within the processing time limit may be selected to execute scheduling. For example processing is executed by only the LOW mode as shown in or a plurality of frequency and voltage control modes are combined as shown in . Alternatively it is possible to select a combination of frequency and voltage control modes with which processing time is minimum and power consumption is minimum.

After the processing costs of the macrotask MT have been determined the compiler determines parallelism among the macrotasks MTs i.e. a condition earliest execution condition which permits execution of each macrotask MTG at the earliest based on the result of simultaneously analyzing the control flow and the data dependency among the macrotasks MTs extracted by the data dependence control flow analysis process .

The earliest execution condition is visibly shown in a macrotask graph MTG . shows MTGs generated by analyzing the input program of . The result of parallelism analysis among the macrotasks is held as a macrotask graph table in an external storage device to be used for a compiling process of a rear stage. This external storage device is a computer not shown for executing the compiler .

Referring to the macrotask MTG will be described below. Each node of the graph indicates a macrotask MT a solid line between the nodes indicates a data dependency relation between the macrotasks a broken line between the nodes indicates a control dependency relation between the macrotasks and a small circle in the node indicates a condition branch. For example solid lines extend from a macrotask MT   to MT   and to MT   . These lines indicate a dependency relation that processing is carried out by using data generated as a result of executing the MT   by the macrotasks MTs   and MT  . Accordingly as an execution order the MT   and the MT   can be executed after the end of execution of the MT  .

As the macrotask MT   obtained from the input program is a coarse grain size block constituted of a plurality of loops or subroutines the compiler further divides the macrotask MT into a plurality of macrotasks MTs in a tiered manner. Therefore in the macrotask graph MTG a macrotask graph MTG   is further generated in another tier in the MT  . In the case of the macrotask MT   similarly a macrotask graph MTGMTG   of another tier is generated.

In the case of the macrotask MTG   in the macrotask MT   the solid lines extend from a task MT    to a task MT    a task MT    and a task MT    after the end of execution of the MT    these three tasks and can be simultaneously executed.

Further the task MT    has dependence on a task MT    . In this case it is only necessary to execute the task of the MT    after the end of the task of the MT    . The solid lines extending from the tasks MT    and MT    to a task MT    mean that the MT    can be executed when the execution of both tasks MT    and MT    is finished.

As described above a task processing order considering parallelism in the macrotasks MTs   is established before execution and tasks can be scheduled onto PUs beforehand in a fixed static manner at a compiling stage.

In the case of a macrotask graph MTG in the macrotask MT   there is a small circle in a macrotask MT    . This indicates that the task MT    includes a condition branch. Broken lines with arrows extend from the small circle to tasks MT    and MT    and an arc of a dotted line indicating an OR condition of control dependence is overlapped therewith which indicates that the condition branches to one of the tasks MT    and MT   .

A broken line with no arrow extends to a task MT    and an arc of a solid line indicating an AND condition in control dependence overlaps with the broken line with no arrow extending to the task MT    and with a broken line connected to the task MT    . This indicates that if the process branches to the task MT    indicated by an arrow under this condition the task MT    dependent for control on the same branch can simultaneously be executed. The broken lines shown in the drawing indicate a control dependency relation to establish task execution and a condition on which a task dependent on data is not executed. The broken line of the arrow indicates that the process is identical to the control flow i.e. original obtained in the data dependence control flow analysis .

The condition branch of the task MT    must be scheduled according to a situation of execution time as a branch direction is not established unless the task MT    is executed. When the condition branch is established and the process branches in the directions of the tasks MT    and MT    as solid lines indicating a data dependency relation extend from the tasks MT    and MT    to the task MT    processing of the task MT    can be executed at the time when processing of both tasks MT and is finished.

When the process branches in the direction of the task MT    processing of tasks MT    and MT    can be executed similarly to the above at the time when the task is finished due to the data dependency relation.

Next the compiler refers to the generated macrotask graph MTG table to execute processor grouping according to a shape and parallelism of the macrotask graphs or an instruction from the user .

Specifically shapes and parallelism of upper tier macrotasks MTs represented by the macrotask graph MTG e.g. the macrotasks MT   and MT   are analyzed the PUs to necessary for processing the macrotasks MTs are grouped and tasks MT are allocated to the groups. One group is formed of a set including at least one general purpose processor CPU for controlling accelerator units DSP DRP and BMP in the group. That is when a proper group configuration of processor PUs can be decided during compiling because of the configuration of the macrotask graph MTG the compiler executes grouping including the accelerator units.

When processor grouping cannot be executed during compiling because of the configuration of the macrotask graph MTG i.e. when tasks to be used by the accelerator units are present in multiple tiers and grouping cannot properly be executed the compiler or the general purpose processor functioning as a scheduler during execution allocates tasks to the accelerator units during compiling. In this case when loads on the accelerator units are large the general purpose processor carries out the process instead of the accelerator units. Decided grouping information is held as a processor grouping table in the external storage device to be used for processing of rear stages.

According to this embodiment in the macrotask graph MTG of processing costs of the macrotasks MT   and MT   are equal to each other and the accelerator units must be controlled by the general purpose processor during the execution of the macrotask graphs MTG   and MTG   in the macrotask. Therefore two processor groups are defined.

Next a configuration of the accelerator units necessary in each processor group is determined according to processing costs and parallelism of the PUs of the macrotasks MT   and MT  . According to this embodiment a necessary unit configuration can be realized by usable resources in the macrotask graph MTG so a processor group is decided to be a CPU a DSP a DRP and a DRP and a CPU a DSP a BMP and BMP during compiling.

The compiler next decides which of a static schedule and a dynamic schedule to adopt as a scheduling method . Each scheduling method will be described below in detail but brief explanation will be made first. In the case of a MT flow where there is no condition branch in a task MT but earliest execution conditions can be predetermined the static schedule is applied where the compiler executes task MT scheduling beforehand to insert synchronous and frequency and voltage control codes scheduling codes among the tasks.

In the case of a MT flow unpredictable during compiling e.g. there is a condition branch in the task MT or processing time of the task MT fluctuates during execution the dynamic schedule is applied and the compiler generates a scheduling program for executing control during execution according to a situation such as a branch. An advantage of generating the scheduling program scheduling codes by the compiler is that overhead of several thousand to several tens of thousand clocks which may be generated if generation of rough grain size tasks and scheduling are requested to the OS or the library as in the case of the conventional multiprocessor can be avoided.

First a process flow of the static scheduling will be described. According to the static scheduling allocation and execution order of the tasks MT have already been decided during compiling. Therefore first a macrotask scheduling process refers to information of the macrostatic table and the processor grouping table to generate control information to synchronize execution tasks of the PUs with one another or start other tasks and to decide an insertion place of the control information.

Data transfer information is simultaneously generated to load data necessary for the task program or the task from the local memory LM of the other PU and the shared memory to the local memory LM of the PU. By such a data localization method the local memory LM is effectively utilized to minimize a data transfer amount. The schedule information generated through the process is held as a macrotask schedule table in the external storage device.

Subsequently the compiler executes a static FV scheduling process . Based on the frequency and voltage control concept during the task parallel processing execution described above with reference to to this process judges a margin determined by task processing costs and a schedule time limit processing deadline from the schedule information macrotask schedule table generated by the macrotask scheduling and generates frequency and voltage control information to set a PU operation mode for deciding a system frequency supply voltage according to the margin. The frequency and voltage control information is held as a power supply frequency and voltage control schedule table in the external storage device. For example the margin is determined based on processing time from an execution start to execution completion and to the processing time limit and indicates a performance margin of each of the PUs to . For example as shown in a margin is judged to be large if time from the execution completion to the processing time limit of the CPU is long. On the other hand a margin is judged to be short when time from the execution completion to the processing time limit is short.

The processing time limit allowance time may be described in the input program or input from a console not shown during the processing of the compiler .

Next a process flow of the dynamic scheduling will be described. According to the dynamic scheduling scheduling contents cannot be decided during compiling because of uncertain data such as a condition branch in the task MT. Therefore the compiler generates a scheduling program to dynamically execute scheduling during program execution based on the processing result of the task MT . This program starts or synchronizes the tasks MT or loads data necessary for the MT based on the processing result. Additionally based on the frequency and voltage control concept of the task parallel processing execution time described above with reference to to the program sets an operation mode frequency and voltage control mode for deciding a system frequency supply voltage of the PU. The generated scheduling program is held as a power supply frequency and voltage control schedule table in the external storage device.

Through the above process the compiler completes the scheduling of the input program to the PUs to . The pieces of scheduling information generated through the process have been stored as the tables to in the external storage device. The compiler accesses the tables to reads the task execution order the data transfer information and the frequency and voltage control information and adds with respect to the input program a control code scheduling code to the static schedule part of and a scheduling program to the dynamic schedule part . The control code is generated by for example using a MPI message passing interface which is a parallel programming standard interface of a distributed memory type multiprocessor system. The input program to which the codes have been added is processed by a local compiler prepared for each type of PU to be converted into an execution binary code of the PU . The local compiler is prepared for each type of PU of the CPU the DSP the DRP and the BMP as descried above and loads the local compiler according to each type of PU to generate an execution binary code.

After the processing end of the macrotask MT   in the CPU the control code generated by the compiler is executed to set a frequency and voltage control mode. Tasks to be processed next are a task MT    and a task MT    designated by the macrotask graph MTG of the lower tier of the macrotasks MT   and MT  . The former is executed by the CPU and the latter is executed by the CPU .

Accordingly the CPU sets the frequency and voltage control register of the CPU for processing the task MT    to a normal mode FULL . Regarding the CPU the frequency and voltage control mode has been set to a normal mode but the normal mode FULL is maintained to successively process the MT   .

In this case as there is no task to be processed in the other PU during the processing of the task MT    and the task MT    an operation mode is maintained OFF for the other PU. Then the CPU starts processing of the task MT    by its own CPU and the task MT    by the CPU .

As described above the scheduling has been executed during compiling since the macrotask MTG   includes no condition branch static scheduling . The tasks MT are allocated to the group of the CPU the DSP the DRP and the DP . As the macrotask MTG   includes a condition branch a program for executing scheduling during execution is added and the tasks MT are allocated to the group of the CPU the DSP the BMP and the BMP based on an execution result.

Next scheduling of the task MT group of the macrotask graph MTG   will be described. Upon an end of the execution of the task MT    at the CPU the CPU executes the control code and sets the frequency and voltage control register to 3 to set the DSP to a normal operation mode FULL so as to process the task MT   . In the case of the tasks MT    and MT    the frequency and voltage control register is set to 2 to set the DRP and the DRP to a low power operation mode MIDDLE based on margin judgment of the tasks by the FV scheduling during compiling. There is no MT to be executed by the CPU but the CPU executes the scheduler to manage the tasks of the DSP the DRP and the DRP in synchronization. Therefore the scheduler sets the frequency and voltage control register to 1 to set a low power operation mode LOW for the CPU . Then processing of the task MT    the task MT    and the task MT    are started. After the MT processing end the task MT    is similarly executed at the DSP . Accordingly task start reservation task registration in task ready queue is made for the task MT    to start the task MT    at the end of the task MT   .

Next upon judging that the processing of the task MT    and the task MT    have both been finished the CPU executes the control code sets the operation mode of its own CPU for processing the task MT    to MIDDLE operation modes of the DRP and the DRP to OFF as there is no task to be processed in the DRP and processing of the task MT    is started in a state where a voltage and a system frequency are reduced from normal levels. Upon end of a processing of the task MT    the CPU executes the control code . Upon judging that the processing of the task MT    has been finished the CPU sets the operation mode of the DSP to OFF as task processing has been completed in the MTG   group.

Next a task MT group of the MTG   will be described. The macrotask MT   includes a branch whose direction cannot be identified unless the task is executed. Accordingly a dynamic scheduler for loading the task and data starting the task and managing the synchronous and frequency and voltage control codes depending on a situation during execution is executed by the CPU . The scheduler first sets an operation mode of the CPU to FULL to execute the task MT    and starts the task MT   . After the execution end of the task MT    the scheduler judges a branch direction to determine a task to be started next.

According to the scheduling shown in the task MT    is processed by the DSP and the task MT    is processed by the BMP . Before the start of the processing the scheduler sets an operation mode of the DSP to FULL and an operation mode of the BMP to LOW according to the FV scheduling result. Though there is no task MT to be executed in the CPU the CPU executes the scheduler to carry out task management of the DSP and the BMP . Therefore the scheduler sets an operation mode of the CPU to a low power mode LOW.

Next upon judging of the processing end of both of the task MT    and the task MT    the dynamic scheduler of the CPU sets an operation mode frequency and voltage control mode of its own CPU for processing the task MT    to FULL and operation modes of the DSP and the BMP having no tasks to be executed to OFF. Then the task MT    is executed by its own CPU .

As described above in the multiprocessor constituted of the PUs to of different types the input programs are parallelized and scheduled by the multigrain parallel processing so as to reduce the execution time to minimum and then system frequency control and power supply management are precisely carried out for each PU. Hence it is possible to reduce power consumption within the minimum execution time without deteriorating performance.

As described above this invention provides the multiprocessor system where various processor units PU are integrated in which the program is divided to be arranged for efficient operation of the PUs and the compiler generates the control code to thereby carry out the process efficiently with low power within minimum processing time while making best use of the performance of the system. Moreover the software developer can create highly efficient programs within a short time without giving consideration to the processor configuration.

The embodiment has been described by way of example where the multiprocessor system equipped with the plurality of PUs to in one chip is applied to this invention. However the multiprocessor system can also be applied to a parallel computer of equipped with a plurality of chips and operation effects similar to the above can be obtained.

According to at least one embodiment the multigrain parallelization compiler is characterized in that the number of processing cycles for processing the unit blocks is obtained based on the profiling information set for each processor unit and the calculation cycle time is obtained from the processing cycles.

According to another embodiment the multigrain parallelization compiler is characterized in that the unit blocks are converted into execution codes by the local compiler set for each processor unit the number of processing cycles for processing the unit blocks is obtained based on the profiling information set for each processor unit and the calculation cycle time is obtained based on the number of processing cycles.

According to a further embodiment the multigrain parallelization compiler is characterized in that the number of processing cycles for processing the unit blocks is obtained based on the profiling information set for each processor unit and the power is obtained from the processing cycles.

According to a further embodiment the multigrain parallelization compiler is characterized in that as regards the calculation cycle time the unit blocks are converted into execution codes by the local compiler set for each processor unit the number of processing cycles for processing the unit blocks is obtained based on the profiling information set for each processor unit and the power is obtained based on the number of processing cycles.

According to yet another embodiment the multigrain parallelization compiler is characterized in that the process of extracting the parallelism of the unit blocks includes a process of storing the extracted unit blocks in the macrotask graph table and grouping the processor units necessary for processing the unit blocks to store the group in the processor grouping table and

the process of generating the scheduling codes includes a process of referring to the macrotask graph table the processor grouping table and the cost information to generate control codes for the processor units and a process of inserting the control codes according to execution order of the unit blocks.

According to an even further embodiment the multigrain parallelization compiler is characterized in that the process of extracting the parallelism of the unit blocks includes a process of storing the extracted unit blocks in the macrotask table and grouping the processor units necessary for processing the unit blocks to store the group in the processor grouping table and

the process of generating the scheduling codes includes a process of referring to the macrotask graph table the processor grouping table and the cost information to generate a scheduling program for dynamically scheduling the unit blocks and a process of inserting the scheduling program according to the execution order of the unit blocks.

According to this invention there is provided a multiprocessor system where various PUs are integrated in which the program is divided to be arranged for efficient operation of the PU and the compiler generates the control code to thereby efficiently carry out the process with low power while making best use of the performance of the processor system. The software developer can efficiently create programs within a short time without giving consideration to the processor configuration. As a result this invention can be applied to an LSI for use in a car navigation system a portable telephone or information appliance which is strongly required to carry out a process with high calculation performance and with low power at the same time to thereby attain functions of performing high quality moving image production or voice processing and image or voice recognition. This invention can also be applied to an LSI for use in an information or control system of an automobile with which automatic driving or safe driving system can be realized. Further the invention can be applied in the future to a supercomputer which is required to have very high microprocessing power at low power consumption

