---

title: Policy-based meta-data driven co-location of computation and datasets in the cloud
abstract: Determining at least one resource node for deployment of an application in a system having a plurality of compute and storage resource nodes includes determining criteria for nodes based on a policy provided for the application, pruning nodes that do not meet a criteria for deploying the application to provide a plurality of remaining nodes, determining a cost of deploying the application on each of the plurality of remaining nodes, where the cost is based on a metric associated with the application, and selecting for deployment a node having a lowest cost. The application may be a vApp that includes a plurality of virtual machine images. The nodes may be interconnected by communication links having associated therewith costs of moving the application from one node to another.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09462056&OS=09462056&RS=09462056
owner: EMC Corporation
number: 09462056
owner_city: Hopkinton
owner_country: US
publication_date: 20100426
---
This application is a continuation in part of U.S. patent application Ser. No. 12 658 635 filed on Feb. 9 2010 pending which is incorporated by reference herein and which is a continuation in part of U.S. patent application Ser. No. 11 981 604 filed on Oct. 31 2007 now abandoned which is incorporated by reference herein.

This application relates to the field of storing data and more particularly to the field of providing services in connection with data storage.

Cloud computing is Internet based computing whereby shared resources software and information are provided to computers and other devices on demand like a public utility. A cloud may be a hybrid system that might consist of physical and virtual compute and storage resources that offer various levels of compute services from infrastructure to platform and application framework level. In addition computations in the cloud may be performed by a collection of distributed applications that cooperate in performing computational tasks. The distributed applications may be provided by a collection of storage objects some of which are executable. Due to the requirements of the application runtime environments some of the storage objects must be co located e.g. the virtual disks of a virtual machine must all be placed in the same virtual infrastructure and some of the objects do not have to be co located e.g. the virtual disks and the application datasets that reside in cloud storage . Also when a distributed application executes code from some executable objects happens to communicate a lot with code from other executable objects tightly coupled computation while communicating less with code from other executable objects loosely coupled computation . Examples of executable objects include virtual disks that contain OS and application code software components e.g. OSGi bundles java or python packages and software distribution packages e.g. RPM packages . Examples of data objects include data virtual disks that contain database and filesystem volumes virtual machine descriptor files application descriptor files and archived and or compressed collections of data objects for use by applications.

One model of the Cloud is a two tier system with one tier comprising geographically dispersed compute resources with relatively small amounts of internal storage. The storage is used for hosting virtual physical machines as they execute on the virtualized physical compute resources. The second tier comprises geographically dispersed storage resources with large amounts of storage generally optimized for storing infrequently modified data e.g. data at rest and snapshots of virtual machines running on the compute resources . The data in the Cloud includes virtual machine disk images both those containing executable code guest OS applications and those containing datasets e.g. database LUNs and filesystem images . Cloud storage provides a variety of storage services for data protection high availability disaster recovery etc. This usually means that there are replicas of the data in the Cloud present in several geographies.

The Cloud is a heavily distributed system that includes collections compute and storage resources in geographically dispersed locations. In addition computations in the Cloud may be performed by collections of virtual machines that process shared datasets. The virtual machines storage footprint and the dataset sizes are often sufficiently large to discourage movement of these objects across network localities. In any case it may be difficult to determine when movement might be advantageous.

Accordingly it is desirable to provide a system that provides for optimal co location of compute and data resources within the Cloud.

According to the system described herein determining at least one resource node for deployment of an application in a system having a plurality of compute and storage resource nodes includes determining criteria for nodes based on a policy provided for the application pruning nodes that do not meet a criteria for deploying the application to provide a plurality of remaining nodes determining a cost of deploying the application on each of the plurality of remaining nodes where the cost is based on a metric associated with the application and selecting for deployment a node having a lowest cost. The application may be a vApp that includes a plurality of virtual machine images. The nodes may be interconnected by communication links having associated therewith costs of moving the application from one node to another. The cost at a particular node may include a cost of moving the application to the particular node a cost of running the application at the particular node and a cost of the application accessing a dataset while running at the particular node. The metrics used for cost may include at least one of runtime resource usage metrics resource rents availability track record aggregate CPU memory disk usage aggregate network and I O bandwidth figures for a compute service installation aggregate space available I O bandwidth of the storage service facility bandwidth for connections between service installations compute storage resource rents performance and availability current locations of data objects current locations of already running computational activities available new locations for storage available new locations for caching data objects available new locations for deploying computational activities available compute capacity in different locations available storage capacity in different locations available bandwidth capacity between different locations costs of running computational activities in different locations costs of storing or caching data in different locations and costs of moving data between locations. Pruning may be based on at least one of constraints described in a policy specification application data locality disk image movement during deployment rent thresholds for specific resources and an overall optimization goal. Determining a node for deployment of an application in a system having a plurality of compute and storage nodes may also include obtaining location information for the nodes. The location information may be included in object metadata or may be external from object metadata.

According further to the system described herein computer software provided in a computer readable storage medium determines a node for deployment of an application in a system having a plurality of compute and storage nodes. The software includes executable code that determines criteria for nodes based on a policy provided for the application executable code that prunes nodes that do not meet a criteria for deploying the application to provide a plurality of remaining nodes executable code that determines a cost of deploying the application on each of the plurality of remaining nodes where the cost is based on a metric associated with the application and executable code that selects for deployment a node having a lowest cost. The application may be a vApp that includes a plurality of virtual machine images. The nodes may be interconnected by communication links having associated therewith costs of moving the application from one node to another. The cost at a particular node may include a cost of moving the application to the particular node a cost of running the application at the particular node and a cost of the application accessing a dataset while running at the particular node. The metrics used for cost may include at least one of runtime resource usage metrics resource rents availability track record aggregate CPU memory disk usage aggregate network and I O bandwidth figures for a compute service installation aggregate space available I O bandwidth of the storage service facility bandwidth for connections between service installations compute storage resource rents performance and availability current locations of data objects current locations of already running computational activities available new locations for storage available new locations for caching data objects available new locations for deploying computational activities available compute capacity in different locations available storage capacity in different locations available bandwidth capacity between different locations costs of running computational activities in different locations costs of storing or caching data in different locations and costs of moving data between locations. Pruning may be based on at least one of constraints described in a policy specification application data locality disk image movement during deployment rent thresholds for specific resources and an overall optimization goal. The software may also include executable code that obtains location information for the nodes. The location information may be included in object metadata or may be external from object metadata.

The system described herein is advantageous over approaches that assume a priori dataset distribution within a datacenter where VM deployment is managed explicitly either by the data processing or by a management application which introduces extra complexity and might require modification of existing applications. The system described herein addresses a problem of co locating computation and datasets across a collection of datacenters and does not assume a priori dataset distribution. Accordingly the system described herein can better handle with dynamic data sets can adapt to changes in dataset availability in various locations and can move data and computation as needed. Additionally the system described herein is policy based so that deployment decision making logic does not need to be coded in the applications thereby reducing application complexity and becoming applicable to existing applications without modification.

Referring to a diagram illustrates servers coupled to a plurality of clients . Each of the clients represents one or more processing devices that receives file services from the servers . Each of the clients may or may not be independent of other ones of the clients . One or more of the clients may be a multiprocessing multiuser system and possibly have multiple independent users. The clients represent any number of clients.

The file services provided by the servers may include data storage and retrieval as well as related operations such as data mirroring cloning etc. The servers may be implemented using a plurality of services and or interconnected file servers including SAN components that are provided by interconnected processing and or storage devices. In an embodiment herein each of the clients may be coupled to the servers using the Web possibly in conjunction with local TCP IP connections. However it is possible for one or more of the clients to be coupled to the servers using any other appropriate communication mechanism and or combinations thereof to provide the functionality described herein.

Referring to the servers are shown in more detail as including a plurality of server groups where each of the groups may include one or more individual servers that may be managed together as a single data storage cloud. The terms cloud data storage cloud etc. should be generally understood herein as an integrated group of servers. Different ones of the groups clouds may be managed separately from each other. As discussed in more detail elsewhere herein the groups may be interconnected to transfer information using any appropriate means including being interconnected through one or more of the clients being interconnected through the Internet a SAN a private LAN or WAN directly connected and or using any other appropriate interconnection to provide for information transfer as discussed elsewhere herein. For the discussion herein one of the groups may be a local cloud that is performing operations discussed herein while another one of the groups may be an external cloud that contains data accessed by the local cloud.

Referring to the client is shown as being coupled to the servers and to one or more other network s . The other network s may include a local area network LAN . Thus the client may be a gateway between the servers and a LAN to which one or more other devices not shown may also be coupled. The client may act as a local file server to the one or more other devices coupled to the LAN by providing data from the servers to the one or more other devices. Of course it is possible for one or more other clients to simultaneous act as gateways to the same or different other network s . Generally for the discussion herein reference to a particular one of the clients may be understood to include reference to any or all of the clients coupled to the servers unless otherwise indicated.

Referring to a diagram shows the client being coupled to the servers and one or more other network s e.g. a LAN in a configuration that is different from that shown in . In the configuration of a router is coupled between the servers and the client . The router may be any conventional router that may be accessed by the client . In the configuration of the client uses only a single connection point to both the servers and to the other network s . In the configuration of the client may act as local file server and gateway between the servers and one or more other devices not shown coupled to the other network s .

Referring to the client as shown as being used to interconnect two server groups Group X and Group Y. The connections to Group X and or Group Y may or may not include a router such as the router shown in and may or may not be direct or through other network configurations as described elsewhere herein. In the embodiment of the client may communicate with either the Group X servers and or the Group Y servers but communication from the Group X servers to the Group Y servers is through the client . One of Group X or Group Y may be a local cloud while the other is a foreign cloud.

Referring to the client as shown as being connected to two server groups Group X and Group Y. The connections to Group X and or Group Y may or may not include a router such as the router shown in and may or may not be direct or through other network configurations as described elsewhere herein. In the embodiment of the client may communicate with the Group X servers and or the Group Y servers. However unlike the embodiment of the Group X servers may communication with the Group Y servers without having to go through the client . Just as with one of Group X or Group Y may be a local cloud while the other is a foreign cloud.

Of course any other appropriate connection configurations may be used by any of the client coupled to the servers the groups and or to any other network s and or devices. In some embodiments the clients may access the metadata provided on one of the groups and then may use the metadata to access data stored on another one of the groups . It is also possible for one of the groups to access data from another one of the groups by routing data requests through one of the clients . In such a case the requests data may pass through the client without any interpretation by the client.

Referring to the client is shown in more detail having server operations software client software and an interface layer that includes a plurality of interfaces between the server operations software and the client software . The server operations software facilitates the exchange of information data between the client and the servers to provide the functionality described herein. In some cases the server operations software may contain proxy servers proxy services for accessing external clouds. The server operations software is described in more detail elsewhere herein.

The client software represents any software that may be run on the client including application software operating system software Web server software etc. that is not part of the server operations software or the interface layer . As described in more detail elsewhere herein it is possible to have the client software interact with the servers through different ones of the interfaces at the same time.

The file services described herein may be implemented by the servers using a set of file objects storage objects where a data that is accessed by the client software includes a metadata file object which points to one or more data file objects that contain the data for the file. Accessing the file would involve first accessing the metadata file object to locate the corresponding data storage objects for the file. Doing this is described in more detail elsewhere herein. Note however that any appropriate storage object mechanism may be used for the system described herein. Also in some embodiments a metadata storage object may be provided on one of the groups of servers local cloud while a corresponding one or more data storage objects are provided on another one of the groups of servers external cloud .

Referring to a file is shown as including a metadata file object and a plurality of data file objects. The metadata file object contains information that points to each of the data file objects . Accessing the file includes first accessing the metadata file object and then using information therein to locate the appropriate one or more of the corresponding data file objects . As discussed elsewhere herein in some cases the metadata file object may be provided on a different one of the groups of servers local cloud than one or more of the corresponding data file objects external cloud .

Referring to the metadata file object is shown in more detail as including an object attributes section and a Layout Storage Object LSO tree section . The object attributes section contains conventional file type attributes such as owner id group id access control list last modification time last access time last change time creation time file size and link count. Many of the attributes are self explanatory. The last modification time corresponds to the last time that the data for the data objects had been modified while the last change time corresponds to when the object metadata had last been changed. The link count indicates the number of other objects that reference a particular file e.g. aliases that point to the same file . In an embodiment herein a file and its related objects are deleted when the link count is decremented to zero.

The LSO tree section includes a data structure that includes one or more maps for mapping the logical space of the file to particular data file objects. The LSO tree section may also indicate any mirrors for the data and whether the mirrors are synchronous or asynchronous. LSO trees and mirrors are described in more detail elsewhere herein.

Referring to a simple LSO tree is shown as including an LSO root node and a single map . The LSO root node is used to identify the LSO tree and includes links to one or more map s used in connection with the file corresponding to the LSO tree . The map maps logical locations within the file to actual data storage location. A process that accesses logical storage space of a file represented by the LSO tree first uses the LSO root node to find the map and then uses the map to translate logical addresses within the file to an actual data storage locations. As discussed in more detail elsewhere herein the map may point to physical storage space in the same one of the server groups that contains the physical storage space for the LSO tree . Alternatively the map may point to objects in storage space in a different one of the server groups than the one of the server groups that contains the physical storage space for the LSO tree .

Referring to an LSO tree is shown as including an LSO root node and a plurality of maps . Each of the maps may represent a different range of logical offsets within the file corresponding to the LSO tree . For example the map may correspond to a first range of logical offsets in the file. The map may map logical locations in the first range to a first actual storage device. The map may correspond to a second range of logical offsets in the file different than the first range which may be mapped to a different actual storage device or may be mapped to the same actual storage device as the map . Similarly the map may correspond to a third range of logical offsets in the file different than the first range and the second range which may be mapped to a different actual storage device or may be mapped to the same actual storage device as the map and or the map . Note that some of the maps may or may not point to physical storage space in the same one of the server groups that contains the physical storage space for the LSO tree while other ones of the maps may or may not point to objects in physical storage space in a different one of the server groups than the one of the server groups that contains the physical storage space for the LSO tree .

Referring to an LSO tree is shown as including an LSO root node and a pair of replication nodes which indicate that the underlying data is to be mirrored replicated and which indicate whether the mirror is synchronous or asynchronous. Synchronous and asynchronous mirrors are discussed in more detail elsewhere herein. The node has a plurality of children maps associated therewith while the node has a plurality of children maps associated therewith. The replication nodes indicate that the data corresponding to the maps is a mirror of data corresponding to the maps . In some embodiments the nodes may be implemented using a single node to indicate replication.

A process accessing a file having the LSO tree would traverse the tree and determine that data is mirrored. As discussed in more detail elsewhere herein depending upon the type of mirroring the process accessing the LSO tree would either write the data to the children of both of the nodes or would provide a message to another process server e.g. the servers that would perform the asynchronous mirroring. Mirroring is discussed in more detail elsewhere herein.

Note that just as with the maps discussed above some of the maps may or may not point to physical storage space in the same one of the server groups that contains the physical storage space for the LSO tree while other ones of the maps may or may not point to objects in physical storage space in a different one of the server groups than the one of the server groups that contains the physical storage space for the LSO tree . Note also however that it may be advantageous in some instances to have the maps for the replication node point to objects on one of the server groups while the maps for the other replication node point to physical objects on another one of the server groups .

In some embodiments it may be beneficial to provide physical storage for all LSO trees on a first one of the server groups e.g. a local cloud while providing physical storage for some or all of the corresponding data on a second different one of the server groups e.g. an external cloud . The first one of the server groups may be a private cloud accessed by a particular organization while the second one of the server groups is a public cloud that is accessed by many organizations such as the Amazon S3 public cloud. Alternatively the first one of the server groups may be a public cloud while the second one of the server groups is a private cloud or both the first and the second one of the server groups could be public clouds or could be private clouds. The LSO trees may be provided on an external cloud. In addition the data may be provided on separate clouds so that a first portion is provided on one cloud and a second or subsequent portion is provided on a second or subsequent cloud where each of the clouds that contain data are separate from each other.

As described herein the federation of a plurality of clouds allows the data to appear to a user client as if the data were provided on a single cloud. Note that since the LSO trees provide meaningful structure to the data then maintaining the LSO trees in a private cloud provides some security even though some or all of the corresponding data may be provided in a public cloud. Note also that the physical storage space required for the LSO trees is expected to be much less than that required for the corresponding data. Accordingly in instances where the LSO trees are provided in a private cloud while the corresponding data is provided in a public cloud the physical storage space that needs to be maintained for the private cloud is much less than it would be otherwise while sensitive metadata may be maintained securely in the private cloud.

Referring to the map described above in connection with is shown as pointing to a physical storage that is provided on a local cloud. The map may represent any of the other ones of the maps described herein and or may represent any appropriate mapping mechanism for accessing physical storage on a local cloud. For example the map may contain an identifier for the physical storage in addition to some type of offset and or additional identifier to indicate a particular portion of the physical storage . There may also be a length or similar value indicating an amount of data that corresponds to the map . As discussed elsewhere herein security for local cloud access may be handled by another mechanism and thus it is not necessary for the map to contain security information although in some embodiments it may be useful to have security information be included with the map .

Referring to the map is shown as pointing to physical storage objects in one or more external clouds. In such a case the map may contain or point to information used to access the objects in the external cloud which of course depends upon the particular access mechanism employed by the external cloud. For example in some systems an account id and a password could be used. There may also be additional information such as file object identifier s subaccount information etc. In an embodiment herein once a connection to data in the external cloud has been established subsequent communications with the external cloud may include at least some of the information e.g. an account id along with a shared secret. Other possible authentication security techniques may be used including RSA ID tokens cryptographic certificates etc.

In an embodiment herein the map as well as any other maps that are used point to a single object provided on the external cloud which corresponds to a single file in the file system of the external cloud . In other embodiments it is possible to provide multiple objects in a single file in the file system of the external cloud . It is even possible to provide objects from different sources e.g. different users accounts private clouds etc. into a single file. However in that case it may be necessary to handle any security issues that are created by this.

Referring to the client is shown using a storage server to access the physical storage containing data from the local cloud as discussed elsewhere herein. The storage server provides data to the client and may represent any combination of software and hardware including at least a portion of the server operations software that is part of the client discussed above . The client may represent any client or other device mechanism that accesses the servers to exchange data therewith. The storage server may provide a specific interface to the client and to software used by the client .

Referring to the client is shown using a proxy server to access the external clouds . The proxy server provides data to the client and may represent any combination of software and hardware including at least a portion of the server operations software that is part of the client discussed above . The proxy server may interact with the client and to software used by the client in a manner that is substantially similar and possibly identical to the interaction between the client and the storage server . The proxy server may exchange information with the external cloud using a protocol based on principles of REST Representational State Transfer protocol which are known. The proxy server may be integrated with one or more other ones of the servers .

In some embodiments it may be possible to have data provided in a local cloud and for that data to point to additional data in an external cloud.

In an embodiment herein the map includes a flag or similar to indicate whether the data pointed to by the map is provided on a local cloud or an external cloud. In instances where the data is provided on a local cloud the storage server or similar is used. In instances where the flag indicates that the data is provided in an external cloud the proxy server is used. Once one of the servers is selected operation of the client and related components is identical or nearly so. Accordingly the system provided herein may provide a federation of clouds that is transparent to a client accessing the servers .

Referring to a flow chart illustrates in detail steps performed in connection with obtaining data from a physical storage location indicated by the map . Processing begins at a first step where it is determined if the data is part of a local cloud or stored in an external cloud as discussed elsewhere herein. If the data is not external then control transfers from the test step to a step where the storage server is used to access the data according to the information provided in the map . Following the step processing is complete.

If it is determined at the test step that the data is located in an external cloud then control transfers from the step to a step where an element used to iterate through the available proxy servers is set to point to the first one of the proxy servers. In an embodiment herein each of the proxy servers may be provided with different capabilities so that for example one set of proxy servers can access external cloud X but not external cloud Y another set of proxy servers can access external cloud Y but not external cloud X yet another set can access both external clouds etc. Furthermore different proxy servers may have different capabilities such as speed efficiency cost etc. that could make one proxy server more desirable than another in certain situations. Accordingly there may be certain criteria imposed that render only some of the proxy servers suitable for accessing the external data. For example is the external data is located on cloud X then only proxy servers capable of accessing cloud X are suitable and satisfy the criteria. Note also that it is possible for a user administrator to indicate that certain proxy servers are suitable acceptable for certain types of accesses.

Following the step is a test step where it is determined if the proxy server pointed to by the element used to iterate through proxy servers satisfies whatever criteria that is imposed. If so then control passes from the test step to a test step where the proxy server is used to access the data. As discussed elsewhere herein the proxy server may provide an account id and password and or an account id and shared secret in connection with accessing the data. In an embodiment herein the external cloud does not rely on any security characteristics imposed by the cloud client from which the request is generated. Thus for example an administrative user for one cloud may still need to provide the same security information as any other user when accessing an external cloud. Note also that the security information needed to access the external cloud may be stored with the map pointed to by the map or stored in some other location. Following the step processing is complete.

If it is determined at the test step that the proxy server indicated by the iteration pointer does not satisfy the criteria then control transfers from the test step to a step where the iteration pointer is incremented to point to the next proxy server. Following the step is a test step where it is determined if the pointer points past the end of the proxy servers i.e. all of the available proxy servers have been examined to determine if any of them meet the specified criteria . If all of the proxy servers have not been examined then control passes from the test step back to the step for another iteration. Otherwise control passes from the step to a step where error processing is performed. The error processing performed at the step can be any appropriate processing including returning an indicator that the data is not available. Note that there could be many reason why the data is not available including the criteria being too restrictive e.g. requiring a transfer speed that is not available one or more of the proxy servers being off line etc. Following the step processing is complete.

For the system described herein file objects are accessed by one of the clients by first requesting and obtaining a lease from the servers . The lease corresponds to the file objects for the particular file being accessed and to the type of access. A lease may be for reading writing and or for some other operation e.g. changing file attributes . In an embodiment herein for objects corresponding to any particular file the servers may issue only one write lease at a time to any of the clients but may issue multiple read leases simultaneously and may issue read lease s at the same time as issuing a write lease. However in some embodiments it may be possible to obtain a lease for a specified logical range of a file for operations only on that range. Thus for example it may be possible for a first client to obtain lease for writing to a first logical range of a file while a second client may independently obtain a lease for writing to a second and separate logical range of the same file. The two write leases for different logical ranges may overlap in time without violating the general rule that the system never issues overlapping write leases for the same data.

The lease provided to the clients from the servers includes security information security token that allows the client appropriate access to the data. The security token may expire after a certain amount of time. In an embodiment herein a client accesses data by providing an appropriate security token for the data as well as client users ownership information. Thus for example a user wishing to access data would first obtain a lease and then would provide the access request to the servers along with the security token and information identifying the owner client accessing the data. The servers would then determine whether the access requested by the client was permissible. After the lease expires the security token expires the user requests the lease again. Data security may be implemented using conventional data security mechanisms.

After obtaining a lease for accessing a file a client may then cache the corresponding metadata including the LSO tree into local storage of the client. The client may then use and manipulate the local cached version of the metadata and may use the metadata to obtain access to the data. As described in more detail elsewhere herein a client does not directly modify metadata stored by the servers but instead sends update messages to the servers to signal that metadata for a file may need to be modified by the servers .

Referring to a flowchart illustrates steps performed by a client in connection with requesting a lease for a file objects associated with a file for performing operations thereon. Processing begins at a first step where the client requests the lease for the file. As discussed in more detail elsewhere herein a client requesting a lease includes specifying the type of access e.g. read write etc. . Following the step is a test step where it is determined if the request has been granted. If not then control transfers from the test step to a step where processing is performed in connection with the lease not being granted to the client. The particular processing performed at the step may include for example providing an error message to the client process requesting access to the file corresponding to the lease and or waiting for an amount of time and then retrying the request. Note that it is possible that a lease for a particular file is not available at one time is subsequently available at another time because for example the lease is released by another client in between the first request and the second request. In any event any appropriate processing may be performed at the step . Following the step processing is complete.

If it is determined at the test step that the lease requested at the step has been granted then control transfers from the test step to a step where the client performs an operation using the file for which the lease was granted. Operations performed at the step include reading data and or writing data. Different types of processing that may be performed at the step are described in more detail elsewhere herein.

Following the step is a test step where it is determined if the operations performed at the step require an update. In some instances a client may obtain a lease and perform operations that do not affect the file or the underlying file objects. For example a client may acquire a lease for reading a file and the operation performed at the step may include the client reading the file. In such a case no update may be necessary since the file and corresponding file objects metadata data objects etc. have not changed. On the other hand if the client obtains a lease for writing data the file and the operation performed at the step includes writing data to the file then the underlying file objects will have been changed and an update message needs to be sent the servers . If it is determined at the test step that an update is necessary then control passes from the test step to a step where an update message is sent by the client to the servers .

Following the step or following the step if no update is necessary control passes to a test step where it is determined if the client is finished with the file. In some instances the client may perform a small number of operations on the file after which the client would be finished with the file at the step . In other cases the client may be performing a series of operations and may not yet have completed all of the operations.

If it is determined at the test step that the client is not finished with the file then control passes from the test step to a test step where it is determined if the lease for the file has expired. Note that a lease may be provided by the servers to the client with a particular expiration time and or the associated security token may expire. In addition it may be possible for the servers to recall leases provided to clients under certain circumstances. In either case the lease may no longer be valid. Accordingly if it is determined at the step that the lease has expired and or has been recalled by the servers then control passes from the test step back to the step request the lease again. Otherwise if the lease has not expired then control passes from the test step back to the step to perform another iteration.

If it is determined at the test step that the client is finished with the file then control passes from the test step to a step where the client releases the lease by sending a message to the servers indicating that the client no longer needs the lease. Once the client releases the lease it may be available for other clients. Following the step processing is complete.

In an embodiment herein data file objects may be indicated as having one of four possible states current stale immutable or empty. The current state indicates that the data object is up to date and current. The stale state indicates that the data is not valid but instead requires updating perhaps by some other process. In some instances the stale state may be used only in connection with mirror copies of data explained in more detail elsewhere herein . Data may be stale because it is a mirror of other data that was recently written but not yet copied. The immutable state indicates that the corresponding data is write protected perhaps in connection with a previous clone snapshot operation. The empty state indicates that no actual storage space has yet been allocated for the data.

Referring to a flow chart illustrates steps performed by a client in connection with performing read operations after obtaining a read lease for a file. Processing begins at a first test step where it is determined if the data object being read is in the current state. If not then control transfers from the test step to a step where it is determined if the data object being read is in the immutable state. If it is determined at the step that the data object being read is in the immutable state or if it is determined at the test step that the data object being read is in the current state then control transfers to a step where the read operation is performed.

A client may read file data by providing the appropriate data file object identifier to the servers as well as providing appropriate security credentials. Accordingly the read operation performed at the step includes the client sending an appropriate request to the servers and waiting for a result therefrom. Alternatively if the file data is stored in a different one of the groups than the processor performing the processing illustrated by the flow chart then performing a read operation at the step may include providing a client ID account info and credentials to the different one of the groups .

Following the step is a test step where it is determined if the servers have returned a result indicating that the data file object is unavailable. In some cases a data file object that is otherwise current or immutable may nevertheless become unavailable. For example the physical storage space that holds the data file object may become temporarily disconnected and or temporarily busy doing some other operation or if a data file object may be stored on a different one of the groups that is unavailable. If it is determined at the test step that the data file object is available then control transfers from the test step to a test step where it is determined if the read operation was successful. If so then control transfers from the test step to a step where the result of the read operation is returned to the process at the client that caused the read operation to be performed. The result may include the data that was read and a status indicator. Following the step processing is complete.

If it is determined at the test step that the read operation performed at the step was not successful then control transfers from the test step to a step where error processing is performed. The particular error processing performed at the step is implementation dependent and may include for example reporting the error to a calling process and or possibly retrying the read operation a specified number of times. Following the step processing is complete.

If it is determined at the test step that the data object being read is not in the immutable state then control transfers from the test step to a test step where it is determined if the data object is in the stale state. If not then by virtue of the test steps and process of elimination the data object is in the empty state. In an embodiment herein reading a data object in the empty state causes zeros to be returned to the calling process. Accordingly if it is determined at the test step that the data object is not in the stale state then control transfers from the test step to a step where zeros are returned in response to the read operation. Following the step processing is complete.

If it is determined at the test step that the data file object is in the stale state or if it is determined at the test step that the data file object is not available then control transfers to a test step to determine if an alternative version of the data file object is available for reading. As discussed in more detail elsewhere herein there may be multiple versions of the same data file objects that exist at the same time due to mirroring. Accordingly if the data file object being read is in the stale state or otherwise unavailable it may be possible to read a mirror copy of the data file object that may be in the current state. The test performed at the step is described in more detail elsewhere herein.

If it is determined at the test step that an alternative version of the data file object is available then control transfers from the test step to a step where the alternative version of the data file object is selected for use. Following the step control transfers back to the test step for another iteration with the alternative data file object.

If it is determined at the test step that an alternative version of the data file object is not available then control transfers from the test step to a step where the client process waits. In an embodiment herein it may be desirable to wait for a data file object to become current and or available. Following the step control transfers back to the step for another iteration. Note that instead of waiting at the step processing may proceed from the step to the step to perform error processing if there is no alternative data file object available. In other embodiments it may be possible to perform the step a certain number of times and then if the data file object is still unavailable or in the stale state and there is no alternative data file object then perform the error processing at the step .

Referring to a flow chart illustrates steps performed by a client in connection with performing write operations after obtaining a write lease for a file. Processing begins at a first test step where it is determined if the data file object to which the write is being performed is in the immutable state. If so then control transfers from the step to a step where new actual storage space is allocated for the data file object to avoid overwriting the immutable data. Allocating new storage space for a data object may include providing an appropriate request to the servers . In instances where the file data is stored in a different one of the groups than the processor performing the processing illustrated by the flow chart then allocating new storage space at the step may include providing a client ID account info and credentials to the different one of the groups . Following the step control transfers back to the step to begin the processing for the write operation again.

If it is determined at the step that the data file object to which the write is being performed is not in the immutable state then control transfers from the step to a step where it is determined if the data file object to which the write is being performed is in the stale state. If not then control transfers from the test step to a test step where it is determined if the data file object to which the write is being performed is in the empty state. If so then control transfers from the step to the step discussed above where new physical storage space is allocated. Following the step control transfers back to the step to begin the processing for the write operation again.

If it is determined at the step that the data file object to which the write is being performed is not in the empty state then control transfers from the test step to a step where the write operation is performed. Note that the step is reached if the data file object to which the write operation is being performed is not in the immutable state not in the stale state and not in the empty state and thus is in the current state . A client writes file data by providing the appropriate data file object location identifier to the servers as well as providing appropriate security credentials. Accordingly the write operation performed at the step includes the client sending an appropriate request to the servers and waiting for a result therefrom. As with the read operation discussed above if the file data is stored in a different one of the groups than the processor performing the processing illustrated by the flow chart then performing a write operation at the step may include providing a client ID account info and credentials to the different one of the groups . Note also that the write operation at the step may also include marking any corresponding mirror data objects as stale in anticipation of subsequent mirror update processing discussed elsewhere herein.

Following the step is a test step where it is determined if the write operation performed at the step was successful. If so then control transfers from the test step to a test step where it is determined if there are synchronous mirrors of the data file object to which the write is being performed. The test performed at the step may include for example determining if a parent node of the data file object in the file LSO tree indicates replication. If not then control transfers from the test step to a step where an update message is sent to the servers indicating that the write had been performed. Following the step processing is complete.

If it is determined at the test step that there are synchronous mirrors of the data file object to which the write is being performed then control passes from the test step to a step where the data that was written at the step is also written to the synchronous mirror s . The processing performed at the step is discussed in more detail elsewhere herein. Following the step control transfers to the step discussed above where an update message is sent to the servers . Following the step processing is complete.

If it is determined at the test step that the write operation performed at the step was not successful or if it is determined at the test step that the data file object to which the write operation is being performed is in the stale state then control transfers to a step where the data file object to which the write is attempting to be performed is removed from the client s local copy of the LSO tree. At the end of the write operation illustrated by the flow chart the client may inform the servers at the step of the difficulty in writing to the data object so that the servers can take appropriate action if necessary.

Following the step is a test step where it is determined if an alternative version of the data is available. As discussed in more detail elsewhere herein there may be multiple versions of the same data file objects that exist at the same time due to mirroring. Accordingly if the data file object to which the write operation is being performed is stale or otherwise cannot be written to it may be possible to write to a mirror copy of the data. The test performed at the step is like the test performed at the step and is described in more detail elsewhere herein. If it is determined at the test step that an alternative version of the data corresponding to the data file object is available then control transfers from the test step to a step where the alternative version is selected for writing. Following the step control transfers back to the test step for another iteration with the alternative data file object.

If it is determined at the test step that an alternative version of the data corresponding to the data file object is not available then control transfers from the test step to a step to perform error processing if there is no alternative available. The particular error processing performed at the step is implementation dependent and may include for example reporting the error to a calling process and or possibly retrying the write operation a specified number of times before reporting the error. Following the step control transfers to the step discussed above to send update information to the servers . Following the step processing is complete.

Referring to a flow chart illustrates in more detail steps performed in connection with the alternative available test step of and or the alternative available test step of . Processing begins at a first test step where it is determined if the file has any mirror data file objects at all. In some instances a file may not use mirrors in which case there would be no alternative copy available. Accordingly if it is determined at the test step that the file does not have any mirror data file objects then control transfers from the test step to a step where a value is returned indicating that no alternative copies are available. Following the step processing is complete.

If it is determined at the test step that mirror copies are available then control transfers from the test step to a step where a pointer is made to point to metadata for a first mirror data file object. For the processing discussed herein a pointer may be used to iterate through metadata for mirror data file objects to find a useable data file object. Following the step is a test step where it is determined if the pointer is past the end of the list of mirror data file objects has iterated through all of the metadata for mirror data file objects . If so then control passes from the test step to the step discussed above to return a value that indicates that no alternatives are available.

If it is determined at the test step that the pointer is not past the end of a list of mirror data file objects then control transfers from the test step to a test step where it is determined if the pointer points to metadata indicating that the corresponding data file object in a stale state. If so then control transfers from the test step to a step where the pointer is made to point to metadata for the next data file object to be examined. Following the step control transfers back to the step discussed above for another iteration. If it is determined at the test step that the pointer does not point to metadata indicating that the corresponding data file object in the stale state then control transfers from the test step to a step where the metadata indicating the data file object that is pointed to by the pointer is returned as an alternative data file object that may be used by the calling process. Following the step processing is complete.

Referring to a flow chart illustrates in more detail operations performed in connection with the step of the flow chart of where data that has been written is copied to a number of synchronous mirrors mirror data file objects . Processing begins at a first step where a pointer that is used to iterate through metadata for the mirror data file objects is set to point to metadata for the first one of the mirror data file objects. Following the step is a test step where it is determined if the pointer used for iterating through the metadata for the mirror data file objects points past the end i.e. if all of the mirror data file objects have been processed . If so then processing is complete. Otherwise control transfers from the test step to a test step where it is determined if the status indicated by metadata for the corresponding mirror data file object pointed to by the pointer indicates that the mirror data file object is current. If not then control passes from the test step to a test step where it is determined if the status indicated by the metadata for the mirror data file object pointed to by the pointer indicates that the mirror data file object is in the stale state. Note that if a mirror data file object is neither in the stale state nor in the current state then the mirror data file object is either in the empty state or in the immutable state. In either case it may be necessary to allocate new space for a data file object to which the data is to be written. Accordingly if it is determined at the test step that metadata indicates that the corresponding data file object is not in the stale state then control passes from the test step to a step where new space is allocated for the mirror data file object similar to the step of discussed above . Following the step is a step where the data that is being copied across synchronous mirror data file objects is written to the mirror data file object pointed to by the pointer used to iterate through the metadata for the mirror data file objects similar to the step of discussed above . Note that the step may also be reached from the test step if it is determined that the mirror data file object is stale. Following the step is a step where the pointer used to iterate through metadata for the mirror data file objects is made to point to the next one. Note that the step may also be reached from the test step if it is determined that the mirror data file object is current. Following the step control transfers back to the test step for another iteration.

The system described herein may access file objects using object identifiers. In an embodiment herein each file object that is stored among the servers including file objects from both local and external clouds may be assigned a unique object identifier that identifies each file object and distinguishes each file object from other file objects in the system. However many applications use a file naming structure and or a hierarchical directory to access files and data therein. For example a file name C ABC DEF GHI.doc indicates a file called GHI.doc stored in a sub directory DEF that is stored in another directory ABC located on a root volume C . A nested directory structure may be provided by implementing directories as special files that are stored in other directories. In the example given above the sub directory DEF may be implemented as a file stored in the directory ABC .

The system described herein may present to applications a conventional naming structure and directory hierarchy by translating conventional file names into file object identifiers. Such a translation service may be used by other services in connection with file operations. In an embodiment herein each directory may include a table that correlates file names and sub directory names with file object identifiers. The system may examine one directory at a time and traverse sub directories until a target file is reached.

Referring to a flow chart illustrates steps performed in connection with providing a file name translation service file name service that translates a conventional hierarchical file name into a file object identifier. The file name service may receive a conventional hierarchical file name as an input and may return an object identifier or in some cases an error . Processing begins at a first step where the file name service receives a file name such as a conventional hierarchical file name. Following the step is a test step where it is determined if the syntax of the file name is OK. Mechanisms for checking the syntax of a hierarchical file name are known in the art and include for example checking that only appropriate characters have been used. If it is determined at the test step that the syntax is not OK then control transfers from the test step to a step where an error indicator error message is returned to the calling process. Following the step processing is complete.

If it is determined at the test step that the syntax of the provided name is OK then control transfers from the test step to a step where the root directory is read. In an embodiment herein all file name paths begin at a single common root directory used for all file objects stored in the servers . In other embodiments there may be multiple root directories where specification of a particular root directory may be provided by any appropriate means such as using a volume identifier specifically selecting a particular root directory etc.

Following the step is a test step where it is determined if the target file or sub directory that is part of the file name path is in the directory that has been read. If not then control passes from the test step to the step discussed above where an error is returned. In some embodiments the file not found error that results from the test at the step may be different from the syntax error that results from the test at the step .

If it is determined that the target file or a sub directory that is part of the file name path is in the directory that has just been read then control passes from the test step to a test step where it is determined if the directory that has just been read contains the target file as opposed to containing a sub directory that is part of the file name path . If so then control passes from the test step to a step where the object identifier of the target file object is returned to the calling process. Following the step processing is complete.

If it is determined at the test step that the directory that has just been read contains a sub directory that is part of the file name path then control transfers from the test step to a step where the sub directory is read so that the sub directory becomes the directory being examined. In effect processing at the step traverses the chain of subdirectories to eventually get to the target file. Following the step control transfers back to the step discussed above for a next iteration.

Referring to a diagram shows the client as including user address memory space and kernel address memory space. In an embodiment herein user address memory space is memory space that is generally used by user applications and related processes while kernel address memory space is memory space that is generally accessible only by system processes such as an operating system kernel and related processes. As discussed in more detail herein it is possible to have different portions of the system described herein reside and operate in the user memory space and or the kernel memory space. In addition it is possible for the client to have multiple different interfaces to access file objects at the servers .

In the client is shown as including an application in the user memory address space and a virtual file system VFS file name services kernel I O drivers a layout manager and a communication interface in the kernel memory address space. The VFS is an abstraction layer on top of a more concrete file system. The purpose of a VFS is to allow client applications to access different types of concrete file systems in a uniform way. The VFS allows the application running on the client to access file objects on the servers without the application needing to understand the details of the underlying file system. The VFS may be implemented in a conventional fashion by translating file system calls by the application into file object manipulations and vice versa. For example the VFS may translate file system calls such as open read write close etc. into file object calls such as create object delete object etc.

The VFS may use the file name services described elsewhere herein to translate file names into object identifiers. The kernel I O drivers provide an interface to low level object level I O operations. The kernel I O drivers may be modeled after and be similar to Linux I O drivers. The layout manager may perform some of the processing on LSO trees corresponding to files as discussed in more detail elsewhere herein. The communication interface provides communication between the client and the servers .

The communication interface may be implemented using any appropriate communication mechanism. For example if the client communicates with the servers via an Internet connection then the communication interface may use TCP IP to facilitate communication between the servers and the client . In instances where objects from one of the groups may be accessed by a client from another one of the groups the communication interface may include an appropriate mechanism to formulate data accesses to a different group. For example the communication interface may include a mechanism for providing a client ID account info and credentials to the different one of the groups .

The application of may correspond to the client software of . The VFS of may correspond to one of the interfaces of . The file name services kernel I O drivers layout manager and communication interface of may correspond to the server operations software of . Similar correlation between components of and other figures may also be found.

Referring to a flow chart illustrates steps performed by a VFS to provide file services in connection with an application running on the client . Processing begins at a first step where a file system operation requested by an application may be translated into one or more object operations. For example a file operation to open a file for reading may be converted to object operations that include obtaining an object lease for reading as discussed elsewhere herein. Following the step is a step where the VFS translates the file name into an object identifiers using the file name services discussed above in connection with . Operations that follow may be performed using the object identifiers obtained at the step .

Following the step is a test step where it is determined if the requested operation requires the LSO tree. As discussed elsewhere herein operations such as read write etc. use LSO trees corresponding to file objects. However some possible file operations may not require accessing a corresponding LSO tree. If it is determined at the test step that the LSO tree is needed then control transfers from the test step to a step where the VFS accesses the LSO manager to perform the necessary operations. For example for a read operation the LSO manager may perform processing like that illustrated in the flow chart of . Following the step or following the step if the LSO is not needed is a step where the operations are passed to low level kernel I O drivers e.g. via one or more appropriate API s . The kernel I O drivers use the communication module to communicate between the client and the servers in connection with performing the requested operation s . In instances where the application running on the client has requested data and or other information from the servers in the same or a different one of the groups the data and or information may be passed back up through the communication interface kernel I O drivers etc. to the VFS and ultimately to the application. As discussed elsewhere herein the communication module may use and or include one or more storage servers and or one or more proxy servers.

Referring to the client is shown as having an application file name services user level I O drivers and a layout manager all provided in user memory address space. The functionality of the VFS that was shown in and described above may be performed instead by library routines linked to the application and thus are part of the application. These routines would provide functionality like that discussed above in connection with . Accordingly it is the application that uses the file name services and makes calls to the user level I O drivers like the kernel I O drivers and to the layout manager. The communication interface is still maintained in the kernel memory address space.

Note that for the configuration of modifications are provided by modifying system processes the operating system which is disadvantageous for a number of reasons. For example if the client is a multiuser computing system then modifying the operating system may involve restarting the entire system and thus disrupting all of the users. In contrast the configuration of is advantageous since it allows modification of the system in the application user memory address space so that the operating system of the client does not need to be modified. However the configuration of does not use a VFS and thus does not obtain the advantageous separation of the application from the file system that is provided by the VFS in .

Referring to the client is shown as having an application in user memory address space that accesses file objects through a VFS in kernel memory address space like that illustrated in . However the file name services I O drivers and the layout manager all reside in the user memory address space like the system illustrated in . The VFS communicates with components in the user memory address space through a bridge between kernel memory address space and user memory address space such as a FUSE or similar interface. The bridge allows file system components to be provided in user memory space instead of kernel address memory space while still preserving the VFS in the kernel address memory space. Thus the configuration illustrated by provides the advantages of using a VFS as illustrated in the configuration of along with the advantages of having file system components in the user address memory space as illustrated in the configuration of .

It is possible in some instances to have applications and or other processing in the user memory address space of the client access file objects directly rather than through a file services layer like the VFS and or equivalent functionality provided by user linkable libraries e.g. the configuration illustrated in . Accessing file objects directly may include invoking routines that create objects read objects modify objects delete objects etc. Accessing file objects may also include if the objects are stored in a different one of the groups providing a client ID account info and credentials to the different one of the groups . If an application and or other process in the user memory address space of the client accesses file objects directly the application would need to know how to interpret and or manipulate the object data which may not always be desirable. For example an application that accesses file objects through the VFS may not need to take into account or even know about the structure of an LSO tree while an application that accesses objects directly may need to use the LSO tree. On the other hand removing the file services layer may provide an opportunity for optimizations not otherwise available. Note that since the servers exchange object information operations with the clients the servers may not need to distinguish or be able to distinguish between application on the clients using a file system interface file services like the VFS and those that are not.

Referring to the client is shown as including an application in the user memory address space and kernel I O drivers a layout manager and file name services in the kernel memory address space. The configuration illustrated in is like that illustrated in except that the VFS is not used. In the configuration illustrated in the application could directly access the file name services the kernel I O drivers and the layout manager. The communication interface in the kernel memory address space communicates with the servers just as in other configurations. The direct access illustrated in allows applications to manipulate file objects via for example appropriate API s while access via the VFS or similar allows applications to accesses file objects indirectly through file system calls to the VFS.

Referring to the client is shown as having an application user level I O drivers a layout manager and file name services all provided in user memory address space. The configuration shown in is like that shown in . However as set forth above the configuration of includes file service libraries that are linked into and thus part of the application. In contrast in the configuration of FIG. the application is not linked into libraries with extensive file services. Instead like the application of the configuration illustrated in the application in the configuration of uses minimal file services and instead uses and operates upon file objects directly using the user level I O drivers the layout manager and if a file name translation is needed the file name services.

Referring to the client is shown as having an application in user memory address space and a bridge in the kernel memory address space. File name services user level I O drivers and a layout manager are provided in user memory address space. However unlike the configuration of the application does not make direct calls to the file system components in the user memory address space. Instead the application calls the file system components indirectly through the bridge. Just as with the configuration illustrated in the configuration of advantageously locates file system components in the user memory address space and at the same time provides a kernel memory address space layer between the application and the file system components.

Referring to the client is shown as having an application in user memory address space and a Web Services module in kernel memory address space. The application may be a Web server application or any application that handles communication with the Web. In an embodiment herein the application allows communication with the client which acts as a Web server to other computing devices not shown that access the client through a Web connection.

The configuration illustrated in provides Web Services in a manner similar to the file services and or file object access provided by other configurations. However the Web Services receives requests data via a Web data protocol such as HTTP and provides responses data also in a Web data protocol which may be the same or different from the protocol used for requests data. Operations handled by the Web Services may include object level operations such as create object delete object read object modify object modify object metadata etc. It is also possible to provide more file system level operations via the Web Services that open files read data from files etc. by including at least some of the functionality of the file services described elsewhere herein with the Web Services. The Web Services may present to the other computing devices a conventional well known Web Services protocol such as REST or SOAP or may provide any other appropriate protocol.

Referring to the client is shown as having an application Web Services user level I O drivers and a layout manager in user memory address space. The application may include a Web connection that allows communication with the client which acts as a Web server to other computing devices not shown that access the client through the Web connection. The configuration of is like that of and . The advantages of the configuration shown in over the configuration shown in is that generally changes to the configuration shown in do not require reconfiguring kernel memory address space processes.

Referring to the is shown as having an application Web Services user level I O drivers and a layout manager in user memory address space. The application may include a Web connection that allows communication with the client which acts as a Web server to other computing devices not shown that access the client through the Web connection. A bridge is provided in the kernel memory address space. The configuration of has similar advantages to the configuration shown in but also has the advantages provided by providing the bridge discussed elsewhere herein.

Referring to the client is shown as having a plurality of applications in user memory address space each of which may use a different interface to access file objects of the servers . Each of the applications shown in is meant to represent one or more applications. Accordingly APP1 may present one or more applications that access file objects at the servers using a Web Services interface. The APP1 application may include a Web connection that allows communication with the client which acts as a Web server to other computing devices not shown that access the client through the Web connection. APP2 may represent one or more applications that access file objects at the servers using the VFS and APP3 may represent one or more applications that directly operate on file objects at the servers . The different interfaces may operate at the client at the same time.

Note that may other combinations of configurations including illustrated configurations are possible so that the client may simultaneously present to applications thereon different interfaces. For example it is possible to combine the configurations illustrated in and or combine the configurations of . Other combinations including combinations of only two illustrated configurations are also possible. The servers provide the file objects to the clients provided 1 the requesting client has appropriate authorization for whatever operation is requested for the file objects and 2 there is no conflict with any previous request. For example in systems where only one client is allowed to write to an object at any one time the servers would not allow one of the clients to modify a particular object while another one of the clients is also modifying the object.

Referring to the servers are shown in more detail as including one or more policy manager servers one or more security manager servers one or more audit servers one or more metadata servers one or more resource manager servers one or more data storage servers and one or more metadata location servers . Each of the servers may be implemented as one or more unitary processing devices capable of providing the functionality described herein. For the discussion herein reference to servers should be understood as a reference to one or more servers. The servers may be interconnected using any appropriate data communication mechanism such as TCP IP and may be coupled to the clients not shown in using any appropriate data communication mechanism such as TCP IP. As discussed elsewhere herein the servers may be provided by different server groups having varying degrees of independence from each other.

The servers may include a user management interface that facilitates system management. The user management interface exchanges data with the policy management servers the security management servers and the audit servers to affect how the servers interact with the clients and corresponding users. The data may be provided through the user management interface in any one of a number of ways including conventional interactive computer screen input and data file input e.g. a text file having user management commands . The data may include information that correlates classes of users and storage parameters such as Quality of Service QOS RAID protection level number and geographic location s of mirrors etc. For example an administrator may specify through the user management interface that users of a particular class users belonging to a particular group store data file objects on storage devices having a particular RAID level protection.

The servers also include physical storage coupled to the data storage servers . Although the physical storage is shown as a single item in there may be any number of separate physical storage units that may be geographically dispersed and distributed among different groups of servers. In addition there may be different types of physical storage units having different capabilities. Accordingly the physical storage generically represents one or more instances of physical data storage for the system that is managed by the data storage servers or possibly multiple data storage servers as explained in more detail below.

Data modifications including modifications of metadata file objects and or policies that affect handling creation of metadata file objects require appropriate security credentials. Accordingly the security manager servers may restrict inhibit the ability of certain administrators users to modify and or create policies for classes of users.

Referring to a flow chart illustrates steps performed by the user management interface to obtain and use security credentials for accessing the policy manager servers . Processing begins at a first step where the user management interface sends a request to the security manager servers to obtain a token or other appropriate security credentials for the operation to be performed by the user management interface . Following the step is a test step where it is determined if the token has been granted provided . In some instances the security manager servers may not issue a security token at all. For example if the administrator user does not have sufficient rights to perform the desired function.

If the security token is not granted then control passes from the step to a step where processing is performed in connection with the security token not being granted. The operations performed at the step may including providing a message to the administrator user through the security management interface indicating that the administrator does not have sufficient rights to perform the desired operation. Following the step processing is complete.

If it is determined at the test step that a security token has been granted provided by the security manager servers then control passes from the test step to a step where the user management interface provides the security token and user id information to the policy manager servers . Of course information indicating the desired operation modification may also be provided at the step . Following the step is a test step where it is determined if the policy manager servers have allowed the requested operation. Note that in some instances the policy manager servers may not allow a particular operation even though the security manager servers have provided a security token. For example if the user id and the user indicated by the security token do not match and or if the requested operation and the operation indicated by the security token do not match.

If it is determined at the test step that the requested operation is not allowed then control passes from the test step to the step described above where processing is performed to indicate that there are security issues. The processing performed at the step may include providing a message to an administrator user indicating that the operation cannot be performed because of insufficient security rights. The message provided when the step is reached from the step may be different than the message provided when the step is reached from the step .

If it is determined at the test step that the requested operation is allowed then control passes from the test step to a step where the operation is performed. Performing the operation at the step may include modifying policy data as described in more detail elsewhere herein. Following the step processing is complete.

Thus an administrator user accessing the policy manager servers would first provide identification information to the security manager servers that would return a security token perhaps having an expiration time . The administrator presents the token and identification information to the policy manager servers which would decide to grant or deny access based on the token and the identification information. Note that the security mechanism illustrated by the flow chart of may be extended to be used in connection with accessing any of the servers and or other data. For example one of the clients could obtain modify file objects by first requesting a security token from the security manager servers prior to performing an operation that includes operations with file objects. Accordingly for the discussion herein it can be assumed that access to file objects servers etc. includes appropriate security procedures like those illustrated in .

The policy manager servers handle placement and protection of file objects. An administrator and or user may input through the user management interface different policy templates that may be applied to different ones of the clients different users different classes of users different object sets or any other appropriate group. For example a policy template may indicate that for a particular group of users whenever a new file is created a mirror will be created that is geographically farther from the initial data set by at least a certain distance. In such a case when a first user of the group creates an initial data set in New York a mirror may be automatically created in Los Angeles while when a second user creates an initial data set in Los Angeles a mirror may be created in New York. The policy manager servers may provide other functionality as described in more detail elsewhere herein.

The audit servers may be used to provide system auditing capability. A user may communicate to the audit servers through the user management interface . The user may indicate the type of information to be audited tracked .

The resource manager servers keep track of available system resources. In some instances the resource manager servers may interact with the policy manager servers in connection with establishing policy templates and or assigning policy templates. In some cases a user may attempt to construct a policy template that is impossible to fulfill if assigned to a group. For example if all of the physical data storage is in a single geographic location then it would not be appropriate to have a policy template indicating that new files should include a mirror that is geographically distant from the initial data set.

The resource manager servers receive information from other components of the system in order to be able to keep track which resources are available. Whenever a resource is added to the system the resource or another component reports that information to the resource manager servers . For example if new physical storage is added to the system the new physical storage itself or a corresponding one of the data storage servers sends a message to the resource manager servers . Similarly if a resource becomes full e.g. a physical disk is full or is removed from the system planned removal or unplanned resource failure information is provided to the resource manager servers . In an embodiment herein system resources may correspond to portions of the physical storage and or data servers that manage the physical storage .

Referring to a resource table is shown as including a plurality of entries each of which corresponds to a particular storage resource. Although only three entries are shown the table may contain any number of entries. The table may be implemented using any appropriate technique including an array linked list etc.

Each of the entries includes a resource field identifying a particular resource corresponding to the entry. In an embodiment herein each of the entries may correspond to a particular one of the data storage servers and or a portion thereof. Each of the entries includes a status field corresponding to the status of the corresponding resource. In an embodiment herein the status field may indicate that a resource is on line available or off line unavailable . The status field may also indicate the percentage of used space of a resource and perhaps indicate any performance degradation.

Each of the entries may also include a capabilities field that indicates the capabilities of the corresponding resource. In an embodiment herein when the resources represent storage areas the capabilities field may indicate particular capabilities of a corresponding storage area. Particular capabilities may include the resource being green low energy use through for example spinning disks down when not in use capable of data deduplication maintaining only a single copy of data that is otherwise duplicated capable of various RAID configurations etc. The capabilities field may indicate any appropriate data storage capabilities.

Referring to a flow chart indicates operation of the resource manager servers in connection with maintaining information about system resources. Processing begins at a first step where the resource manager servers are initialized with information about resources. The initialization processing performed at the step may take any form including loading a fixed table of initially available resources having the resource manager servers poll system resources etc.

Following the step is a test step where the resource manager servers wait for new information to be provided. In an embodiment herein after initialization the resource manager servers wait to receive information from other system components. In other embodiments it may be possible to have the resource manager servers periodically poll system components to see if anything has changed. If it is determined at the test step that no new information is available control loops back on the test step to continue polling.

Once it is determined at the test step that new information is available then control transfers from the test step to a test step where it is determined if the new information relates to a new resource added to the system. If so then control transfers from the test step to a step where the new entry is added to the resource table that is managed by the resource manager servers . Following the step control transfers back to the step to continue waiting for new information.

If it is determined at the step that the received resource information does not related to a new resource and thus relates to a change of an existing resource then control transfers from the step to a step where the existing entry is located in the resource table. Following the step is a test step where it is determined if the capability is being changed for the modified resource. The capability of a resource may change under many different circumstances. For example a resource may degrade and lose capabilities a resource may be modified enhanced and gain capabilities a local manager of a resource may decide to make certain capabilities available unavailable etc.

If it is determined at the step that the capabilities of a resource have changed then control transfers from the test step to a step to change the capabilities field for the resource being modified. Otherwise control transfers from the test step to a step to change the status field of the resource being modified e.g. resource is full resource is off line resource is on line etc. . Following either the step or the step control transfer back to the step discussed above for another iteration.

Note that the resource manager servers may represent a plurality of separate computing devices that may be dispersed throughout the system. Furthermore each of the separate computing devices may maintain its own copy of the resource table. The separate computing devices that are used to implement the resource manager servers may or may not share resource information and may or may not receive the same resource status messages. In instances where information sharing and or receipt of status messages is not perfect then each of the computing devices may have a somewhat different version of the resource table and it is possible for no one version of the resource table to reflect a completely accurate picture of the exact state of all of the resources of the system.

The physical storage may be provided using any type of hardware including high end hardware relatively inexpensive off the shelf mass produced storage hardware and or any combinations thereof. In an embodiment herein at least some of the physical storage may be implemented using serial ATA disk drives which are available from a number of manufactures such as Seagate and Western Digital. As discussed elsewhere herein the physical storage may be geographically dispersed. However each portion of the physical storage may be managed controlled by at least one of the data storage servers which may be implemented using conventional computing devices local to the corresponding portion of the physical storage .

In an embodiment herein the data storage servers may present an OSD Standard interface to the system. Thus the servers and or the clients may access physical storage through the data storage servers using OSD calls and may receive information data according to the OSD protocol. In addition the data storage servers may handle managing posting the capabilities and status of different portions of the physical storage . Thus for example when a portion of the physical storage is managed by a particular server of the data storage servers the particular server may send a message to the resource manager servers indicating the new status.

Referring to a flow chart illustrates steps performed by the resource manager servers in connection with servicing an inquiry for a resource with particular capabilities i.e. finding a resource with particular capabilities . Processing begins at a first step where a pointer used to iterate through each entry of the resource table is set to point to the first entry. Following the step is a test step where it is determined if the pointer points past the end of the table i.e. all entries have been examined . If so then control passes from the test step to a step where a result indicating no match for the requested capabilities is returned by the resource manager servers . Following the step processing is complete.

If it is determined at the test step that the pointer used to iterate through the entries does not point past the end of the table then control transfers from the test step to a test step where it is determined if the entry currently indicated by the pointer is a match for the requested capability. Note that the test at the step may include checking the status of a resource to ensure that the resource is on line and not full or otherwise unusable. If it is determined at the step that the resource indicated by the pointer has the requested capability then control transfers from the test step to a step where the resource manager servers return an indicator indicating the matching resource. Following the step processing is complete.

If it is determined at the step that the resource indicated by the pointer does not have the requested capability or is off line full etc. then control transfers from the test step to a step where the pointer is incremented. Following the step control transfers back to the step discussed above for another iteration.

The LSO trees that are part of the metadata objects for files are created maintained and manipulated by the metadata servers . The metadata servers handle updates from the clients in connection with manipulation of file objects e.g. at the step of the flow chart of at the step of the flow chart of etc. . The metadata servers may also handle any actions besides modifying the LSO tree that may need to be performed in connection with the updates. The metadata servers also handle leases obtained for file objects. As discussed elsewhere herein in some embodiments it is possible to also allow clients to maintain the LSO trees.

Referring to a flow chart illustrates steps performed by the metadata servers in connection with servicing a request for a lease for a file. As discussed elsewhere herein a lease may be requested by one of the clients . However it is also possible for one of the components of the servers to request a lease. It is even possible for one of the metadata servers to request a lease. One of the metadata servers may request a lease in connection with file maintenance e.g. repairing mirrors as described in more detail elsewhere herein. In an embodiment herein leases are maintained by the metadata servers in a table that indicates the entity that has acquired the lease the type of lease e.g. read or write and possibly an expiration time.

In addition as discussed elsewhere herein it is possible to perform lease operations on ranges of logical addresses in a file so that for example one set of lease operations may be performed on logical addresses A B for a file while another set of lease operations may be independently performed for logical addresses C D for the same file where A B does not overlap C D. In a system where only one write lease is issued at a time it may still be possible for one entity to acquire a write lease for the A B portion of a file while another independent entity simultaneously acquires a write lease for the C D portion of the same file. Accordingly for the discussion herein in appropriate instances a reference to a file or files should be understood to include non overlapping portions of a file or files.

Processing begins at a first test step where it is determined if the requested lease is available. The test at the step determines if the requestor has appropriate security credentials if the corresponding data file exists etc. Also as discussed in more detail elsewhere herein leases may be purposely made unavailable in certain circumstances. If it is determined at the test step that the lease is not available then control transfers from the test step to a step where a failure indicator is returned to the requestor. The failure indicator may include a reason for the failure e.g. improper security credentials file does not exist etc. . Following the step processing is complete.

If it is determined at the test step that the requested lease is available then control transfers from the step to a test step where it is determined if the lease request is for writing data to the file corresponding to the lease. In an embodiment herein multiple users e.g. clients servers may read from the same file simultaneously while only one user may write to the same file. Accordingly if it is determined at the test step that a user is not requesting write access then control transfers from the test step to a step where the metadata servers return the lease i.e. returns an appropriate indicator identifier corresponding to granting the lease . In an embodiment herein leases may also be provided with a predetermined expiration time after which the leases are no longer valid. Lease expirations and lease recalls are discussed in more detail elsewhere here. In addition leases may be provided along with security credentials generated perhaps by the security manager servers that only allow for the requested operation e.g. read only read and write etc. . The security credentials may also expire at or around the same time that the lease expires in order to enforce lease expirations. Following the step processing is complete.

If it is determined at the test step that the user is requesting a write lease then control transfers from the test step to a test step where it is determined if another user has already obtained a write lease for the same file. As discussed elsewhere herein only one write lease at a time is granted for a file. If it is determined at the test step that another write lease has already been granted then control transfers from the test step to a step where a failure indicator is returned. Just as with the step the failure indicator returned at the step may include information identifying the nature of the failure. Following the step processing is complete. If it is determined at the test step that another write lease has not been granted then control transfers from the test step to a step where the metadata servers return the lease possibly along with an expiration. Following the step processing is complete.

As discussed elsewhere herein it may be desirable in some instances to issue leases with expiration dates. In an embodiment herein a particular one of the metadata servers may be responsible for a particular file and corresponding file objects. The responsible one of the metadata servers issues leases for the file and corresponding file objects and handles lease expiration processing. The lease information may be stored in appropriate data structures e.g. table s linked list s etc. by the responsible one of the metadata servers . In addition it is possible to have more than one of the metadata servers be responsible for a particular file or set of files where one of the metadata servers is a primary server and other responsible metadata servers are secondary servers that maintain appropriate information but do not otherwise provide services unless the primary server fails.

Referring to a flow chart illustrates steps performed by a responsible one of the metadata servers in connection with monitoring lease expiration. Processing begins at a first step where a pointer that iterates through all of the leases file and lease combinations for which the server is responsible is made to point to the first one. Following the step is a test step where it is determined if the lease has expired. The processing performed at the step may use any appropriate technique including comparing lease expiration times with the current time. If it is determined at the step that a lease has expired then control transfers from the step to a step where the lease is recalled. Recalling the lease at the step is discussed in more detail elsewhere herein.

Following the step or following the step if the lease has not expired is a step where the pointer that iterates through the files and leases for which the server is responsible is incremented. Following the step is a test step where it is determined if the pointer points past the end i.e. all files and corresponding leases have been processed . If so then control transfers from the step back to the step discussed above to reset the pointer to point to the first one and begin another pass to check for expired leases. If it is determined at the step that the pointer does not point past the end then control transfers from the test step back to the step discussed above for another iteration.

In an embodiment herein the system may provide close to open consistency where data consistency is provided after an entity has released write access. Said differently consistency is provided for a file when no entity has an active write lease for the file. Conversely while any entity has an active write lease the state of the data may not be guaranteed for any entity reading the data. In the system described herein leases may be recalled after expiration or may be recalled for other reasons. Recalling the leases may improve the consistency of the data being accessed by other entities.

Referring to a flow chart illustrates steps performed in connection with a particular one of the metadata servers recalling a lease. Processing begins at a first step where a message is sent to the entity holding the lease e.g. one of the clients to alert the entity that the lease is being recalled. As discussed elsewhere herein any appropriate entity may hold a lease including clients other servers or even one of the metadata servers . In some embodiments the step may include ensuring receipt of the message by the entity e.g. waiting for an acknowledgement while in other embodiments the message is simply sent and it is assumed that the message is received by any operational recipient. Of course in systems that wait for an acknowledgement there may be a timeout and or a limit on the number of attempts.

Following the step is a step where the appropriate tables are adjusted to reflect that the lease that has been recalled is no longer outstanding. Tables and other data structures used with leases are discussed in more detail elsewhere herein. Following the step is a test step where it is determined if the lease that was recalled was a write lease lease to allow writing data . As discussed elsewhere herein the system may provide close to open consistency so that when a write lease is released data reads are made consistent. This may be facilitated by recalling all read leases when a write lease is recalled. Entities for whom a read lease is recalled may flush their internal buffers prior to reacquiring the read lease after the recall. Note by the way that an entity for which a write lease is recalled may also flush buffers by writing unsaved data to the physical storage through the data storage servers in response to receiving a recall notification. Accordingly in some embodiments an entity receiving a recall message for a write lease may be provided with a certain amount of time in which to write any unsaved data to physical storage. For this purpose the security credentials provided along with a write lease may be set to expire a predetermined amount of time after the write lease expires.

If it is determined at the step that the lease that is being recalled is not a write lease then processing is complete. Otherwise control transfers from the test step to a step where a pointer used to iterate through all of the outstanding leases for the file for which the write lease is being recalled is made to point to the first outstanding lease. Following the step is a test step where it is determined if the pointer points past the end i.e. all outstanding leases have been recalled . If so then processing is complete. Otherwise control transfers from the test step to a step where the lease is recalled. The lease may be recalled by calling the processing illustrated by the flow chart and thus may be recursive. Following the step is a step where the pointer used to iterate through entities having outstanding leases for a file is incremented. Following the step control transfers back to the step for another iteration.

Referring to a table is shown as including a plurality of entries used to keep track of files for which a particular one of the metadata servers is responsible. Of course other appropriate data structures may be used instead of the table such as a linked list a doubly linked list etc. Each primary one of the metadata servers and any corresponding secondary one s of the metadata servers may contain data corresponding to specific file sets for which the particular one s of the metadata servers are responsible. Thus for example a first primary one of the metadata servers may contain a version of the table for a first set of files for which the first primary one of the metadata servers is responsible while a second primary one of the metadata servers may contain a completely different version of the table for a second different set of files for which the second primary one of the metadata servers is responsible.

Each entry of the table includes a file identifier field FID that uniquely identifies the file corresponding to an entry. In an embodiment herein the FID field may be the object id of the metadata object for the file for example the metadata object in the diagram of . Note that as discussed elsewhere herein the metadata object for a file may be used to locate all of the other data objects for the file.

The MD LOC field may describe the data storage location of the metadata object for the file. In an embodiment herein the MD LOC field may contain an identifier for the one of the data storage servers that stores the metadata object for the file. The MD LOC field may also contain a unique identifier perhaps initially assigned by the one of the data storage servers that may be used to retrieve and store data at the one of the data storage servers .

The LEASE LIST field may contain information about all entities that have active leases outstanding for the corresponding file. In an embodiment herein the LEASE LIST field may contain a pointer to a linked list of elements that corresponding to entities having outstanding leases. Of course any other appropriate data structure e.g. array may be used.

Referring to a diagram illustrates a linked list that may be used to keep track of entities having an outstanding active lease for a file. Each element of the list contains a NEXT field that points to the next element in the list. The element at the end of the list contains a null indicator. Thus the list may be traversed by starting with the element pointed to by the LEASE LIST pointer and subsequently pointing to the elements pointed to by the NEXT field. e.g. in connection with the processing illustrated in the flow chart of . Similarly conventional linked list operations may be used to add and remove elements.

Each element of the list also contains a TYPE field that indicates the type of lease e.g. read or write and includes an EXP field that indicates when the lease corresponding to the element expires. Each element also contains an ENT field that indicates the entity e.g. one of the clients another server etc. that holds the corresponding lease.

Manipulation of the linked list is fairly straight forward. When a lease is granted fields of an element are populated with the type expiration and entity corresponding to the lease and the element is then added to the list. Similarly when a lease is recalled or otherwise returned the corresponding element is removed from the list. Of course other data structures may be used instead of a linked list.

Referring to a table is shown as containing a plurality of entries that correlate object identifiers OID with location information LOC . In an embodiment herein object identifiers are a numerical value. Each of the metadata servers may be provided with a unique range of object identifiers and or set of ranges to use manage. Managing many small sets of ranges has the advantage of allowing ranges to be allocated and or transferred as needed. In some embodiments object identifiers may be reused while in other embodiments object identifiers are not reused. Of course in instances where object identifiers are not reused each of the metadata servers needs to be provided with a sufficient range of useable object identifiers.

The LOC field is like the MD LOC field for the table . The LOC field describes the data storage location of the corresponding object. In an embodiment herein the LOC field may contain an identifier for the one of the data storage servers containing handling the object as a unique identifier perhaps assigned by the one of the data storage servers that may be used to retrieve and store data for the object. Thus if one of the metadata servers has a table entry for a particular object an entity can pass the object identifier to the one of the metadata servers and receive in return the corresponding LOC information to allow the entity to access the appropriate one of data storage servers directly.

Having a number of metadata servers allows for distributed servicing of file operations and thus significant scalability as well as providing failover redundancy capability. In some instances objects may be reassigned from one of the metadata servers to another. However since each of the metadata servers contains information for only a subset of files and corresponding file objects it may be necessary to provide a mechanism for locating an appropriate one of the metadata servers in connection with performing operations.

The metadata location servers provide location services for an entity seeking the appropriate one of the metadata servers for operations on a particular file. In an embodiment herein each of the metadata location servers may receive a call having an object identifier and can return a specific one of the metadata servers that handles the particular object. In addition as discussed in more detail elsewhere herein the metadata location servers may assist in connection with the creation of new objects by indicating to a calling entity e.g. one of the clients a specific one of the metadata servers to be used for the new object. The metadata servers may operate like Domain Name Servers on the Web and each of the clients and other entities may be provided with a primary and a secondary one of the metadata location servers to consult.

Referring to a table is shown as containing entries for use by one of the metadata location servers . Each entry includes an OID RANGE field which indicates a range of object identifiers and an MDS ID field which identifies a particular one of the metadata servers or possibly a group of the metadata servers with one being primary and the remainder being secondary. An entity may provide a particular object identifier to the metadata location server which may then consult the table and return the corresponding value from the MDS ID field.

In addition the metadata location servers may assign a particular one of the metadata servers in connection with creation of a new object. The assignment may be based on any appropriate metric including random assignment assignment based on geographic proximity load balancing and or a policy input by a user through the user management interface discussed above. A policy may indicate for example that new objects created by a particular client are provided on a particular metadata server.

Referring to a flow chart illustrates processing by one of the metadata location servers to assign a particular one of the metadata servers in connection with creation of a new file object. Processing begins at a first step where the policy may be consulted. As discussed elsewhere herein it may be possible to input policies through the user management interface . The policies may dictate directly or indirectly which of the metadata servers are to be used for which of the clients . Note that other policies are possible. For example the policies may indicate which of the metadata servers are to be used at different times of the day independent of the clients or based on the load the user etc. The policy information may be stored at the user management interface and accessed in connection with the step or may be stored at the one of the metadata location servers after having been previously passed thereto. Following the step is a step where identification information for a specific one of the metadata location servers is returned to the calling entity. Following the step processing is complete.

Referring to a flow chart illustrates steps performed by one of the metadata servers in connection with deleting a file for which the one of the metadata servers is responsible. Processing begins at a first step where all leases for the file are recalled e.g. by iterating through the lease list and providing recall processing like that illustrated by the flow chart of . Following the step is a step where the leases are made unavailable for other processes e.g. by setting an appropriate flag that prevents granting further leases for the file . Following the step is a step where the metadata for the file is obtained e.g. by retrieving the metadata object for the file . Note that as discussed elsewhere herein the metadata object for a file contains information about the location of all the file objects used in connection with the file.

Following the step is a step where a pointer used to iterate through the objects used in connection with a file is made to point to the first object. The pointer and subsequent iterative processing uses information obtained at the step to determine the objects for the file. Following the step is a test step where it is determined if the pointer used to iterate through the objects points past the end i.e. all of the file objects have been processed . If so then control transfers from the test step to a step where the table entry corresponding to the file i.e. the entry in the table of is deleted e.g. set to null . Following the step processing is complete.

If it is determined at the step that there are more file objects to process then control transfers from the step to a step where the LOC information is obtained for the object. The LOC information is like the information stored in the table of discussed above. In some instances the LOC information will be local to the one of the metadata servers performing the processing. In other instances it may be necessary to call one of the metadata location servers to get the location information for the object. Following the step is a step where a message is sent to the appropriate one of the data storage servers i.e. the one handling the object to cause the object to be deleted.

In an embodiment herein it may be possible for different files to use the same object e.g. deduplication file aliasing etc. in which case the one of the data storage servers would simply decrement a counter for the object indicating the number of users thereof. When the counter is decremented to zero the data storage server may delete the data corresponding to the object. Note that the object s associated with a file may be deleted asynchronously. Following the step is a step where the pointer used to iterate through the file objects is incremented. Following the step control transfers back to the step discussed above for another iteration.

Referring to a flow chart illustrates steps performed by one of the metadata servers in connection with creating a new file. Note that prior to performing the processing illustrated in the entity creating the file e.g. one of the clients may first consult the metadata location servers to determine the proper one of the metadata servers to use to create the file.

Processing begins at a first step where the policy manager servers are consulted to obtain policy information for new files e.g. new files for client X have a mirror geographically located at least a certain distance from the primary data set . Following the step is a step where the resource manager servers are consulted to determine the available resources to meet the dictates of the policy obtained at the step . Following the step is a test step where it is determined if it is possible to meet the dictates of the policy given the available resources. For example it may not be possible to satisfy the policy of having geographically separated mirrors if all of the remaining physical storage in a system is in one geographic location. If it is determined at the test step that it is not possible to fulfill a policy then control transfers from the test step to a step where alternative processing is performed. Any appropriate processing may be performed at the step including returning an error indicator to the calling entity creating the file with the next best available resources etc. Following the step processing is complete.

If it is determined at the step that it is possible to fulfill the policy with available resources then control transfers from the test step to a step where the metadata object for the file is created. Creating the metadata object may include populating the data fields of the metadata object and obtaining storage from an appropriate one of the data storage servers . In an embodiment herein the data storage servers may be a pool and absent any other specific requirements may provide storage space at any appropriate portion of the physical storage upon request. The metadata objects created at the step will be like those described herein. See for example and the corresponding description. Following the step is a step where a table entry is created in the table for the new file. Following the step is a step where the object id of the metadata object for the file is returned to the calling entity. Following the step processing is complete.

As discussed elsewhere herein when a client or other entity unsuccessfully attempts a write operation a message update is sent to the servers by the client or other entity. Similarly a message update may also be sent to the servers in connection with finding a stale mirror in connection with a synchronous mirror copy see the step of the flow chart of and or writing to data having an asynchronous mirror.

Referring to a flow chart illustrates steps performed by one of the metadata servers in connection with handling a message that a write operation was unsuccessful. Processing begins at a first step where all of the leases for the file are recalled. Following the step is a step where leases for the file are made unavailable. Following the step is a step where new storage space is allocated to replace the old storage space to which the write operation was unsuccessful. Following the step is a step where the appropriate information in the metadata object for the file is adjusted. Following the step is a step where a data copy operation is begun to repopulate the new data storage space with for example data from one of the mirrors. While the data copy operation is being performed the data may be indicated as being stale at the step . Of course if there are no mirrors or other data that can be used to repopulate the new storage space then the processing at the step would not be performed. Following the step is a step where the leases for the file are made available. Following the step processing is complete.

Referring to a flow chart illustrates processing preformed in connection with one of the metadata servers receiving an indication that a synchronous mirror was stale. Processing begins at a first test step where it is determined if the mirror is currently in the process of being populated with data perhaps in connection with a previous bad write operation . If so then the data population operation is allowed to continue and processing is complete. Otherwise control transfers from the test step to a step where processing like that illustrated in the flow chart of discussed above is performed. Following the step processing is complete.

Referring to a flow chart illustrates steps performed in connection with the servers receiving a message that an object with asynchronous replicas has been updated and thus the asynchronous replicas need to be updated. Processing begins at a first step where information is added to a queue e.g. a job queue provided at the affected one of the metadata servers indicating that asynchronous data needs to be copied. As discussed in more detail elsewhere herein a process at each of the metadata servers services the corresponding queue. Following the step processing is complete.

Referring to a flow chart illustrates processing performed by a process at each of the metadata servers that services the corresponding queue that is populated by the processing illustrated by the flow chart of . Processing begins at a first test step where it is determined if the queue is empty. If so then control transfers back to the test step to continue to poll the queue. If the queue is not empty then control transfers from the test step to a step where the next entry in the queue is removed. In an embodiment herein queue elements may be processed on a first in first out basis. However it is also possible to selectively remove elements from the queue in any order. For example elements associated with files that receive higher priority may be removed before other elements e.g. in connection with a flush operation for the file . As another example elements may be removed according to size of needed write operation or according to any other appropriate criteria.

Following the step is a step where the write lease for the affected file is recalled. Following the step is a step where the write lease is obtained. Following the step is a step where the write operation is performed to write the asynchronous data to the mirror. Following the step is a step where the write lock is released. Following the step control transfers back to the step to continue to poll the queue.

In some instances it may be desirable to deploy services to provide additional functionality. Such services include data immutability RAID including software erasure coding techniques versioning snapshots backup asynchronous replication for Disaster Recovery DR asynchronous space reclamation object encryption data at rest encryption data compression green spindown services auto deletion of objects based on object age and others. As described in more detail elsewhere herein the policy management system may be expanded to provide a unified framework for such services and any other services that may be desired.

In an embodiment herein the policy management system may be used to annotate metadata objects which are then accessed by other services to perform operations related to the data. For example the policy manager servers may be used to propagate a policy whereby data objects of a certain class and a certain age are archived by annotating the metadata objects corresponding to the selected data objects so that a service that performs the archiving locates and archives the objects. Note that it is possible to invoke the service at the time the annotation is being performed e.g. to archive the objects at the time the objects are selected for archiving . In other cases the policy manager servers may annotate metadata for an object and the corresponding service may be invoked asynchronously at a later time.

It is possible to provide policy descriptors that may be used as templates for specific policy instances. For example a specific policy definition may be provided for compliance to a particular government regulation or in connection with a company wide data handling policy. Users and or administrators may then create policy instances by assigning one or more policy descriptors to particular data objects e.g. those data objects that meet a particular criteria .

Note that as discussed elsewhere herein appropriate credentials need to be provided by the processes used to annotate metadata objects and or perform related services. Thus for the discussion herein it may be assumed that appropriate credentials are used in connection with registering policy instances performing services associated with policy instances etc. In some embodiments users administrators that provide policy descriptors may have a higher level of authority than users administrators that provides specific policy instances. Thus for example a first user administrator with a relatively high level of authority may provide a specific policy descriptor for complying with government HIPAA requirements while other users administrators each possibly having a relatively lower level of authority than the first user administrator may provide specific policy instances corresponding to the HIPAA policy descriptor and may cause those policy instances to be applied to particular data.

It is possible for the policy manager servers to interact with the resource manager servers to ascertain if there are sufficient resources available prior to annotating metadata for a particular service. For example the resource manager servers may indicate to the policy manager servers that there is no service that archives data in which case the policy manager servers may return an error when a user administrator attempts to provide a policy instance that causes data objects to be archived. In other embodiments the policy manager servers may annotate metadata irrespective of whether corresponding services currently exist in which case the metadata may remain annotated waiting for a future time when a corresponding service is provided.

Referring to a table includes a plurality of policy instances that may be used to provide expanded functionality to the system described herein. The table may be maintained and used by one or more of the policy management servers . The contents of the table may be specified by one or more users through the user management interface using appropriate specification techniques such as providing a command file using a GUI to select and specify options etc. In an embodiment herein the policy management servers handle management and use of the table . However in other embodiments it is possible to shift at least some of the functionality described herein to other ones of the servers and or possibly to processors servers outside of the servers .

Referring to the policy instance is shown as including a plurality of fields such as an object definition field a service type field an action field an SLO service level objective field a trigger event field an object count limit field and an armed field. In an embodiment herein the policy instances may be generated from policy descriptors that may or may not specify initial values for some or all of the fields. The policy instances may be generated using a policy descriptor and modifying some or all of the initial field values. In some embodiments policy descriptors may be loaded cached and later consulted by the policy management servers to deploy policy instances. The policy management servers may be directed to reload policy descriptors when the corresponding service s need to be re configured or to unload the policy descriptor when the corresponding service s are taken down.

The object definition field may define an object set that includes zero or more objects. The set may be defined as x P m x where x is a storage object m x is metadata for x including both system and extended attributes and P m x is a predicate that when evaluated as true for a particular object indicates that the object belongs to the set. Thus object sets are defined in terms of metadata attributes and it is fairly straightforward to determine whether a particular object is part of the object set or not i.e. whether P M x is true or false . Users and applications may control object set membership programmatically by way of creating modifying object s metadata through standard APIs e.g. POSIX setxattr lsetxattr and fsetxattr APIs . Storage systems that allow for extended sets of user application defined object metadata a.k.a. extended attributes may enable rich collections of object sets and thus provide users applications with the means of flexible and dynamic control over object sets.

In an embodiment herein the policy manager servers act as selectors that use the predicate regular expression P M x to select or reject objects for which corresponding services s are to be provided. Thus for example the policy instance may have a P M x indicating that all email messages created by an email application are archived six months after creation. In such a case the policy manager servers would interact with the metadata servers to obtain appropriate information about objects and annotate appropriate objects for archiving.

The service type field may be used to indicate that the service is interested in a certain subset of system lifecycle events. Some services such as replication and erasure coding for instance may need to be notified of system events that affect data durability availability and integrity. Such events include system component and system service faults and failures as well as maintenance events for system services and components. These events may not need to be specified explicitly provided that the service type is specified. Some pre defined service types may include data protection compliance e.g. retention and deletion and security e.g. encryption . Other service types may be referred to as external.

The action field indicates the service s to be invoked in connection with invoking the policy instances. In some instances the service may be provided by a service designer who might be an end user. In other embodiments the service may be already provided by the system. In an embodiment herein the particular services s that may be invoked are not restricted. The action field may include a section that contains service specific parameters that are used to configure the service functional module. Examples of services include services for data protection availability and integrity e.g. synchronous replication data immutability RAID including software erasure coding techniques versioning snapshots backup and services that improve application performance and take on some aspects of application functionality e.g. asynchronous space reclamation object encryption and auto deletion of objects based on object age.

The SLO field provides information regarding the service level objective of the user and indicates the relative importance of the services as well as shares of system resources the services are allowed to consume so that an infrastructure provider has the information necessary to properly schedule the services. Additionally the SLO may specify the order priority in which multiple services execute. Use of the SLO field is described in more detail elsewhere herein.

The trigger event field indicates an event that causes the corresponding service to be invoked. Examples of trigger events include object lifecycle and object access related events create open data read write metadata including attributes read write ACL changes close delete events generated on a pre defined schedule in which case the schedule may become a part of the policy definition events that describe changes in the state of the storage system faults load changes utilization thresholds component failure events etc. as well as events that are asynchronous with respect to the internal storage system activities external to the system and that are delivered through the user management interface or a similar related mechanism along with the indication of the object set the event relates to e.g. using the predicates P M x discussed above .

The object count limit field indicates a maximum number of objects per invocation that may be provided in connection with invoking a service. Although it is possible to invoke a service once for each object it may be more efficient to pass one or more references to multiple objects in connection with a single service invocation. However in some cases there may be a maximum number of objects or references thereof that may be passed in a single service invocation. The object counts field may indicate that maximum number. In other embodiments and or in some policy instances the object count field is not used at all.

The armed field contains a Boolean value indicating whether or not the policy is in force. When the armed field is true for a particular policy instance the service s corresponding to the particular policy instance are invoked. When the armed field is false the service s are not invoked. Use of the armed field is described in more detail elsewhere herein.

Note that in some embodiments it is possible to use UUID s to identify various components such as policy instances object sets etc. Using UUID s may facilitate avoiding collisions.

Referring to a flow chart illustrates steps performed in connection with creating a new policy instance. As discussed elsewhere herein a specific policy instance may be initiated using one of a plurality of policy templates. For example a user desiring to provide a snapshot service may start with a policy descriptor that contains initial values in the fields corresponding to providing snapshot services. The user could then modify some of the fields such as the object definition field and the trigger field to provide a particular snapshot policy instance. At least some of the policy instance information may be provided through the user management interface . The information may be provided in any appropriate form including a command text file or through an appropriate graphical user interface.

Processing begins at a first step where a one or more of the policy manager servers is selected to provide the services specified by the policy instance being specified. In an embodiment herein one of the policy manager servers may be selected as a primary policy server to provide services for a particular policy instance while another one of the policy manager servers may be selected as a backup policy server to provide policy services if the primary policy server fails. Of course other configurations are possible including having multiple ones of the policy manager servers share processing for a single policy instance. In an embodiment herein one of the resource manager servers may select which of the policy manager servers to use for the primary policy server and the backup policy server using appropriate criteria such as the proximity of objects stored in the object definition. In other embodiments the user may select specific ones of the policy manager servers in connection with specifying the policy instance.

Following the step is a step where the new policy instance is evaluated to determine the objects that correspond to the policy instance. This is discussed in more detail elsewhere herein.

Following the step is a step where the policy instance is placed in a list of policy instances that are processed by the particular one of the policy manager servers handling the policy instance. In an embodiment herein the list of policy instances may be ordered according to the relative ordering provided in the SLO field if any in each of the policy instances managed by a policy server. Alternatively the policy instances may be placed in a list in any order and the SLO field may be examined and used for ordering the policy instance services at the time the services for the policy instances are provided. Alternatively still the information from the SLO field may be used by the service provider s to control service ordering in any manner that is appropriate for a particular service or group of services. Following the step processing is complete.

In some embodiments it is possible to forgo evaluating a policy when the policy is first added. For example it may be possible to initially add a new policy and then evaluate that policy at a later time such as when a particular event occurs or when objects are added. This illustrated by an alternative path which provides that control transfers from the step to the step without executing the step .

Referring to a flow chart illustrates selecting objects corresponding to an object definition field of a policy instance. The processing illustrated by the flow chart iterates through a set of objects to determine if one or more of the objects should be annotated for inclusion with a particular service. This may be useful for example when a new service is added or an existing service is modified. See for example the step in the flow chart discussed above.

Processing begins at a first step where a pointer used to iterate through all of the objects being tested for inclusion is set to point to the first one of the objects. Following the step is a test step where it is determined if the pointer has iterated through all of the objects being tested. If so then processing is complete. Otherwise control transfers from the test step to a test step where it is determined if the particular object object metadata being pointed to by the pointer used to iterate through all of the objects meets the criteria set forth in the object definition field for the policy instance i.e. if P m x is true as discussed elsewhere herein . If so then control transfers from the test step to a step where the metadata for the object is annotated for inclusion of the object in the object set that will be processed when the corresponding service is invoked. Note that in some embodiments it is also possible to cause the object object metadata to point to the policy instance at the step . Having each object point to corresponding policy instance s is an optimization that may facilitate processing for the system. In addition it is also possible at the step to have a component that manages the object being annotated subscribe to a trigger event that is specified for the policy instance being registered. Subscribing to a trigger event causes the policy instance to be reevaluated and or the corresponding service to be invoked whenever the trigger event occurs. For example if a service is to be invoked whenever a particular portion of the storage system changes state e.g. transitions from off line to on line then subscribing to the trigger event at the step causes the managing component to receive an appropriate notification when the state change occurs. In an embodiment herein trigger event notifications may be provided by appropriate ones of the servers that handle parts of the system relating to the events. Thus for example if a trigger event relates to changes in object metadata then the event notification may be provided by one or more of the metadata servers . Alternatively if the trigger event is periodic e.g. perform service every hour then event notifications may be provided by one or more of the servers that maintain periodic scheduling information time. In some instances it may be possible for trigger events to relate at least in part to data outside the servers e.g. a service that is performed when a UPS indicates a power outage .

Following the step is a step where the pointer that iterates through the objects is incremented. Following the step control transfer back to the test step for another iteration. Note that the step may also be reached directly from the test step if the object object metadata being examined does not meet the criteria set forth in the object definition field for the policy instance i.e. P m x is false .

Referring to a flow chart illustrates annotating object metadata that corresponds to an object definition field of a policy instance. The processing illustrated by the flow chart iterates through a set of policies possibly all policies to determine if a particular object should be annotated for inclusion with a service according to a policy definition. This may be useful for example when a new object is added or an existing object is modified.

Processing begins at a first step where a pointer used to iterate through all of the policies is set to point to the first one of the policies. Following the step is a test step where it is determined if the pointer has iterated through all of the policies being tested. If so then processing is complete. Otherwise control transfers from the test step to a test step where it is determined if the object object metadata under examination meets the criteria set forth in the object definition field for the policy instance of the particular policy pointed to by the pointer used to iterate through the policies. If so then control transfers from the test step to a step where the metadata for the object is annotated for inclusion of the object in the object set that will be processed when the corresponding service is invoked. Note that in some embodiments it is also possible to cause the object object metadata to point to the policy instance at the step . It is also possible to register trigger events at the step in a manner similar to that described above for the step . Following the step processing is complete.

If it is determined at the test step that the object object metadata under examination does not meet the criteria set forth in the object definition field for the policy instance of the particular policy pointed to by the pointer used to iterate through the policies then control transfers from the test step to a step where the pointer that iterates through the policies is incremented. Following the step control transfer back to the test step for another iteration. Note that the processing illustrated by the flow chart annotates the object being examined according to a single policy. In other embodiments it may be possible to annotate an object according to multiple policies.

In an embodiment herein an appropriate mechanism may be used to keep track of the objects object metadata corresponding to particular service s . In such a case a service may access objects of interest using the mechanism instead of needing to examine all of the object metadata to find appropriate annotation. For example a background process could construct for each service an index or a linked list of objects that are operated upon by the service. For embodiments that do not include such a mechanism then a service being invoked could examine all object metadata for specific annotation indicating inclusion for the service.

The annotated metadata may be used in a number of ways. One way that the annotated metadata may be used is by client or server software components when applications access data in the system. The software components may examine the object metadata in the process of handling the operation. For any synchronous operations specified by a policy the client may directly invoke the corresponding services. On the other hand for any asynchronous operations specified the software components may post a message to a job service queue that causes the action to be performed when appropriate. Another way that the annotated metadata may be used is on time based triggers. When an object is created the policy may indicate that something should happen in the future. At create time a timer may be set to perform that event. Upon firing routine initiated by the timer may first check that its action should still be performed. Alternatively a mechanism may be provided to cancel timers that become obsolete. Another way that policy annotations could be used is in responding to event triggers. When an object comes under management by some component that component may register for any triggers specified by one or more policies associated with the object. If the event occurs the component may locate all objects interested in the trigger and respond appropriately. Different mechanisms for using annotated data are discussed in more detail elsewhere herein.

Referring to a flow chart illustrates steps performed in connection with invoking a service. As discussed elsewhere herein a service may be invoked for any of a number of reasons including being invoked periodically e.g. a data archiving service because a policy is being reevaluated e.g. redetermining which objects are affected by a particular service when particular objects are added e.g. file creation synchronously or asynchronously by a client a server etc. In an embodiment herein at least some services may be invoked periodically by the metadata servers . The period may be once per day but the frequency may be increased in response to registering a policy instance corresponding to a service that requests more frequent periodic running. Particular mechanisms for invoking one or more of the services are discussed in more detail elsewhere herein.

Processing begins at a test step where it is determined if the corresponding policy instance is armed. As discussed elsewhere herein it is possible for a policy instance and thus a corresponding service to be armed operational or not armed not being invoked . If it is determined at the test step that the policy is armed then control passes from the test step to a step where objects that are affected by the service are collected. As discussed elsewhere herein the policy managers may annotate objects for operation by the services and some or all of the objects may include pointers to the policies services that operate on the objects.

The processing at the step may simply locate metadata that has been annotated for operation by the service. Alternatively the processing at the step may be like that illustrated by the flow chart discussed above. Following the step is a step where the service is invoked. Invoking the service at the step is discussed in more detail elsewhere herein. Following the step processing is complete. Note that the steps are not performed if it is determined at the test step that the corresponding policy is not armed.

Referring to a flow chart illustrates in more detail the step in which a service is invoked for one or more objects. Processing begins at a first step where a timer is set for the service based on the number of shares provided for the policy instance in the SLO field. As discussed elsewhere herein it is possible to use the SLO field to specify both a relative ordering of services and a relative number of shares amount of processing resources used by each of the services. Thus for example a service that is allocated two shares may use half of the resources of a service allocated four shares. The value used for the timer at the step may be proportional to the number of shares allocated for the service so that for example the time may be set to a value N for a service that is allocated two shares and may be set to a value 2 N for a different service that is allocated four shares.

Following the step is a step where the service specified in the action field of the policy instance is initiated invoked for the object s . The processing at the step causes the service to be invoked and to run concurrently with the processing illustrated by the flow chart . Initiating the service at the step may use any one or more appropriate mechanisms such as spawning a task that performs a direct function call making an RPC call etc. In some embodiments objects i.e. collected at the step discussed above may be passed to the function RPC etc. being called by for example passing one or more pointers to the objects corresponding to the service.

Following the step is a test step where it is determined if the timer initially set at the step discussed above has expired timed out . As discussed elsewhere herein the timer may be used to ration resources to each service based on the number of shares allocated to each service as set forth in the SLO field. If it is determined at the step that the timer has expired then control transfers from the test step to a step to disengage the service that was initiated at the step . Any appropriate mechanism may be used at the step to disengage the service including issuing an appropriate abort command. Following the step processing is complete.

If it is determined at the test step that the timer has not expired then control transfers from the test step to a test step where it is determined if the service initiated at the step has completed for the objects. If so then processing is complete. Otherwise control transfers from the test step back to the test step for another iteration.

Referring to a flow chart illustrates steps performed in connection with modifying a policy instance. Processing begins at a first step where the armed field of the policy instance is set to false thus preventing the service s associated with the policy instance from being invoked while the policy instance is being modified. Following the step is a step where the modification is made to the policy instance. The modification could be anything including modifying the action field to change the services that are performed in connection with the policy instance. In some embodiments modification of a policy instance causes a reevaluation of the objects associated with the corresponding service i.e. causes processing like that illustrated by the flow chart discussed above to be performed . Following the step is a step where the armed field of the policy instance is set to true so that the services associated with the policy instance will be performed when the services are invoked. Following the step processing is complete. Note that as discussed elsewhere herein in some embodiments modifying the policy may cause the policy to be reevaluated. Also in some cases it is possible to modify the policy without first disarming the policy in which case the steps are not performed.

Note that other appropriate mechanisms different from that illustrated by the flow chart may be used to operate services according to guidelines provided in the SLO including providing relative service ordering and or resource shares. In an embodiment herein relative service ordering and or share values are provided in the SLO field and passed to a system mechanism that handles running services. In other embodiments there may be no mechanism for providing relative service ordering and or for providing service resources according to share values in which case the all or part of the value s in the SLO field are not used.

Referring to a flow chart illustrates steps performed in connection with a client or server component using the metadata annotation mechanism described herein. Processing begins at a first step where the software component examines the metadata annotation of an object. Following the step is a test step where it is determined if the metadata is annotated for handling by a service. If not then processing is complete. Otherwise control transfers from the test step to a test step where it is determined if the service for the object is a synchronous service. If so then control transfers from the test step to a step where the software component causes the service to be invoked e.g. using an RPC sending an appropriate message to one of the servers etc. . Following the step processing is complete. If it is determined at the test step that the service for the object is an asynchronous service then control transfers from the test step to a step where the software component causes the service to be scheduled e.g. using an appropriate mechanism to cause the service to be placed in a job queue . Following the step processing is complete.

Referring to a flow chart illustrates steps performed in connection with a trigger time based or event trigger causing a service to be invoked. Processing begins at a test step where it is determined if a trigger event has occurred. The test step represents polling for a trigger event but of course any other appropriate mechanism may be used to cause particular processing to be performed in response to a trigger event. If it is determined at the test step that a trigger event has occurred then control transfers from the test step to a test step where it is determined if the service object trigger association is still valid. In an embodiment herein intervening events may cause the associate to become invalid between the time the association is initially made but before the trigger occurs. If it is determined at the step that the event is no longer valid then processing is complete. Otherwise control transfers from the test step to a step where the service is invoked. Following the step processing is complete.

In an embodiment herein services may be classified into one of two groups core system services and external services. The core services include services whose function is tightly coupled with that of the storage system. Such services may be responsible for data integrity availability and durability. Examples of such services are synchronous asynchronous replication erasure coding retention versioning snapshots asynchronous space reclamation scheduled object deletion background de duplication and data encryption. The core services may execute in performance critical code paths and may be triggered based on certain well defined set of events closely related to object lifecycles. The core services may be deployed upgraded and taken down as a part of the system lifecycle.

External services may be extensions of the storage system s functionality implemented as applications that use storage system interfaces such as the user management interface . External services may also use storage service management framework interfaces to integrate with other storage services and be managed in a uniform fashion. Thus for example one or more external services may be deployed across a plurality of the groups of servers . External services may run in a storage system cluster but not be tightly coupled with the storage system or the core services. The external services may be executed based on the trigger events that are asynchronously communicated to the external services by the policy management servers of at least one of the groups . External services may be configured to be triggered by a wide range of event types. In addition the functionality of external services may be limited only by the available storage system and policy management server interfaces.

In some embodiments the core services may use efficient back channels interfaces with more options for optimizations because the interfaces between the service and the system are tightly coupled and can be changed without any impact on the external system interfaces . The non core services on the other end may be limited to the well defined and hard to change interfaces that the system exposes externally such as the user management interface .

Note that various optimizations may be provided. For example at runtime it may be possible to keep track of the following 

The relationships may be maintained in a table indexed by object set by event type and perhaps by action service if needed. The table indices may be used to dispatch actions based on object set memberships and the events. Additional work may be needed to rearrange the tables indices when object memberships and or policies change either because of changes in objects or because of changes in policy definitions. It is useful to strike a balance between optimizing runtime application of policies vs. what happens when the policies change. In some cases the former may be more important than the latter as it occurs much more frequently. However specific system requirements may steer to various design points that strike a different kind of balance.

Computing and storage resources may be co located in physical datacenters which creates opportunities for low latency and high bandwidth data access as compared to the access over WAN links by applications running in the virtual machines. It may be useful to be able to query the system at runtime for locations of virtual machine images and datasets accessed by the virtual machine images. This information allows optimization of data movement so that the deployment process and or redeployment process completes within reasonable time frame while providing good performance due to dataset access locality. This is described in detail below.

It is also possible to use a graph to describe collections of VMs that perform computations vApps graph . Such collections may be referred to as a virtual appliances a term that is used in the OVF specification which is publically available or vApp for short. An OVF descriptor for a vApp lists virtual machine resource requirements as well as the executable images and datasets needed by the computation.

The system described herein may include a virtual infrastructure inventory and a vApp catalog. The virtual infrastructure inventory describes virtual infrastructure that the vApp is deployed into. This inventory provides a logical description of the virtual infrastructure e.g. a virtual data center vDC with the VMs that are deployed therein. The vApp catalog is a directory public or private of available vApp templates that can be deployed in the vDCs.

Note that as used herein the term deploy may include redeployment so that for example after an initial deployment based on available criteria one or more vApps may be redeployed for any number of reasons including reevaluation of employment criteria redeployment for load balancing availability reasons or for changes in SLO conditions. Thus for the system described herein the description associated with deploying vApps includes initial deployment as well as redeployment.

Referring to a resource graph includes a plurality of P nodes representing computer processing resources and a plurality of S nodes representing storage resources. The nodes are connected by edges that represent communication links therebetween. Each of the edges has an associated cost C C that corresponds to a cost of transferring data between the connected nodes. The costs represent the relative value of whatever metric is being used to optimize placement of compute and storage objects. For example if the placement is being optimized based on minimizing running time then the costs C C may represent the time it would take to transfer a VM image from its current location to a different node. Thus if the running time for the VM is one hour on node A and two hours on node B where it is currently stored then the questions of whether it is better to move the VM image from node B to node A depends on the cost in this case the time it would take to perform the transfer.

Of course there are many possible metrics that could be used to determine the cost such as runtime resource usage metrics amounts of virtual resources consumed and amounts available for consumption resource rents cost per unit of resource per unit of time availability track record historic availability rating in number of 9s . Such metrics may also include aggregate CPU memory disk as well as aggregate network and I O bandwidth figures for a compute service installation aggregate space available and I O bandwidth out of the storage service facility bandwidth for connections between service installations compute storage resource rents performance and availability current locations of stored or cached data objects current locations of already running computational activities available new locations for storage or for caching data objects available new locations for deploying computational activities available compute capacity in different locations available storage capacity in different locations available bandwidth capacity between different locations costs of running computational activities in different locations costs of storing or caching data in different locations and or costs of moving data between locations.

Referring to an application deployment graph includes a plurality of VM nodes and a plurality of Ad nodes. VM nodes connected by edges labeled T are tightly coupled indicating that the nodes perform computations that are interdependent e.g. a number of VMs used to take and fill orders for on line merchandise sales for a single vendor source . In many instances it is useful to have tightly coupled VM nodes be in close physical proximity so that data transfer rates between the nodes are relatively high. Nodes that are tightly coupled may be co located in the same datacenter.

VM nodes connected by edges labeled L are loosely coupled indicating that there is no close interdependence between computations performed by the VM nodes so coupled. Loosely coupled VM nodes may not be in close physical proximity and the data transfer rates therebetween may be relatively low e.g. using a WAN and or through the Internet . The communication cost discussed elsewhere herein between tightly coupled nodes may be significantly less than communication costs between loosely coupled nodes.

Application processing using virtual machines may be performed by collections of tightly coupled virtual machines e.g. a multi tier web based application that may be referred to as vApps which are known in the art. The vApps may access local disk storage virtual disk storage as well as application level datasets. The virtual machines may be provided at any one or more of the VM nodes. Tightly coupled VM nodes are illustrated in by a dotted oval enclosing the tightly coupled VM nodes which are explained in more detail elsewhere herein.

The application deployment graph also shows nodes that are labeled with Ad indicating that the particular ones of the nodes contain application datasets. The application datasets are used by the applications in connection with performing processing. For example a bank application may use an application dataset that contains customer names and bank account information. Note that an application and or a related set of applications may use more than one dataset.

Referring to a application deployment graph is like the application deployment graph of except that the dotted ovals containing VM nodes are replaced with nodes labeled vApp to indicate that the particular node corresponds to a plurality of tightly coupled VMs that form a vApp. The different virtual machines of the vApp may not be subdivided. That is all of the virtual machines of a single vApp run on a single P node or on a plurality of P nodes that are in relatively close proximity i.e. in the same data center . The system described herein determines an optimal selection of P nodes and S nodes the resource graph of nodes for deploying the vApps and the corresponding data sets based on user supplied criteria i.e. policy based criteria .

Referring to a resource graph is like the resource graph except that some of the nodes are crossed out pruned . The system described herein initially examines all of the resource nodes and the vApp deployment criteria e.g. supplied by a user and determines which of the resource nodes do not meet the criteria. For example if the criteria includes the capability of simultaneously running one thousand virtual machines and a particular P node supports no more than five hundred simultaneous virtual machines then that particular P node will be pruned.

Some of the cost metrics may be useful in making pruning decisions for the resource graph based on the resource requirements and some of the metrics are used to calculate deployment and execution costs. The pruning decisions can also be made based on the constraints described in a policy specification such as compliance constraints e.g. geographical region constraints whether or not application data locality is important in which case application level datasets are specified whether to optimize the disk image movement during the deployment process or optimize only by the execution costs bound the rents thresholds for specific resources this addresses applications that are bound by a specific resource CPU memory I O intra vApp communication or Internet and or overall optimization goal or a combination thereof cost speed availability.

Compliance constraints include security and compliance of the environment in which resources reside geography of applicability of certain laws e.g. local authorities ability to access to Customer data or Customer requirement that computation and or data must be in US or in Europe or whatever place Customer law policy dictate. Such requirements may include that the environment compute node provide access logs progress logs and a like to ensure compliance. The same may be applied to networks used to move vApps and data. This may all be policy based and not coded in applications. In some instances the requirements may be we viewed as attributes of Compute Storage nodes and links and thus may be handled in connection with pruning which is discussed in detail elsewhere herein.

Additionally a policy may specify various aspects of SLOs for deploying one or more of the vApps. The SLOs may specify resource reservation resource options an expressed guarantee that additional resources will be available upon request as well as data availability durability integrity objectives. The policy may specify the base location and location matching rules and may include deployment execution constraints a desired SLO description and or location preferences base matching rules 

Information indicating the locations of the resource nodes and the connections therebetween may be provided using any appropriate mechanism. In an embodiment herein nomenclature is used for describing relative locations of datasets executable disk images as well as a method for associating the location object layout information with the dataset executable image storage objects. The information may be indexed in object location metadata and metadata for replica objects to provide for efficient querying. Alternatively location information may be stored externally in a specialized metadata store. Querying may be based on indexing of the objects location metadata either by the storage system itself or by the external extension. In the former case it may be possible to moderate location query load on the storage system. In the latter case query processing scalability may be improved. Other applicable optimizations that reduce the query load and improve query scalability may be used as well. The object location metadata is used by the virtual infrastructure for co location of computation and datasets in the system described herein.

In an embodiment herein a hierarchical notation may be used for describing locations of resources and objects. Location components may include continent country administrative locale state province etc municipal locale city town village etc datacenter ID rack ID and host ID. Relative paths may be specified starting at any level of the hierarchy. It is possible to specify a base location and have all the relative paths relate to the base. In other instances the base does not need to be specified so as not to tie the location to a particular base but to provide relative distances starting at a given layer of the hierarchy.

Referring to a flow chart illustrates steps performed in connection with determining a resource node for deploying a vApp while incurring the minimal cost. Processing begins at a first step where a resource graph containing P nodes and S nodes is constructed. The resource graph may be constructed using location data that may be obtained using the indexed location data described elsewhere herein. Following the step is a step where the vApp nodes are located overlaid in the resource graph based on the current location of the vApp images. That is as an initial state the resource graph is overlaid with vApp information corresponding to the initial current location where images are stored for the VMs that make up each of the vApps. Following the step is a step where the Ad nodes are located overlaid in the resource graph using for example information indicating the current location of existing application datasets which may be provided by application information for the vApp and or the indexed location information which is discussed elsewhere herein.

Following the step is a step where unusable resource nodes are pruned. As discussed elsewhere herein unusable resource nodes are those which cannot meet the specified criteria for the one or more vApps. Following the step is a step where a location for deploying the one or more vApps is determined. The processing performed at the step is discussed in more detail elsewhere herein. Following the step processing is complete.

Referring to a flow chart illustrates in more detail processing performed at the step of the flow chart discussed above where the optimal node s for deployment of the vApp s is are determined. Processing begins at a first step where the cost for deploying the vApp at its current resource node is determined. Determining deployment cost at a particular resource node is discussed in more detail elsewhere herein. Following the step is a step where a variable structure that keeps track of the lowest cost resource node is initially set to the current location of the vApp. Following the step is a step where an index variable I is initialized. The index variable I is used to iterate through the possible resource nodes to determine an optimal node for deployment.

Following the step is a test step where it is determined if there are more resource nodes P nodes to examine. If not then processing is complete. Otherwise control transfers from the test step to a step to determine the cost of deploying vApp on node I the resource node indicated by I . Following the step is a test step where it is determined if the deployment cost determined at the step is less than the cost for the resource node indicated by the LOWEST variable structure . If so then control transfers from the test step to a step where LOWEST is set to indicate the node I resource node. Otherwise control transfers from the test step to a step where the index variable I is incremented. Note that the step is also reached directly after the step . Following the step control transfers back to the step discussed above for another iteration.

Referring to a flow chart illustrates steps performed in connection with calculating the cost of deploying a vApp on a particular resource node. Processing begins at a first step where the cost of moving the vApp from its current location to the particular resource node is determined. Of course if the vApp is already provided on the particular resource node then the cost determined at the step is zero.

Following the step is a step where the cost of running the vApp on the particular resource node is determined. In some embodiments the cost of running the vApp as a function of resource node characteristics may be provided with the vApp e.g. by the vApp developer . For example if the cost metric is minimizing response time then the running cost may be for example a function of the number of possible simultaneous virtual machines that can be provided at the resource node as well as the I O speed of the storage used by the resource node. In some cases the running costs may be estimated based on various known factors.

Following the step is a step where the cost for accessing the various datasets from the particular resource node is determined. As discussed elsewhere herein there may be a number of replica datasets Ad for the vApp. Thus the processing at the step may include using the dataset having the minimum cost for access at the resource node. Following the step processing is complete. The cost of deploying the vApp at the particular resource node is the sum of the costs determined at the step .

Similarly to the storage policies evaluation of the cloud policies may be triggered in the context of relevant operations e.g. deployment or is time based e.g. VM snapshots . However the classifying predicates may be evaluated not only against vApp template OVF package object metadata but also against its contents as well taking advantage of the fact that OVF is an XML document . Additionally there may be several objects of interest that are involved in a particular operation. As an example the deployment operation involves not only the template but the vDC see below . So the deployment policy selection might be performed based on one or more of the following factors attributes of the vDC attribute of the template and the contents of the template. This provides flexibility.

The pruned graph is used to find the deployment that results in meeting the optimization goals while complying with the SLOs that are stated in the policy description.

Note that in some embodiments it may be possible to determine costs by iterating through various instances of moving the one or more of the Ad nodes to other S nodes. Note also that the system described herein may work with any number of nodes of any type interconnected in any appropriate manner.

The system described herein is applicable not only to virtual infrastructures including virtual infrastructures platforms and application frameworks but also for physical hybrid cloud infrastructures. The system described herein may be used to provide optimal deployment of any type of compute resource including storage real virtual or some other type devices accessed by the system etc.

The system described herein may be used with any server or any group of servers capable of providing the functionality described herein. The particular form of the file objects may vary without departing from the spirit and scope of the invention. In some instances the order of steps in the flow charts may be modified where appropriate. The system described herein may be implemented using a computer program product software provided in a computer readable storage medium e.g. a fixed computer readable storage medium and executed on one or more processors.

While the invention has been disclosed in connection with various embodiments modifications thereon will be readily apparent to those skilled in the art. Accordingly the spirit and scope of the invention is set forth in the following claims.

