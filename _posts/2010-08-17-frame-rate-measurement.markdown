---

title: Frame rate measurement
abstract: A method and system of measuring a frame rate with an imaging device may include, capturing images of a number of frames of at least a portion of a series of frames output on a display device, determining if consecutive images of the captured images are different.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08358347&OS=08358347&RS=08358347
owner: Hewlett-Packard Development Company, L.P.
number: 08358347
owner_city: Houston
owner_country: US
publication_date: 20100817
---
Developments in the production and display of video content have lead to an ever increasing desire to improve the way in which video content is presented on a display device. Developments have been made in display devices such as liquid crystal displays LCD s plasma displays high definition televisions and cathode ray tube CRT displays in order to improve the appearance of displayed images.

Throughout the drawings identical reference numbers designate similar but not necessarily identical elements.

Frame rate is an important variable in quantifying the performance of a video display system. Frame rate is the number of frames per unit time that are displayed by the system. Various embodiments of the principles described herein provide for measurement of a frame rate of a video signal provided by a video source or of video frame rates output on a display device. An imaging device or frame grabber is provided to capture a number of frames of the output of the source or display device. By dividing the number of different frames captured by the imaging device or frame grabber by the duration or elapsed time of the streaming video the frame rate of the source or display device may be measured.

It is difficult to measure the video performance of applications running in a networked environment for example on a virtualized host or in a client server configuration when the application is designed to run as a local application. For example in a computing system a user can playback a locally stored video clip or run a local application which renders 3D images in real time. Using software which intercepts calls to the operating system it is possible to accurately determine the rate at which frames are updated in these local operations. For example using FRAPS a video capture utility which uses application programming interfaces APIs provided for handling tasks related to multimedia it is possible to accurately determine the rate at which frames are updated.

Outside of the local computing context issues arise in measuring frame rates. For example when an application that is producing video is run in a virtualized computer the reported frame rates may be inaccurate because of the lack of correlation between the virtual computer s time and actual time. In a networked environment if the same application is run on a server and a remote client is used to display the output some mechanism is used to move rendered video from the server to the client. However it is often not possible to access the internals of that mechanism to determine which frames were transferred. Since implementations of such a mechanism will usually drop frames measured frame rates on the server do not correlate to what is actually displayed on the client. Additionally because the servers are commonly implemented as virtual servers the inaccuracy of measuring the frame rate is compounded.

In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the present systems and methods. It will be apparent however to one skilled in the art that the present apparatus systems and methods may be practiced without these specific details. Reference in the specification to an embodiment an example or similar language means that a particular feature structure or characteristic described in connection with the embodiment or example is included in at least that one embodiment but not necessarily in other embodiments. The various instances of the phrase in one embodiment or similar phrases in various places in the specification are not necessarily all referring to the same embodiment.

As used in the present specification and the appended claims the term frame rate is meant to be understood broadly as the number of frames of a series of frames which are displayed on a display device in a predefined amount of time or the frequency at which individual frames are displayed. Frame rate is measured in and may be expressed in units of frames per second fps . A frame rate of 30 fps is often referred to in the art as real time speed of video because it has a high enough frame rate that the video appears smooth to the human eye. However 24 fps is considered sufficient for film. In many cases 16 fps is sufficient for viewing without producing detectable frame transitions. At a slower frame rate of 12 15 fps video and film may appear choppy to the human eye if objects are moving in the scene.

Further as used in the present specification and the appended claims the term image is meant to be understood broadly as any representation of an object in any form including for example data or film. Further as used in the present specification and the appended claims the term frame is meant to be understood broadly as a single complete still image in a sequence of images that creates the illusion of motion within a scene when displayed in rapid succession for example streamed . Frame may also be used to refer to digital information representative of the single still image.

Still further as used in the present specification and the appended claims the term imaging device is meant to be understood broadly as any device configured to capture images. Such imaging devices may include for example a camera a video camera web camera a frame grabber or a photodetector among others.

Even still further as used in the present specification and the appended claims the term display device is meant to be understood broadly as an output device configured to output data for visual reception. Such display devices may include for example liquid crystal displays LCD s light emitting diode LED displays organic light emitting diode OLED displays plasma display panels televisions computer monitors high definition televisions and cathode ray tube CRT displays among others.

Turning now to a diagram of one example of a system for measuring video frame rates according to an embodiment of the principles described herein is depicted. The system may comprise a source and a display device configured to display a number of frames based on data input from the source . The system may further comprise an imaging device or frame grabber configured to capture a number of frames displayed on the display device . The imaging device or frame grabber may be in communication with to a computing device in which the computing device is configured to process the frames captured by the imaging device or frame grabber . Additionally the system may comprise a counter for use by the computing device in counting the number of different frames output by the display device and captured by the imaging device or frame grabber . Each of these elements will now be discussed in more detail below.

The source may be any device configured to provide video content in the form of data to the display device and may include for example a personal computer a thin client a workstation a server a television program provider and combinations thereof among others. The frame rate of the original video content may be significantly altered from that which is eventually displayed on the display device . This may be due to the fact that the original video content is often subject to compression decompression coding decoding and other forms of processing by various hardware and software elements such as processors network elements memory elements operating systems and application programs. These hardware and software elements affect the original video content through their CPU speed network parameters such as bandwidth latency and errors available memory and type of operating system. Therefore it is often undetermined how these various networked elements affect the frame rate of the original video content at the source and at the display device .

The source may be configured to provide any form of streaming digital or analog data. The data transmitted by the source may be provided for the purpose of determining the frame rate output by the display device or the source itself after the data has been rendered compressed sent over a network to a receiver decoded and output to the display device . In one example the data transmitted by the source is data that is not compared to the actual output frame rate of the display device captured by the imaging device or frame grabber . In another example the data transmitted by the source is data provided and known by a user with the intention that original frame rate of the transmitted data is compared to the actual output frame rate of the display device captured by the imaging device or frame grabber . These embodiments will be described in more detail below.

The display device may be for example a liquid crystal display LCD a light emitting diode LED display an organic light emitting diode OLED display a plasma display panel a television a computer monitor a high definition television or a cathode ray tube CRT display among others. In one example the display device may be a display device that uses a technology that does not require the display to be continuously updated for example an LCD display.

A CRT based display however is a display device that is continuously updated. The principles described herein could be extended to support such display devices by genlocking the imaging device or frame grabber to the vertical synchronization signal of the CRT display device . Genlock generator lock is a technique where the video output of one source or a specific reference signal is used to synchronize other television picture sources together. To allow for a display device to display an image properly a standard component video signal comprises horizontal vertical frame and color components RGB . Genlock synchronizes the vertical horizontal frame and or color components of the signal. Thus by genlocking the source with the imaging device or frame grabber a CRT based display may also be utilized. However in another example a CRT based display may still be used without genlocking the source with the imaging device or frame grabber .

As mentioned above the imaging device or frame grabber is configured to capture the number of frames displayed on the display device . The imaging device or frame grabber may be configured to capture images at a high rate of frame acquisition. In one example the frame acquisition rate of the imaging device or frame grabber may be based on the frequency in frames per second fps attributed to the data input from the source . In one example the imaging device or frame grabber is configured to provide a frame acquisition rate that is at least twice the frame rate to be measured that is the actual output frame rate of the display device or the frame rate of the data output from the source . In other embodiments the frame acquisition rate may be at least three to five times the frame rate to be measured. In other embodiments the frame acquisition rate of the imaging device or frame grabber may be at least 48 fps for data output from the source comprising an output frame rate of 24 fps at least 60 fps for data output from the source comprising an output frame rate of 30 fps or at least 120 fps for data output from the source comprising an output frame rate of 60 fps.

The imaging device or frame grabber may be for example a camera a video camera a web camera a frame grabber or a photodetector. In one example the imaging device or frame grabber is a web camera. In another example the imaging device or frame grabber may be a photodiode a photodetector a photosensor a light emitting diode LED a charge coupled device CCD or a solar cell among others. Further the imaging device or frame grabber may comprise arrays of photodiodes photodetectors photosensors light emitting diodes LEDs charge coupled devices CCDs solar cells or combinations thereof. In yet another example the imaging device could be a frame grabber electrically coupled directly to the output of the source. A frame grabber is any hardware software or combinations of hardware and software that capture individual digital still frames from an analog video signal or a digital video stream.

Images captured by the imaging device or frame grabber are sent to a computing device in communication with the imaging device or frame grabber . The computing device having memory and a processor not shown is configured to process the frames captured by the imaging device or frame grabber . In processing the images the computing device is configured to distinguish between the images captured by the imaging device or frame grabber . In one example the computing device is configured to determine if two consecutive images captured by the imaging device or frame grabber are different. In this manner the frame rate output by the display device can be determined by distinguishing the frames captured by the imaging device or frame grabber incrementing a counter when it is determined that two consecutive frames captured by the imaging device are different and dividing the number indicated by the counter by the duration for example in seconds of the analyzed clip to obtain the frame rate output by the display device . The counter may be embodied as hardware software or a combination of hardware and software. In one example the counter is configured to reset the number of increments to zero for each new series of frames being analyzed.

The threshold level for detecting whether consecutive images are different may be selected based on the type of content the image acquisition parameters of the imaging device or frame grabber and the desired level of sensitivity to changes. In one example the threshold is automatically selected based on these and other parameters. In another example the threshold may be set by a user of the system .

Several methods may be applied in determining if two consecutive images captured by the imaging device or frame grabber are different. These include for example an absolute error AE count a mean absolute error MAE algorithm a mean squared error MSE algorithm a peak signal to noise ratio PSNR algorithm a root mean squared error RMSE algorithm a normalized sum of squared differences root mean squared error NRMSE algorithm a normalized cross correlation a histogram comparison a simple hash by applying a discrete cosine transform DCT to the images and comparing the resulting frequency coefficients both DC and AC and combinations of these among others. Each of these methods will now be described in more detail below.

The absolute error AE count method is a method of differentiating between two consecutive images. The method analyzes the images pixel by pixel to determine the number of different pixels within two consecutive frames and performs such a comparison for each consecutive frame pair in the series of frames. In this embodiment the images may need to be preprocessed for example low pass filtered bit quantization etc. beforehand.

Another method of determining whether two consecutive images captured by the imaging device or frame grabber are different is by using a mean absolute error MAE normalized. The MAE algorithm may be expressed as follows in Equation 1 

The mean squared error MSE algorithm method is an industry standard method that is computationally demanding relative to the MAE method. The MSE algorithm may be expressed as follows in Equation 2 

Next the peak signal to noise ratio PSNR is also an industry standard method. The PSNR algorithm may be expressed as follows in Equation 3 

Root mean squared error RMSE algorithm may also be employed in determining whether two consecutive images captured by the imaging device or frame grabber are different. The RMSE algorithm may be expressed as follows in Equation 4 

Yet another method may include the use of a normalized sum of squared differences root mean squared error NRMSE algorithm. The NRMSE algorithm is an industry standard with a balance between accuracy and computational resource utilization. The NRMSE algorithm may be expressed as follows in Equation 5 

Other methods include employing a normalized cross correlation method. The normalized cross correlation method may be used to determine whether two consecutive images are different. A histogram comparison may also be relatively easy to perform although it may be less accurate compared to other methods. Use of simple hash functions for example MD5 SHA are computationally demanding and may be subject to false matches due to hash collisions. Further another method may include utilization of a wavelet transform algorithm or a Fourier transform algorithm. Additionally a discrete cosine transform DCT may be applied to the images and one may compare the resulting frequency coefficients both DC and AC . As for the time frequency transform algorithms such as the above mentioned wavelet transform Fourier transform algorithm and DCT algorithm the resulting coefficients of these algorithms may be compared in order to determine if consecutive frames are different.

Turning now to a block diagram of one example of a system for measuring video frame rates according to another embodiment of the principles described herein is disclosed. The system depicted in may comprise a source and a display device configured to display a number of frames based on data input from the source . The source may comprise a transmitter and a receiver . The receiver decompresses and renders the video or other data received from the transmitter and outputs it to the display device for display. In one example the receiver may be a thin client. The transmitter for example a server provides video content to the receiver . The receiver and transmitter may be incorporated into the same device or may be separate devices operating on a network. In one example the transmitter may be a server existent at a separate location from and communicatively coupled to the receiver via a network.

The system may further comprise an imaging device configured to capture a number of frames displayed on the display device or as described above the imaging device may be a frame grabber configured to capture individual digital still frames from the output of the source and more specifically the receiver . The imaging device may be in communication with a computing device in which the computing device is configured to process the frames captured by the imaging device . Additionally in one example the system may comprise a counter for use by the computing device in counting the number of different frames output by the source or the number of different frames output by the display device and captured by the imaging device . In another example utilizing a frame grabber the system may comprise a counter for use by the computing device in counting the number of different frames output by the source .

In a test signal is added along with the source in which the test signal is provided to the computing device . In this manner the computing device may provide the data that comprises the test signal . In other example the test signal may be provided by any other source including a computing device other than the computing device depicted in or a standalone pattern generator. The test signal may be combined with the source for example inserted into or overlaid onto the signal provided by the source in order to determine whether the source and or display device drops a frame during display of the frames that are based on the data input from the source . The system can detect if one or more frames were dropped as will be discussed in more detail below.

The source within the system may provide any type of displayed content including 2D for example a presentation and 3D applications with a test signal added. For a situation where the source is data relating to a 3D application for example animated film incorporation of a test signal can be performed by running an application on the processor not shown of the computing device in which the computing device generates a pattern which changes on each frame of the source .

The manifestation of the test signal on the display device may be a test pattern . In one example the test pattern may be four small rectangles configured to display a binary number for example a Gray code system in a small portion of the display device . The test pattern is synchronized to the vertical sync of the source . Thus the changing of the test signal for example changing of the test pattern would represent the frame rate of the source as well as the fastest frame rate that the source and or display device could possibly output. For example the display device may not be able to display all the frames provided by the source and may drop a number of frames. Alternatively in another example the source may drop a number of frames due to the rendering compression and transmission of the data representing the series of frames by the transmitter and the subsequent decompression and rendering of the series of frames by the receiver . In these situations the changing of the test pattern will indicate whether any number of frames of the source were dropped since the test pattern would indicate the display of a non consecutive frame. Although four small rectangles are depicted in any type or form of test signal may be incorporated with the source other than the four rectangles of the present example.

Further although more accurate frame rate calculations may be performed by providing for a different test pattern for each frame in one example the test pattern may be the same pattern for two or more frames. Further the test signal may apply a test pattern to less than all the frames or the same test pattern may be applied to several consecutive or non consecutive frames. In one example the system is configured to detect changes in the test signal indicative of a change in frame.

If the source comprises video content the video content may be augmented with the test pattern by preprocessing it with an application that processes the compressed video content adds the test pattern and saves the resultant bit stream. Depending on the device or computer program used to encode and decode CODEC the source it is possible to add the test pattern without decompressing and recompressing the content. The application used to incorporate the test signal into the source may be embodied as hardware software or a combination of hardware and software.

In the embodiment depicted in the imaging device may be configured to capture only the manifestation of the test signal that is the test pattern . In one example the test pattern is manifested on a small portion of the display area of the display device . In this embodiment the effect on the output frame rate and bit rate of the display device would be insignificant. Further since the test pattern would be positioned at a known location on the display device and would be relatively small the imaging device may be a lower resolution video acquisition system for example VGA instead of UXGA . In this manner the image processing demands placed on the computing device and the system as a whole may be considerably reduced. This is because the images captured by the imaging device are smaller and the detection of individual frames may be reduced to simply looking for whether a given set of pixels are on or off. For example this may be performed by using a simple threshold comparison of the average luminance value of the pixels in a given area of the display device .

The system of utilizes a photodetector . The photodetector may be for example a photoresistor configured to change resistance according to light intensity a solar cell configured to produce a voltage and supply an electric current when illuminated a photodiode configured to convert light into either current or voltage depending upon the mode of operation a charge coupled device CCD and combinations of these among others.

In one example the system of may include a number of photodetectors arranged in an array. In this embodiment if the source has been augmented with the test signal as described above in connection with the system does not need a video camera and associated image processing. In this embodiment an array of photodetectors may be in communication with an input of the computing device . If the photodetectors are positioned in front of the display device where the test pattern will be displayed and the outputs of the individual photodetectors within the array are in communication with an input of the computing device the resulting set of values can be processed more simply to determine the frame rate output by the display device .

Since the output of the source for example digital or analog output directly correlates to the value which the test pattern represents and the test pattern is supposed to represent a differing value for each frame for example an increasing or decreasing or following a known pattern it is simple to determine if a frame or number of frames was were dropped between the source and output frames detected by the photodetectors . As before dividing the number of different detected frames by the period of acquisition for example in seconds allows for the calculation of the average frame rate or the frame rate at any given point in time . The embodiment of provides for a method of accurately calculating the frame rate output by the source and or the display device .

In addition to the system depicted in and described above in one example capture of the video output may be performed by an analog to digital converter ADC connected to a video graphics array VGA output. In another example the photodetector or photodetectors may in communication with a general purpose input output GPIO such as a parallel port or an oscilloscope if the video has been augmented as described above.

Next is a block diagram of one example of a system for measuring video frame rates according to still another embodiment of the principles described herein. The system depicted in may comprise a source comprising a transmitter and a receiver and a display device configured to display a number of frames based on data input from the source . Further the system may comprise a counter for use by the computing device in counting the number of different frames.

The system shown in utilizes a frame grabber as the imaging device. The frame grabber is in communication with the source and may in some examples be electrically coupled directly to the output of the source.

As described above a frame grabber is any hardware software or combinations of hardware and software that capture individual digital still frames from an analog video signal or a digital video stream output by the source . The output of the frame grabber may be in communication with the computing device . In this manner the frame grabber captures individual frames output by the source and more specifically the receiver . These individual frames are then output to the computing device . As described in previous embodiments the computing device then determines if two consecutive images captured by the frame grabber are different. For each different image detected the counter is incremented. The computing device then computes the frame rate by dividing the number indicated by the counter by the duration for example in seconds of the analyzed clip. Thus the embodiment of provides for an even simpler and cost efficient manner of determining the frame rate output from the source .

Turning now to a flowchart illustrating a method of measuring video frame rates according to an embodiment of the principles described herein is depicted. The method begins with directing an imaging device at a display device and capturing a number of images of display device with the imaging device . In an embodiment using a frame grabber this is performed by capturing a number of images output from the receiver with the frame grabber. As discussed earlier the imaging device may be configured to have a frame rate acquisition greater than the output frame rate of the display device or the source. Once the imaging device captures the images the images are output to a computing device . Then the images captured by the imaging device are processed . The computing device and more specifically the processor not shown of the computing device determines whether two consecutive images captured by the imaging device are different . As discussed above determining whether two consecutive images captured by the imaging device are different may be performed by analyzing the data associated with consecutive images using an algorithm to determine if the data representing the consecutive images is different.

If the computing device determines that two consecutive images are the same that is the images are not different determination NO then it is determined if additional images captured by the imaging device and output to the computing device need to be processed . In may be applied in determining if two consecutive images are the same or if two consecutive test patterns are the same. If additional images need to be processed determination YES then the process loops back to and the next two consecutive images are analyzed to determine if they are different . In one example these next two consecutive images are the second image of the previous set of consecutive images analyzed and the next image after the second image of the previous set of images. In this manner each image in the sequence of images is analyzed to determine whether a given image differs from its immediately preceding and immediately subsequent images. If additional images do not need to be processed determination NO then the frame rate is calculated as will be described in more detail below.

If the computing device determines that two consecutive images are not the same that is the images are different determination YES then the counter is incremented . The counter is incremented every time it is determined that two consecutive images differ determination YES .

After a number of images captured by the imaging device are analyzed through the frame rate may be calculated based on the number of different frames detected as indicated by the counter . In one example the number of images analyzed may be any number of images sufficient to determine the frame rate output by the source and or the display device. For example the system may be configured to analyze a set duration of video measured in seconds. Thus by dividing the number of different frames acquired by the imaging device by the duration of the video clip in seconds the frame rate in frames per second fps of the display device or output by the receiver may be determined.

Next the images of the test pattern or the data collected by the frame grabber are output to a computing device . Then the images of the test pattern captured by the imaging device are processed . As described above the computing device determines whether two consecutive images captured by the imaging device are different . If the computing device determines that two consecutive images are the same that is the images are not different determination NO then it is determined if additional images captured by the imaging device and output to the computing device need to be processed . If additional images need to be processed determination YES then the process loops back to and the next two consecutive images are analyzed to determine if they are different . If additional images do not need to be processed determination NO then the frame rate is calculated as will be described in more detail below.

In one example in which the test patterns are detected by an imaging device the values of the test pattern may be decoded directly as ones and zeros and the current values may be compared to previous values to determine if the image changed. In one specific embodiment the camera or photodetector may detect for example whether a change in intensity of a portion of the display device in the area the camera or photodetector is imaging occurred or not. In this embodiment image processing is not required to determine if the image has changed or not. Simply looking for the number to change is sufficient. By knowing the expected sequence for example the Gray code it is possible to tell if any frames were dropped.

If the computing device determines that two consecutive images of the test pattern are not the same that is the images are different determination YES then the counter is incremented each time the test pattern changes or a different frame is detected in the case of the embodiment depicted in . After a number of images captured by the imaging device are analyzed through the frame rate may be calculated based on the number of different test patterns or frames detected as indicated by the counter . As in previous embodiments dividing the number of different frames acquired by the imaging device as indicated by the counter by the duration of the video clip in seconds the frame rate in frames per second fps of the display device may be determined.

The preceding description has been presented only to illustrate and describe embodiments and examples of the principles described. This description is not intended to be exhaustive or to limit these principles to any precise form disclosed. Many modifications and variations are possible in light of the above teaching.

