---

title: Apparatus for displaying an image and sensing an object image, method for controlling the same, and computer-readable storage medium storing the program for controlling the same
abstract: The present invention includes: a display/optical sensor section () that displays an image and captures an object image located in the vicinity of the display/optical sensor section (); a browser processing section () that causes a window including a placement area to be displayed on the display/optical sensor section (), the placement area being an area for placing an object; an API processing section () that converts first area information into second area information, the first area information indicating the location of the placement area in the window, the second area information indicating the location of the placement area in the display/optical sensor section (); and a driver processing section () that derives a captured image, the captured image being an image of the object located in the vicinity of the display/optical sensor section () and captured through an area defined by the second area information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08698742&OS=08698742&RS=08698742
owner: Sharp Kabushiki Kaisha
number: 08698742
owner_city: Osaka
owner_country: JP
publication_date: 20100308
---
The present invention relates to an apparatus for displaying an image and sensing an object image the apparatus capable of concurrently carrying out display of an image and capture of an image of an object a method for controlling the same a program for controlling the same and a computer readable storage medium storing the program.

In recent years the Internet has become popular. This has led to extensive use of a technique that uses a WWW World Wide Web browser or the like to allow a client device such as a PC Personal Computer to obtain download data from a server device and to transmit upload data to the server device. Thanks to this a user can uses the WWW browser to obtain e.g. a certain Web page from the server device and can transmit to the server device a document image and or the like captured by a scanner device or the like.

As an example of means to transmit data from the client device to the server device with use of the WWW browser use of a Web page shown in is considered. shows an example of a WWW browser screen that displays a Web page for transmitting data to a server device. The description here deals with as an example a case where the data to be sent to the server device is data of an image of a name card captured by a scanner device or the like.

This Web page is described in a language such as HTML HyperText Markup Language so that an image specified in a text box is transmitted to the server device in response to a push of a SEND button shown in .

That is a user can use this Web page in the following manner 1 First the user causes a scanner device or the like to read a name card so that an image of the name card is generated. 2 Thereafter the user specifies the generated image on the Web page and then pushes the SEND button. By carrying out this operation the user can send the image of the name card to the server device.

Incidentally there have been conventionally known client devices each having a scanning capability. Among these in particular there is a display capturing device capable of carrying out in a single screen display of an image and capture of an image of a document and or the like. Specifically this display capturing device is configured such that i a plurality of light emitting elements for image display and ii a plurality of light receiving elements for capturing an image of a document etc. placed on a display screen are arranged in a single screen. Installing a WWW browser in this display capturing device allows a user to carry out in a single screen i operation for capturing a document etc. and ii operation for transmitting a document image etc. with use of the WWW browser. However even in this case the user must individually carry out i the operation for capturing an image of the document etc. and ii the operation for transmitting the image in order to transmit the image of the name card to the server device.

Other examples of the technique for transmitting data from the client device to the server device with use of the so called web techniques encompass not only the example described above but also techniques disclosed in Patent Literatures 1 and 2.

Patent Literature 1 discloses a technique for uploading data held by a PC or a personal digital assistant to a facsimile device on the basis of an HTML file and a CGI Common Gateway Interface program. Patent Literature 2 discloses an image processing device that displays a predetermined button on a display section in accordance with an HTML document obtained from a server device and in response to a push of the button transmits to the server device a document image scanned by a scanner device.

As described above in the case where the Web page explained with reference to is used to transmit to the server device an image of a document and or the like scanned by the scanner device or the above described display capturing device the user must carry out individually i the operation for capturing an image of the document etc. and ii the operation for transmitting the document image with use of the WWW browser.

Further although the above described display capturing device has the function of capturing an image of a document and or the like with its capture surface this function does not closely cooperate with the so called web techniques. Therefore it is not easy for the server device to provide a Web page SaaS Software as a Service application for causing the capture surface to capture of an image of a document and or the like.

One possible measure for solving these problems is as follows A display capturing device where a single surface serves both as a display surface and a capture surface is made capable of capturing an image of a document and or the like placed on a WWW browser that shows a Web page provided by a server device and a captured image is transmitted from the WWW browser to the server device. However such a technique is not disclosed in Patent Literature 1 or 2.

The present invention was made in view of the above problems and an object of the present invention is to provide an apparatus for displaying an image and sensing an object image where a single surface serves both as a display surface and a capture surface that displays a placement area which is not shown at a fixed position and that is capable of capturing an image of an object placed on the placement area a method for controlling the same a program for controlling the same and a computer readable storage medium storing the program.

In order to solve the foregoing problems an apparatus for displaying an image and sensing an object image according to the present invention is an apparatus for displaying an image and sensing an object image the apparatus comprising a panel component that displays an image and captures an object image located in the vicinity of the panel component the apparatus further comprising window display control means that causes a window including a placement area to be displayed on the panel component the placement area being an area for placing an object coordinates converting means that converts first area information into second area information the first area information indicating the location of the placement area in the window the second area information indicating the location of the placement area in the panel component and image deriving means that derives a capture image the captured image being an image of the object located in the vicinity of the panel component and captured through an area defined by the second area information.

Further a method for controlling an apparatus for displaying an image and sensing an object image according to the present invention is a method for controlling an apparatus for displaying an image and sensing an object image the apparatus comprising a panel component that displays an image and captures an object image located in the vicinity of the panel component the method comprising a window display control step of causing a window including a placement area to be displayed on the panel component the placement area being an area for placing an object a coordinates converting step of converting first area information into second area information the first area information indicating the location of the placement area in the window the second area information indicating the location of the placement area in the panel component and an image deriving step of deriving a captured image the captured image being an image of the object located in the vicinity of the panel component and captured through an area defined by the second area information.

According to the above arrangement it is possible to cause the window including the placement area to be displayed on the panel component the placement area being an area for placing an object. Further it is possible to convert first area information into second area information the first area information indicating the location of the placement area in the window the second area information indicating the location of the placement area in the panel component. Still further it is possible to obtain a captured image the captured image being an image of the object located in the vicinity of the panel component and captured through an area defined by the second area information.

This makes it possible to obtain the second area information from the first area information. Therefore wherever the window is displayed on the display surface and wherever the placement area is placed in the window it is possible to determine the position of the placement area in the panel component.

This yields the effect of causing the panel component to reliably capture the image of the object placed on the placement area in the window. That is this yields the effect of causing the panel component to reliably capture the image of the object placed on the placement area which is not shown at a fixed position in the panel component.

Additional objects features and strengths of the present invention will be made clear by the description below. Further the advantages of the present invention will be evident from the following explanation in reference to the drawings.

Schematically speaking a data display sensor apparatus apparatus for displaying an image and sensing an object image of the present embodiment includes a sensor equipped liquid crystal panel planer member described later capable of i displaying data of an image or the like and ii sensing an object image located in the vicinity of the sensor equipped liquid crystal panel . Further the data display sensor apparatus is capable of capturing an image of an object located in the vicinity of the sensor equipped liquid crystal panel while the sensor equipped liquid crystal panel displays an image See .

Note that the object refers to a physical object which can be an object whose image is to be captured by the sensor equipped liquid crystal panel . More specifically the object can be a text document including characters and or a picture s examples of which encompass books cards leaflets and various materials. In particular the object assumed herein is a name card C on which a name an address an e mail address and or the like information are written. Note that capturing of an image of the object is also expressed as scanning herein.

The following will schematically describe with reference to a configuration of a system including the data display sensor apparatus of the present embodiment and an external server first external device second external device . is a view schematically showing the configuration of the system . Assume that the data display sensor apparatus and the external server are connected to each other via a generally known communication network and that the data display sensor apparatus and the external server can communicate with each other through use of a generally known communication protocol such as HTTP HyperText Transfer Protocol .

The data display sensor apparatus is a client terminal e.g. a PC provided with a function of requesting the external server for a source code hereinafter referred to as source H of a Web page described in HTML. Further the data display sensor apparatus displays in accordance with the source H obtained from the external server the Web page through use of a WWW browser window .

Note that the WWW browser is hereinafter referred to as browser W . The browser W is displayed on the sensor equipped liquid crystal panel by an OS operating system program of the data display sensor apparatus . Note also that the position and size of the browser W shown can be changed by user s operation or the like operation and are not fixed to specific ones.

Here assume that the source H is described so as to display on a Web page content an area hereinafter referred to as capturing area RA that is 1 an area placement area indicating a range where an object is to be placed and 2 an area indicating a range corresponding to an image which is extracted as a captured result from an image later described captured image CG captured by an entire capture surface of the sensor equipped liquid crystal panel . Further the source H is also described such that in response to a user s instructions the source H instructs the capture surface of the sensor equipped liquid crystal panel to capture an image of an object located in the vicinity thereof and transmits the captured image CG to the external server . Note that these descriptions are represented by tags such as a scan tag ST which will be described later.

Therefore in accordance with the source H obtained from the external server the data display sensor apparatus displays the Web page where the capturing area RA is shown. Further the data display sensor apparatus derives a captured image CG from an image captured by the entire capture surface of the sensor equipped liquid crystal panel a part corresponding to the capturing area RA. Then the data display sensor apparatus transmits the extracted captured image CG to the external server via the browser W more specifically by using an HTML POST method . Note that the Web page where the capturing area RA is shown is hereinafter referred to as capturing page CP .

Meanwhile the external server is a server device provided with the function of offering in response to a request from the data display sensor apparatus the source H to the data display sensor apparatus . Further the external server includes a storage section that stores various data. Examples of the various data encompass the source H to be offered to the data display sensor apparatus and the captured image CG sent from the data display sensor apparatus .

In the external server an application program is executed which carries out a predetermined process on the captured image CG sent from the data display sensor apparatus . As described above in the present embodiment the object is assumed to be the name card C and therefore the application program is particularly assumed to recognize characters of a name an address an e mail address and or the like information and to carry out a process for registering data of the recognized characters in a table which is stored as an address list in the storage section . This application program is hereinafter referred to as character recognition application .

In the case where the character recognition application is executed in the external server the system is also referred to as name card management system for example.

The following will describe with reference to a typical example of processes carried out by the data display sensor apparatus for causing the sensor equipped liquid crystal panel to capture an image of an object that is placed on the capturing area RA shown in the capturing page CP. Note that the description here deals with an overview of the processes and details of the processes will be described later.

First with reference to characters displayed on the name card C which is the object will be specifically described. a of is a view showing a front side of the name card C. As shown in a of the front side of the name card C includes i the characters MIMURA which represent a surname ii the characters YAMATOKORIYAMA SHI NARA which represent an address and iii the characters mimura xxx.com which represent an e mail address. b of is a view showing a back side of the name card C.

Next is a view schematically showing the following state On a desktop area DA i.e. an entire display surface of the sensor equipped liquid crystal panel a desktop screen of the OS program and the browser W i.e. an application program are shown so as to overlap each other and on a client area CA described later of the browser W the capturing page CP is shown in accordance with the source H obtained from the external server . As shown in the capturing area RA is shown in the capturing page CP. In the capturing area RA is gray colored.

Note that the client area CA refers to a part where content such as a Web page is shown in a window region of the browser W i.e. a part not including a title bar a status bar and the like . In the client area CA is an area surrounded by broken lines.

Next the following will describe an example of the description of the source H to be processed by the data display sensor apparatus . is a view schematically showing an example of the description of the source H. In particular as illustrated in the source H includes a form tag FT a scan tag ST and an input tag IT.

The form tag FT describes as an action carrying out a process of transmitting by the POST method on an URL Uniform Resource Locator specified as http meishi.jp . Note that the URL specified as http meishi.jp is assumed to be an URL on the external server . Note also that data to be sent by the POST method is a captured image CG which will be described later.

The scan tag ST describes the capturing area RA. In the example shown in the scan tag ST describes that the capturing area RA has a width indicated as width of 440 a height indicated as height of 300 and a color indicated as bgcolor of gray .

Note that the scan tag ST is a tag that is not defined by the HTML standards. As such assume that the example here uses an HTML that is extended from the standards and that uniquely defines the scan tag ST. Further assume that the browser W has a capability expanded so as to interpret the scan tag ST and carry out a process corresponding to the tag.

The input tag IT describes a button BT that a user can push. A push of the button BT starts a process for causing the sensor equipped liquid crystal panel to capture an image of an object placed on the capturing area RA and then an image generated as a result of the capture is transmitted by the POST method as described by the form tag FT.

Next is a view schematically showing a state where a user places in the state of the name card C on the capturing area RA for the purpose of performing capture of an image of the front side of the name card C. In order to cause the image of the front side of the name card C to be captured the name card C is placed in such a manner that the front side of the name card C is in contact with the sensor equipped liquid crystal panel . In this state the user can see the back side of the name card C as shown in .

Then when the user pushes the button BT while the name card C is placed on the capturing area RA a process starts for causing the sensor equipped liquid crystal panel to capture an image of the front side of the name card C placed on the capturing area RA.

Next is a view schematically showing an image generated in the data display sensor apparatus as a result of the sensor equipped liquid crystal panel s capture of the image of the front side of the name card C placed on the capturing area RA.

The data display sensor apparatus extracts from an image captured by the entire capture surface of the sensor equipped liquid crystal panel only a part corresponding to the capturing area RA so as to generate the image shown in . As such the generated image and the capturing area RA are identical in size. Then the extracted image is transmitted to the external server by the POST method. Note that the extracted image is the captured image CG.

In the case where the user places the name card C within the capturing area RA the captured image CG includes as shown in i the characters MIMURA which represent a surname ii the characters YAMATOKORIYAMA SHI NARA which represent an address and iii the characters mimura xxx.com which represent an e mail address each of which items are described on the front side of the name card C. Then in the external server the character recognition application recognizes these characters indicating the name address e mail address included in the captured image CG and carries out a process for registering data of the recognized characters in a table stored as an address list in the storage section .

Note that an image of the object captured by the sensor equipped liquid crystal panel is obtained as a mirror image of the front side of the object. Therefore the image thus obtained is mirror reversed by a generally known method.

In order to extract cut out the captured image CG from the image captured by the entire capture surface of the sensor equipped liquid crystal panel it is necessary to identify information second area information indicative of the location of the capturing area RA in a coordinate system hereinafter referred to as desktop coordinate system whose origin point is a top left vertex i.e. DO of the desktop area DA. The information indicative of the location of the capturing area RA is specifically a group of coordinates representing representative points vertexes of the capturing area RA.

Note that the OS program uses the desktop coordinate system to manage the positions of parts windows icons etc. shown on the desktop screen. The desktop area DA coincides with the entire display surface of the sensor equipped liquid crystal panel . Therefore a physical position of the display surface of the sensor equipped liquid crystal panel is indicated by using the desktop coordinate system.

Here the browser W shows the capturing area RA in the client area CA. Therefore the browser W has information first area information indicative of the location of the capturing area RA in a coordinate system hereinafter referred to as client coordinate system whose origin point is a top left vertex i.e. CO of the client area CA. Note that the browser W uses the client coordinate system to manage the positions of parts buttons icons characters etc. shown in the capturing page CP which is content.

Therefore the present embodiment carries out prior to the process for extracting the captured image CG a process for converting the information indicative of the location of the capturing area RA in the client coordinate system into the information in the desktop coordinate system. Then the information obtained by the conversion is used to carry out the process for extracting the captured image CG.

Note that coordinates in the client coordinate system are hereinafter referred to as client coordinates and coordinates in the desktop coordinate system is hereinafter referred to as desktop coordinates .

The following will specifically describe with reference to the client coordinates and the desktop coordinates of the capturing area RA. is a view schematically showing a positional relationship between the desktop area DA the client area CA and the capturing area RA.

In the capturing area RA is a rectangular area where a top left vertex is a point R and a bottom right vertex is a point R.

The points R and R are represented in the client coordinates as Xb Yb and Xb Xc Yb Yc respectively. Note that the browser W has the values Xb Yb Xc and Yc in order that to show the capturing area RA in the capturing page CP.

Meanwhile the points R and R are represented in the desktop coordinates as Xa Xb Ya Yb and Xa Xb Xc Ya Yb Yc respectively.

That is in this example merely adding Xa and Ya to the client coordinates allows conversion into the desktop coordinates. Thus it is possible to convert the client coordinates into the desktop coordinates merely by a simple calculation.

In other words it is possible to find the coordinates after conversion from a relative position between i the position of the top left vertex CO of the client area CA in the desktop coordinate system and ii the positions R and R of the capturing area RA in the client coordinate system.

The sensor equipped liquid crystal panel included in the data display sensor apparatus is a liquid crystal panel capable of not only display of data but also detection of an image of an object. Here the detection of the image of the object means e.g. i detection of a position at which a user points touches with his her finger a pen or the like or ii capture scanning of an image of a printing material or the like. Note that the device to be used for display is not limited to the liquid crystal panel and may be an organic EL Electro Luminescence panel or the like.

The following will describe with reference to the structure of the sensor equipped liquid crystal panel . is a view schematically showing a cross section of the sensor equipped liquid crystal panel . Note that the sensor equipped liquid crystal panel described herein is just one example. Alternatively a sensor equipped liquid crystal panel having any structure may be used as long as a single surface of the panel serves both as a display surface and a capture surface.

As shown in the sensor equipped liquid crystal panel includes an active matrix substrate A disposed on a back side of the sensor equipped liquid crystal panel a counter substrate B disposed on a front side thereof and a liquid crystal layer sandwiched between these substrates. The active matrix substrate A includes pixel electrodes data signal lines an optical sensor circuit not illustrated an alignment film and a polarizing plate . The counter substrate B includes color filters red green and blue a light shielding film a counter electrode an alignment film and a polarizing plate . Note that a backlight is provided behind the sensor equipped liquid crystal panel .

A photodiode included in the optical sensor circuit is provided in the vicinity of the pixel electrode for which the blue color filter is provided however the present invention is not limited to this. Alternatively the photodiode may be provided in the vicinity of the pixel electrode for which the red color filter is provided. Further alternatively the photodiode may be provided in the vicinity of the pixel electrode for which the green color filter is provided.

Next the following will describe with reference to a method of detecting an image of an object. is a view schematically showing a state in which detection of an image of an object is performed by sensing a reflected image of the object. Light is emitted from the backlight and then the optical sensor circuit including the photodiode senses the light reflected by the object such as the name card C whereby the reflected image of the object can be sensed. In this manner the sensor equipped liquid crystal panel can detect the image of the object by sensing the reflected image thereof.

Next essential components of the data display sensor apparatus will be described with reference to . is a block diagram showing the essential components of the data display sensor apparatus . As shown in the data display sensor apparatus includes a display optical sensor section a circuit control section a data processing section a main control section a storage section a temporary storage section an operation section an external communication section an audio output section and an audio input section .

The display optical sensor section is the so called liquid crystal display device with built in optical sensor. The display optical sensor section includes the sensor equipped liquid crystal panel the backlight and a peripheral circuit for driving the sensor equipped liquid crystal panel and the backlight .

The sensor equipped liquid crystal panel includes a plurality of pixel circuits and a plurality of optical sensor circuits both of which are arranged in a matrix manner. Detailed structure of the sensor equipped liquid crystal panel will be described later.

The peripheral circuit includes a liquid crystal panel driving circuit an optical sensor driving circuit a signal converting circuit and a backlight driving circuit .

The liquid crystal panel driving circuit is a circuit that outputs a control signal G and a data signal S according to a timing control signal TC and a data signal D from the display control section of the circuit control section so as to drive the pixel circuits . Details of a driving method of the pixel circuits will be described later.

The optical sensor driving circuit is a circuit that applies a voltage to a signal line R according to a timing control signal TC from a sensor control section of the circuit control section so as to drive the optical sensor circuit . Details of a driving method of the optical sensor circuit will be described later.

The signal converting circuit is a circuit that converts sensor output signals SS outputted from the optical sensor circuit into digital signals DS and then transmits the resultant digital signals to the sensor control section .

The backlight includes a plurality of white LEDs Light Emitting Diodes and is disposed on the back of the sensor equipped liquid crystal panel . When the power supply voltage is applied from the backlight driving circuit to the backlight the backlight lights up and illuminates the sensor equipped liquid crystal panel . A color of the LEDs in the backlight is not limited to white and may be any other color. Further the backlight may include instead of LEDs a cold cathode fluorescent tube CCFL Cold Cathode Fluorescent Lamp .

When a control signal BK from a backlight control section of the circuit control section is in high level the backlight driving circuit applies the power supply voltage to the backlight . Conversely when the control signal BK from a backlight control section is in low level the backlight driving circuit does not apply the power supply voltage to the backlight .

Next the circuit control section will be described. The circuit control section serves as a device driver that controls the peripheral circuit of the display optical sensor section . The circuit control section includes a display control section a sensor control section a backlight control section and a display data storage section .

The display control section receives display data from a display data processing section of the data processing section and transmits the timing control signal TC and the data signal D to the liquid crystal panel driving circuit of the display optical sensor section according to an instruction from the display data processing section so that the display data having been received from the display data processing section is displayed on the sensor equipped liquid crystal panel .

The display control section temporarily stores the display data having been received from the display data processing section into the display data storage section . Then the display control section generates the data signal D on the basis of the temporarily stored display data. The display data storage section is for example VRAM video random access memory or the like.

The sensor control section transmits the timing control signal TC to the optical sensor driving circuit of the display optical sensor section according to an instruction from a sensor data processing section of the data processing section so that the sensor equipped liquid crystal panel executes scanning.

Further the sensor control section receives the digital signals DS from the signal converting circuit . Then the sensor control section generates image data on the basis of the digital signals DS corresponding to the sensor output signals SS having been outputted from all of the optical sensor circuits included in the sensor equipped liquid crystal panel . In other words the sensor control section generates image data on the basis of an image captured in the entire capturing area of the sensor equipped liquid crystal panel . Then the sensor control section transmits the image data thus generated to the sensor data processing section .

The backlight control section transmits the control signal BK to the backlight driving circuit of the display optical sensor section according to instructions from the display data processing section and the sensor data processing section so that the backlight is driven by the backlight driving circuit .

Assume that the data display sensor apparatus includes a plurality of display optical sensor sections . In this case upon receipt of an instruction including the designation of which of the display optical sensor sections to display the display data from the data processing section the display control section controls the liquid crystal panel driving circuit of the designated display optical sensor section . Further upon receipt of an instruction including the designation of which of the display optical sensor sections to scan the object from the data processing section the sensor control section controls the optical sensor driving circuit of the designated display optical sensor section and receives digital signals DS from the signal converting circuit of the designated display optical sensor section .

Next the data processing section will be described. The data processing section serves as a middleware that provides an instruction to the circuit control section according to a command received from the main control section . Details of the command will be described later.

The data processing section includes the display data processing section and the sensor data processing section . When the data processing section receives the command from the main control section the display data processing section and or the sensor data processing section operates according to a value of each field described later contained in the received command.

The display data processing section receives display data from the main control section and also provides instructions to the display control section and the backlight control section according to the command having been received by the data processing section so that the received display data is displayed on the sensor equipped liquid crystal panel . Operations of the display data processing section corresponding to commands will be described later.

The sensor data processing section provides instructions to the sensor control section and the backlight control section according to the command having been received by the data processing section .

Further the sensor data processing section receives the image data from the sensor control section and then stores the received image data itself into an image data buffer . Subsequently the sensor data processing section transmits at least one of the following data entire image data partial image data including coordinate data of a partial image and coordinate data to the main control section on the basis of the image data stored in the image data buffer according to the command having been received by the data processing section . The entire image data the partial image data and the coordinate data will be described later. Further operations of the sensor data processing section corresponding to commands will be described later.

Next the main control section controls operations of the components included in the data display sensor apparatus . The main control section reads various kinds of programs stored in the storage section to control the components of the data display sensor apparatus and realize various kinds of functions of the data display sensor apparatus .

The main control section transmits the command and the display data to the data processing section so as to cause the sensor equipped liquid crystal panel to show the display data and to cause the sensor equipped liquid crystal panel to perform scanning of the object. Further in a case where the command designates data type the main control section receives as a response to the command at least one of the following data the entire image data the partial image data and the coordinate data from the data processing section .

Note that the circuit control section the data processing section and the main control section are each realized by CPU Central Processing Unit memory and the others. Further the data processing section may be realized by a circuit such as ASIC application specific integrate circuit .

Next the storage section stores 1 control programs for the respective components 2 OS program 3 application programs all of which are executed by the main control section and 4 various kinds of data to be read for execution of these programs. The storage section is realized by a non volatile storage device such as flash memory. The storage section also contains API Application Programming Interface used by the application programs to use the functions of the OS and a driver for performing communications with various kinds of devices.

The temporary storage section is realized by a volatile storage device such as RAM Random Access Memory . The temporary storage section is also used as a workspace where data is temporarily held in the process of the main control section executing the above described programs.

The operation section accepts an input operation from the user of the data display sensor apparatus . The operation section is realized by an input device such as switches a remote controller a mouse and or a keyboard for example. The operation section generates a control signal corresponding to the input operation from the user of the data display sensor apparatus and then transmits the generated control signal to the main control section .

The above switches assume to be hardware switches such as a power supply switch that is an on off switch for the power supply and a user switch that has predetermined functions assigned.

The data display sensor apparatus may optionally include an external communication section for communications with an external device through wireless or wired connection an audio output section for voice output such as a speaker and an audio input section for input of audio signals such as a microphone.

The following will describe details of the command to be transmitted from the main control section to the data processing section with reference to . is a schematic diagram showing an exemplary frame structure of the command. is an explanatory view showing exemplary values that can be assigned to each of the fields contained in the command and showing an overview of the values.

As shown in the command contains a header field a data obtaining timing field a data type field a scanning mode field a scanned image grayscale level field a scanning resolution field a scanning panel field a display panel field and a reserve field. To each of the fields the values shown in for example can be assigned.

The header field is a field indicating start of a frame. A value of the header field may be any value as long as it can identifies the header field.

The data obtaining timing field is a field to designate a timing at which data is to be transmitted to the main control section . To the data obtaining timing field values of 00 sense 01 event and 10 all can be assigned.

 Sense specifies immediate transmission of the latest data. Therefore upon receipt of the command having sense assigned as a value of the data obtaining timing field the sensor data processing section immediately transmits the latest data designated by the data type filed to the main control section .

 Event specifies transmission at a timing at which there occurs change to the image data received from the sensor control section . Therefore upon receipt of the command having event assigned as a value of the data obtaining timing field the sensor data processing section transmits data designated by the data type field to the main control section at a timing when a change greater than a predetermined threshold value has occurred to the image data received from the sensor control section .

 All specifies transmission of data at predetermined intervals. Therefore upon receipt of the command having all assigned as a value of the data obtaining timing field the sensor data processing section transmits data designated by the data type field to the main control section at predetermined intervals. The predetermined intervals coincide with intervals at which scanning is performed by the optical sensor circuit .

Next the data type field is a field to designate a type of data obtained from the sensor data processing section . To the data type field values of 001 coordinates 010 partial image and 100 entire image for example can be assigned. With a sum of any combinations of these values coordinates and either partial image or entire image are concurrently designated. For example 011 can be specified for concurrent designation of coordinates and partial image .

Upon receipt of the command having entire image assigned as a value of the data type field the sensor data processing section transmits the image data itself stored in the image data buffer to the main control section . The image data itself stored in the image data buffer is referred to as entire image data .

Upon receipt of the command having partial image assigned as a value of the data type field the sensor data processing section extracts from the image data received from the sensor control section a region including a part where a change greater than the predetermined threshold value has occurred and then transmits image data corresponding to the extracted region to the main control section . Here such image data is referred to as partial image data . In a case where a plurality of partial image data items have been extracted the sensor data processing section the extracted partial image data items to the main control section .

Further upon receipt of the command having partial image assigned as a value of the data type field the sensor data processing section detects typical coordinates of the partial image data and then transmits to the main control section coordinate data representing the location of the typical coordinates in the partial image data. Examples of the typical coordinates include center coordinates of the partial image data and barycentric coordinates of the partial image data.

Next upon receipt of the command having coordinates assigned as a value of the data type field the sensor data processing section transmits to the main control section coordinate data representing the location of the typical coordinates in the entire image data. In a case where a plurality of partial image data items are extracted the sensor data processing section detects sets of typical coordinates respectively corresponding to the extracted partial image data items in the entire image data and then transmits to the main control section coordinate data items representing the respective sets of typical coordinates multipoint detection .

Specific examples of the entire image data the partial image data and the coordinate data will be described later with reference to a schematic diagram.

The scanning mode field is a field to designate whether the backlight is to be lit up or not during the execution of scanning. To the scanning mode field values of 00 reflection 01 transmission and 10 reflection transmission for example can be assigned.

 Reflection specifies scanning performed with the backlight lit up. Therefore upon receipt of the command having reflection assigned as a value of the scanning mode field the sensor data processing section provides instructions to the sensor control section and the backlight control section so that the sensor driving circuit and the backlight driving circuit operate in sync with each other.

 Transmission specifies scanning performed with the backlight turned out. Therefore upon receipt of the command having transmission assigned as a value of the scanning mode field the sensor data processing section provides instructions to the sensor control section and the backlight control section so that the optical sensor driving circuit is operated but the backlight driving circuit is not operated. Reflection transmission specifies scanning performed with reflection and transmission used in combination.

The scanned image grayscale level field is a field to designate grayscale levels of the partial image data and the entire image data. To the scanned image grayscale level field vales of 00 binary and 01 multilevel for example can be assigned.

Upon receipt of the command having binary assigned as a value of the scanned image grayscale level field the sensor data processing section transmits to the main control section the partial image data and the entire image data in the form of monochrome data.

Meanwhile upon receipt of the command having multilevel assigned as a value of the scanned image grayscale level field the sensor data processing section transmits to the main control section the partial image data and the entire image data in the form of multilevel grayscale data.

The scanning resolution field is a field to designate resolutions of the partial image data and the entire image data. To the resolution field values of 0 high and 1 low for example can be assigned.

 High specifies a high resolution. Therefore upon receipt of the command having high assigned as a value of the scanning resolution field the sensor data processing section transmits to the main control section the partial image data and the entire image data at high resolutions. For example it is desirable that high is designated for image data to be subjected to image processing such as image recognition image data of a fingerprint .

 Low specifies a low resolution. Therefore upon receipt of the command having low assigned as a value of the scanning resolution field the sensor data processing section transmits the partial image data and the entire image data at low resolutions to the main control section . For example it is desirable that low is designated for image data which sufficiently identifies the position or the like of a touch e.g. image data of a finger or a hand touched .

The scanning panel field is a field to designate which of the display optical sensor sections to scan the object. To the scanning panel field values of 001 first display optical sensor section and 010 second display optical sensor section for example can be assigned. With a sum of these values a plurality of display optical sensor sections can be concurrently designated. For example 011 can be assigned for concurrent designation of the first and second display optical sensor sections .

The sensor data processing section provides instructions to the sensor control section and the backlight control section so that the sensor control section and the backlight control section control the optical sensor driving circuit and the backlight driving circuit of the display optical sensor section designated by the scanning panel field contained in the received command.

The display panel field is a field to designate which of the display optical sensor sections to show the display data. To the display panel field values of 001 first display optical sensor section and 010 second display optical sensor section for example can be assigned. With a sum of these values a plurality of display optical sensor sections can be concurrently designated. For example 011 can be assigned for concurrent designation of the first and second display optical sensor sections .

For example upon receipt of the command having first display optical sensor section assigned as a value of the display panel field the display data processing section provides instructions to the display control section and the backlight control section so that under control of the display control section and the backlight control section the liquid crystal panel driving circuit and the backlight driving circuit of the display optical sensor section cause the first display optical sensor section to show the display data.

Hereinafter for the purpose of explanation the data display sensor apparatus according to the present embodiment assumes to include one display optical sensor section . Therefore in order to perform scanning the command having first display optical sensor section 001 assigned as a value of the scan panel field is transmitted to the data processing section . Further in order to perform data display the command having first display optical sensor section 001 assigned as a value of the display panel field is transmitted to the data processing section .

Next the reserve field is a field to specify any further information other than the information items that can be specified in the foregoing fields if necessary.

For the applications executed by the main control section all of the foregoing fields are not necessarily used in transmitting the command. In this case an invalid value NULL value etc. is set in unnecessary fields to use.

Further in order to obtain coordinate data corresponding to a position at which the user touches with his her finger a pen or the like the command having coordinates assigned in the data type field is transmitted to the data processing section . Since the finger the pen etc. are movable it is desirable that all is assigned in the data obtaining timing field of the command in order to obtain the coordinate data . Further scanning accuracy is not necessarily high since it is essential only that the coordinate data corresponding to the position at which the user touches can be obtained. Therefore low should be set as a value of the resolution field of the command.

Still further under the situation where coordinates is assigned in the data type field of the command assume that the user touches the sensor equipped liquid crystal panel with his her plural fingers or plural pens at the same time. even in this case it is possible to obtain coordinate data items respectively corresponding to the positions at which the user touched multipoint detection .

Yet further in order to obtain image data of a document or the like the command having entire image assigned in the data type field is transmitted to the data processing section . Generally the document or the like is scanned while it is remained still. Therefore it is not necessary to perform scanning periodically. In this case it is desirable that sense or event is assigned in the data obtaining timing field. For scanning of the document or the like it is desirable that the document or the like is scanned with a high degree of accuracy in order to increase user s readability of characters. Therefore it is desirable that high is assigned in the resolution field.

Giving an example the following will describe the entire image data the partial image data and the coordinate data with reference to . Image data shown in a of is image data obtained as a result of scanning of the entire sensor equipped liquid crystal panel when the object is not placed on the sensor equipped liquid crystal panel . Further image data shown in b of is image data obtained as a result of scanning of the entire sensor equipped liquid crystal panel when the user is touching the sensor equipped liquid crystal panel with his her finger.

User s touch of the sensor equipped liquid crystal panel with his her finger changes the amount of light received by the optical sensor circuit in an area around the touched spot. Accordingly there occurs a change in voltage to be outputted by the optical sensor circuit . As a result of this there occurs change in brightness level as pixel values at the spot touched by the user in the image data generated by the sensor control section .

In the image data shown in b of brightness level as pixel values at a spot corresponding to the user s finger is higher as compared with the image data shown in a of . In b of the partial image data is image data corresponding to a smallest rectangular area area PP including pixel values with great changes in brightness level compared with a predetermined threshold value.

Further coordinate data of typical coordinates Z of the partial image data area PP in the entire image data area AP is represented by Xa Ya . Coordinate data of the typical coordinates Z in the partial image data area PP is represented by Xp Yp .

The following will describe the structure of the sensor equipped liquid crystal panel and the structure of the peripheral circuit around the sensor equipped liquid crystal panel with reference to . is a block diagram showing essential components of the display optical sensor section particularly the structure of the sensor equipped liquid crystal panel and the structure of the peripheral circuit .

The sensor equipped liquid crystal panel includes the pixel circuits for setting optical transmittance luminance and the optical sensor circuits that each outputs a voltage corresponding to light intensity of light received by the optical sensor circuits . The term pixel circuit collectively refers to an R pixel circuit a G pixel circuit a B pixel circuit respectively corresponding to red green blue color filters.

On the sensor equipped liquid crystal panel are arranged m number of the pixel circuits in the column direction longitudinal direction and 3n number of the pixel circuits in the row direction lateral direction . A group of the R pixel circuit the G pixel circuit and the B pixel circuit all of which form one pixel are contiguously arranged in the row direction lateral direction . The group of these pixel circuits forms one pixel.

Setting of the optical transmittances for the pixel circuits is performed as follows. First to a scanning signal line Gi connected to a gate terminal of a TFT Thin Film Transistor included in the pixel circuit a high level voltage voltage that turns the TFT on is applied. Then a predetermined voltage is applied to a data signal line SRj connected to a source terminal of the TFT in the R pixel circuit . In the same manner optical transmittances for the G pixel circuit and the B pixel circuit are set. Setting of the optical transmittances for these pixel circuits allows for image display on the sensor equipped liquid crystal panel .

Next the optical sensor circuits are arranged for each pixel. Alternatively the optical sensor circuits may be arranged respectively in the vicinities of the R pixel circuit the G pixel circuit and the B pixel circuit

In order to cause the optical sensor circuit to output a voltage corresponding to light intensity the followings are performed. First a predetermined voltage is applied to a sensor reading line RWi connected to one electrode of the capacitor and to a sensor reset line RSi connected to an anode terminal of a photodiode . In this state when light is directed to the photodiode a current corresponding to the amount of incident light is flown to the photodiode . Then according to the current flown to the photodiode a voltage lowers across a node at which the other electrode of the capacitor and the cathode terminal of the photodiode are connected to each other the node is hereinafter referred to as connection node V . Then when a power supply voltage VDD is applied to a voltage application line SDj that is connected to a drain terminal of a sensor preamplifier a voltage across the connection node V is amplified and the amplified voltage is outputted from a source terminal of the sensor preamplifier to a sensing data output line SPj. Thus on the basis of the outputted voltage the amount of light received by the optical sensor circuit can be calculated.

Next the following will describe the liquid crystal panel driving circuit the optical sensor driving circuit and a sensor output amplifier all of which are peripheral circuits around the sensor equipped liquid crystal panel .

The liquid crystal panel driving circuit is a circuit for driving the pixel circuits and includes a scanning signal line driving circuit and a data signal line driving circuit .

The scanning signal line driving circuit sequentially selects according to the timing control signal TC having been received from the display control section one scanning signal line from among the scanning signal lines G through Gm in each line period of time and a high level voltage is applied to the selected scanning signal line and a low level voltage is applied to the other scanning signal lines.

The data signal line driving circuit applies on the basis of the display data D DR DG and DB having received from the display control section a predetermined voltage corresponding to the one line s display data to data signal lines SR through SRn SG through SGn and SB through SBn in each line period of time line sequential mode . Alternatively the data signal line driving circuit may perform driving in a dot sequential mode.

The optical sensor driving circuit is a circuit for driving the optical sensor circuits . The optical sensor driving circuit applies on the basis of a timing control signal TC having been received from the sensor control section a predetermined reading voltage to one sensor reading signal line selected in each line period of time from among sensor reading signal lines RW through RWm and the optical sensor driving circuit applies a voltage other than the predetermined reading voltage to the other sensor reading signal lines. In the same manner the optical sensor driving circuit applies on the basis of the timing control signal TC a predetermined reset voltage to one sensor reset signal line selected in each line period of time from among sensor reset signal lines RS through RSm and the optical sensor driving circuit applies a voltage other than the predetermined reset voltage to the other sensor reset signal lines.

Sensing data output signal lines SP through SPn are divided into a p number of groups p is an integer not less than 1 and not greater than n . The sensing data output signal lines that belong to each group are connected to the sensor output amplifier via a switch that is sequentially turned on by time division. The sensor output amplifier amplifies a voltage from a group of the sensing data output signal lines connected via the switch and then outputs the amplified voltage as a sensor output signal SS SS through SSp to the signal converting circuit .

The following will describe more specific configuration of the data display sensor apparatus with reference to . To make the following explanation more easily understandable explanations of operations of the data processing section and the circuit control section both of which are located between the main control section and the display optical sensor section will be omitted. To be precise for the display of data and the capture of an image of the object each component of the main control section transmits a command to the data processing section the data processing section controls the circuit control section on the basis of the command and the circuit control section then transmits a signal to the display optical sensor section . Further the main control section obtains from the data processing section the entire image etc. as a response to the command having been transmitted to the data processing section .

As shown in the main control section includes a browser processing section window display controlling means source code obtaining means and image transmitting means an API processing section coordinates converting means and a driver processing section image deriving means and image storing means .

First the browser processing section will be described. The browser processing section reads and executes a program for the browser W stored in a browser storage section which will be described later. The browser W executed by the browser processing section makes a request for obtaining the source H describing the capturing page CP to the external server via the external communication section and the browser W receives the source H from the external server . To display the capturing page CP on the basis of the received source H the browser W calls up a display API. The display API is executed by an API processing section which will be described later and the display API is an API for performing communications with a display driver which will be described later.

The browser W executed by the browser processing section may be identical to a browser that has the same functions as those of a generally known WWW browser Internet Explorer etc. except that the browser W has a capability extended so as to interpret the aforementioned scan tag ST. Explanation of details of the browser W will be therefore omitted.

Further the timing at which the source H is obtained from the external server is not particularly limited. For example the source H may be obtained when the user has inputted a URL indicating the location of the source H to the browser W. Alternatively the source H may be obtained at the startup of the browser W.

When the browser W executed by the browser processing section accepts an instruction to execute capture of an image of the object push of a button or the like operation from the user the browser W calls up a capture API for the purpose of performing capture of an image of the object. In this case the browser W obtains client coordinates of the capturing area RA which is described in the source H and calls up the capture API with the obtained client coordinates an argument.

Note that the capture API is executed by a capture API processing section which will be described later and the capture API is an API for performing communications with a capture driver which will be described later.

Further the browser W executed by the browser processing section receives information by which an address inside a captured image storage section can be identified as a response return value from the capture API that has been called up. The captured image storage section will be described later. Note that captured image CG is stored at the address of the captured image storage section as will be described later. The browser W reads the captured image CG stored at the address identified by the received information and then transmits the read captured image CG to the external server via the external communication section .

Next the API processing section will be described. The API processing section reads and executes the display API and the capture API both of which are stored in an API storage section . The API storage section will be described later. The display API and the capture API are APIs for the browser W reading the functions of the OS program. The API processing section includes a display API processing section and a capture API processing section .

The display API processing section reads the display API from the API storage section and then executes the display API. When the browser W calls up the display API for the purpose of displaying the capturing page CP the display API processing section executes the display API. Then the display API calls up the display driver for the purpose of displaying the capturing page CP.

Note that the display driver is executed by a display driver processing section and the display driver is a driver program for performing communications with the data processing section . The display driver processing section will be described later.

The capture API processing section reads the capture API from the API storage section and then executes the capture API. When the browser W calls up the capture API for the purpose of performing capture of an image of the object the capture API processing section executes the capture API.

First the capture API converts the client coordinates of the capturing area RA which are designated as an argument at the calling into desktop coordinates. Then for the purpose of capturing an image of the object the capture driver is further called up. In this case the capture API calls up the capture driver with the desktop coordinates of the capturing area RA which have been obtained after the conversion as an argument.

Note that the capture driver is executed by a capture driver processing section and the capture driver is a driver program for performing communications with the data processing section . The capture driver processing section will be described later.

Further the capture API receives information by which an address inside the captured image storage section can be identified as a response return value from the capture driver that has been called up. Then the capture API transmits the received information as a return value to the browser W which is a calling end.

Next the driver processing section will be described. The driver processing section reads and executes the display driver and the capture driver both of which are stored in a driver storage section . The driver storage section will be described later. For this purpose the driver processing section includes a display driver processing section and a capture driver processing section .

The display driver processing section reads the display driver from the driver storage section and then executes the display driver. When the display API calls up the display driver for the purpose of displaying the capturing page CP the display driver processing section executes the display driver. Then the display driver generates display data in order to cause the capturing page CP to be displayed on the sensor equipped liquid crystal panel and then transmits the generated display data to the data processing section . Correspondingly the display driver transmits to the data processing section a command having 001 first display optical sensor section assigned as a value of the display panel field.

The capture driver processing section reads the capture driver from the driver storage section and then executes the capture driver. When the capture API calls up the capture driver for the purpose of performing capture of an image the object the capture driver processing section executes the capture driver. Then the capture driver generates a command in order to cause the sensor equipped liquid crystal panel to perform capture of an image of the object and then transmits the generated command to the data processing section .

Note that the following values are assigned in the fields of the above generated command. That is 01 event is assigned as a value of the data obtaining timing field 100 entire image is assigned as a value of the data type field 00 reflection is assigned as a value of the scanning mode field 01 multilevel is assigned as a value of the scanned image grayscale level field 0 high is assigned as a value of the scanning resolution field 001 first display optical sensor section is assigned as a value of the scan panel field.

As described above particularly in order to obtain the entire image from the data processing section 100 entire image is assigned as a value of the data type field. Further since capture of an image of a front side of the name card C and character recognition subjected by the external server are assumed it is desirable that values in the scanned image grayscale level field and in the scanning resolution field are 01 multilevel and 0 high respectively.

Further with the above command the capture driver obtains the entire image from the data processing section as a result of causing the sensor equipped liquid crystal panel to execute the capture. Then the capture driver performs a process of extracting the captured image CG from the obtained entire image using the desktop coordinates of the capturing area RA which have been designated as an argument at the calling.

Then the capture driver stores the extracted captured image CG in the captured image storage section and transmits information by which an address where the captured image CG is stored can be identified as a return value to the capture API which is a calling end.

The storage section includes the browser storage section the API storage section and the driver storage section . The browser storage section stores a browser W s program in a readable form. The API storage section stores the display API and the capture API in readable forms. The driver storage section stores the display driver and the capture driver in readable forms.

The temporary storage section includes the captured image storage section . The captured image storage section stores the captured image CG that is stored by the capture driver which is executed by the capture driver processing section . It is essential that the captured image CG is stored in the captured image storage section at least during a time until it is read by the browser W executed by the browser processing section . Therefore for the realization of a higher level of security the captured image CG may be deleted immediately after it is read by the browser W.

Next with reference to the following will describe an example of a flow in which the data display sensor apparatus according to the present embodiment performs capture of an image of the object placed on the place where the capturing area RA is displayed and the external server subjects the captured image to character recognition.

First when the user provides an instruction to obtain the capturing page CP by inputting the URL indicating the location of the source H that describes the capturing page CP to the browser W or by the like operation step S the browser W executed by the browser processing section requests the external server via the external communication section to obtain the source H step S . Then in response to the request the external server transmits the source H step S .

Next upon receipt of the source H from the external server the browser W calls up the display API for the purpose of displaying the capturing page CP on the basis of the received source H step S . When the display API is called up the display API processing section executes the display API. The display API further calls up the display driver step S .

When the display driver has been called up the display driver processing section executes the display driver. Then the display driver generates the display data for the purpose of causing the capturing page CP to be displayed on the sensor equipped liquid crystal panel then and transmits the generated display data to the data processing section and transmits a command having 001 first display optical sensor section as a value of the display panel to the data processing section step S .

Then the data processing section controls the circuit control section according to the display data and the command and the circuit control section transmits a signal to the sensor equipped liquid crystal panel so that the capturing page CP is displayed on the sensor equipped liquid crystal panel step S .

After the capturing page CP has been displayed on the sensor equipped liquid crystal panel the user places the name card C as the object at the place where the capturing area RA is shown on the sensor equipped liquid crystal panel step S and the user provides an instruction to carry out capture of an image of the object with a push of a SEND button or by the like operation step S . Then the browser W obtains the client coordinates of the capturing area RA and calls up the capture API with the obtained client coordinates as an argument step S .

When the capture API is called up the capture API processing section executes the capture API. The capture API converts the client coordinates of the capturing area RA which are designated as an argument at the calling into the desktop coordinates and then calls up the capture driver with the desktop coordinates as an argument step S .

When the capture driver has been called up the capture driver processing section executes the capture driver. Then the capture driver generates a command for the purpose of causing the sensor equipped liquid crystal panel to perform capture of an image of the object and then transmits the generated command to the data processing section step S . The fields in the generated command are the ones as described previously. Particularly 100 entire image is assigned as a value of the data type field in order to obtain the entire image from the data processing section .

The data processing section controls the circuit control section according to the command and the circuit control section transmits a signal to the display optical sensor section . This causes the sensor equipped liquid crystal panel to carry out capture of an image of the object. Then the data processing section generates the entire image as a capturing result and then transmits the entire image to the capture driver step S .

When the capture driver obtains the entire image from the data processing section the capture driver performs a process of extracting the captured image CG from the obtained entire image using the desktop coordinates of the capturing area RA which have been designated as an argument at the calling. Subsequently the capture driver stores the extracted captured image CG in the captured image storage section and transmits information by which an address where the captured image CG is stored can be identified as a return value to the capture API which is a calling end step S .

When the capture API receives the information by which the address can be identified from the capture driver the capture API further transmits the received information as a return value to the browser W which is a calling end step S .

Upon receipt of the information by which the address can be identified from the capture API the browser W reads the captured image CG that is stored at the address identified by the received information and then transmits the read captured image CG to the external server via the external communication section step S .

Upon receipt of the image from the browser W the external server stores the incoming captured image CG in the storage section step S and starts the character recognition application to perform a process of recognizing characters from the captured image CG stored in the storage section step S .

 Conversions of the Coordinate System of the Display Surface and the Coordinate System of the Capture Surface on the Sensor Equipped Liquid Crystal Panel 

On the sensor equipped liquid crystal panel the resolution of the display surface is not necessarily the same as the resolution of the capture surface. For example there can be a case where the display surface provides a 1024 768 resolution whereas the capture surface provides a 2048 1536 resolution which is twice the resolution of the display surface. As in this case in a case where the resolution of the display surface is different from the resolution of the capture surface in the sensor equipped liquid crystal panel it is necessary to convert information coordinates indicating the location of the capturing area RA in the display surface into information coordinates indicating the location of the capturing area RA in the capture surface for proper extraction of the captured image CG.

The following will describe a specific example of the conversion. For example assume that the display surface provides a 1024 768 resolution and the capturing area RA in the display surface is a rectangular area surrounded by coordinates x y and coordinates x y . Further assume that the capture surface provides a 2048 1536 resolution and an area corresponding to the capturing area RA in an image captured by the entire capture surface is a rectangular area surrounded by coordinates x y and coordinates x y .

In this case the coordinates x y and the coordinates x y can be found by conversions of the coordinates xy and the coordinates x y as expressed by the following equations 11 12 12 and 22 22 1 22 1 .

In the above descriptions 1 the browser W executed by the browser processing section obtains the client coordinates of the capturing area RA 2 the capture API executed by the capture API processing section converts the client coordinates of the capturing area RA into the desktop coordinates and 3 the capture driver executed by the capture driver processing section generates the command which causes the sensor equipped liquid crystal panel to perform capture of an image of the object. However the entities that execute these processes are not limited to these entities.

For example the entity that converts the client coordinates into the desktop coordinates may be the browser W or the capture driver. However for easier development of the application program it is desirable that the coordinates conversion process is performed by the capture API or the capture driver both of which are located at lower layers.

Further in the above descriptions 4 the capture driver executed by the capture driver processing section extracts the captured image CG from the entire image and then stores the captured image. CG in the captured image storage section 5 the browser W executed by the browser processing section reads the captured image CG from the captured image storage section . However the entities that execute these processes are not limited to these entities.

For example the entity that extracts the captured image CG from the entire image may be the capture API or the browser W.

In the above descriptions the main control section consists of the following three layers the browser processing section the API processing section and the driver processing section . However this is not the only possibility. For example the API processing section and the driver processing section may be an integral unit so that the main control section consists of the two layers as a whole. Alternatively the browser processing section the API processing section and the driver processing section may be an integral unit so that the main control section consists of the one layer as a whole.

The above descriptions has presented the approach of describing the source H for the capturing page CP using an HTML capable of describing the scan tag ST. This approach requires the HTML to be extended from the standards and also requires a capability of the browser W to be extended so that the browser W can support the extended HTML. However such an approach is effective in allowing the user to use the system simply by installation of the capability extended browser W on the data display sensor apparatus .

Moreover the above approach is also effective in allowing a provider of the capturing page CP to easily describe the source H since it is simply a matter of describing the scan tag ST in the source H.

Alternatively the capturing page CP may be described using a script language such as Java Script. This alternative approach also requires specifications of the script language to be extended and also requires a capability of the browser W to be extended so that the browser W can interpret the extended script language. However such an alternative approach is effective in allowing the user to use the system simply by installation of the capability extended browser W on the data display sensor apparatus .

Moreover the above alternative approach is also effective in allowing the provider of the capturing page CP to create a dynamic Web page although the provider of the capturing page CP needs to describe a script in the extended script language.

Further alternatively the capturing page CP may be realized by a plug in that provides instructions to perform display and capture. This approach is effective since it eliminates the above described requirements i.e. extensions of the HTML standards and of the specifications of the script language and extension of the capability of the browser W.

However the further alternative approach requires the user to install the plug in and also requires the provider of the capturing page CP to create such a capturing page CP that calls up the plug in at the time of displaying the capturing page CP.

In some case a part of the client area CA is hidden and not shown due to the user s operations such as scrolling of the browser W through a scroll bar or reduction of the size of the browser W. In such a case it is desirable that the user is prompted to perform an appropriate operation to bring the entire capturing area RA into view.

An exemplary message given to the user is described with reference to . is a diagram showing an exemplary message given to the user when the part of the capturing area RA is hidden and not shown. In an example of a message MS is shown to prompt the user to perform an appropriate operation to show the entire capturing area RA.

In the above descriptions the external server is not arranged to transmit a response to the reception of the captured image CG to the data display sensor apparatus . However the external server may be arranged to transmit the response to the data display sensor apparatus and the data display sensor apparatus may be arranged to display the content of the response. This allows the user of the data display sensor apparatus to check to see the completion of the processing performed by the external server and whether or not the processing desired by the user has been executed.

The content of the response may be for example a message containing the fact that the external server has received the captured image CG a screen showing the captured image CG that the external server has received or a screen showing characters that the character recognition application has recognized.

The above descriptions have dealt with the arrangement where the sensor equipped liquid crystal panel causes the entire capture surface thereof to sense the object image located in the vicinity thereof. Alternatively the sensor equipped liquid crystal panel may cause a predetermined area of the capture surface thereof to sense the object image located in the vicinity thereof i.e. the capture is performed only by a part of the capture surface .

In this case the main control section transmits to the data processing section a command containing information that designates the predetermined area of the capture surface of the sensor equipped liquid crystal panel . The data processing section controls the circuit control section according to the command. Under the control of the data processing section the circuit control section transmits a signal to the display optical sensor section . Further the main control section obtains image data captured by the predetermined area of the capture surface from the data processing section as a response to the command transmitted to the data processing section .

In a case where the predetermined area is identical to the capturing area RA subjected to capture the image itself obtained by the data processing section is the captured image CG. This therefore eliminates the need for the extraction process performed by the capture driver.

Further in the above descriptions the data display sensor apparatus is arranged to include the data processing section and the circuit control section . However this is not the only possibility. For example the main control section may be arranged to directly control the circuit control section so that the main control section generates the entire image data partial image data coordinate data. Moreover the main control section may be arranged to directly control the display optical sensor section .

As described above an apparatus for displaying an image and sensing an object image according to the present invention is an apparatus for displaying an image and sensing an object image the apparatus comprising a panel component that displays an image and captures an object image located in the vicinity of the panel component the apparatus for displaying an image and sensing an object image the apparatus further comprising window display control means that causes a window including a placement area to be displayed on the panel component the placement area being an area for placing an object coordinates converting means that converts first area information into second area information the first area information indicating the location of the placement area in the window the second area information indicating the location of the placement area in the panel component and image deriving means that derives a captured image the captured image being an image of the object located in the vicinity of the panel component and captured through an area defined by the second area information.

Further a method for controlling an apparatus for displaying an image and sensing an object image according to the present invention is a method for controlling an apparatus for displaying an image and sensing an object image the apparatus comprising a panel component that displays an image and captures an object image located in the vicinity of the panel component the method comprising a window display control step of causing a window including a placement area to be displayed on the panel component the placement area being an area for placing an object a coordinates converting step of converting first area information into second area information the first area information indicating the location of the placement area in the window the second area information indicating the location of the placement area in the panel component and an image deriving step of deriving a captured image the captured image being an image of the object located in the vicinity of the panel component and captured through an area defined by the second area information.

This makes it possible to obtain the second area information from the first area information. Therefore wherever the window is displayed on the display surface and wherever the placement area is placed in the window it is possible to determine the position of the placement area in the panel component. Thus it is possible to reliably determine the capturing area in the panel component.

This yields the effect of causing the panel component to reliably capture the image of the object placed on the placement area in the window. That is this yields the effect of causing the panel component to reliably capture the image of the object placed on the placement area which is not shown at a fixed position in the panel component.

Still further in the above arrangement an apparatus for displaying an image and sensing an object image according to the present invention may be such that the first area information is contained in source code the source code defining content that is shown in the window and contains the placement area and the window display control means causes the window to be displayed on the panel component according to the source code in such a state where the content containing the placement area is located in the window.

According to the above arrangement the first area information is contained in source code the source code defining content that contains the placement area and the window can be caused to be displayed on the panel component according to the source code in such a state where the content containing the placement area is located in the window.

Therefore it is possible to cause the location of the content containing the placement area in the window to be defined by the source code and it is possible to cause the placement area to be shown in the window according to the defined source code. Thus it is possible to cause the panel component to capture the image of the object placed in the placement area which has been shown according to the source code.

This yields the effect of allowing a provider of the content a provider of the source code to create the content that provides a function for performing capture of an image of the object without consideration of the position of the capturing area in the panel component.

Besides the user can obtain a service into which a content browsing service and a service that provides capture of an image of a document and or the like are integrated and the user can perform the operation for content browsing and the operation for capturing an image of a document and or the like through use of the same window. This yields the effect of improving convenience and operability of the user.

Yet further in the above arrangement an apparatus for displaying an image and sensing an object image according to the present invention may further comprises source code obtaining means that obtains the source code from a first external device.

According to the above arrangement it is possible to obtain the source code from the first external device.

Therefore it is possible to cause the panel component to capture the image of the object that is placed on the placement area having been shown according to the source code obtained from the first external device.

This yields the effect of allowing the provider of the content to provide content containing a function for performing the capture through the server device which is the first external device.

That is the provider of the content can provide the content containing the function for performing the capture through an external server device thus realizing construction of the content as an SaaS application.

Further in the above arrangement an apparatus for displaying an image and sensing an object image according to the present invention is such that the image deriving means derives the captured image by causing the entire panel component to capture the object image located in the vicinity of the panel component and extracting the area defined by the second area information from a captured object image.

According to the above arrangement it is possible to derive the captured image by extracting the area defined by the second area information from an image of the object located in the vicinity of the panel component and captured by the entire panel component.

Therefore it is possible to extract the image in the placement area which image contains the image of the object from the image captured by the entire panel component. That is it is possible to remove a part corresponding to an area outside the placement area from the image captured the entire panel component.

This yields the effect of enabling deriving of the captured image that reliably contains the image of the object placed on the placement area but does not contain the image corresponding to an area outside the placement area.

Still further in the above arrangement an apparatus for displaying an image and sensing an object image according to the present invention may be such that the image deriving means derives as the captured image the image of the object located in the vicinity of the panel component and having been captured by the panel component through the area defined by the second area information.

According to the above arrangement it is possible to derive as the captured image the image of the object located in the vicinity of the panel component and having been captured by the panel component through the area defined by the second area information.

Therefore it is possible to derive as the captured image the image of the placement area which image contains the image of the object through the panel component.

This yields the effect of enabling deriving of the captured image that reliably contains the image of the object placed on the placement area but does not contain the image corresponding to an area outside the placement area.

Yet further in the above arrangement an apparatus for displaying an image and sensing an object image according to the present invention may further comprise image storing means that stores the captured image having been obtained by the image deriving means in a storage section of the apparatus.

According to the above arrangement it is possible to store the captured image in the storage section of the apparatus for displaying an image and sensing an object image.

Therefore it is possible to store the image in the placement area which image contains the image of the object in the storage section of the apparatus for displaying an image and sensing an object image.

This yields the effect of enabling the image of the object captured by the panel component to be subjected to various kinds of processes such as an image analyzing process and an external transfer process.

Further in the above arrangement an apparatus for displaying an image and sensing an object image according to the present invention may further comprise image transmitting means that transmits the captured image having been obtained by the image deriving means to the second external device.

According to the above arrangement it is possible to transmit the captured image to the second external device.

Therefore it is possible to transmit the image in the placement area which image contains the image of the object to the second external device.

This yields the effect that the server device which is the second external device can subject the image of the object captured by the panel component to various kinds of processes such as an image analyzing process.

For example the server device can perform the following processes a process of subjecting an image of a name card captured by the panel component to character recognition so as to recognize characters included in the image of the name card such as a name an address and an e mail address and a process of registering data of the recognized characters into the address list table.

The above apparatus for displaying an image and sensing an object image may be realized by a computer. In this case the present invention encompasses a program for controlling the apparatus for displaying an image and sensing an object image that causes a computer to operate as the foregoing means so that the apparatus for displaying an image and sensing an object image is realized by the computer and computer readable storage medium storing the program.

Finally the main control section the data processing section and the circuit control section of the data display sensor apparatus may be constituted by hardware logic or may be realized by software by means of a CPU central processing unit as shown below.

That is the data display sensor apparatus includes a CPU that executes the order of a control program for realizing the aforesaid functions ROM read only memory that stores the control program RAM random access memory that develops the control program in executable form and a storage device storage medium such as memory that stores the control program and various types of data therein. The object of the present invention is realized by a predetermined storage medium. The storage medium stores in computer readable manner program codes executable code program intermediate code program and source program of the control program of the data display sensor apparatus which is software for realizing the aforesaid functions. The storage medium is provided to the data display sensor apparatus . With this arrangement the data display sensor apparatus alternatively CPU or MPU as a computer reads out and executes program code stored in the storage medium provided.

The storage medium may be tape based such as a magnetic tape or cassette tape disc based such as a magnetic disk including a floppy disc and hard disk and optical disk including CD ROM MO MD DVD and CD R card based such as an IC card including a memory card and an optical card or a semiconductor memory such as a mask ROM EPROM EEPROM and a flash ROM.

Further the data display sensor apparatus may be arranged so as to be connectable to a communications network so that the program code is supplied to the data display sensor apparatus through the communications network. The communications network is not to be particularly limited. Examples of the communications network include the Internet intranet extranet LAN ISDN VAN CATV communications network virtual private network telephone network mobile communications network and satellite communications network. Further a transmission medium that constitutes the communications network is not particularly limited. Examples of the transmission medium include i wired lines such as IEEE 1394 USB power line carrier cable TV lines telephone lines and ADSL lines and ii wireless connections such as IrDA and remote control using infrared light Bluetooth 802.11 HDR mobile phone network satellite connections and terrestrial digital network. Note that the present invention can be also realized by the program codes in the form of a computer data signal embedded in a carrier wave which is embodied by electronic transmission.

The present invention is not limited to the aforementioned embodiments and is susceptible of various changes within the scope of the accompanying claims. Also an embodiment obtained by suitable combinations of technical means disclosed in the different embodiments are also included within the technical scope of the present invention.

Specific embodiments or examples implemented in the description of the embodiments only show technical features of the present invention and are not intended to limit the scope of the invention. Variations can be effected within the spirit of the present invention and the scope of the following claims.

The present invention is applicable to a device that performs a process of displaying an image and the like and a process of capturing an image of an object. Particularly the present invention is applicable to a PC capable of displaying a Web page through a browser.

