---

title: Methods and systems for testing methods in a multi-tenant database environment
abstract: In accordance with embodiments disclosed herein, there are provided systems, devices, and methods for testing methods in a multi-tenant database environment, including, for example, hosting a plurality of customer codebases within a host organization, where each of the plurality of customer codebases includes a plurality of operational statements and one or more test methods. Such a method further includes generating a first test result set by executing the one or more test methods associated with each of the plurality of customer codebases against a production release codebase of the host organization; generating a second test result set by executing the one or more test methods associated with each of the plurality of customer codebases against a pre-release codebase of the host organization; and identifying errors associated with the pre-release codebase based on a comparison of the first test result set and the second test result set.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08707264&OS=08707264&RS=08707264
owner: salesforce.com, inc.
number: 08707264
owner_city: San Francisco
owner_country: US
publication_date: 20101220
---
This application is related to and claims priority to the provisional utility application entitled METHODS AND SYSTEMS FOR TESTING METHODS IN A MULTI TENANT DATABASE ENVIRONMENT filed on May 18 2010 having an application No. 61 345 979 the entire contents of which are incorporated herein by reference.

A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records but otherwise reserves all copyright rights whatsoever.

Embodiments of the invention relate generally to the field of computing and more particularly to methods and systems for testing methods in a multi tenant database environment.

The subject matter discussed in the background section should not be assumed to be prior art merely as a result of its mention in the background section. Similarly a problem mentioned in the background section or associated with the subject matter of the background section should not be assumed to have been previously recognized in the prior art. The subject matter in the background section merely represents different approaches which in and of themselves may also correspond to embodiments of the claimed inventions.

When making changes to software and code to be released into a production or live environment in which the software is utilized by customers or a business it is important to test the software to ensure appropriate operation upon its release. Business Enterprises may expend substantial time cost and effort to ensure that changes to its codebase do not interrupt normal business operations once released into a production environment as doing so may cause harm to the business in the form of opportunity costs reputational costs etc.

Conventional testing models and release cycles are limited in their scope and ability to identify potential errors or compatibility issues because the business Enterprise typically must develop its own custom test cases to test its own custom codebase.

The present state of the art may benefit from the methods and systems for testing methods in a multi tenant database environment as described herein.

Described herein are systems devices and methods for testing methods in a multi tenant database environment. In one embodiment such a method includes hosting a plurality of customer codebases within a host organization where each of the plurality of customer codebases includes a plurality of operational statements and one or more test methods. Such a method further includes generating a first test result set by executing the one or more test methods associated with each of the plurality of customer codebases against a production release codebase of the host organization generating a second test result set by executing the one or more test methods associated with each of the plurality of customer codebases against a pre release codebase of the host organization and identifying errors associated with the pre release codebase based on a comparison of the first test result set and the second test result set. In accordance with some embodiments the method may further include instantiating a development sandbox execution environment and executing the test methods against the production release codebase and the pre release codebase within the development sandbox so as to negate potentially adverse affects on a live production environment utilized by customer organizations and service subscribers of the host organization.

Organizations which develop test and release software to customers face the difficult task of ensuring broadly compatible and completely bug free operation of their code while at the same time organizations lack a detailed view of the manner in which their code will be utilized once released. Although customers and business partners may have a vast array of functionality which will eventually be executed against released code provided by such an organization the organization responsible for developing the released codebase conventionally lacks access to such functionality. Where an organization develops tests and releases software for use internally the organization may have access to functionality which will be executed against the released codebase however the available functionality for use in regression testing is limited to only that organization s internal code.

In an on demand service environment where a host organization provides computing resources such as the multi tenant database system described herein for use by multiple customer organizations and provides an execution environment in which such customer organizations may develop and execute their own customer specific codebases there is an opportunity to leverage the varied codebases provided by the customer organizations and hosted stored within the host organization for use in regression testing. In such a way performing regression testing against a pre release codebase e.g. for the purposes of backward compatibility error free execution compilation etc. may provide a more thorough extensive and overall higher quality result potentially negating problems in released production codebases which are used by the customer organizations and relied upon for the operation of their business concerns.

In the following description numerous specific details are set forth such as examples of specific systems languages components etc. in order to provide a thorough understanding of the various embodiments. It will be apparent however to one skilled in the art that these specific details need not be employed to practice the disclosed embodiments. In other instances well known materials or methods have not been described in detail in order to avoid unnecessarily obscuring the disclosed embodiments.

In addition to various hardware components depicted in the figures and described herein embodiments further include various operations which are described below. The operations described in accordance with such embodiments may be performed by hardware components or may be embodied in machine executable instructions which may be used to cause a general purpose or special purpose processor programmed with the instructions to perform the operations. Alternatively the operations may be performed by a combination of hardware and software.

Embodiments also relate to a system or apparatus for performing the operations described herein. The disclosed system or apparatus may be specially constructed for the required purposes or may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a non transitory computer readable storage medium such as but not limited to any type of disk including floppy disks optical disks CD ROMs and magnetic optical disks read only memories ROMs random access memories RAMs EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing non transitory electronic instructions each coupled to a computer system bus. In one embodiment a computer readable storage medium having instructions stored thereon causes one or more processors within a host organization to perform the methods and operations which are described herein. In another embodiment the instructions to perform such methods and operations are stored upon a non transitory computer readable medium for later execution.

The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus nor are embodiments described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the embodiments as described herein.

The hardware software and logic elements of the multi tenant database system are separate and distinct from a plurality of customer organizations A B and C which utilize the services provided by the host organization by communicably interfacing to the host organization via network . Additionally depicted within host organization is a customer code execution environment upon which customer codebases belonging to the various customer organizations A C may be executed under the direction and control of the customer organizations A C themselves. Customer codebases may be received at the host organization e.g. via customer requests and stored upon a datastore within the host organization .

In one embodiment each of the separate and distinct customer organizations A C may be remotely located from the host organization that provides services to the customer organizations A C via the multi tenant database system and the customer code execution environment executing therein. Alternatively one or more of the customer organizations A C may be co located with the host organization such as within the same organization that hosts and provides the multi tenant database system upon which underlying data is persistently stored. Where the customer organizations A C are remote host organization provides remotely implemented cloud computing services.

In one embodiment the hardware software and logic elements of the multi tenant database system include at least a non relational datastore and a relational datastore which operate in accordance with the hardware software and logic elements that implement the database functionality and code execution environment within the host organization . Host organization receives various customer requests from one or more of the plurality of customer organizations A C via the network. For example an incoming customer request may be a login request a request for services e.g. triggering code execution or a database transaction or a request to modify or store data associated with a customer s codebase .

Customer requests may be processed via the host organization s production release codebase to perform various operations such as database transactions etc. Where functionality associated with a customer codebase is invoked such functionality may execute within the customer code execution environment as supported by e.g. executed against the host organization s production release codebase which in turn operates in conjunction with the multi tenant database system .

In accordance with one embodiment the host organization hosts a plurality of customer codebases within the host organization where each of the plurality of customer codebases have a plurality of operational statements and one or more test methods . Hosting the customer codebases may include storing them within a datastore of the host organization or alternatively storing them within the multi tenant database system of the host organization which in turn persistently stores data upon a non relational datastore a relational datastore or both. The operational statements within each of the customer codebases may be organized within one or more applications e.g. A and B belonging to one of the customer organizations A C organized as a series of methods e.g. A and B within application A organized as functional blocks classes objects etc. The one or more test methods provide test coverage for the operational statements making up each customer s respective codebase .

For example depicted are a series of test methods which invoke various operational statements within a customer s codebase and in particular within method A of application A. By triggering or invoking the operational statements via test methods the respective customer organizations A C may test and validate their own code functionality and software present in their respective customer codebase .

Additionally because host organization hosts and stores the customer codebases within its infrastructure the host organization has the capability of viewing or otherwise accessing the various test methods associated with its customer organization s A C software and applications A B as such test methods are present within the hosted customer codebases . The host organization may therefore leverage the test methods belonging to e.g. controlled by maintained by authored by provided by owned by one or more of its customer organizations A C to perform regression testing upon the host organization s code base which is used to provide services to the customer organizations A C. In some embodiments customer organizations A C may opt in or opt out of participating in regression testing performed by the host organization or otherwise specify that their respective customer codebases are either available or not available to be viewed or accessed by the host organization .

In accordance with one embodiment the host organization performs regression testing by generating a first test result set by executing the one or more test methods associated with each of the plurality of customer codebases against a production release codebase of the host organization . In such an embodiment the host organization further generates a second test result set by executing the one or more test methods associated with each of the plurality of customer codebases against a pre release codebase of the host organization . Execution of the customer organization s A C test methods may utilize the customer code execution environment e.g. execute on application servicers and other computing resources available for executing functionality within the customer codebases .

In accordance with such an embodiment the host organization further identifies errors associated with the pre release codebase based on a comparison of the first test result set and the second test result set .

In the above exemplary embodiment the production release codebase of the host organization may be considered the stable or live variant of the host organization s production release codebase and thus may be considered as a baseline upon which to measure the quality stability and backward compatibility of upgrades bug fixes and other types of changes which are present in the host organization s pre release codebase . The pre release codebase may be considered a release candidate or beta code which embodies various operational changes and enhancements the host organization wishes to release but which require additional testing including regression testing before the pre release codebase may be appropriately released and promoted to the state of a production release codebase for the host organization .

By performing analysis and comparing the test result sets and resulting from executing the test methods against the host organization s production release codebase and re executing the test methods against the host organization s pre release codebase a better understanding may be attained as to how the host organization s pre release codebase may affect the various applications A B and functionality belonging to the host organization s customers. The host organization may seek to ensure backward compatibility for its customers or work to proactively address potential errors that may result from the host organization upgrading or otherwise modifying its production release codebase e.g. such as by releasing and promoting the pre release codebase to a production release codebase .

In accordance with one embodiment the host organization provides on demand database services to a plurality of customer organizations A C via the multi tenant database system of the host organization . In such an embodiment multi tenant database system operates in conjunction with the production release codebase of the host organization and each of the plurality of customer codebases hosted within the host organization are associated with a corresponding one of the plurality of customer organizations A C. The customer organizations each operate distinct from the host organization and may be physically and geographically remote from the host organization . Nevertheless the customer codebases associated with the various customer organizations A C reside within the host organization .

In accordance with one embodiment the production release codebase of the host organization is maintained and controlled by the host organization and each of the plurality of customer codebases hosted by the host organization are maintained and controlled by a corresponding customer organization A C which subscribes to on demand database services provided by the host organization.

In accordance with some embodiments each of the customer organizations have authority to view alter and execute a corresponding one of the plurality of customer codebases e.g. the customer codebase belonging to that particular customer organization . In such an embodiment the host organization has authority to view alter and execute the production release codebase of the host organization. In such an embodiment the host organization has further authority execute the one or more test methods associated with each of the plurality of customer codebases . In such embodiments each of the various customer organizations A C may not have authority to view alter or execute other customer codebases besides their own. Additionally each of the customer organizations A C may not have authority to view alter or execute the host organization s production release codebase or the host organization s pre release codebase . The customer organizations A C may however have authority to invoke various functions and methods embodied within codebases belonging to the host organization where such functions methods and functionality are exposed via for example interfaces e.g. Application Programming Interfaces APIs User Interfaces UIs Graphical User Interfaces GUIs web interfaces public classes etc. . Conversely the host organization may have authority to access view and execute customer codebases belonging to its customer organizations A C that are stored and or hosted within the host organization . In particular the host organization may view and invoke test methods belonging to the various customer organizations.

In accordance with one embodiment the host organization receives each of the plurality of customer codebases from a respective one of the plurality of customer organizations A C and uniquely associates each of the plurality of customer codebases with one of the plurality of customer organizations A C based on an Organizational Identifier OrgID and or User Identifier UserID . In such an embodiment the host organization stores each of the plurality of customer codebases received within a datastore of the host organization . For example the host organization may store a received customer codebase in a storage space allocated to a particular customer organization based on the OrgID and or UserID associated with the received customer codebase .

The received customer codebase is not necessarily received as a total unit complete application or as a single package e.g. attached to an incoming customer request although it may be. Rather the received customer codebase may result from a synchronization between a locally modified copy of the customer codebase in which the various applications A B methods A B test methods and or operational statements are modified locally at a customer organization s A C location and then uploaded synchronized to the host organization . Alternatively the customer organizations A C may communicate remotely with the host organization and modify an existing customer codebase through an interface such as an on line on demand development environment provided by the host organization. Alternatively the customer organizations may send new or updated classes objects methods test methods and or operational statements to the host organization for inclusion with a specified customer codebase .

In one embodiment the host organization may establish a policy or requirement that its customer organizations A C establish a minimum amount of code coverage for any application e.g. A B method A B or set of operational statements present in a customer s codebase . Such code coverage is provided through the associated test methods . For example the host organization may establish a minimum code coverage threshold of 75 by way of example and then require that each customer s codebase adhere to the established minimum code coverage threshold.

In one embodiment the host organization further performs code coverage validation on each of the plurality of customer codebases . In one embodiment performing the code coverage validation for each customer codebase includes generating a statement count by identifying each of the plurality of operational statements within the customer codebase e.g. each operational statement may be tagged and counted as a statement . Other units of execution may be used for counting purposes such as declared methods etc.

Code coverage validation may further include generating a tested statement count by executing the one or more test methods within the customer codebase and identifying which of the plurality of operational statements are invoked via the one or more test methods . Ideally all operational statements present in a customer s codebase are capable of being invoked or triggered by one or more associated test methods resulting in 100 code coverage. However some operational statements may be invoked multiple times while other operational statements may be present within the customer s codebase yet never referenced or invoked by the one or more test methods resulting in a less than complete or less than 100 code coverage. Where operational statements exist within a customer s codebase and yet are not invoked by any of its test methods there is a risk that an unknown error may escape detection. Accordingly it is advantageous to the customer organizations A C to ensure as much code coverage as feasible within their respective customer codebases thus maximizing the stability of their own customer applications e.g. A B throughout release cycles. Higher code coverage within the customer s codebases may further enhance the scope depth and rigor of regression testing performed by the host organization .

Code coverage validation may further include calculating a test coverage percentage based on a comparison of the statement count and the tested statement count and comparing the test coverage percentage against a minimum test coverage ratio specified by the host organization . Depending on whether a customer codebase passes validation the host organization may undertake various actions. For example the host organization may prevent use and execution of all or portions e.g. allow some applications but not others of the customer codebase based on the validation results notify a corresponding customer organization A C that their customer codebase fails to adhere to the minimum level of code coverage and so forth.

In one embodiment the host organization generates a regression test suite for example to perform regression testing against a pre release codebase of the host organization.

For example the host organization may generate or create a regression test suite having the one or more test methods associated with each of the plurality of customer codebases specified therein by recursively searching each of the plurality customer codebases for units of operation self labeled as test methods or otherwise detectable as test methods . The host organization may then register list link or include each discovered test method within the regression test suite. The resulting test suite may therefore include numerous test methods associated with multiple distinct customer codebases . Such a test suite may encompass all available test methods available within the host organization s datastore upon which the various customer codebases are stored or may include a subset based on selected criteria such as a specified or enumerated list of customer organizations A C.

In one embodiment generating the first test result set includes executing the regression test suite as supported by e.g. executed against the production release codebase of the host organization and capturing output from the execution of the regression test suite as the first test result set . In such an embodiment generating the second test result set may include re executing the regression test suite e.g. running executing the identical list or grouping of test methods as supported by e.g. executed against the pre release codebase of the host organization and capturing output from the re execution of the regression test suite as the second test result set . For example a first run of the regression test suite is performed on the baseline code e.g. the host organization s production release codebase and then a second re execution of the same regression test suite is performed on the modified code e.g. the host organization s pre release codebase .

In one embodiment the production release codebase of the host organization represents the currently released and currently operating implementation logic to support on demand services provided by the host organization and the pre release codebase of the host organization represents an upgraded variant of the production release codebase having functionality which requires regression testing against available test methods to ensure backward compatibility between the pre release codebase of the host organization and the plurality of customer codebases hosted by the host organization.

In one embodiment the plurality of operational statements within each of the customer codebases syntactically adhere to an Apex On Demand compatible programming language. In such an embodiment a plurality of customer organizations A C create customer specific applications e.g. A B in the Apex On Demand compatible programming language via the plurality of operational statements within each of the customer codebases .

In accordance with disclosed embodiments the production release codebase of the host organization provides Application Programming Interfaces APIs to the customer specific applications e.g. A B . For example the APIs may enable the customer specific applications A B to perform operations against the multi tenant database system executing within the host organization that operates in conjunction with the production release codebase .

In accordance with one embodiment identifying errors associated the pre release codebase of the host organization based on a comparison of the first test result set and the second test result set includes identifying one or more incompatibilities between the customer specific applications e.g. A B and the pre release codebase of the host organization . For example identifying errors associated with the pre release codebase may be based on a comparison of the first test result set and the second test result set in an effort to find or identify a change in an output from for example the same test method when run on each of the respective codebases of the host organization. Some changes such as a distinct time stamp or a distinct user name may be inconsequential and thus be ignored. Other changes however may highlight problems or issues that are exhibited when a customer s codebase associated with the test method in question is executed against the host organization s pre release codebase e.g. if the pre release codebase were released to production without a change correction or bug fix . For example changes in output including messages exit states exit codes total execution time and so forth may be detected and subject to further analysis.

In one embodiment the customer organizations A C have no means or mechanism by which to execute their test methods against pre release codebases of the host organization and thus are unable to detect errors resulting from an upgrade until new upgraded code is released to production. Thus in accordance with some embodiments the host organization performs the appropriate regression testing on behalf of the customer organizations A C utilizing the customer organization s respective test methods to minimize the potential for future errors resulting from a codebase upgrade by the host organization .

In accordance with one embodiment identifying errors associated with the pre release codebase of the host organization based on a comparison of the first test result set and the second test result set includes eliminating output from each of the first test result set and the second test result set based on a set of criteria. The resulting dataset therefore includes output from those test methods which require further investigation or which are potential errors relating specifically to the use of the host organization s pre release codebase .

For example criteria for eliminating output from the first test result set and the second test result set may include a where corresponding test method outputs in the first test result set and the second test result set each indicate a successful result e.g. if both pass there may be little value in reviewing the output b where a test method output in the first test result set indicates failure and a corresponding test method output in the second test result set indicates success e.g. if the new pre release codebase corrects a problem it may be unnecessary to review the output c where corresponding test method outputs in the first test result set and the second test result set indicate identical failure modes e.g. where a pre existing failure using the production release codebase remains a failure using the pre release codebase it may be acceptable to eliminate the output on the basis that the output is more likely attributable to the customer codebase in question rather than the host organization s pre release codebase d where corresponding test method outputs in the first test result set and the second test result set indicate identical compilation error and e where a test method output in the first test result set and or a corresponding test method output in the second test result set matches one or more regular expressions set forth in an enumerated list of elimination patterns e.g. some outputs from test methods may be known noise or false positives or otherwise correspond to known events that have been investigated and deemed to be of no value or are otherwise appropriate for elimination from the first test result set and the second test result set .

In one embodiment when generating the first test result set and generating the second test result set the host organization establishes a development sandbox so as to prevent a potentially adverse impact to its customer organizations A C. For example it may be undesirable to consume a large amount of computational resources including bandwidth memory processor cycles etc. within a live production environment because consumption of these resources may degrade performance for uses of the production system. Moreover some of the test methods within the customer codebases may initiate transactions to a connected multi tenant database system potentially causing undesirable data changes or unexpected data results.

Therefore in accordance with one embodiment the host organization generates the first test result set and generating the second test result set by executing the one or more test methods associated with each of the plurality of customer codebases against the pre release codebase of the host organization within a development sandbox having an execution environment within the host organization that is populated with replicated data mirrored from a live production multi tenant database system of the host organization. In such an embodiment execution of the test methods e.g. within the development sandbox are prevented from having any affect upon data within the live production multi tenant database system of the host organization .

For example in one embodiment the host system instantiates a development sandbox within the host organization within which regression testing and other such development activities may be performed. In such an embodiment the host organization further replicates a live production multi tenant database system of the host organization to a mirrored development multi tenant database system within the development sandbox . The mirrored development multi tenant database system may embody a similar or identical architecture so as to facilitate testing in an environment which simulates the live operational multi tenant database system and may further have a replicated copy of data within the multi tenant database system but is isolated to the development sandbox and constrained in such a way that transactions and operations taking place on the mirrored development multi tenant database system have no affect on the live operational multi tenant database system .

In accordance with such an embodiment the host organization may further instantiate the production release codebase within the development sandbox upon the mirrored development multi tenant database system thus causing the mirrored development multi tenant database system within the development sandbox to operate in conjunction with the production release codebase instantiated within the development sandbox. In such an embodiment the host organization generates the first test result set by executing the one or more test methods associated with each of the plurality of customer codebases against the production release codebase of the host organization within the development sandbox .

In one embodiment the host organization further performs a rollback of any change to the mirrored development multi tenant database system within the development sandbox resulting from execution of the one or more test methods associated with each of the plurality of customer codebases . The host organization may further terminate the instantiated instance of the production release codebase within the development sandbox upgrade to the pre release codebase within the development sandbox and instantiate the pre release codebase within the development sandbox upon the mirrored development multi tenant database system . For example the host organization may install patches updates introduce additional code into the production release codebase within the development sandbox or otherwise modify the operational codebase so as to attain the host organization s pre release codebase within the development sandbox .

In such an embodiment the host organization further generates the second test result set by executing the one or more test methods associated with each of the plurality of customer codebases against the pre release codebase of the host organization comprises within the development sandbox .

In accordance with some embodiments the host organization may implement additional live production data safeguards. For example one data safeguard includes the host organization replicating the production release codebase of the host organization and a multi tenant database system operating in conjunction with the production release codebase to a development sandbox as described above.

The host organization may terminate Simple Network Management Protocol SNMP capabilities within the development sandbox to prevent remote execution of functionality external to the development sandbox by executing functionality within the development sandbox . For example some functionality triggered by the test methods may potentially invoke remote procedure calls or other such remote events which reference and attempt to trigger actions external to the development sandbox . Terminating SNMP and similar capabilities may prevent such remote events from succeeding to escape the development sandbox .

In one embodiment the host organization may configure datastores within the host organization to be read only from within the development sandbox . For example the host organization may allow datastore or a similar data repository to be accessible from functionality executing within the development sandbox but implement a read only policy so as to prevent changes. Alternatively a replicated datastore may be established. In some embodiments a copy on write policy may be employed allowing reads as normal but forcing writes to first copy the specified write location to a temporary space utilized by the development sandbox and then allowing the requesting function to write to the temporary space rather than writing to the originally specified location. Alternatively the host organization may create a temporary writable datastore to accept any write attempts invoked by execution within the development sandbox .

In one embodiment the host organization configures the replicated multi tenant database system e.g. a replicated development multi tenant database system within the development sandbox to implement a policy to accept but not commit database transactions. Such a policy may enable rollback of all transactions performed against the replicated multi tenant database system e.g. or similar . Performing such a roll back operation may permit the host organization to perform multiple iterations of regression testing or of other such tests without corrupting the underlying replicated copy of the database which may result in sub optimal data results if database transactions were to otherwise be permanently committed.

Various configuration optimizations may be utilized in accordance with described embodiments. For example the host organization may specify organizational identifiers Orglds to be utilized in regression testing thus allowing the selection and execution of only test methods associated with a specified set of customer organizations rather than all organizations recognized. Heap size use of simultaneously executing threads modified path settings and so forth may be configured so as to enable appropriate references to point to the development sandbox or to a read only mount of a datastore or enable parallelizing execution as appropriate.

In one embodiment system includes a memory and a processor or processors . For example memory may store instructions to be executed and processor s may execute such instructions. System includes bus to transfer transactions and data within system such as database transactions execution requests and API method invocations among a plurality peripheral devices and components interfaced with bus . System further includes web server for example to receive requests return responses and otherwise interface with remote clients such as client devices located within customer organizations A C. Customer codebases provides a repository for codebases belonging to customers of a host organization such as one or more of customer organizations A C as set forth in . Application server s provides computational resources and an execution environment in which customer organizations may execute applications and other functionality embodied within their respective customer codebases .

System includes a multi tenant database system which operates in conjunction with an instance of production release codebase . System further includes a mirrored multi tenant database system in which instances of a host organization s production release codebase and pre release codebase are available to operate in conjunction with or in support of the mirrored multi tenant database system . Mirrored multi tenant database system may be isolated to a development sandbox or otherwise firewalled and prevented from impacting a live or production based environment such as multi tenant database system .

Distinct within system is hardware based regression tester which includes code reader test executor results collector and results analyzer . In accordance with one embodiment code reader provides a search and discovery mechanism to recursively traverse available customer codebases such as those at element and identify test methods. Code reader may further provide logic for conducting validation of customer codebases for example to ensure test code coverage adheres to a specified requirement. Code reader may build a regression test suite based on the results of its search and discovery mechanism. Test executor executes test methods such as those discovered by code reader against the host organization s production release codebases including production release codebases and pre release codebases . Results collector collects the results from the test methods executed including output e.g. console output log output etc. . Results analyzer provides an analysis mechanism used to compare results output from the execution and re execution of a regression test suite or specified test methods as described herein e.g. comparing the results from execution of a regression test suite against a production release codebase and the results from execution of a regression test suite against a pre release codebase .

Method begins with processing logic receiving customer codebases at the host organization block . For example receiving applications methods functions logic operational statements test methods etc. from one or more customer organizations for storage within a customer organization s respective customer codebase. At block processing logic validates the customer codebases at the host organization. For example ensuring it complies with a minimum required level of code coverage via test methods.

At block processing logic causes a host organization to host or store the customer codebases within the host organization.

At block processing logic recursively searches each of a plurality customer codebases for units of operation identified as test methods. This test method discovery mechanism may be automated and triggered periodically to discover all test methods available within a host organization or only those test methods associated with a specified one or more customer organizations.

At block processing logic generates a regression test suite having the one or more discovered test methods within each of the plurality of customer codebases specified therein.

At block processing logic instantiates a development sandbox within the host organization to perform regression testing and at block processing logic replicates a live production multi tenant database system of the host organization to a mirrored development multi tenant database system within the development sandbox for use with the regression testing.

At block processing logic generates a first test result set by executing the regression test suite against a production release codebase of the host organization and at block processing logic generates a second test result set by re executing the regression test suite against a pre release codebase of the host organization. A results collector may collect the results into central location or a specified location for analysis.

At block processing logic identifies errors associated with the pre release codebase based on a comparison of the first test result set and the second test result set. The identified errors may then be stored for later review or sent to an operator for review.

The exemplary computer system includes a processor a main memory e.g. read only memory ROM flash memory dynamic random access memory DRAM such as synchronous DRAM SDRAM or Rambus DRAM RDRAM etc. static memory such as flash memory static random access memory SRAM volatile but high data rate RAM etc. and a secondary memory e.g. a persistent storage device including hard disk drives and persistent multi tenant database implementations which communicate with each other via a bus . Main memory includes host organization codebases including production release codebases and pre release codebases requiring regression testing each capable of operating in conjunction with a multi tenant database system of the host organization codebases . Main memory further includes customer codebases each corresponding to a customer organization and each providing one or more operational statements making up methods functionality and applications of the customer organization and further including one or more test methods to provide test coverage for the various operational statements within the customer codebases . Main memory and its sub elements e.g. and are operable in conjunction with processing logic and processor to perform the methodologies discussed herein.

Processor represents one or more general purpose processing devices such as a microprocessor central processing unit or the like. More particularly the processor may be a complex instruction set computing CISC microprocessor reduced instruction set computing RISC microprocessor very long instruction word VLIW microprocessor processor implementing other instruction sets or processors implementing a combination of instruction sets. Processor may also be one or more special purpose processing devices such as an application specific integrated circuit ASIC a field programmable gate array FPGA a digital signal processor DSP network processor or the like. Processor is configured to execute the processing logic for performing the operations and functionality which is discussed herein.

The computer system may further include a network interface card . The computer system also may include a user interface such as a video display unit a liquid crystal display LCD or a cathode ray tube CRT an alphanumeric input device e.g. a keyboard a cursor control device e.g. a mouse and a signal generation device e.g. an integrated speaker . The computer system may further include peripheral device e.g. wireless or wired communication devices memory devices storage devices audio processing devices video processing devices etc. The computer system may further include a Hardware based regression tester to implement regression testing capabilities for testing methods and functionality provided by customer organizations within their respective customer codebases against codebases of a host organization.

The secondary memory may include a non transitory machine readable storage medium or more specifically a non transitory machine accessible storage medium on which is stored one or more sets of instructions e.g. software embodying any one or more of the methodologies or functions described herein. The software may also reside completely or at least partially within the main memory and or within the processor during execution thereof by the computer system the main memory and the processor also constituting machine readable storage media. The software may further be transmitted or received over a network via the network interface card .

While the subject matter disclosed herein has been described by way of example and in terms of the specific embodiments it is to be understood that the claimed embodiments are not limited to the explicitly enumerated embodiments disclosed. To the contrary the disclosure is intended to cover various modifications and similar arrangements as would be apparent to those skilled in the art. Therefore the scope of the appended claims should be accorded the broadest interpretation so as to encompass all such modifications and similar arrangements. It is to be understood that the above description is intended to be illustrative and not restrictive. Many other embodiments will be apparent to those of skill in the art upon reading and understanding the above description. The scope of the disclosed subject matter is therefore to be determined in reference to the appended claims along with the full scope of equivalents to which such claims are entitled.

