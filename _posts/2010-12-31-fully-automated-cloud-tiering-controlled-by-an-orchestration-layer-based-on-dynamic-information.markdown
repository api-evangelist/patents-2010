---

title: Fully automated cloud tiering controlled by an orchestration layer based on dynamic information
abstract: A distributed storage system includes an orchestration layer that provides policy driven orchestration for controlling access and/or load balancing in connection with servicing I/O requests from one or hosts at one or more compute sites in a cloud configuration. The I/O requests may be received over a communication link, and the orchestration layer maintain policies and/or other information that control the selection of an compute site for processing of the I/O according to one or more policies and based on tiering designations of the compute sites. For example, according to various embodiments, policy information of the orchestration layer may control the passing of I/O requests to the one or more compute sites with respect to such factors as requirements of particular service legal agreements, specific tolerances for handling the I/O requests and/or times and rates for processing I/O requests at particular compute sites.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08682955&OS=08682955&RS=08682955
owner: EMC Corporation
number: 08682955
owner_city: Hopkinton
owner_country: US
publication_date: 20101231
---
This application is related to the field of data storage and more particularly to systems for managing data sharing on a storage network.

In current storage networks and particularly storage networks including geographically remote access nodes and storage resources preserving or reducing bandwidth between resources and access nodes is highly desirable as well as providing optimized data availability and access. Data access may be localized in part to improve access speed to pages requested by host devices. Caching data at access nodes provides localization however it is desirable that the cached data be kept coherent with respect to modifications at other access nodes that may be caching the same data. An example of a system for providing distributed cache coherence is described in U.S. Patent App. Pub. No. 2006 0031450 to Unrau et al. entitled Systems and Methods for Providing Distributed Cache Coherency which is incorporated herein by reference. Other systems and techniques for managing and sharing storage array functions among multiple storage groups in a storage network are described for example in U.S. Pat. No. 7 266 706 to Brown et al. entitled Methods and Systems for Implementing Shared Disk Array Management Functions which is incorporated herein by reference.

Fully automated storage tiering FAST is a technology that provides for the automated storage and movement of data according to characteristics of the data such as frequency of use time of last use of the data and or user information associated with the data among other characteristics. Data may be automatically moved between different storage areas or tiers periodically and or after a trigger event according to various policies based on the data characteristics for example. A FAST system may operate in connection with thin or virtual provisional technologies in which a storage system presents a large amount of storage capacity to a host but consumes space only as needed from a shared pool. With thin provisioning the host visible capacity e.g. storage perceived by the applications may be larger than the actual allocated space on the storage system. For discussions of various automated storage tiering systems including the use of thin provisioning see for example U.S. Patent App. Pub. No. 2009 0070541 to Yochai entitled Automated information life cycle management with thin provisioning and U.S. Pat. No. 7 822 939 to Veprinsky et al. entitled Data de duplication using thin provisioning which are both incorporated herein by reference.

Additionally cloud computing technologies may provide for the use of online compute and storage services to execute applications in a virtual environment and in which resources may be efficiently allocated to provide on demand compute and storage capacity over a network infrastructure. For discussions of systems and techniques for online services to provide on demand data storage functions see for example U.S. Pat. No. 7 836 018 entitled Simultaneously accessing file objects through web services and file services US Patent App. Pub. No. 2009 0112811 entitled Exposing Storage Resources with Differing Capabilities US Patent App. Pub. No. 2009 0112921 entitled Managing Files Using Layout Storage Objects US Patent App. Pub. No. 2009 0112880 entitled Managing File Objections in a Data Storage System and US Patent App. Pub. No. 2009 0112789 entitled Policy Based File Management all to Oliveira et al. and which are all hereby incorporated by reference.

It is noted that various issues may occur in connection with the management of resources using technologies like that discussed above. In particular for example policies such as service level agreements SLAs between clients and service providers may cause issues involving for example access times processing costs and load balancing requirements among multiple data centers that are geographically dispersed and subject to varying levels of access demands depending on particular locations and or particular times.

Accordingly it would be desirable to provide an system that efficiently and effectively manages distributed storage to address issues like that noted above particularly for a system in which resources are geographically dispersed.

According to the system described herein a method for managing I O request processing includes receiving an I O request. Policy information is maintained at an orchestration layer that is coupled to a plurality of compute sites that service I O requests in which the policy information affects servicing of the I O request. Using the policy information of the orchestration layer at least one of the plurality of compute sites to service the I O request is determined. Servicing of the I O request at the at least one compute site is orchestrated based on the policy information. The policy information may include dynamically updated information. The policy information may include i rate information for processing resources at the plurality of compute sites and or ii information corresponding to a service level agreement between a customer and a service provider. The plurality of compute sites may be located geographically distant from each other and the determining the at least one of the plurality of compute sites to service the I O request may include basing the determining on policy information that corresponds to a local time at the at least one of the plurality of compute sites. Servicing of the I O request at the at least one of the plurality of compute sites may be transparent to a host that sends the I O request. The method may further include receiving the policy information at the orchestration layer from an interface which may include an application programming interface and or a graphical user interface.

According further to the system described herein a computer readable medium stores computer software for managing I O request processing. The computer software may include executable code that receives an I O request. Executable code may be provided that maintains policy information at an orchestration layer that is coupled to a plurality of compute sites that service I O requests in which the policy information affects servicing of the I O request. Executable code may be provided that determines using the policy information of the orchestration layer at least one of the plurality of compute sites to service the I O request. Executable code may be provided that orchestrates servicing of the I O request at the at least one compute site based on the policy information. The policy information may include dynamically updated information. The policy information may include i rate information for processing resources at the plurality of compute sites and or ii information corresponding to a service level agreement between a customer and a service provider. The plurality of compute sites may be located geographically distant from each other. The executable code that determines the at least one of the plurality of compute sites to service the I O request may include executable code that bases the determination on policy information that corresponds to a local time at the at least one of the plurality of compute sites. Servicing of the I O request at the at least one of the plurality of compute sites may be transparent to a host that sends the I O request. Executable code may be provided that receives the policy information at the orchestration layer from an interface which may include an application programming interface and or a graphical user interface.

According further to the system described herein a system for managing I O request processing includes a plurality of compute sites that are connected and an orchestration layer that is coupled to the plurality of compute sites. The orchestration layer may include a computer readable medium storing computer software for managing I O request processing. The computer software may include executable code that maintains policy information at the orchestration layer that affects servicing of an I O request received for processing at the plurality of compute sites. Executable code may be provided that maintains policy information at the orchestration layer in which the policy information affects servicing of the I O request. Executable code may be provided that determines using the policy information of the orchestration layer at least one of the plurality of compute sites to service the I O request. Executable code may be provided that orchestrates servicing of the I O request at the at least one compute site based on the policy information. The plurality of compute sites may be located geographically distant from each other. The executable code that determines the at least one of the plurality of compute sites to service the I O request may include executable code that bases the determination on policy information that corresponds to a local time at the at least one of the plurality of compute sites. Executable code may be provided that receives the policy information at the orchestration layer from an interface.

Each of the hosts may be communicably coupled to one or more of access nodes over one or more network connections . It is noted that host devices may be operatively coupled with access nodes over any of a number of connection schemes as required for the specific application and geographical location relative to each of the access nodes including for example a direct wired or wireless connection an Internet connection a local area network LAN type connection a wide area network WAN type connection a VLAN a proprietary network connection etc.

Each of the access nodes may also include or be communicably coupled with one or more array management functions AMFs and may be communicably coupled with one or multiple storage resources each including one or more disk drives and or other storage volume over one or more storage area networks SANs and or other appropriate network such as a LAN WAN etc. The access nodes may be located in close physical proximity to each other or one or more may be remotely located e.g. geographically remote from other access nodes. Each of the access nodes may also be able to intercommunicate with other access nodes over an IP network a peripheral component interconnected PCI bus and or a Fibre channel FC network over the network and or over the SANs . Several of the access nodes may be grouped together at one or more sites in connection with the multiple storage resources and in which the sites are geographically distant from one another. The SANs may be separate networks located at the geographically distant locations. Alternatively in an embodiment the SANs may optionally be coupled to one another as schematically illustrated by a dashed line connecting the SANs .

Each directory manager may be responsible for providing coherence mechanisms for shared data across a distributed set of access nodes. The set of access nodes that are caching data from a shared data volume may be called a share group. In general the directory manager may include a module with software executing on a processor or other intelligence module e.g. ASIC in an access node. The directory manager may be implemented in a single access node or distributed across multiple intercommunicating access nodes. In certain aspects each of the nodes may be embodied as a controller device or blade communicably coupled to the storage network that allows access to data stored on the storage network. However it may be appreciated that an access node may also be embodied as an intelligent fabric switch a hub adapter and or other appropriate network device. Because Locality Conscious Directory Migration LCDM is applicable to databases any suitable networked compute node may be configured to operate as an access node with directory manager functionality. For example a directory manager may be run on a desktop computer with a network connection.

The multiple compute sites may together be engaged in a joint operations in connection with I O requests of one or more hosts like the host . The joint operations may include facilitating data mirroring including possibly allowing write access to multiple sites as well as managing access to the mirrored data for example in connection with data mirroring operations for example like that provided by a Remote Data Facility RDF storage product produced by EMC Corporation of Hopkinton Mass. such as a Symmetrix product and or a Clariion product. For further discussion of RDF and the use thereof in data recovery and storage techniques see e.g. U.S. Pat. No. 5 742 792 to Yanai et al. entitled Remote Data Mirroring and U.S. Patent App. Pub. No. 2006 0069887 to LeCrone et al. entitled Triangular Asynchronous Replication which are incorporated herein by reference.

The sites may be coupled via SANs to storage resources . The storage resources may be located in proximity to the sites and or may be remotely located and accessed. In an embodiment the SANs may be separate networks. Alternatively in another embodiment the SANs may be part of the same network an embodiment shown represented by a dashed line connecting the SANs . In various embodiments the joint operations may include multiple independent sub computations and may include operations of a clustered small computer system interface SCSI device corresponding to use of external storage nodes that may be accessed by one or more of the sites .

A distributed layer is shown schematically as a system of the sites that may be distributed across the sites in connection with processing of one or more access nodes. In a virtualization environment the distributed layer may function like a virtual center that provides for control of managing monitoring provisioning and migrating virtual machines A virtual machine is a software implementation of a machine that executes programs like a physical machine. The virtual center may provide for managing deployment of virtual machines at one or more data centers like the sites and may operate to control virtual machines at the sites in connection with cloud computing including both internal and external cloud infrastructures and hybrids thereof. Configuring and deploying virtual machines is known in the field of computer science. For example U.S. Pat. No. 7 577 722 to Khandekar et al. entitled Provisioning of Computer Systems Using Virtual Machines which is hereby incorporated by reference discloses techniques for configuring and deploying a virtual machine according to user specifications. The system described herein may operate in connection with a VPLEX product produced by EMC Corporation of Hopkinton Mass. that may provide a distributed software layer operating in a virtualization environment.

According to the system described herein an orchestration layer may be provided that provides policy driven orchestration for controlling access and or load balancing in connection with servicing I O requests among the sites in a cloud computing environment. I O requests from the hosts may be received by one or more of the sites over a communication link that may be a network such as the Internet and or other suitable communication link. The orchestration layer may be coupled to the sites including the distributed layer via a communication link that may be the same as or a different network than the communication link . The orchestration layer may control and implement policies and or other information for the servicing I O requests at one or more of the sites as further discussed elsewhere herein. In various embodiments the orchestration layer may be a software layer that is distributed across the sites like the distributed layer and or may be integrated in connection with an independent compute entity coupled to the sites . The orchestration layer orchestrates based for example on policies and or other information fed from manual and dynamic inputs where compute and storage processes may reside and provides non disruptive control for the servicing of I O requests that is fully enabled by a dynamic active active storage platform.

In another embodiment the GUI may provide information obtained from at one or more of the compute sites and or from one or more of the hosts with input information obtained from one or more users. The inputs may reflect specific information corresponding to service legal agreements SLAs with respect to service agreements for one or more customers and service providers. The orchestration layer may maintain and update various types of policies for controlling and or otherwise governing processing requirements such as requirements of a particular SLA load balancing requirements requirements of minimizing processing costs and or maximizing processing speed for one or more I O requests and or other processing considerations. In various embodiments the orchestration layer may include a policy engine that makes determinations driven by business policies SLAs performance requirements utility or other rate schedules and or other appropriate type of dynamic service input or dynamic triggers to execute various orchestration events.

The orchestration layer may be used to control selection of compute sites for the servicing of I O requests according to the one or more policies and based on the inputs to the orchestration layer . In an embodiment the distributed layer of one or more of the compute sites may determine an appropriate one of the compute sites to handle any particular I O request based on the policy and or other information maintained by the orchestration layer and route the I O request to the appropriately determined compute site. The system described herein provides a system that may respond to a particular level of activity at one or more of the compute sites . For example a burst of data processing requests may occur for a particularly high usage period in the middle of the day for one or more of the compute sites e.g. compute site . Accordingly routing of I O requests to one or more of the other computes sites e.g. compute sites may be controlled using the orchestration layer in response to a burst period.

According to an embodiment of the system described herein each of the computes sites may be geographically distant from other of the compute sites. Thus for example based on a policy that dictates processing at compute sites having a local time in the middle of the night e.g. a time tier of 1 00 am to 4 00 am for which processing activity may be low and or processing resources may be inexpensive the orchestration layer may provide policies and maintain information such as utility rate information to control the passing of at least some of the I O requests to compute sites having a local time within the desired time tier. Since the compute sites may for example be geographically dispersed world wide as time passes different sites may enter the desired time window tier thereby becoming a preferred compute site e.g. becoming for example a tier 0 compute site while other compute sites located geographically elsewhere may exit the desired time window tier and be designated a less preferred compute site becoming for example a tier 1 or other tier compute site . The orchestration layer keeps track of this information and or other policy requirements which is used to route I O requests accordingly among the compute sites .

In various embodiment there may be three main categories of input feed types provided by the inputs that are implemented by the orchestration layer . One input feed type may include static information for which I O requests are routed according to specific information for example specific time and location based information and or processing characteristic requirements. A second input feed type may static dynamic information for which I O requests are routed according to specific business policy and or SLAs for example. Once this input is received the system described herein may dynamically interact across geographies to determine what actions to take based upon the initial static entry. A third input feed type may be fully dynamic for which the inputs are dynamic and fed from other automated inputs. For example a fully dynamic input may be a utility rate schedule that triggers various behaviors in the system described herein. Another example may be a retail billing system feeding information triggering various behaviors in the system described herein to accommodate application needs.

In other embodiments various ones of the computes sites may have specific processing characteristics such as a site with predominantly fast flash memory or large capacity inexpensive memory and or other processing capabilities that designates that site at a particular tier level according to a policy implemented by the orchestration layer . For example an SLA for a particular customer may require processing at a specified resource criteria. Such policy information may be maintained by the orchestration layer and I O requests may be routed to appropriate compute sites that meet the requirements of the policy for the particular SLA. As discussed elsewhere herein other types of policies may be used in accordance with the system described herein based on any appropriate criteria.

After the step processing proceeds to a step one or more sites from among the cloud configuration of sites like the sites is determined as suitable to service the I O request according to the policy and the input information maintained by the orchestration layer . For example in an embodiment the policy and inputs may correspond to preferred servicing of the I O request at a site having a local time in the middle night where processing activity and or cost is low and the orchestration layer may determine the appropriate site in a tier that is presently within the desired time window. After the step processing proceeds to a step where the I O request is routed to the appropriate site for servicing based on the policy and or other information maintained by the orchestration layer . In various embodiments a distributed layer like the distributed layer discussed elsewhere herein may control the routing of the I O request among the compute sites based on the policy and or other information maintained at the orchestration layer . After the step processing proceeds to a test step where it is determined whether other I O requests at to be routed according to the system described herein. If so then processing proceeds back to the step . If not then processing is complete.

It should be noted that according to an embodiment of the system described herein the compute sites servicing I O requests may be transparent to the requesting host. That is the host may not be aware that different ones of the computes sites at different geographical locations are processing the host s I O requests.

Various embodiments discussed herein may be combined with each other in appropriate combinations in connection with the system described herein. Additionally in some instances the order of steps in the flowcharts flow diagrams and or described flow processing may be modified where appropriate. Further various aspects of the system described herein may be implemented using software hardware a combination of software and hardware and or other computer implemented modules or devices having the described features and performing the described functions. Software implementations of the system described herein may include executable code that is stored in a computer readable storage medium and executed by one or more processors. The computer readable storage medium may include a computer hard drive ROM RAM flash memory portable computer storage media such as a CD ROM a DVD ROM a flash drive and or other drive with for example a universal serial bus USB interface and or any other appropriate tangible storage medium or computer memory on which executable code may be stored and executed by a processor. The system described herein may be used in connection with any appropriate operating system.

Other embodiments of the invention will be apparent to those skilled in the art from a consideration of the specification or practice of the invention disclosed herein. It is intended that the specification and examples be considered as exemplary only with the true scope and spirit of the invention being indicated by the following claims.

