---

title: Accurate pelvic fracture detection for X-ray and CT images
abstract: Accurate pelvic fracture detection is accomplished with automated X-ray and Computed Tomography (CT) images for diagnosis and recommended therapy. The system combines computational methods to process images from two different modalities, using Active Shape Model (ASM), spline interpolation, active contours, and wavelet transform. By processing both X-ray and CT images, features which may be visible under one modality and not under the other are extracted and validates and confirms information visible in both. The X-ray component uses hierarchical approach based on directed Hough Transform to detect pelvic structures, removing the need for manual initialization. The X-ray component uses cubic spline interpolation to regulate ASM deformation during X-ray image segmentation. Key regions of the pelvis are first segmented and identified, allowing detection methods to be specialized to each structure using anatomical knowledge. The CT processing component is able to distinguish bone from other non-bone objects with similar visual characteristics, such a blood and contrast fluid, permitting detection and quantification of soft tissue hemorrhage. The CT processing component draws attention to slices where irregularities are detected, reducing the time to fully examine a pelvic CT scan. The quantitative measurement of bone displacement and hemorrhage area are used as input for a trauma decision-support system, along with physiological signals, injury details and demographic information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08538117&OS=08538117&RS=08538117
owner: Virginia Commonwealth University
number: 08538117
owner_city: Richmond
owner_country: US
publication_date: 20100317
---
This application is a 371 of international application PCT US10 27601 filed Mar. 17 2010 which claims priority to U.S. Provisional Applications Serial No. 61 167 279 filed Apr. 7 2009 and to Ser. No. 61 167 275 filed Apr. 7 2009.

The U.S. Government has a paid up license in this invention and the right in limited circumstances to require the patent owner to license on reasonable terms as provided for by the terms of Grant No. 05 0033 02 awarded by U.S. Medical Research and Material Command Combat Casualty Care Research Program and by the terms of NSF Grant No. IISO758410.

The present invention generally relates to a system and method for the application of advanced image processing techniques to detect key pelvic structures and more particularly to the automated analysis of X ray radiographs and Computed Tomography CT images to provide diagnostic recommendations for physicians and radiologists. As used herein X ray images refer to plain film radiographs.

Pelvic fractures are among the most life threatening injuries that can be suffered by a major trauma patient. Most deaths from such injuries are caused by complications other than the fracture itself severe hemorrhage is a particularly high risk. Prompt and appropriate treatment is therefore vital to patient survival. X ray imaging is the first line diagnostic step in treating pelvic injury patients due to its speed and low cost. It also causes relatively little disturbance to the injured patient. However the structure of the pelvis is complex and fractures may be hard to recognize on low resolution X rays even by medical professionals. A system capable of quickly identifying pelvic fracture would prove valuable in a trauma center environment and a crucial component of such a system is a method to detect and segment key pelvic structures.

Location of fracture has considerable impact on its severity and visual characteristics. Current X ray segmentation techniques focus on the use of deformable models. However most studies have focused on segmentation of simpler structures such as bones in the hand. Furthermore many of these methods rely on some measure of manual interaction by the user to correctly initialize the algorithm as deformable models are typically very sensitive to initialization in a high stress trauma environment any useful system would need this to be performed automatically.

Computed Tomography CT of the pelvic regions is used to diagnose the more complicated cases as it is more detailed. CT is usually used to confirm hip displacement to detect acetabular fracture to determine whether or not internal bleeding is present and to evaluate the severity of hemorrhage. Identifying and classifying bone by segmenting CT images is an important and challenging task in detecting pelvic fractures. The density of the outer bone cortical bone is much higher from that of the core cancellous bone. Cortical bone appears to be bright and smooth while cancellous bone is darker and has a sponge like texture therefore bone density cannot be uniformly characterized see for example T. B. S. Authors H. Tek J. J. Crisco and B. B. Kimia Segmentation of carpal bones from ct images using skeletally coupled deformable models 7 1 21 45 March 2003 . Differences in density can result in bone not being segmented correctly regions of bone that need to be connected are identified as being separate. Another factor that adds to the complexity of the problem is the high number of slices in a CT scan. The differences between the positioning of the bones across the slices and the different types of fractures make identifying the presence of a fracture very difficult. Detecting the exact edges of bone is hard as they are diffused due to the partial volume effects in CT images. When distance between distinct bones is small distinguishing between the bones becomes more difficult.

Pelvic fractures as well as open or closed internal bleeding can be diagnosed by trauma surgeons and radiologists after inspection of X rays and CT scans of the pelvic region. A system that would analyze these images and identify possible locations of fractures and or bleeding would be useful in improving the decision making process.

An embodiment of the invention provides advanced image processing techniques to analyze pelvic images to detect key pelvic structures for fracture detection.

An embodiment of the invention provides a fully automated system and method to accurately segment bone tissue in order to assess the presence of pelvic fractures.

In an embodiment of the invention accurate pelvic fracture detection is accomplished with automated X ray and Computed Tomography CT images for diagnosis and recommended therapy. The embodiment combines computational methods to process images from two different modalities. By processing both X ray and CT images features which may be visible under one modality and not under the other are extracted and validates and confirms information visible in both. The X ray component uses hierarchical approach based on directed Hough Transform to detect pelvic structures removing the need for manual initialization. The X ray component uses cubic spline interpolation to regulate ASM deformation during X ray image segmentation. Key regions of the pelvis are first segmented and identified allowing detection methods to be specialized to each structure using anatomical knowledge. The CT processing component is able to distinguish bone from other non bone objects with similar visual characteristics such a blood and contrast fluid permitting detection and quantification of soft tissue hemorrhage. The CT processing component draws attention to slices where irregularities are detected reducing the time to fully examine a pelvic CT scan. The quantitative measurement of bone displacement and hemorrhage area are used as input for a trauma decision support system along with physiological signals injury details and demographic information.

According to one aspect of the invention deformable models are applied to the task of X ray segmentation specifically Active Shape Model ASM as has been done previously. However there are two crucial differences. The first is the use of a hierarchical algorithm to handle automatic initialization based on knowledge of pelvic anatomy This involves the use of Hough Transform and edge detection and some statistical knowledge of bone size and shape. The second is the extension of the standard ASM algorithm to incorporate cubic polynomial splines. These maintain the natural curvature of the pelvic structure and help prevent the model from converging to false edges a common problem in low resolution X ray images. Although splines have been used in medical image segmentation before they have not been combined with ASM and have also not been used primarily for constraining model deformation as opposed to finding new points on the edge of the desired structure. Both algorithms are trained on a set of images taken from pelvic trauma patients and tested on a separate set.

According to another aspect of the invention the system and method employs advanced image processing techniques to analyze pelvic CT images to correctly segment bone tissue in a fully automated manner. The invention implements wavelet processing Laplacian filtering morphology operations a series of region growing techniques and gradient based segmentation methods to create an automated segmentation system and provides an automated decision making system that provides physicians with reliable recommendations for the treatment of traumatic pelvic injuries.

According to a further aspect of the invention X ray images and CT images are combined with raw physiological signals and other information including demographics and injury details to produce a processed pelvic trauma database. Machine learning methods are applied to this database in a trauma decision support system. More particularly machine learning techniques including creating decision trees and extracting rules are applied to the database to generate predictive models of patient outcome. These models are used to provide recommendations and predictions to physicians assisting them in making rapid and accurate treatment choices for new patients.

While the invention is described in terms of a specific embodiment specialized toward pelvic injuries those skilled in the art will recognize that the techniques implemented by the embodiment can be adapted to other bone structures and the analysis methods reconfigured using anatomical knowledge.

The embodiment of the invention is described in terms of a system on which the methods of the invention may be implemented. The system is composed of various imaging components databases and computational interfaces that one of ordinary skill in the computational arts will be familiar with. The methods of the invention are described with reference to flowcharts which illustrate the logic of the processes implemented. The flowcharts and the accompanying descriptions are sufficient for one of ordinary skill in the computer programming and image processing arts to prepare the necessary code to implement the embodiment of the invention.

Referring now to the drawings and more particularly to there is presented in block diagram form an overview of the decision support system framework and the function that the X ray and CT components serve. X ray image processing is performed at the X ray images being input at . CT image processing is performed at the CT images being input at . Other information including demographics injury details etc. are input at . The X ray images input at are subjected to automated hierarchical segmentation via spline Active Shape Modeling ASM at . Then fracture detection via wavelet transform and edge tracing is performed at . Additionally quantitative measures of displacement and symmetry are performed at . CT images input at are subjected to automated segmentation via active contour and wavelet filtering at . Then bone identification via template shape matching is performed at . The data from and are input to a processed pelvic trauma database . The processing done thus far may be referred to as pre processing and the data stored in database is pre processed data requiring further processing in order to generate diagnosis and recommended therapy.

This database is accessed by data processor which applies machine leaning techniques specifically creating decision trees and extracting rules to generate predictive models of patient outcome. In the training phase the demographic and injury data input at and stored in database is a prior dataset used to train the predictive model generated by the data processor . This prior dataset in the case of the embodiment of the invention was obtained from two hospitals along with matching CT and or X ray images for each patient and their eventual outcome. When the generated model is later used to make predictions for a new patient the same information is collected and used as input. These models are used by the system to provide recommendations and predictions to physicians assisting them in making rapid and accurate treatment choices for patients. The recommendations and predictions are displayed on display and data processor correlates the recommendations and predictions and actions taken by the physician as input on user interface with the patient s records which are stored in patient record database .

The process of hierarchical automated segmentation of pelvic structures illustrated generally at in is shown in more detail in . This component requires training prior to deployment. This only needs to be done once using a set of training X ray images where the specific structures to be detected have been labeled by placing landmark points around their edges . This component of the system segments key structures from an input frontal pelvic X ray supplied as a Digital Imaging and Communications in Medicine DICOM file. With reference to a frontal pelvis X ray image of pelvic trauma patient is input to process . At step vertical Directed Hough Transform is applied to the lower third of X ray image to detect femoral shafts. The Directed Hough transform examines each pixel in the given image portion and looks for evidence of a straight line restricted to 45 of the vertical. If one is found the transform calculates the unknown parameters m and b of the straight line equation y mx b. The process then increases the value of the corresponding bins for m and b in a two dimensional 2D accumulator array. After all pixels are considered a set of candidate femoral shaft edges are extracted by finding the bins with the highest values via thresholding. These are then paired into candidate shafts.

The probability pthat a pair of lines i in the test image form a shaft contour is given by 1 where and are the mean and standard deviation of shaft width calculated from a sample training set of X ray images and Mis the mean of the intensity gradient magnitudes of the points along both lines in the pair. The top four candidates are kept. A similar process is then used to match shaft pairs using a distribution calculated based on the distance between the left and right shafts in the X ray training set. Full implementation details of Hough Transform for line and circle detection can be found Use of the Hough Transformation to Detect Lines and Curves in Pictures Richard O. Duda and Peter E. Hart Technical Note 36 Artificial Intelligence Center 1971 .

In step Hough Circle Transform is applied to detect approximate position of femoral heads. The process of step returns coordinates representing detected femoral shaft edges. These are used to direct Hough Transform circle detection to identify the femoral heads on both sides. This uses the same approach as Hough Line Transform in Box except it uses a three dimensional 3D accumulator since there are three unknown parameters a b and r for the parametric circle equation x a y b r .

In step the left and right femur are detected via Spline ASM place initial model using detected circle. On each side the topmost point on the detected femoral head circle is used to initialize Spline ASM to detect the femur as a whole. This component combines cubic spline interpolation with the standard Active Shape Model ASM deformable model approach.

Standard ASM searches for a target shape in an image using a model defined by an set of landmark points. It takes as input a series of training images in which the target shape has been labeled by landmark points. These images provide a set of shapes represented as vectors of x y coordinates. Alignment and Principal Component Analysis are performed on the set so each shape can be approximated by 2 where P contains the t eigenvectors of the covariance matrix calculated during PCA and b is a t dimensional vector which defines the parameters for the deformable shape model. A grey level model is built by sampling the derivative of the intensity values along the profile normal to the landmark in each training image. For each landmark the normalized mean and covariance Sof the sample is calculated. During each iteration of the shape matching process a specific number of pixels are sampled along the profile normal to each current landmark point p. The quality of fit for each pixel q x y is calculated as 3 The landmark point is moved to the pixel with the lowest value of f g and b is updated to fit these new positions. The process halts when an iteration results in no significant changes in b. More details of basic ASM are found in Active shape models their training and application T. F. Cootes C. J. Taylor D. H. Cooper and J. Graham Computer Vision and Image Understanding vol. 61 no. 1 pp. 38 59 January 1995 .

Spline ASM incorporates cubic spline interpolation into the ASM quality of fit function. Cubic spline interpolation is used to approximate more complicated curves and involves building a cubic spline from n piecewise cubic polynomials between a set of given data points along the curve. Given n 1 distinct knots points xwhere I 0 . . . n and n 1 corresponding knot values y the aim is to find a piecewise cubic spline function S x such that

In Spline ASM when considering landmark point p an interpolated cubic spline function is constructed using m points on each side of p. This function is used to predict the best new location of point pusing its x coordinate to give the predicted point location l x y . When considering pixel q as a possibly new landmark location the distance between qand l is calculated and squared to obtain an error measure e 6 The quality of fit function then becomes 7 where is chosen via experimental results. In the most recent set of experiments the optimal value of was found to be 0.00001.

Spline ASM requires initial placement of the shape model which will then try to deform to the nearest suitable edges. For the femur this placement is done by matching the position of the topmost landmark on the femur shape model with the topmost point of the femoral head circle detected in process step .

Process step passes on two matrices describing the detected left and right femurs. Each matrix consists of multiple coordinate pairs sequential points in the image that define the femur. Two selected coordinate pairs one from the left femur and one from the right femur are used to initialize placement of the pelvic ring model. Spline ASM is then repeated to detect the pelvic ring in process .

The output of process is input to process to detect left and right iliac crests. In step directed Hough Circle Transform is used for approximate position of iliac Crests using uppermost land marks on pelvic ring . The two uppermost landmark points on the pelvic ring are used to create two separate windows likely to contain the left and right iliac crests. These windows are used to direct Hough Circle Transform for approximate detection of the crests. In step refined detection of left and right crests is performed via Spline ASM. For each crest the topmost point on the circle detected in step is used to initialize placement of the iliac crest ASM model. Spline ASM is then performed to detect the crest.

The process in step detects left and right pubis via Spline ASM initialized using femur landmark positions and pelvic ring landmarks from step . For each side of the pubis two selected coordinate pairs one from the femur and one from the pelvic ring are used to initialize placement of the pubis ASM model. Spline ASM is then performed to detect each side of the pubis.

The output of this stage is a set of detected pelvic structures i.e. iliac crests pelvic ring pubis and femurs in the form of matrices of landmark points around the edge of each structure.

The calculation of displacement process shown in is illustrated in more detail in . This stage of the system calculates displacement and symmetry measures using the structures segmented in the first stage . A set of pelvic structures detected in stage iliac crests pelvic ring pubis and femurs in the form of matrices of landmark points around the edge each structure are input. Process calculates vertical pubis displacement. At step the vertical distance between topmost and bottommost landmarks along inner edge of left and right pubis is measured and then in step the average is calculated to get vertical pubis displacement. Each detected side of the pubis is represented by a matrix of x y points. On each side the topmost and bottommost points on the inside vertical edge of the pubis are selected to give two pairs of points t x y t x y b x y b x y . Vertical displacement is calculated as 

The structures segmented in the first stage are also input to process for calculation of the horizontal pubis gap. In step the horizontal distance between each landmark along inner edge of left and right pubis is measured and in step the average of distances is calculated to get horizontal pubis gap. Horizontal gap is determined by calculating the average horizontal distance between the left and right pubis. The n landmarks along the inside edges of each structure s model are paired up and the difference in the x coordinates of each pair is calculated and the results averaged over the number of landmarks n. Let lx ly be the landmark coordinates on the left pubis and rx ry those on the right pubis where I 0 . . . n 1 . The horizontal gap g is calculated as 

The structures segmented in the first stage are also input to process to calculate ring symmetry displacement. In step a straight vertical line equal distance between inner edge of left and right pubis is found. This step finds the vertical straight line roughly equal distance between the left and right pubis. The line is found using the calculations already completed in steps and . In step a straight vertical line dividing pelvic ring into roughly equal halves is found based on average distance between corresponding landmarks on each side . By comparing the line calculated in step to a second line dividing the area inside the pelvic ring into two roughly symmetric halves symmetric displacement can be measured which may indicate deformation of the pelvic structure and loss of ring integrity . This second line is calculated in a similar method to the horizontal gap in steps and using corresponding landmarks on either side of the pelvic ring model in place of those on the inside edge of the pubis. Then in step the horizontal distance between both lines is calculated. The horizontal distance between the vertical straight lines constructed in steps and is calculated as the absolute difference of their x coordinates.

Process receives the outputs from each of processes and and normalizes all values by average diameter of left and right femoral heads calculated using landmark positions . The distance of the X ray machine from the patient may vary therefore the pelvic structure size will not be standardized across multiple X ray images. To adjust for this the raw displacement and symmetry measures are normalized using the average diameter in pixels of the left and right femoral heads.

The fracture detection process shown in is illustrated in more detail in . This stage of the system detects fractures of the acetabulum upper pubis and general pelvic ring using the structures segmented in the first stage. The input to this stage is the set of pelvic structures detected in stage i.e. iliac crests pelvic ring pubis and femurs in the form of matrices of landmark points around the edge each structure. In step overlapping windows are created around the pelvic ring using landmark positions. The pelvic ring is represented by twenty six consecutive landmarks starting at the top right and ending at the top left. This structure is separated into overlapping windows each covering four landmarks and each window is analyzed separately for presence of fracture. The windows overlap i.e. the first window covers landmarks one to four the second window covers landmarks three to seven etc. to prevent fractures crossing between windows from being missed. Each window is labeled according to the type of fracture it is likely to contain here acetabulum upper pubis or general pelvic ring.

The output window of step is subject iterative processing in process . In step adaptive histogram equalization and de noising by DWT 2 level Haar wavelet is performed. Step outputs a set of window sub images around the ring. Each is analyzed individually. X rays are often low contrast therefore Contrast Limited Adaptive Histogram Equalization CLAHE is first performed on the window to make the ring edges more visible. CLAHE partitions the X ray into regions and applies histogram equalization to CLAHE one improving contrast and evening out grey level distribution. This is widely used in imaging software and the full mathematical details of the algorithm can be found in Contrast Limited Adaptive Histogram Equalization Karel Zuiderveld Academic Press Graphics Gems Series Graphics Gems IV pp. 474 485 1994 . The window is then de noised via two level 2D stationary wavelet decomposition using the Haar wavelet. This decomposes the window into two levels of approximation and detail coefficients. The detail coefficients are thresholded. All coefficients are used to reconstruct the window which is now de noised. This simplifies edge detection by smoothing over X ray artifacts stationary wavelet decomposition is used as it does not require sub sampling of the original window. The mathematical description of SWT is lengthy it can be found in full in The Stationary Wavelet Transform and some Statistical Applications G. P. Nason and B. W. Silverman Dept. of Mathematics University of Bristol 1995 .

In step a 2D Discrete Wavelet Transform DWT is used for pelvic ring boundary detection 1 level Haar wavelet . Single level 2D wavelet decomposition is performed on the de noised window using the Barr wavelet. The window is regarded as a series of one dimensional 1D row signals and as a series of 1D column signals. The 1D DWT is calculated for each row and the N rows of result values used to form a matrix X. The same is repeated for columns to form a matrix X. This process is repeated on Xand X giving output matrices X X X and X. The first two contain information on the window s vertical and horizontal variations respectively and the third and fourth the diagonal variations the detail coefficients for the window . More information on 2D DWT can be found in Kayvan Najarian and Robert Splinter CRC Press 2006 .

In step the coefficient for reconstruction is chosen diagonal horizontal vertical by gradient between window landmarks. The best detail coefficient for edge detection is chosen as the one most similar in direction and angle to the bone boundary. The gradient of the bone boundary is approximated by the gradient along the landmark points used to select the window. If the absolute value of the gradient is closest to 0 the horizontal coefficient is chosen 0.5 the diagonal 1 the vertical.

In step the window image is reconstructed with ring boundary highlighted and converted to binary form and then in step opening and thinning morphological operations are used to remove artifacts and combine edges. The chosen coefficient at level one decomposition is used to reconstruct the window. The resulting 8 bit grey level image is thresholded to create a binary image. The threshold value is chosen using Otsu s method such that it minimizes the intra class variance of the black and white pixels. Implementation details are in A Threshold Selection Method from Grey Level Histograms Nobuyuki Otsu vol. SMC 9 No. 1 January 1979 . The resulting binary image will highlight the boundary detected by the wavelet transform in white pixels. However there will be noise such as dual edges and isolated pixels or small objects. A sequence of morphological opening and thinning operations is performed to remove these pixels and artifacts and join close edges along the detected bone boundary.

In step edge tracing using 8 neighborhood of each pixel along ring bone boundary is performed. After steps and the output is a binary image in which the approximate bone boundary appears as a white line. If there are fractures present this line will have breaks. Starting at the top of the window the edge is traced using 8 neighbor connectivity. If the end of the edge is reached i.e. there are no more white pixels a new edge is started.

In step the edges found in window are output as matrices of pixel positions. 1 edge indicates break in ring i.e. a possible fracture. If more than one edge is returned from there is a possible fracture. The edges are stored as matrices of pixel positions therefore the end pixels of the two edges either side of the break can be used to identify the potential fracture s location. This is originally given in coordinates relative to the window and is therefore adjusted based on window position to give coordinates relative to the entire X ray image.

In step consecutive overlapping windows are checked by landmark ensure each fracture only detected once . Each window covers four landmarks with the final two overlapping with the start of the next window. The windows are considered in sequence if a detected fracture falls within these two landmarks it will not be counted in the following windows. Fracture type e.g. acetabulum upper pubis or general pelvic ring is identified by window label as described in step .

Turning next to the CT image processing system in reference is now made to which presents a flowchart describing the operation of the CT bone detection subsystem. Pelvic CT slices are input at to a process which performs preprocessing and preliminary segmentation. This is accomplished by the process generally indicated at the first segmentation stage and described in more detail with reference to . The first step of this process is to isolate the abdominal region. Next in step the bone mask is formed. Then in step seeds are formed on the contours and the seeds are grown. The output of process are candidate bone objects. These are received by process shape matching object recognition. This is accomplished by the process generally indicated at and described in more detail with reference to . The first step is to form bone templates. Then matching cost between template and preliminary segmentation is calculated at step . Based on this calculation the template with the lowest matching cost is selected at step . The selected template is used in step to exclude or retain segmentation regions. The output of the shape matching object recognition process is the roughly segmented bone. This is input to the snake model for final bone segmentation process . This is accomplished by the process indicated at second segmentation stage. The first step is to filter the original CT slice. Then in step a snake model is generated. This is input to step which initializes the snake model in the object detected image. Finally in step the snake model is evolved for final bone segmentation. The output is the detected bones.

The first segmentation stage is shown in more detail in . This stage of the. system performs initial segmentation of a single CT slice removing artifacts and returning a set of regions that may contain bone matter candidate bone objects . The input to this stage is an individual pelvic CT slice.

The first process isolates the abdominal region. At step the CT slice is converted to binary image and in step blob analysis is used to find the largest object. Since bone matter has a brighter grey level value than soft tissue the slice is thresholded to a binary black and white image . As with steps and in Otsu s method is used to determine the most appropriate threshold. Bright objects in the slice will appear as white pixel regions in the binary image. Since binary thresholding is always approximate morphological operations such as opening are applied to disconnect these objects. For example cables around the patient often appear as bright pixel regions in the CT slices and must be disconnected from the main abdominal region. Since the abdominal area will always be the largest object in a CT slice blob analysis is used in step to calculate the area of each detected object and the largest one is retained.

In step an abdominal mask is built using largest object. The abdominal object detected in step is isolated into a new binary image the abdominal mask. This mask is multiplied in step with the original CT slice to isolate the abdominal area from background artifacts. The resulting image will be known as I.

The image Iis input to process to form the initial bone mask. In step the image de noised and smoothed via Gaussian filter and wavelet transform. A 2D Gaussian filter is applied to image Ito reduce noise. This is the product of two 1D Gaussian filters and is formulated as 

In steps and the threshold is calculated using statistical measures and threshold bone mask. First we calculate the mean and standard deviation of the grey level values of all pixels in I. These are used to calculate the threshold tfor creating a bone mask given by t m st where 

The initial bone mask output from process is input to process to find seed regions. At step the original image smoothed i.e. eliminate noise from original image using adaptive Gaussian filter. The initial bone mask Breturned from step is refined to create an intermediary bone mask B. First an initial Gaussian filter is applied to the abdominal image Ito create filtered image G. The difference image Dis formed by subtracting Gfrom I. The standard deviation of the grey level values of Dis then calculated and used to determine the size of a filter window to be used in constructing an adaptive Gaussian filter which offers better noise reduction. Full details are found in An Adaptive Gaussian Filter For Noise Reduction and Edge Detection G. Deng and L. W. Cahill Nuclear Science Symposium and Medical Imaging 1994 . The adaptative 2D Gaussian filter is applied to I creating image I. The initial bone mask Bis applied to this image via multiplication to create the intermediary bone mask B.

In step Laplacian filter is applied to enhance discontinuities and then in step Canny edge detection is performed to find seed regions. A Laplacian filter is applied to the original image Ifor edge detection. Seeds scattered in the brightest regions of the slice are then identified by selecting the pixels in the filled mask Bwith corresponding negative values in the Laplacian filtered image. The regions containing these seeds are then identified using Canny edge detection as outlined in A Computational Approach to Edge Detection Canny 1986 . The edge pixels and seed pixels for each region are combined and regions less than 50 pixels in area are discarded. Contour seeds are placed on the edges of the remaining regions again detected using the Canny method .

The output of process is input to process growing seed regions. At step 9 9 neighborhood of each seed pixel is found and gradients calculated. Each seed placed in steps and is considered in turn. The 9 9 pixel neighborhood of each seed pixel is found i.e. a set of the 80 pixels forming a 9 9 square around the seed pixel in the image excluding the seed pixel itself . The gradients of the grey level values between the seed pixel and each of its neighbor are then calculated. After all gradients are calculated the average gradient vis found.

At step average grey level of 5 5 neighborhood of each seed neighbor is calculated. For each neighbor pixel found in step we extract its 5 5 neighborhood. This contains 24 pixels in total. We calculate the average grey level value gof all 24 pixels.

Finally in step the gradient and grey level is used to decide whether to include neighbor in growing seed region. The neighbor is added to the seed set if it is on the inside of the edge its grey level value is gas calculated in step and the gradient value between the seed and the neighbor calculated in is v. Note that steps to the region growing stage are repeated until either until ten iterations have occurred or until the number of new seeds that an iteration adds is less than 10 of the number of existing seeds in the region.

Shape matching and object recognition as performed in process of is shown in more detail in . This stage of the system analyzes the set of candidate bone objects and removes those less likely to be actual bone matter via a shape matching approach. The input is the set of candidate bone objects created by initial segmentation stage represented by a segmented slice image.

At step bone templates are manually formed from reference CT scan. Bone templates are created using CT images from the Visible Human Project by manually selecting bone regions from the chosen slices. Template matching is necessary since the set of candidate objects created by initial segmentation is likely to contain blood tissue and fluids as well as bone matter and these must be filtered out.

Then for each bone template process is performed. In step control points on edges of each shape in segmented image and template are selected. The method for shape matching was introduced by Shape matching and object recognition using shape contexts S. Belongie J. Malik and J. Puzicha vol. 24 no. 4 pp. 509 522 April 2002 . Each bone template Ris considered in turn. For each object in the segmented image Iand each object in the bone template R control points are placed around the edge. These control points allow matching of objects between the two images. The number of control points used for each object is a percentage of its total number of edge points.

At step the shape context around each control point is determined. Shape context is a way of describing a shape that allows for measuring shape similarity. For a control point pon the contour of an object the shape context is given by Card 15 In other words shape context is provided by the histogram of the relative coordinates of all the other control points around the same object. We calculate the shape context for all contour points in both the template image and the segmentation image.

At step matching cost for points between two shapes is calculated and at step the total matching cost between each shape is determined. The cost Cof matching a point pin the segmented image with a point qin the bone template is 

The output of process is input to process filter candidate bone object set. There at step the total matching cost between segmented image and each bone template is calculated to find best template. The steps in process are repeated for each bone template image. An image match cost value is calculated each time as the sum of the shape match costs between the segmented image and template. The best bone template R for the CT slice currently under consideration is the one that gives the lowest image match cost. Or more formally min 17 

At step the best template is used to eliminate objects in segmented image. We use the template Rto select the most likely bone objects from the candidate set. This is done by sequentially eliminating individual candidate bone objects from the segmented image then calculating the image match cost between the resulting segmentation partition and the bone template. If an object representing bone is incorrectly removed this cost will increase. Conversely if a non bone object is removed the cost will decrease. This method is repeated to obtain the lowest matching cost the corresponding segmentation partition contains the most likely set of hone objects.

The second segmentation stage shown in is illustrated in more detail in . This stage of the system takes the set of likely bone objects returned by shape matching and performs more accurate segmentation using a snake method. This is the second and final stage of bone detection segmentation. The input to this stage is the set of most likely bone objects created during object recognition and the adaptive Gaussian filtered version of the original image created during the initial segmentation stage see .

The first process is to calculate snake parameters. At step the magnitude of the gradient for the adaptive gaussian filtered version of the original image I is calculated and in step the edge map is created. Active contours or snakes are used frequently in computer vision for detecting object edges. A snake is defined as an energy minimizing spline whose energy depends on its shape and location within the image. Its behavior is guided by external and internal forces and use of the right external force helps guide the snake toward edges. For this we use the Vector Field Convolution VFC method as defined in Active contour external force using vector field convolution for image segmentation Bing Li and Scott T. Acton vol. 16 no. 8 pp. 2096 2106 August 2007 . First the edge map f x y is calculated from the image I generated in the initial segmentation stage by applying an adaptive Gaussian filter to the original abdomen image I . This is done by calculating I s gradient magnitude using the following formula 

At step the Vector Field Kernel VFK is calculated. The vector field kernel VFK k x y u x y v x y is defined by 20 where m x y is the magnitude of the vector at x y and n x y is the unit vector that points towards the kernel origin. This is given by 

At step VFC external force is calculated using VFK. The external force to apply to the snake is calculated as the convolution of the VFK determined in step and the edge map generated in step 22 In the edge map points near image edges have larger values so they contribute more to the VFC force. This causes the snake to be attracted to edges in the image i.e. the contours of bone objects. This force is passed straight to process which evolves the snake.

The input to process initialize snake is the set of most likely bone objects. In step the binary version of shape matched image is obtained and in step dilation is applied to enlarge region s shape. The segmented shape matched image containing most likely bone objects is thresholded to give a binary image B. The separate regions or objects in the binary image are identified. In the original image these regions are most likely to contain the pelvic bones. Once identified morphological dilation is applied to enlarge each region. This ensures that the edges of the regions in Bare outside the natural bone edges in the segmented shape matched image.

In step the object edges in shape matched image are detected via Canny edge detection and in step 5 10 of edge points are selected as seeds to initialize the snake. Edges in the shape matched image are identified using Canny edge detection full mathematical details on this method can be found in A Computational Approach to Edge Detection John Canny Fischler and Firschein Eds. Morgan Kaufmann Pub. pp. 184 203 1987 . Seeds for initializing the snake are then placed along the detected edges at approximately equal distances apart. The total number of seeds placed is 5 10 of total edge length.

In step the snake curve is initialized. More specifically the snake curve is initialized as a B spline curve. This is a continuous parametric curve that depends only on a set number of control points and is defined by 

Returning to process the snake curve is evolved to minimize energy functional. The snake curve evolves by trying to minimize the sum of its internal and external energies defined by the energy functional 

In step a correlation based selection is made of subset containing most significant features for prediction task. The Correlation based Feature Selector algorithm CFS ranks feature subsets according to a correlation based evaluation function favoring those than contain features highly correlated with the class and uncorrelated with each other. This chooses the most predictive feature subset for the task. The evaluation function is given by 

The results are input to rule generation process . In step decision trees are built using CART and C4.5 algorithms. Using the reduced feature subset output by process the Classification and Regression Tree CART and C4.5 algorithms are used to build binary decision trees classifying input cases into one of two classes for example ICU Intensive Care Unit days 2 and 2 . At each step of tree construction the process chooses the best variable to split on where best reflects how well the split creates subsets that have the same value as the target variable.

CART uses the Gini index which measures the impurity of a data partition. It reaches its maximum value when the two subset sizes at the node are equal and minimum when only one of the two classes is present at the node. Gini index is defined as 

C4.5 splits on the variable with the highest normalized information gain a measure based on the concept of entropy. This is calculated as Entropy Entropy 27 where S is the dataset A is the splitting variable and entropy is defined as 

In step grammatical rules are extracted by following tree branches. The decision trees output by step can be converted to sets of IF THEN grammatical rules by following each combination of branches down to its leaf node which contains a class label . The number of rules extracted depends on the size of the tree. Each rule takes the form IF combination of attribute values THEN class label .

In step test plus validate rules are applied using ten fold cross validation and in step filter rules are applied keeping those with high accuracy 85 . Filtering is applied to the set of rules output by step . Rules that apply to too few examples in the training set are removed. Accuracy sensitivity and specificity measures are individually calculated for each of the remaining rules. Rules with 85 accuracy are retained. The performance metrics are calculated using ten fold cross validation to better test the generalization capabilities of each rule.

As described with reference to the decision support system of the embodiment of the invention provides views on display which advise and assist the physician in treatment of the patient. illustrates in diagrammatic form a standard prediction view. The display screen is divided into four areas three across the top of the display screen and one across the bottom of the screen. It will be understood however that this arrangement and contents can be varied within the scope of the invention. In the example illustrated the first area provides a display of the X ray image with highlighted potential fractures or displacement. The next area provides a display of a CT slice with segmented bones which will be used to show fracture and areas of concern. The third area provides text and numeric patient data such as age sex blood pressure readings tests performed and other pertinent data. The area below the first three areas provides predicted patient outcome e.g. expected stay in Intensive Care Unit the rules used to predict patient outcome with option to view rule tree and recommendations for treatment. Should the physician elect to view the rule tree the tree view shown in would be presented on display shown in .

While the invention has been described in teens of a single preferred embodiment those skilled in the art will recognize that the invention can be practiced with modification within the spirit and scope of the appended claims.

