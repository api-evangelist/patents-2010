---

title: Feedback loop between a query optimizer and a cache manager
abstract: Systems, methods and computer program products are disclosed for managing a database cache. In one embodiment, access to a data object stored in a database is monitored. A memory residency priority for the data object is determined, based on the access patterns. Further, an access plan is determined for a query, based on the memory residency priority. Access to the data object is also monitored when the access plan is executed, thereby providing a feedback loop between determining memory residency priorities and determining query access plans.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08380703&OS=08380703&RS=08380703
owner: International Business Machines Corporation
number: 08380703
owner_city: Armonk
owner_country: US
publication_date: 20100726
---
Embodiments of the invention relate generally to computer databases and more particularly to managing database caches.

Databases are computerized information storage and retrieval systems. A relational database management system is a computer database management system DBMS that uses relational techniques for storing and retrieving data. The most prevalent type of database is the relational database a tabular database in which data is defined so that it can be reorganized and accessed in a number of different ways.

Regardless of the particular architecture in a DBMS a requesting entity e.g. an application or the operating system demands access to a specified database by issuing a database access request. Such requests may include for instance simple catalog lookup requests or transactions and combinations of transactions that operate to read change and add specified records in the database. These requests are made using high level query languages such as the Structured Query Language SQL . Illustratively SQL is used to make interactive queries for getting information from and updating a database such as International Business Machines IBM DB2 Microsoft s SQL Server and database products from Oracle Sybase and Computer Associates. The term query denominates a set of commands for retrieving data from a stored database. Queries take the form of a command language that lets programmers and programs select insert update find out the location of data and so forth.

Embodiments of the invention provide a computer implemented method computer program product and system for performing an operation that may generally include monitoring access to at least a data object stored in a database. The operation may also include determining a memory residency priority for keeping the data object pinned in memory based on the monitored access to the data object. The operation may also include determining an access plan for a query accessing the data object based on the memory residency priority for keeping the data object pinned in memory.

Embodiments of the invention provide techniques for managing a database cache. In one embodiment a database management system DBMS executing on a computer system manages data objects in a database cache of the computer system. The database cache may also be referred to as a database buffer pool. In one embodiment the database cache refers to an area of virtual storage e.g. in main memory that temporarily stores pages of table spaces or indexes. When an application requests for a row of a table the DBMS places a database page containing that row in the database cache. If the requested data already resides in the database cache the DBMS returns the data to the application without incurring the costs of retrieving the data from disk. Avoiding the need to retrieve data from disk may result in improved performance of the DBMS and or of the requesting application.

Further the DBMS tracks access patterns associated with data objects. The DBMS determines a memory residency priority for keeping each data object in the database cache. In some embodiments keeping a data object in the database cache causes the data object to remain pinned in memory. Based on the memory residency priority for a given data object the DBMS determines an access plan for a query. Consequently the DBMS may provide an access plan that is more suitable for the query than when the memory residency priority is not taken into account. Accordingly performance of the DBMS and or requesting applications may be improved.

In the following reference is made to embodiments of the invention. However it should be understood that the invention is not limited to specific described embodiments. Instead any combination of the following features and elements whether related to different embodiments or not is contemplated to implement and practice the invention. Furthermore although embodiments of the invention may achieve advantages over other possible solutions and or over the prior art whether or not a particular advantage is achieved by a given embodiment is not limiting of the invention. Thus the following aspects features embodiments and advantages are merely illustrative and are not considered elements or limitations of the appended claims except where explicitly recited in a claim s . Likewise reference to the invention shall not be construed as a generalization of any inventive subject matter disclosed herein and shall not be considered to be an element or limitation of the appended claims except where explicitly recited in a claim s .

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

The computer generally includes a processor connected via a bus to a memory a network interface device a storage an input device and an output device . The computer is generally under the control of an operating system . Examples of operating systems include UNIX versions of the Microsoft Windows operating system and distributions of the Linux operating system. More generally any operating system supporting the functions disclosed herein may be used. The processor is included to be representative of a single CPU multiple CPUs a single CPU having multiple processing cores and the like. Similarly the memory may be a random access memory. While the memory is shown as a single identity it should be understood that the memory may comprise a plurality of modules and that the memory may exist at multiple levels from high speed registers and caches to lower speed but larger DRAM chips. The network interface device may be any type of network communications device allowing the computer to communicate with other computers via the network .

The storage may be a persistent storage device. Although the storage is shown as a single unit the storage may be a combination of fixed and or removable storage devices such as fixed disc drives floppy disc drives tape drives removable memory cards or optical storage. The memory and the storage may be part of one virtual address space spanning multiple primary and secondary storage devices.

The input device may be any device for providing input to the computer . For example a keyboard keypad light pen touch screen track ball or speech recognition unit audio video player and the like may be used. The output device may be any device for providing output to a user of the computer . For example the output device may be any conventional display screen or set of speakers along with their respective interface cards i.e. video cards and sound cards not shown . Although shown separately from the input device the output device and input device may be combined. For example a display screen with an integrated touch screen a display with an integrated keyboard or a speech recognition unit combined with a text speech converter may be used.

As shown the memory of the computer includes the operating system a DBMS and an application . The DBMS may manage a database shown in storage . In one embodiment the DBMS is the DB2 product offered by the IBM Corporation for the MVS AIX or Linux or Microsoft Windows operating systems. Generally those skilled in the art will recognize that the present invention has application to any DBMS software that uses SQL and may similarly be applied to database software using non SQL queries. More generally however it should be understood that the data to be accessed need not be part of a DBMS at all. The application and more generally any requesting entity including the operating system is configured to issue queries against the database . Although only one database is shown for simplicity the DBMS may manage multiple databases. Further the databases may be distributed relative to one another e.g. over the network . And although the application and the DBMS are shown to be executing on the computer the application may also execute on a different computer that communicates with the computer via the network .

In one embodiment the database is representative of any collection of data regardless of the particular physical representation of the data. A physical representation of data defines an organizational schema of the data. By way of illustration the database may be organized according to a relational schema accessible by SQL queries or according to an XML schema accessible by XML queries . However embodiments of the invention are not limited to a particular schema and contemplates extension to schemas presently unknown. As used herein the term schema generically refers to a particular arrangement of data.

In one embodiment the database stores database tables that include data pages. Each data page is configured to store data rows that in turn store information. The database table may also include a database index for logically ordering the data rows. The database index includes index pages. Each index page is configured to store index entries where each data row is referenced by a corresponding index entry. The data pages and the index pages are arranged to be stored on and retrieved from a storage medium such as the storage .

In one embodiment the application issues a request to the DBMS . The request includes a query statement e.g. a select insert or update . Depending on the embodiment the request issued by the application may be predefined i.e. hard coded as part of the application or may be generated in response to input e.g. user input .

In one embodiment to service the request from the application the DBMS performs a number of database operations. For example the DBMS retrieves index entries and data rows from storage e.g. disk or tape into a database cache e.g. in main memory . The speed of accessing the storage may be much slower than other operations involved in servicing a request such as operations involving the database cache. Consequently performance of the DBMS in servicing the request may be to a large extent determined by a frequency with which the DBMS accesses the storage .

In one embodiment the DBMS manages which data objects reside in the database cache to improve performance of the DBMS and requesting applications. To this end the DBMS tracks access patterns associated with data objects. Based on the access patterns the DBMS determines a memory residency priority for keeping each data object in the database cache. Based on the memory residency priority for a given data object the DBMS determines an access plan for a received query. Taking the memory residency priority into account in determining the access plan may yield more efficient access plans in some cases. Accordingly the performance of the DBMS in servicing requests may be improved.

In one embodiment upon receiving a query statement the query parser parses the received query statement. Parsing the query statement may involve checking for correct syntax according to a query language specification associated with the DBMS . For example the query parser may create input tokens from a sequence of characters in the received query statement and generate data structure such as a parse tree an abstract syntax tree or the like based on input tokens. Depending on the embodiment a separate lexical analyzer may be used to create the input tokens from a sequence of characters in the received query statement.

In one embodiment prior to the query statement being executed the query optimizer optimizes the query statement. Optimizing the query statement may involve determining how tables addressed by the query statement are accessed. As a result of optimizing the query statement the query optimizer may determine an access plan from the data structure created by the query parser where the access plan specifies how tables addressed by the query statement are accessed. In other words the output of the query optimization process is an access plan. The access plan may include in a proprietary form specific to the query optimizer DBMS low level information specifying precisely what steps the database engine should take and in what order to execute the query statement. The access plan may also include an estimate by the query optimizer of how long it may take for the database engine to execute the query statement in accordance with the access plan.

In one embodiment the query optimizer may determine the access plan in the following manner. Depending on the embodiment the query optimizer may be a rule based query optimizer or a cost based query optimizer. A rule based query optimizer generates an access plan based on predefined rules. The rules may be defined by a database administrator to specify how an access plan is generated from a query statement. These rules for example may relate to creating or using indices or may relate to how join statements are performed e.g. join orders join algorithms etc. . At least in some cases the more skillful the user is in specifying the rules the better the resulting access plan may perform. Further the rules may take into account memory residency priorities determined by the cache manager which is further described below in conjunction with . Advantageously the rule based query optimizer may determine a more suitable access plan for the query statement.

In one embodiment a cost based query optimizer includes information on multiple alternative ways that a query statement may be converted into an access plan. The cost based query optimizer determines an estimated cost for executing each alternative access plan. The cost based query optimizer then determines the access plan having the lowest estimated cost. In determining an estimated cost for executing an access plan the cost based query optimizer may take into account memory residency priorities determined by the cache manager which is further described below in conjunction with .

In some cases the cost based query optimizer may evaluate a large number of access plans for a query statement. The large number of access plans may stem from the query statement accessing numerous tables that include many data columns of various types numerous methods of accessing actual data records from each table referenced e.g. using an index a hash table etc. etc. However evaluating the large number of access plans for the query statement may consume a large amount of system resources and may hamper throughput of the DMBS . Accordingly the cost based query optimizer may take memory residency priorities into account in evaluating and selecting an access plan. Advantageously the cost based query optimizer may more efficiently determine a suitable access plan for the query statement.

In one embodiment the database engine executes the query statement using the access plan generated by the query optimizer . The database engine retrieves and processes the data for the query statement. The access plan includes a list of instructions to be executed by the database engine . The list of instructions specify access methods to be used data objects to be created and system resources to be acquired. The database engine may also communicate with the cache manager to specify which data objects from the database are to remain in the database cache .

In one embodiment the cache manager manages the database cache which may be arranged as a buffer pool and stores retrieves data and index pages from the database . Data pages may correspond to physical blocks of the storage that contains the database . Depending on the embodiment the DBMS may also include a media manager not shown that communicates with the storage via I O operations addressing the physical blocks and the cache manager may interface with the media manager to store and retrieve data. In some embodiments the cache manager and or media manager may use operating system functions to store and retrieve data and to thereby manage the database cache . These operating system functions may be part of an application programming interface API provided by the operating system.

In one embodiment the database cache includes a collection of frames. Each frame may store a data page from the database as the data page is brought in from the storage to the memory . Each data page stored in the database cache may include a property indicating whether the respective data page is pinned. Depending on the embodiment the property may be a boolean or an integer value. A pinned data page indicates to the cache manager that the pinned data page in the frame of the database cache should not be replaced with another data page. An unpinned data page indicates to the cache manager that the unpinned data page in the frame of the database cache may be replaced with another data page. The cache manager may also apply an algorithm such as the least recently used LRU algorithm to determine which data pages in the database cache should be replaced with data pages subsequently retrieved from disk.

In one embodiment each data page stored in the database cache may also include a property indicating whether the respective data page is dirty i.e. whether the data page includes changes that should be persisted to the storage . A dirty data page indicates to the cache manager that the dirty data page should be flushed to the storage . A clean data page indicates to the cache manager that the clean data page need not be flushed to the storage .

In one embodiment to determine which data pages reside in which frames of the database cache the cache manager may create and or maintain an index such as a hash table. The hash table may be implemented as an array referencing lists of tuples. Each tuple includes a data page identifier and a corresponding frame identifier of the frame where the data page identifier is stored in the database cache .

In one embodiment the statistics manager performs statistical analysis on data objects stored in the database to determine structures of the data objects and distributions of data values in the data objects. As further described below in conjunction with in some embodiments the DBMS provides a feedback loop that includes at least the query optimizer and the cache manager .

In one embodiment the query optimizer of the DBMS generates an access plan from the parsed statement . For example the query optimizer compiles the parsed statement using descriptive information maintained by the statistics manager and using memory residency priority information maintained by the cache manager . As described above the access plan includes instructions to be executed by the database engine . The query optimizer generates an access plan that access one or more specific data objects residing in the database cache . As multiple access plans are generated by the query optimizer in response to multiple database queries the cache manager increases a memory residency priority associated with the one or more specific data objects. That is the memory residency priority is increased because the multiple access plans each accessing the one or more specific data objects residing in the database cache .

The database engine may then execute the access plan to retrieve and process data from the database to generate a result set . The database engine may place a request to the cache manager specifying that data objects or portions of the data objects should remain in the database cache e.g. remain resident in memory . In some embodiments the access plan may also include instructions to have the cache manager pre load data objects that are subsequently accessed by the access plan . Once the result set is generated by the database engine the DBMS returns the result set to the application responsive to the database query .

In one embodiment the cache manager manages data objects in the database cache . The cache manager schedules I O operations for moving the data objects from the database to the database cache . The cache manager also determines a memory residency priority for a data object based on usage of the data object by the database engine . Further the cache manager provides a feedback mechanism to the query optimizer . Using the feedback mechanism the query optimizer may tailor subsequent access plans based on predefined criteria. The criteria may include memory resource availability a likelihood that data objects accessed by the subsequent access plans reside in the database cache and a frequency with which each of the data objects are accessed by previous access plans and or by the subsequent access plans. Accordingly the query optimizer may generate access plans that specify for data objects to be pre loaded to be used during execution of the access plan.

As described above the cache manager determines the memory residency priority for the data object based on usage of the data object by the database engine . In one embodiment the memory residency priority is determined based on criteria such as on a frequency of a data object being accessed a given period of time of day and or day of week month of year etc. that the data object is accessed and or correlations between data objects that are accessed by the same access plan. The cache manager may then enforce the memory residency priority to pre load high priority data objects into the database cache prevent higher priority data objects from being replaced in the database cache etc.

As described above in one embodiment the statistics manager performs statistical analysis on data objects stored in the database to determine structures of the data objects and distributions of data values in the data objects. The statistics manager may work in conjunction with the query optimizer and or the database to maintain descriptive information regarding the data objects stored in the database . For example the statistics manager may monitor a frequency with which each data object is referenced in an access plan generated by the query optimizer . The statistics manager may also provide usage statistics of the data objects to the cache manager . The cache manger then calculates and or adjusts memory residency priorities for data objects based on the usage statistics. The memory residency priority may include a range of different priority values. For example the range may include a highest priority value that specifies to pin a data object in the database cache to a lowest priority value that permits another data object to easily replace the data object in the database cache .

In one embodiment the cache manager provides the memory residency priority to the query optimizer for use in determining an access plan for the database query . Depending on the embodiment the query optimizer generates multiple access plans and estimates a cost of executing each access plan. The query optimizer may then select an access plan based on the estimated cost. Illustratively if data objects accessed by a given access plan have a high memory residency priority the query optimizer calculates a lower access cost for random accesses of the data object. The extent to which the access cost is lowered may be scaled according to the magnitude of the memory residency priority on the range of different priority values. The extent to which the access cost is lowered may also be scaled according to access characteristics of the memory and the storage of the computer e.g. ratio of access times . Accordingly the query optimizer may use the memory residency priority to determine a suitable access plan for the database query .

In one embodiment by allowing the optimizer to provide feedback to the cache manager the cache manager weighs the usage data against system resource constraints to perform predefined actions. The actions may include maintaining in the database cache data objects most likely to accessed and or pre loading data objects before the database engine requests the data objects. Advantageously the data objects that are best exploited in the database cache are maintained in the database cache and the query optimizer determines access plans that better exploit the data objects. As such the DBMS provides a feedback loop that includes at least the query optimizer and the database cache . The feedback loop associates usage statistics of data objects and cache statuses of the data objects and provides the associated information to at least the query optimizer and the database cache . Consequently performance of the DBMS and or the application may be improved.

In one embodiment when the access plan is subsequently executed by the DBMS e.g. by the database engine the statistics manager tracks access patterns of the access plan accordingly step and the cache manager updates memory residency priorities of data objects accordingly step . After the step the method terminates. The DBMS may also repeat the method to process additional queries and corresponding access plans . Because the DBMS tracks access patterns of the access plan in executing the access plan the DBMS provides a feedback loop between determining memory residency priorities and determining access plans for queries e.g. between the cache manager and the query optimizer .

Advantageously embodiments of the invention provide techniques for providing a feedback loop that includes at least a query optimizer and a cache manager of a DBMS. In one embodiment the DBMS manages which data objects reside in the database cache to improve performance of the DBMS and or the application. Further the DBMS tracks access patterns associated with data objects and determine a memory residency priority for keeping each data object in the database cache. The DBMS also determines an access plan for a received query based on the memory residency priority. Accordingly data objects accessed by the access plan may more often reside in the database cache and not incur a costly retrieval from storage. Consequently performance of the DBMS and or requesting applications may be improved.

While the foregoing is directed to embodiments of the present invention other and further embodiments of the invention may be devised without departing from the basic scope thereof and the scope thereof is determined by the claims that follow.

