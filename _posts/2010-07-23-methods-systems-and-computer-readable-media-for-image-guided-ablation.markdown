---

title: Methods, systems, and computer readable media for image guided ablation
abstract: The subject matter described herein includes methods, systems, and computer readable media for image guided ablation. One system for image guided ablation includes an ultrasound transducer for producing a real-time ultrasound image of a target volume and of surrounding tissue. The system further includes an ablation probe for ablating the target volume. The system further includes a display for displaying an image to guide positioning of the ablation probe during ablation of the target volume. The system further includes at least one tracker for tracking position and orientation of the ablation probe during the ablation of the target volume. The system further includes a rendering and display module for receiving a pre-ablation image of the target volume and for displaying a combined image on the display, where the combined image includes a motion tracked, rendered image of the ablation probe and an equally motion tracked real-time ultrasound image registered with the pre-ablation image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09265572&OS=09265572&RS=09265572
owner: The University of North Carolina at Chapel Hill
number: 09265572
owner_city: Chapel Hill
owner_country: US
publication_date: 20100723
---
This application is a continuation of PCT International Patent Application No. PCT US2009 032028 filed Jan. 26 2009 which claims the benefit of U.S. Provisional Patent Application Ser. No. 61 023 268 filed Jan. 24 2008 the disclosures of each which are incorporated herein by reference in their entireties.

This presently disclosed subject matter was made with U.S. Government support under Grant No. 1 R01 CA101186 01A2 awarded by the National Institutes of Health. Thus the U.S. Government has certain rights in the presently disclosed subject matter.

The subject matter described herein relates to image guided medical treatment systems. More particularly the subject matter described herein relates to methods systems and computer readable media for image guided ablation.

Ablation such as radio frequency ablation RFA microwave ablation and cryo ablation is a first line treatment for non resectable hepatic and other types of tumors. RFA is a minimally invasive intervention MII uses high frequency electrical current introduced under 2D ultrasound guidance via a percutaneous needle like probe to heat the targeted tissues to physiologically destructive levels. RFA probes are characterized by manufacturer specified ablation zones that are typically spheres or ellipsoids. The interventional radiologist who performs the procedure must place the probe such that the entire tumor as well as a safety boundary of several millimeters thickness are contained within the predicted ablation area. Frequent tumor recurrence on the periphery of the original tumor 1 indicates that probe placement accuracy may be a major cause for the low 5 year survival rates of hepatic carcinoma patients.

It is believed that physicians will more accurately target RFA to hepatic and other tumors using a contextually correct 3D visualization system than with standard 2D ultrasound alone. If proven beneficial 3D guidance could decrease the high post RFA tumor recurrence rate 3 . Prior experience in developing and evaluating a guidance system for breast biopsy 5 yield results that support this hypothesis.

Accordingly there exists a long felt need for methods systems and computer readable media for image guided ablation.

The subject matter described herein includes methods systems and computer readable media for image guided ablation. One system for image guided ablation includes an ultrasound transducer for producing a real time ultrasound image of a target volume to be ablated and surrounding tissue. The system further includes an ablation probe for ablating the target volume. The system further includes a display for displaying an image to guide position of the ablation probe during ablation of the target volume. The system further includes at least one tracker for tracking position of the ablation probe during the ablation of the target volume. The system further includes a rendering and display module for receiving a pre ablation image of the target volume and for displaying a combined image on the display where the combined image includes a motion tracked rendered image of the ablation probe and the real time ultrasound image registered with the pre ablation image of the target volume.

The subject matter described herein for image guided ablation may be implemented using a computer readable medium comprising computer executable instructions that are executed by a computer processor. Exemplary computer readable media suitable for implementing the subject matter described herein includes disk memory devices programmable logic devices and application specific integrated circuits. In one implementation the computer readable medium may include a memory accessible by a processor. The memory may include instructions executable by the processor for implementing any of the methods described herein for image guided ablation. In addition a computer readable medium that implements the subject matter described herein may be distributed across multiple physical devices and or computing platforms.

The subject matter described herein includes methods systems and computer readable media for image guided ablation. The following paragraphs describe how an exemplary implementation of the present subject matter was designed comparing the two designs introduced in a see through head mounted display and a fish tank virtual reality display.

Our research team has developed 3D guidance for MIIs since the mid 1990s all our systems were based on see through head mounted displays ST HMDs 6 . We demonstrated superior targeting accuracy in breast lesions when comparing ST HMD guidance with the standard 2D method 5 . In addition to stereoscopy and head motion parallax the system based on motion tracked ST HMDs provided a view of the patient that included a synthetic opening into the patient showing live echography data and 3D tool guidance graphics in registration with the real world and therefore also with the patient as well as with the motion tracked instruments note which shows the ultrasound transducer in an early RFA guidance system prototype based on a video see through HMD .

Stereoscopic visualization with head motion parallax can also be implemented with fixed displays i.e. without mounting the display on the user s head. Such fish tank displays may use CRT monitors and frame sequential shutter glasses 2 or at a larger scale projection displays and passive polarized glasses for example. Recently devices based on LCD panels and a semi transparent mirror have become available from Planar Systems Inc. 4 these use passive linearly polarized glasses.

While we obtained encouraging results in the past with ST HMD systems we are disappointed with the bulky and uncomfortable low resolution devices resulting from today s state of the art in HMDs. Moreover since there are no satisfactory video see through devices on the market we always constructed our own with rather modest resources 6 . For these reasons when designing the RFA 3D guidance system we considered both an ST HMD approach and a commercial fish tank system . With respect to the augmented reality AR view provided by the ST HMD we noted that in Mils our driving problem the interface between the relevant components of the real world in our case the patient the RFA probe and the ultrasound transducer and the virtual display in our case the echography image the RFA probe representation inside the patient and the 3D guidance graphics is essentially limited to the location where the RFA probe penetrates the skin . Furthermore once the probe pierces the skin it is moved only lengthwise through this entry point which is no longer under constant observation by the radiologist. The radiologist then focuses on internal anatomy as he guides the probe into the tumor. From this we conclude that MII our driving problem may in fact not derive much benefit from exact registration between real and virtual imagery as provided by an ST HMD at least not during the most critical final phase of the probe targeting approach as the probe tip is introduced into the tumor.

The above considerations led us to favor a fish tank type display even though it does not offer registration between virtual display and internal patient anatomy. Since our display metaphor proposes life size representations of the ultrasound image and of the ablation probe projection displays are unsuitable and CRT based stereo has disadvantages such as the requirement for active stereo glasses which can exhibit flicker. The Planar SD1710 display 4 was almost ideally suited its small 17 inch 1280 1024 display can fully contain our 3D display elements at life size. Furthermore it does not exhibit flicker and has manageable bulk.

In the system further includes an ablation probe for ablating the target volume. An exemplary ablation probe suitable for use with embodiments of the subject matter described herein includes the LeVeen RFA needle electrode probe available from Boston Scientific. Probe may also include a tine deployment tracker for tracking deployment of the probe tines for RFA ablation probes . In one implementation tine deployment tracker may include a light emitting diode attached to the probe to measure movement of the plunger within the probe that indicates the length of the portions of the tines that are deployed. The LED may be mounted on the plunger and its motion relative the probe handle can be observed by a tracking system. In an alternate embodiment a linear potentiometer may be used to track tine deployment.

The system illustrated in further includes a headband to be worn by the user of ablation probe . Headband may include a cluster of infrared or other suitable LEDs for tracking purposes. The purpose of headband is to track position and orientation of the user s head to be used in rendering a combined image from the viewpoint of the user onto the stereoscopic fish tank display. A tracker tracks position of the ultrasound transducer ablation probe headband and display . Any suitable tracking system for tracking such components can be used. In one implementation tracker includes a sensor that senses infrared signals from LEDs mounted to ultrasound transducer ablation probe headband and display and computes the positions and orientations of these elements from the signals detected from the LEDs. A triangular LED arrangement suitable for tracking display is shown in left and . Commercially available trackers suitable for use with the subject matter described herein include infrared trackers available from PhaseSpace or Northern Digital Inc.

The subject described herein is not limited to using a fish tank VR display. As stated above a virtual see through head mounted display may be used without departing from the scope of the subject matter described herein. In an embodiment that uses a virtual see through head mounted display tracker can track both the display and the user s head using headband since the display is worn on the user s head.

A rendering and display module receives the real time ultrasound image pre ablation image data tracking data from tracker produces combined stereoscopic head tracked imagery and displays the imagery on display . The combined imagery may include a motion tracked rendered image of the RFA probe the real time ultrasound image registered with the pre ablation image of the target volume shown from a viewpoint of the user. Exemplary images that may be computed and displayed by rendering and display module will be illustrated and described in detail below.

In one exemplary implementation of the present subject matter a motion tracker is mounted on the display as in handheld augmented reality applications. Thus both the tracker base and the stereoscopic display can be moved relative to each other at any time without recalibration to adjust for space and or line of sight constraints within the operating environment this aims to improve visibility of the tracked system components by the tracker and thereby tracking accuracy and or reliability. The control software i.e. rendering and display module ensures that the 3D display preserves orientation e.g. the virtual representations of tracked devices such as the RFA probe in the display are always shown geometrically parallel to the actual devices in this case the handheld ablation probe . The same applies to the ultrasound transducer . In other words as opposed to the registration in both position and orientation provided by the ST HMD this technique maintains only orientation alignment it introduces a translational offset between the location of the instruments in the real world on the one hand and their virtual counterparts in the 3D display on the other hand. The interface implemented by rendering and display module has three presentation modes that differ in how these user induced translational movements of the instruments are echoed in the 3D display orientation changes are always fully shown as mentioned 

Given the small size of the display it is important for the system to accurately track the user s eyes in order to minimize geometric distortions. A fast and accurate method to calibrate the user s eyes to the head tracker is referenced in the context of which is set forth below 7 .

Table 1 summarizes the principal characteristics of the two display techniques we have considered using for the RFA guidance system ST HMD and fish tank VR system .

At present there is no controlled study comparing the performance of the head tracked fish tank display to an ST HMD device. An interventional radiologist Charles Burke MD UNC Radiology who has used the head tracked fish tank display extensively reports that depth perception is good and that the display correctly portrays three dimensional relationships during RFA probe targeting. A depth perception study conducted with this display revealed that most subjects a randomly selected group of 23 were able to determine which of two objects located only a few millimeters apart in depth was closer based solely on stereoscopic and motion parallax cues provided by the fish tank display.

The present 3D RF ablation guidance system has been tested on specially constructed liver phantoms the completed system is currently used in a controlled animal study to ablate liver carcinomas in woodchucks FIG. left . The study randomizes each woodchuck to either the ultrasound only conventional guidance method or to the present ultrasound with 3D guidance technique.

According to one aspect of the subject matter described herein rendering and display module may display the target volume such as the tumor with successively smaller size as ablated regions are eliminated from display with each ablation pass. Such an image is useful for multiple pass techniques that are aim to treat a large tumor with multiple overlapping ablations. In one embodiment an initial target volume to be ablated may be shown as a three dimensional structure on a display screen. The initial target volume may be rendered from the pre ablation image data such as MRI or CT image data. illustrates an example of an initial target volume that may be displayed by rendering and display module . In three dimensional region represents the initial target volume. Rendering represents ultrasound transducer and its real time orientation. Rendering represents the real time ultrasound image continuously produced by ultrasound transducer . Rendering is a virtual representation of ultrasound transducer or in other words the ultrasound transducer s avatar.

After a first ablation pass the volume affected by the first ablation pass may be subtracted from the displayed representation of the initial target volume. The volume affected by the first ablation pass may be determined mathematically based on the position of the ablation probe at the time of the first ablation pass the geometry of the ablation probe and the tine deployment and power settings of the ablation probe during the first ablation pass. For example if the probe is the above referenced LeVeen needle electrode probe the affected volume for an ablation pass may be determined based on manufacturers specifications. In one current implementation a constant ellipsoid based on what the probe data sheet indicates is used as the affected ablation volume may be subtracted from the image of the target volume. In alternate implementations pre calibrated volumes shapes measured in a test ablated human organ like phantom or varying the shape based on time deployment can be used to determine the affected sub volume. However the probes are usually specified to be used with fully deployed times and manufacturers do not give partial deployment information. Additional bio chemo thermo geometric calibration and simulation work possibly taking into account fluid flow through blood vessels may be utilized to increase the accuracy of the affected ablation volume estimates.

Region illustrated in represents the portion of target volume that is affected by multiple ablation passes. Wireframe mesh represents the treatment volume that will be affected based on the current position of the RFA probe. Such rendering may be particularly suitable for treating large lesions to inform the interventional radiologist of portions of a large tumor that have already been ablated as well as of those that still remain to be treated.

As stated above rendering and display module may both calculate and display in real time the amount of tumor and background tissue that would be ablated for the momentary location of the ablation probe in order to illustrate on the display the impact of probe position. The calculation and display of the amount of tumor and background tissue that would be affected by an ablation can be performed in real time or may use a lookup table based on the geometry and location of the probe. As stated above the affected volume can be determined using the data from the probe manufacturer or using experimental data. The volume that would be affected by the ablation can be super imposed about the ablation probe position and displayed to the user. illustrates an example of displaying the amount of tumor and background tissue that would be ablated for a particular location of the ablation probe. In relative amounts of healthy and tumor tissue that would be affected by the ablation pass are shown as vertical bars in the lower left hand corner in different shading. Such a display may be useful in probe positioning to maximize the proportion of tumor tissue that is treated with respect to healthy tissue.

According to another aspect of the subject matter described herein the guidance system will benefit from accurate registration of the user s eyes for precise head tracked stereoscopic visualization. An exemplary method for accurate registration of the user s eyes for precise head tracked stereoscopic visualization will now be described.

The high accuracy is achieved in the same calibrated stereoscopic head tracked viewing environment used by the guidance system. While the current implementation requires a head mounted tracker future embodiments may use un encumbering tracking such as vision based head pose recovery. It is important to note that the technique described here does not require pupil tracking it uses only head pose which can generally be obtained less intrusively with higher reliability and from a greater distance away than camera based pupil tracking. An additional pupil tracker is not required unless the system must know the user s gaze direction for example in order to record user behavior in training related applications 14 .

In fish tank VR systems the calibration between the head tracker and the eyes is usually obtained from measurements such as the user s inter pupillary distance IPD measured with a pupillometer 8 the location of the tracker on the user s head as well as from assumptions about the most suitable location of the projection origin inside the eye. Popular choices for the latter include the eye s 1st nodal point 2 the entrance pupil 9 and the center of the eye 10 . Our method uses the eye center 10 because it is easy to calibrate and yields exact synthetic imagery in the center of the field of view regardless of the user s gaze. However the 1st nodal point and the entrance pupil are better approximations for the actual optics within the eye. Therefore by rendering stereo images from the eye centers i.e. from a few mm too far back and thus with a slightly exaggerated separation the EEC system deforms the stereoscopic field 11 ever so slightly. For higher accuracy a pupil tracker could detect the user s gaze directions and assuming that the user converges onto the virtual object found along those directions the rendering and display module could move the projection origins forward to the 1st nodal point or all the way to the pupil.

The eye calibration technique was inspired by previous methods 12 13 and modified for the additional display tracker. A small panel with a circular hole is temporarily mounted in front of the bottom LCD panel. Both the hole and the bottom LCD monitor are pre calibrated one time only to the Planar s tracker with the Certus calibration stylus. The eye calibration program shows a circular disk on the display. Using a mirror image of the user s head as a guide the user moves and orients his head to line up the disk through the hole twice through each eye under different head orientations. To avoid confusion users wear frames with one eye masked off as shown by the mirror guides at the top of . The program collects four line equations in head tracker coordinates. In pairs of two these four lines define the eye centers at their intersections or rather at the closest points between them. The entire task takes 1 2 minutes except for inexperienced first time users which take longer mostly because they must receive and follow instructions.

Since the current head band tracker does not guarantee repeatable positioning on the user s head the user should not remove it between calibration and the following interactive phase i.e. using the system to guide an ablation . User specific head conforming gear equipped with IR LEDs or with passive markers for camera based head tracking could eliminate this restriction and could thus reduce each user s eye calibration to a one time procedure.

As stated above the user s head or eyes can be tracked during image guided ablation and the combined display shown by the rendering and display module can adjust the combined display of the treatment volume based on the current position of the user s head and or eyes. For example in the images illustrated in as the user is conducting an RFA procedure the display illustrated in may be continually updated based on the viewpoint of the user. As the user s head moves during treatment the viewpoint of the display will be updated. shows the stereoscopic display in this case depicting a photorealistic human head as seen by a head tracked user moving around it. Note that the user is able to naturally look around the subject head motion parallax as if the display contained actual three dimensional structures. Together with stereoscopic rendering and exact eye calibration the illusion is almost perfect.

Exact eye calibration in an ablation procedure can be used to produce the same 3D effect illustrated in in the combined image displayed by rendering and display module as the user moves about display . For example the exact eye calibration method described herein is used to determine whether the user s eyes are with respect to headband which is tracked. When the user moves about display rendering and display module uses the position data from headband and the offset for each eye produced during eye calibration to determine the positions of each of the user s eyes. Rendering and display module produces left and right eye images based on the tracked position of headband and the eye calibration data. The left and right eye images appear as a single image on display because the user wears stereoscopic glasses. An example of such a combined image viewed through stereoscopic glasses is shown in right .

According to another aspect of the subject matter described herein rendering and display module may render preoperative data including an anatomical context for the ablation of the target volume. For example rendering and display module may render organs or anatomical structures such as bones or blood vessels adjacent to the target volume. illustrates an example of such a context.

The disclosure of each of the following references is hereby incorporated herein by reference in its entirety.

Although the examples described above relate primarily to RFA the subject matter described herein is not limited to image guided RFA. The image guided techniques and systems described herein can be used with any type of ablation including microwave ablation and cryo ablation. In microwave ablation a needle delivers microwave energy to the target volume. In cryo ablation a needle delivers cold fluid to the target volume. The tracking rendering and display techniques and systems described above can be used to track render and display microwave and cryo ablation needles in the same manner described above. In addition the techniques and systems described above for displaying predicted ablation volumes and ablated volumes for successive ablation passes can be applied to microwave and cryo ablation probes by configuring rendering and display module with manufacturer s specifications for these types of probes.

It will be understood that various details of the subject matter described herein may be changed without departing from the scope of the subject matter described herein. Furthermore the foregoing description is for the purpose of illustration only and not for the purpose of limitation as the subject matter described herein is defined by the claims as set forth hereinafter.

