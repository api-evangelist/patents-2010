---

title: Debugger presentation of parallel application threads
abstract: User interface technologies for viewing the state of threads of a target parallel application, such as a massively parallel application intended to run on a GPGPU system, during debugging of the target parallel application are disclosed. The target parallel application includes a kernel, and the kernel includes a set of threads. Coalesced thread information of the threads is presented with the user interface technologies based on user-controllable criteria.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08566647&OS=08566647&RS=08566647
owner: Microsoft Corporation
number: 08566647
owner_city: Redmond
owner_country: US
publication_date: 20101220
---
A current focus for improving processor power is to provide multiple processor cores on a die to increase processor throughput. Central processing units in higher performing computing devices such as workstations and servers often include several processor cores included on a single die. Many of these devices also include one or more graphics processing units that each can include hundreds of processor cores on a single die. Graphics processor units in addition to providing computations for computer graphics are often configured to provide computations in applications previously provided by the central processing with a technique referred to as general purpose computing on graphics processing units or GPGPU. In one example GPGPU computing uses central processing units and graphics processor units together in a heterogeneous co processing computing model. The sequential or relatively light parallel parts of the application runs on the cores in the central processing units and the computationally intensive often massively parallel parts of the application are accelerated by the many cores in the graphics processing units. Parallel computer applications having many concurrent threads executed in GPGPU computing can realize a performance boost ten to one hundred times that over the applications executed on multiple core central processing units. Additionally GPGPU systems typically are less expensive and use less power per core than multiple core central processing units.

Parallel computer applications having concurrent threads and executed on multiple processors present great promise for increased performance but also present great challenges to developers. The process of developing parallel applications is challenging in that many common tools techniques programming languages frameworks and even the developers themselves are adapted to create sequential programs.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

The present disclosure describes user interface technologies for viewing the state of threads of a target parallel application such as a massively parallel application intended to run on a GPGPU system during debugging. The user interface technologies can also apply to target parallel applications in GPGPU software emulators clusters or other device that executes programs having a large number of threads in parallel. A debugger is set to focus on a kernel of the target parallel application and each kernel includes a plurality of thread groups each including a plurality of threads. When the target kernel enters break state for example the debugger has a notion of a current thread and a current stack frame. The debugger determines a current thread group and information related to the threads. The thread information is collected and provided to a user interface and can be included within a presentation layer of the debugger. Coalesced thread information of the threads is presented based on user controllable criteria. For example coalesced thread information of the threads can be based by thread group vector thread status or source location among other user controllable criteria.

In the following Detailed Description reference is made to the accompanying drawings which form a part hereof and in which is shown by way of illustration specific embodiments in which the invention may be practiced. It is to be understood that other embodiments may be utilized and structural or logical changes may be made without departing from the scope of the present invention. The following detailed description therefore is not to be taken in a limiting sense and the scope of the present invention is defined by the appended claims. It is to be understood that features of the various exemplary embodiments described herein may be combined with each other unless specifically noted otherwise.

Computing device can also have additional features or functionality coupled together with a bus. For example computing device may also include additional storage removable and or non removable including but not limited to magnetic or optical disks or solid state memory or flash storage devices such as removable storage and non removable storage Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any suitable method or technology for storage of information such as computer readable instructions data structures program modules or other data. Memory removable storage and non removable storage are all examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile discs DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices universal serial bus USB flash drive flash memory card or other flash storage devices or any other medium that can be used to store the desired information and that can be accessed by computing device . Any such computer storage media may be part of computing device .

Computing device includes one or more communication connections that allow computing device to communicate with other computers applications . Computing device may also include input device s such as keyboard pointing device e.g. mouse pen voice input device touch input device etc. Computing device may also include output device s such as a display speakers printer or the like.

The computing device can be configured to run an operating system software program and one or more software applications which make up a system platform. In one example the computing device includes a software component referred to as a managed or runtime environment. The managed environment can be included as part of the operating system or can be included later as a software download. The managed environment typically includes pre coded solutions to common programming problems to aid software developers to create software programs such as applications to run in the managed environment.

A computer application configured to execute on the computing device includes at least one process or task which is an executing program. Each process provides the resources to execute the program. One or more threads run in the context of the process. A thread is the basic unit to which an operating system allocates time in the processor . The thread is the entity within a process that can be scheduled for execution. Threads of a process can share its virtual address space and system resources. Each thread can include exception handlers a scheduling priority thread local storage a unique thread identifier and a thread context or thread state until the thread is scheduled. A thread context includes the thread s set of machine registers the kernel stack a thread environmental block and a user stack in the in the address space of the process corresponding with the thread. In parallel applications threads can be concurrently executed on the processors .

In an example graphics processor can be packaged as System on Module SoM cards that use a bus such as a PCI Express bus as an interconnect. The cards can be inserted directly into a computing device with a free PCI Express slot. In this example the processing system can run an operating system tuned for the desktop environment such as that sold under the trade designation Windows 7 available from Microsoft Inc. of Redmond Wash. USA. In another example graphics processor can be packaged as standalone rack mounted systems that often have an integrated central processor . In this example the processing system can run an operating system tuned for cluster configuration such as under the trade designation Windows HPC Server also available from Microsoft Inc.

In the example at least some of the physical cores may be capable of efficiently and concurrently executing multiple threads of a concurrent process. Such physical cores are often referred to as Simultaneous Multi Threading or often simply SMT cores and each of the concurrently executed threads on each SMT physical core shares hardware resources included with the SMT physical core. In the example of the multiple core processing system each physical core is capable of multithreading. Multithreading technology aims to increase core efficiency through thread level and instruction level parallelism. Each physical core capable of multithreading or the like can present the operating system with as many logical cores as concurrently executing threads. In the example multiple core processing system each physical core is capable of concurrently executing two threads and thus provides the operating system with eight concurrent logical cores in the central processor . The computing device can theoretically execute as many concurrent threads as there are logical cores in the device .

In an example processing flow of the multiple core system data from a main memory is copied into the memory of the graphics processor . The central processor provides instructions to the graphics processor on how to process the data. The graphics processor will process the data in multiple concurrent threads. The graphics processor will then copy the result into the central processor . Other examples are possible and a GPGPU may be constructed in various architectures other than architecture .

Developers generally find parallel programming or parallelizing serial applications challenging enough with the current tools and lack of expertise. Parallel programming techniques for GPGPU systems add another level of complexity to an already challenging process. Additionally debugging a target parallel program for a GPGPU is notoriously difficult. Traditional debuggers do not support computer applications intended for massively parallel devices such as GPGPU systems or they require a developer to select one thread at a time for analysis.

In one example debugger is a source level debugger which can show the line or expression in the source code that resulted in a particular machine code instruction of a running program loaded in memory. This can be used to analyze the target application in high level terms such as source level flow control constructs procedure calls named variables rather than simply in terms of machine instructions and memory locations. Source level debugging also makes it possible to step through execution a line at a time and set source level breakpoints through the debugger front end . When the target application reaches a preset condition such as a crash the debugger front end will shows the position in the original code. Debugger can also offer other functions such as running a target application step by step stopping or breaking at some event or specified instruction as selected with a breakpoint and tracking the values of some variables.

The target application can include a massively parallel application intended to run in a cluster structure such as a GPGPU system software emulators of GPGPU systems or other computer hardware. Software code for massively parallel applications on GPGPU systems often is organized into one or more data parallel kernels such as compute shaders. For example a developer constructs the data parallel kernel using a high level language such as HLSL High Level Shader Language developed by Microsoft Inc. compiles the kernel and loads it onto a processing system for execution. The kernel can be organized into one or more thread groups and each thread group can have many threads. Thread groups are referenced within the kernel by a set of coordinates and threads within each thread group are also referenced by a set of coordinates. For example the thread group can be referenced by a set of 3 coordinates x y z and the threads can also be referenced by a set of 3 coordinates x y z . The coordinates define vectors and the vectors remain unchanged as the kernel executes.

During any point of the execution of kernel some threads have completed execution some threads are scheduled to run and some threads are actively running. The active threads however can be at various locations in the code. At the hardware level vectors of the active threads often in groups of sixteen to thirty two threads which execute instructions together. For example the vectors of the active threads can be formed into a warp wavefront that can be executed in a given number of cycles such as four. If the code in the executing kernel includes branches some threads will be inactive or diverged such as if the vector or warp wavefront is running but not all threads are executing instructions at the same time . A graphics processor in a GPGPU system can include hundreds of groups with thousands of threads executing concurrently in such vectors and the GPGPU system can include a plurality of graphics processors.

The tool bar in the example appears at the top of the user interface . In one example the tool bar includes a drop down menu allowing a user to select a kernel from the one or more kernels of the target parallel application to analyze. In the example the selected kernel is labeled as transpose. The tool bar can also include a button to show only flagged threads a statistics button that can make a window appear having additional information on the debugging process and other buttons.

The thread switcher bar is located on the user interface between the tool bar and the list view . The thread switcher bar can display the coordinates of a thread in the graphics processor by thread group and thread. The user can edit some or all of the coordinates to select a specific thread or thread group. The thread switcher bar can include a pull down menu or range of valid coordinates for the kernel selected in the tool bar . For example the thread switcher bar can indicate that the valid ranges of the x y and z coordinates for the thread group be 0 to 1 0 to 1 and 0 to 1 respectively and the valid ranges of the x y and z coordinates for the threads within the selected thread group be 0 to 15 0 to 3 5 and 0 respectively 

The list view occupies a large portion of the area of the user interface of the example. Thread information for a plurality of threads are coalesced together and presented in a row . In the example the list view includes threads coalesced by thread group for a specified kernel. The threads can be further coalesced by criteria listed in the columns of the list view .

The list view also includes columns such as a flag column a thread group column or vector column a thread count column a status column showing the state of the coalesced threads and a location column . One or more of these columns can be hidden from view and additional or other columns can be included.

In one example a coalescing algorithm can consider certain attributes of each thread such as the method name of the thread at the top of the stack location in terms of line number and byte offset within the method status of the thread flagged state of the thread and thread group.

For threads flagged in the window or in another user interface window of the debugger threads coalesced by flags or as not having flags are presented in a row with a flag icon in the flag column . The example window includes five rows of flagged coalesced threads and three rows of unflagged coalesced threads.

The thread group column displays the thread group coordinates or vectors. In the example window the user interface presents four thread groups by vector i.e. 0 0 0 0 1 0 1 0 0 1 1 0 presented over the eight rows. Certain programming models however do not expose thread group. An example includes DPC Data Parallel C which is an extension of C computer language with typing mechanisms and parallel language constructs that provide a deterministic by default programming model. The window can be made aware of whether the target parallel application exposes threads such as with an application programming interface API . In the case of programming models such as DPC a thread group column is automatically not shown in a corresponding user interface.

The thread count column indicates the number of threads represented in the row or the number of threads coalesced by the criteria.

The status column displays the state of the row of threads. The example user interface includes five states of a thread in a graphics processor when the debugger enters the break mode. In the example the first three states are explicitly presented in the list view . An active state means the thread of was executing code when the debugger entered the break mode. A diverged state is part of a warp is not executing code at the break mode due to a diversion. A blocked state is blocked at a barrier. Further a thread in a trot started state has not begun to execute code yet but peer threads in the same thread group are active. Not started threads can be reported as in an active state at the first line of the compute shader. Still further a thread in a completed state has finished execution but peer threads in the same thread group are still active. Completed threads also can be reported as in an active state at the last line of the compute shader. Threads that have not begun execution or have completed execution are not shown in the list view if they do not have peer threads in the active state but can be accounted for in a statistics section not shown .

The list view can also include other columns and indicia not shown in the user interface . For example the list view can show a line offset column presenting a line number of the method that the thread has at the top of its stack including the byte offset if the line number appears on other rows of the list view with a different byte offset. For example the row at the line offset column can read at line 11 0 2 bytes. Also when the debugger enters a break state the row of threads that includes the current thread can include an indicator such as an arrow on the list view . During break state a user can switch the current thread to designate a thread from another row to become the current thread and the indicator will change to that row.

Although specific embodiments have been illustrated and described herein it will be appreciated by those of ordinary skill in the art that a variety of alternate and or equivalent implementations may be substituted for the specific embodiments shown and described without departing from the scope of the present invention. This application is intended to cover any adaptations or variations of the specific embodiments discussed herein. Therefore it is intended that this invention be limited only by the claims and the equivalents thereof.

