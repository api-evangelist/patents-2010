---

title: Alternate source for controlling an animation
abstract: Techniques and tools described herein provide effective ways to program a property of a target object to vary depending on a source. For example, for a key frame animation for a property of a target UI element, an alternate time source is set to a property of a source UI element. When the target UI element is rendered at runtime, the animation changes the target value depending on the value of the property of the source UI element. Features of UI elements and animations can be specified in markup language. The alternate time source can be specified through a call to a programming interface. Animations for multiple target UI elements can have the same source, in which case different parameters for the respective animations can be used to adjust source values in different ways.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08866822&OS=08866822&RS=08866822
owner: Microsoft Corporation
number: 08866822
owner_city: Redmond
owner_country: US
publication_date: 20100907
---
When designing a user interface UI a software developer sometimes creates a UI element having a property that is dependent on the property of a second UI element or other source. A change to the property of the second UI element or other source causes a change to a property of the first UI element. For example the size of an image graphic can be programmed to change depending on the size of a window that includes the image graphic. When the size of the window changes the size of the image graphic changes accordingly. Or as another example the sliding scroll indicator in a scroll bar can be programmed to slide to different positions within the scroll bar depending on which part of a list of content is in a display area. When a user scrolls to view a different part of the content the scroll indicator changes positions.

When programming a property of a UI element to be dependent on a source value a developer can program software to compute the value of the property as a function of the source value. A code function is one common way to compute the property value. A typical code function accepts the source value as a parameter or otherwise gets the source value and returns the value of the property of the first UI element. In some software systems code functions are simple to implement and run quickly. In other systems however code functions can be difficult to implement or slow to run. In particular in systems in which UI elements are specified in markup language that is processed to render the UI elements accessing a code function can be difficult or slow. Such systems are common for UI rendering in mobile computing devices and other computing devices.

Techniques and tools described herein provide effective ways to program a property of a target object such as a UI element to vary depending on a source. In example implementations a key frame animation is set to change the value of the property of the target object depending on the value of the source. In such example implementations features of the target object and key frame animation can be specified in markup language which simplifies programming for the target object and animation.

According to a first aspect of the techniques and tools described herein a computing device determines an animation for a target graphical user interface GUI element and sets an input of the animation to relate to a property of a source GUI element. The target and source GUI elements are graphical features of the UI. The target GUI element and animation can at least in part be defined in markup language that the computing device processes or they can be specified in some other way. At runtime the computing device renders for display the target GUI element according to the animation and value of the property of the source GUI element. For example to render the target GUI element the computing device iteratively determines the value of the property of the source GUI element adjusts the value according to one or more adjustment parameters normalizes the adjusted value according to duration of the animation and interpolates within the animation to compute a value of the target GUI element at the normalized adjusted source value. In this way the value of the property of the target GUI element changes as a function of the value of the property of the source GUI element. This provides a simple way to animate one graphical feature of a UI depending on the value of a property of another graphic feature of the UI.

In example implementations the animation includes one or more key frames. The key frame s specify variations in the value of the property of the target GUI element. The key frame s can be added when processing markup language with statements defining the animation and target UI element or the key frame s can be added when processing a script separate from the markup language or the key frame s can be added by some other mechanism.

A programming interface can simplify the process of specifying the relationship between the target and source GUI elements. For example when the computing device sets the input for an animation the computing device calls a programming interface that returns a source variable whose value depends on value of the property of the source GUI element then assigns the source variable to an animation input property of the animation.

The computing device can repeat the process for one or more other target GUI elements. For example the computing device sets an input of a second animation to relate to the property of the source GUI element where the second animation is for a second target GUI element. At runtime the computing device then renders the second target GUI element according to the second animation and the value of the property of the source GUI element. In this way the rendering of multiple target GUI elements changes as a function of the same property of the source GUI element.

According to a second aspect of the techniques and tools described herein a computing device provides a programming interface that facilitates binding of an input of an animation to a given source other than time. The animation specifies variations in value of a property of the target object. The device receives a call to the programming interface and returns from the call. For example the call returns a source variable whose value depends on value of the given source. The call to the programming interface can include a property parameter that identifies the given source and can include one or more adjustment parameters that indicate adjustments to the value of the given source. In some cases the value of the given source is a scalar floating point value and the adjustment parameters include a multiplier an exponent and or an offset according to which the value of the given source is adjusted.

The device can also process a specification for the animation. For example the specification includes one or more statements that at least in part define the animation and one or more statements that set the input of the animation to the given source other than time. The specification can also include one or more statements defining a key frame for the animation where the key frame indicates a specific point in the variations in the value of the property of the target object.

According to a third aspect of the techniques and tools described herein a computing device with a rendering engine determines multiple animations for different target objects and iteratively renders the target objects at runtime. Each of the multiple animations specifies variations in value of a property of one of the target objects. When animation inputs of the respective animations are set to the same non temporal source changes to the value of the source cause changes to the respective target object properties. This provides a simple way to animate multiple target objects depending on the value of the same source.

The computing device determines a first animation that specifies variations in value of a first target object property. The computing device also determines a second animation that specifies variations in value of a second target object property. The animation input for the first animation and the animation input for the second animation are set to a given source other than time. As part of iterative rendering of the first and second target objects at runtime the computing device evaluates the first animation based on the value of the given source computing the value of the first target object property and the computing device evaluates the second animation based on the value of the given source computing the value of the second target object property. For example the evaluation includes adjusting the value of the source for purposes of a given animation normalizing the adjusted value according to length of the given animation where for a typical key frame animation with key frames that set different property values for different times the length of the animation is the duration defined by the times of the key frames and interpolating within the given animation to compute the value of the target object property at the normalized adjusted source value.

In example implementations an animation includes key frames that define different property values for different values of the animation input. For a typical key frame animation the values of the animation input are by convention labeled as time values in key frames even if the animation input for the animation is bound to a non temporal source. Each of the key frames indicates a different value of the property of the target object for a different value of the animation input. The key frames can be added when processing markup language that includes statements that at least in part define the animation. Or the key frames can be added when processing a script separate from such a markup language specification.

Different parameters for the multiple animations can be used to adjust the value of the given source in different ways. For example when the first animation is evaluated the value of the given source is adjusted according to one or more first parameters e.g. for a multiplier exponent and or offset that indicate how to adjust the value of the given source for purposes of the first animation. When the second animation is evaluated the value of the given source is adjusted according to one or more second parameters that indicate how to adjust the value of the given source for purposes of the second animation. When one of the first parameters differs from a corresponding one of the second parameters evaluation of the same source value during rendering can yield different results. This provides a simple yet flexible way to adjust the value of the source for different target objects.

Similarly the computing device can create different source variables whose values depend on the value of the given source then assign the different source variables to the animation inputs of the respective animations. For example the computing device creates a first source variable whose value depends on the value of the property of the given source and sets the animation input of the first animation to the first source variable. The computing device also creates a second source variable whose value depends on the value of the property of the given source and sets the animation input of the second animation to the second source variable. The values of the first and second source variables can also depend on adjustment parameters e.g. for a multiplier exponent and or offset specified for the respective source variables.

The computing device can repeat the process for other target objects. For example the computing device performs the determining and the rendering for each of one or more other target objects. In doing so the computing device can use the same source for two of more of the target objects or use different sources for different target objects.

The foregoing and other objects features and advantages of the invention will become more apparent from the following detailed description which proceeds with reference to the accompanying figures.

Techniques and tools described herein provide effective ways to program a property of a target object such as a UI element to vary depending on a source. For example a key frame animation is set to change the value of the property of the target object depending on the value of the source. In example implementations features of a target object and animation are specified in markup language that is processed to render the target object. Many markup languages provide animation features. Animation timelines for such animations however use time as their input. Allowing specification of an alternate input other than time for an animation timeline provides an effective way for developers to author a function in a markup language animation framework.

Generally techniques and tools described herein can be implemented with mobile computing devices or other computing devices. Computer readable media can store computer executable instructions for causing a processor programmed thereby to perform one or more of the techniques described herein. The various techniques and tools can be used in combination or independently. Different embodiments implement one or more of the described techniques and tools. Some of the techniques and tools described herein solve one or more of the problems described in the Background section but techniques and tools described herein need not solve such problems.

The device determines an animation for a target object that has a property. Generally the animation specifies variations in the value of the property of the target object depending on which input value is provided by the animation input for the animation. In example implementations by analogy to conventional key frame animations the animation input is alternately termed the time source for the animation. Changes to value of the animation input of the animation are associated with changes in value for the property of the target object. The animation can be a key frame animation for which key frames specify variations in value of the property of the target object or the animation can be another type of animation. Depending on implementation the determination of the animation by the device can include simply identifying or providing an animation that was previously specified or it can also include defining one or more features of an animation.

The device sets the animation input of the animation for the property of the target object to a source other than time. For example the source is a property of a source GUI element and the device sets the animation input to relate to the property of the source GUI element. In example implementations the device sets the animation input by creating a source variable whose value depends on the value of the source then assigning the source variable to the animation input of the animation. For example the device calls a programming interface that returns the source variable then assigns the source variable to a source property of the animation. The source variable can also depend on one or more adjustment parameters that are specified for the source variable. Alternatively the device sets the animation input of the animation using another mechanism.

At runtime the device renders the target object according to the animation and the value of the source. The device iteratively determines the value of the source and evaluates the animation for the determined value of the source computing a value of the property of the target object. For example the device adjusts the value of the source according to one or more adjustment parameters normalizes the adjusted source value according to length of the animation such as a duration defined by key frames and interpolates within the animation to compute a value of the property of the target object at the normalized adjusted source value. In this way the value of the property of the target object changes as a function of the value of the source that is set to be the animation input of the animation.

In example implementations the value of the property of the target object and the value of the source are scalar floating point values that represent e.g. width height opacity horizontal position vertical position or another value in one dimension. When the animation input is set for an animation one or more parameters can be specified that indicate an adjustment to the value of the source e.g. a multiplier exponent offset or other adjustment to the value of the source . When the target object is rendered the device adjusts the value of the source according to the parameter s . Alternatively the device renders the target object using another approach.

Some conventional animation authoring tools allow an author to scrub through an animation to evaluate the animation at different times during development. For example the author moves a graphical time indicator in the UI of the authoring tool to change which time is evaluated for the animation. Mouse cursor location or the location of the time indicator may temporarily affect how the animation is evaluated during authoring. When the animation is finalized however the time source for the animation is set so that actual time is the input for rendering at runtime. In contrast according to example implementations described herein an alternate time source is specified for an animation to provide values that the animation uses for evaluation at runtime. In this way the animation input for an animation can be bound to any changeable property in a UI rendering environment.

The device can perform the technique when parsing or otherwise processing markup language that includes statements about the target object and or animation. For example the markup language can include one or more statements at least in part defining the target object and animation and one or more statements setting the animation input for the animation. Or the device can perform the technique for an animation and target object defined in some other way.

Finally although shows the acts of determining setting and rendering in succession the acts can be performed in different order when rendering animations for multiple target objects. For example a device can perform the determining and setting for each of multiple target objects. Later possibly after saving the results of the setting the same device or a different device can determine the animations for which the animation inputs were set then perform the rendering for the multiple target objects.

The application is software that provides functionality to a user. For example the application is a media player a game an organizer for media or games an email client a telephone application or any other software that provides functionality to a user. In the application uses services provided by the application library the rendering library and the operating system .

The application library implements functionality for the application that is common to multiple applications. In this way the multiple applications can reuse the same library . In the application library provides services to the application and uses services provided by the rendering library . The application library can also use services provided by the operating system .

The rendering library provides services to the application and application library and the rendering library uses services provided by the operating system . In example implementations the rendering library implements software for playing key frame animations. The key frame animation processing is conventional in most respects. The rendering library has been modified however to implement a programming interface that is exposed to the application and or application library . The application and or application library can call the programming interface to create and receive a source variable for a key frame animation. When an alternate source is specified for the animation the rendering library plays the animation according to values from the alternate source.

The operating system provides services to the application application library and rendering library . The operating system can be an operating system adapted for a mobile computing device or other operating system. One or more modules in the operating system convert user input from a touchscreen directional buttons on a keypad or keyboard trackball microphone or other input device into recognized UI events e.g. a button click gesture messages e.g. in response to a panning or flick gesture by the user interacting with a touchscreen navigation messages or other information that can be used in UI rendering. The operating system can provide such events messages etc. to the application application library and rendering library . The events messages etc. generated in response to user input are translated into direct UI manipulation events for UI elements being rendered.

Within the rendering library and or operating system one or more modules receive a markup language specification or other declarative description of one or more animations and UI elements. Generally a declarative description includes information that defines UI elements. The declarative description can be provided to markup generator along with other information such as style information and or configuration properties and the markup generator generates markup language that can be used to render the UI elements. For layout UI rendering requests are generated from the markup language description as well as direct UI manipulation events and other commands. The rendering library and or operating system include one or more modules for playing animations based on the markup language specification and laying out UI elements for rendering. The operating system includes one or more modules for receiving rendering requests and causing a rendered UI to be output for display.

Alternatively the software architecture includes more or fewer layers. For example a given layer can be split into multiple layers or different layers can be combined into a single layer. Functionality described with reference to one layer e.g. rendering functionality programming interface for alternate time source can in some cases be implemented as part of another layer.

A programming interface provides a way for a developer to specify an input other than time for an animation input for a property of a target object. For example a computing device provides a programming interface that facilitates binding of an animation input of an animation to a given source other than time. The programming interface can be implemented as part of a rendering library as part of an operating system or as part of other software. The computing device receives a call to the programming interface and then returns from the call. For example the call returns a source variable whose value depends on value of the given source where the source variable can then be assigned to the animation input. Or the computing device sets the animation input to the given source as part of programming interface implementation processing and then returns from the call. By setting an alternate source for the animation input which provides input values evaluated like times along a timeline for the animation using the programming interface the developer can easily specify the property of the target object as a function of an arbitrary input. Depending on implementation the programming interface can be an application programming interface or other system provided software routine or a method function or other software routine provided as part of a software library or other software object.

In example implementations an application or other software calls a programming interface to create a source variable. The source variable will propagate a source s value to an animation input effectively making the source s value the input for the animation timeline. A property of the animation is set to the source variable or the animation receives the source variable using some other mechanism. In this way as the value of the source changes the animation evaluates to different values for the property of the target object.

For example an animation and target object can be defined at least in part by a specification such as a markup language document in a format suitable for processing by a rendering engine. The specification for the animation and target object includes one or more statements that at least in part define the animation for the target object. Other features of the animation and target object can be defined in one or more separate files such as other markup language documents other source code files or other software libraries. The animation specifies variations in value of a property of the target object. The specification also includes one or more statements that set the time source animation input of the animation to a given source other than time. In particular the specification includes a call to a programming interface that returns a source variable whose value depends on value of the given source. The call to the programming interface can include a property parameter and one or more adjustment parameters. The property parameter identifies the given source. The adjustment parameter s indicate adjustments to the value of the given source e.g. when the value of the source is a scalar a multiplier exponent and or offset for the value of the source . The specification can also include one or more statements defining a key frame for the animation.

For the example programming interface of possible types for the animation property include opacity Alpha horizontal position PositionX vertical position PositionY width SizeX height SizeY horizontal scale ScaleX and vertical scale ScaleY . Each of these is represented using a scalar floating point value. Alternatively the animation property can be set to another type and or represented with another value. At runtime the queried source value x is modified by the exponent p multiplier m and offset a according to the formula m x a. Alternatively the queried source value can be modified according to another value function.

In some scenarios multiple target objects are animated according to the same source. In such scenarios different calls to the programming interface can specify different adjustment parameters for different source variables. With this flexibility a value from the same source can be adjusted in different ways for different target object properties. For example a control can be authored for which animations of different UI elements are set to the same alternate source but change positions of the respective UI elements at different rates to provide a parallax effect.

Calls to the programming interface can be set in a markup language specification for the animation and target object. Or calls to the programming interface can be set in a script or other programming language document.

Conventionally a key frame animation specifies variations in the value of a target object property at different times along an animation timeline. An individual key frame indicates a value of the target object property for a given time along the timeline. In example implementations the time source animation input for a key frame animation is set to a source other than time such that different source values correspond to different times along the timeline input values for the animation and such that changes to the source value result in changes to the value of the target object property. Complex controls can be created with key frame animations that are not time based. Providing the ability to specify an alternate source allows for authoring within a key frame framework while also permitting binding of an animation to the alternate source.

A conventional key frame animation has a timeline that starts at zero may include one or more key frames at intermediate times relative to the start and ends at a time defined by the last key frame. The duration of the animation is the difference between the time defined by the last key frame and the time defined by the first key frame or default 0 . By interpolation a value for the target object property can be determined for any time within the duration of the timeline.

In example implementations key frames define values of a target object property for different input values from a source. illustrates an approach that uses linear interpolation to determine values for a target object property. A key frame sets the value of the target object property to be 100 when the animation input value is 200. By linear interpolation any input value in the range of 0 . . . 200 can be mapped to a corresponding target property value in the range of 0 . . . 100. Alternatively instead of linear interpolation the interpolation can be splined interpolation interpolation along a Bezier curve or another type of interpolation. The type of interpolation can be defined for the device or specified for a given animation. The length of the key frame animation is the difference between the input value defined by the last key frame and the input value defined by the first key frame or default 0 .

In general the value of a source has a range and the animation has a length. The range of the source value can be the same as the length of the animation e.g. both 0 . . . 200 or both 0.0 . . . 1.0 . In many instances however the length of the animation is different than the source value range especially when the value of the source is adjusted according to a multiplier exponent offset or other parameter during rendering. Moreover different animations can have different lengths even when set to the same source. When an animation length is different than the source value range the source value is adjusted to fit within the animation length.

For example suppose a first animation has a first length and a second animation has a second length different than the first length. The value of a given source has a source value range different than the first and second animation lengths. When the first animation is evaluated during rendering the value of the given source is normalized to the first animation length. When the second animation is evaluated during rendering the value of the given source is normalized to the second animation length.

Key frame animations can be authored in a markup language such as Extensible Application Markup Language XAML which is a descriptive programming language for creating UIs or authored in another variation of extensible markup language XML . In general constructs in a XAML file specify UI features and may in turn call or reference other code. An authoring tool can allow a user to specify key frames and alternate sources for animations directly in markup language. Alternatively key frame animations and their sources are specified using a graphical animation authoring tool that generates markup language output from higher level instructions. When key frames are known when markup is authored key frames can be added at that time. Otherwise key frames can be added by a separate script.

In the listing of statements define features of a panel named ScrollRoot. As a container for content the panel controls the positioning and rendering of the content. The panel includes a repeater which is a control that repeats a specified template for each item in a list. According to the listing the items of the list are laid out in a horizontal orientation.

The listing of shows a call to the CreateRelativeTo programming interface for the panel ScrollRoot. In the call the property parameter identifies a source property to query AnimationProperty.PositionX. Three other parameters specify an exponent p 1 multiplier m 1.0 and offset a 0.0 for adjustment of the queried source value at runtime. The call returns a source variable named ScrollRootRelativeTo which can be passed around in model classes to other UIs. Once accessible the variable ScrollRootRelativeTo can be assigned to be the animation input of an animation for another UI element.

The listing of shows statements that in part define an animation named HeaderAnimation that will be associated with a header label UI element. The animation is an idle animation that loops endlessly. The listing shows two key frames for which default conventional times are associated with default horizontal position values. The listing also shows assignment of the source variable ScrollRootRelativeTo to the TimeSource property of the animation. In this way even though the key frame animation is conventional in most respects the time source for HeaderAnimation is changed with the source values acting as times for purposes of key frame evaluation.

Once information is available to the UI to calculate the animation key frames can be added to the animation. The listing of shows the addition of a key frame when the number of key frames is known at the time markup language is authored. In the listing the header label named HeaderLabel has a property LayoutSize.Width. A PositionXKeyFrame type key frame is added for which the input value keyframe.Time is double the width of the header label and the corresponding horizontal position value is the width of the header label. The new key frame defines the extreme at which the maximum horizontal position value is used. Another default key frame defines the other extreme at which the minimum horizontal position of zero is used. The routine UpdateAnimation is then called.

If the number of key frames is not known at markup time key frames can nevertheless be added through a script. shows a listing that adds two key frames through a script. As in a header label has a property LayoutSize.Width. A first new PositionXKeyFrame type key frame defines the extreme at which the minimum horizontal position of zero is used. The first new key frame is added to the animation. Then a second new PositionXKeyFrame type key frame defines the other extreme at which the maximum horizontal position value is used. For the second new key frame the input value keyframe.Time is double the width of the header label and the corresponding horizontal position value is the width of the header label. The second new key frame is added to the animation and UpdateAnimation is called.

In the UpdateAnimation routine shown in the listing of the animation HeaderAnimation is conditionally attached to HeaderLabel through a call to a member function of HeaderLabel. The member function AttachAnimation is called when scroll position is changing as indicated by the IsScrolling property. Alternatively another property can be used to trigger the animation such as when the Scroller is programmatically scrolled. In any case running the animation when the scroll position is changing provides the desired adjustments to horizontal positions of the target UI element. On the other hand stopping the animation when the scroll position is not changing by programming the animation to detach when the animation is idle avoids unnecessary evaluation of target values and helps save battery life.

Table 2 shows example target values for horizontal position of the visual element HeaderLabel for different source values for horizontal position of the scroll content. For Table 2 the width of the header label is 100. An original source value is adjusted according to the parameters p 1 m 1.0 and a 0 in effect no adjustment for this example . The adjusted source value is mapped to the length of the animation which has a range of 0 . . . 200 according to the approach explained with reference to 

The listing of shows an alternative way to assign the source for the animation HeaderAnimation. As in the listing of the animation is an idle animation that loops endlessly and two key frames associate default conventional times with default horizontal position values. The listing shows a different way however to assign the TimeSource of the animation.

In scrolling content is scrolled horizontally according to finger gesture input on a touchscreen display. The scrolling content can be images graphical icons text lists or other information to be presented visually. The scrolling content moves at a base rate that corresponds to the rate indicated with gesture input. The other UI elements are set to scroll in the same direction as the scrolling content but at different rates. The background image is set to scroll horizontally at a rate much less than the base rate. The header label and category label are also set to scroll at slower rates than the content .

In the display shows the header label category label content and background image in initial positions aligned at the left of the display. In the display of two new content images and have scrolled into view the category label has scrolled at a lower rate the header label has scrolled at an even lower rate and the background image has scrolled slightly. The display of shows similar scrolling adjustments at the same rates respectively. In the display of the end of the scrolling content is reached and the header label category label content and background image are shown in final positions aligned at the right of the display.

In the example of a UI element can have a negative horizontal position to indicate a start before the edge of the display. Table 3 shows example target values for the source UI element and the respective target UI elements of . For this table the rates of the background image header label and category label are 1 15 and respectively the base rate of the scrolling content.

The animation behavior shown in Table 3 and can be specified using a multiple of m 1.0 and two key frames per animation. For example for each animation the first key frame is the initial default key frame for which input value key frame time is 0 and the property value is 0 and the second key frame has an input value key frame time equal to the width of the scrolling content minus the display width width diff e.g. 450. For the category label animation the second key frame has a property value of width diff 3 . Similarly the second key frame for the header animation has a property value of width diff 5 and the second key frame for the background image has a property value of width diff 15 .

In the display shows the content and scroll indicator in initial positions at the top of the display . In the display of six new content images to have scrolled upward into view and the scroll indicator has scrolled in the opposite direction downward to the middle of the scroll bar . In the display of the end of the scrolling content is reached and the content and scroll indicator are shown in final positions.

Table 4 shows example target values for the source UI element content and target UI element indicator . As the user scrolls down through the scroll content region the vertical position PositionY of the scroll content region decreases in value but the vertical position PositionY of the scroll indicator increases in value at a proportional rate.

The animation behavior shown in Table 4 and can be specified using a multiple of m 1.0 and two key frames for the scroll indicator animation. For example according to the first key frame when the input value key frame time is 0 the property value of the vertical position of the scroll indicator is 0. According to the second key frame the input value time of the key frame is the maximum value for the scroll content region scrolled to the end of the content and the property value of the key frame is the maximum value for the scroll indicator scrolled to the bottom of the scroll bar . A source variable is created that is tied to the vertical position PositionY of the scroll content region. The source of the scroll indicator animation is set to the source variable. Other properties of the scroll indicator can similarly be animated as a function of a property of the scroll content region. For example the width of the scroll indicator can vary in inverse proportion to the length of the scroll content region.

The illustrated mobile device can include a controller or processor e.g. signal processor microprocessor ASIC or other control and processing logic circuitry for performing such tasks as signal coding data processing input output processing power control and or other functions. An operating system can control the allocation and usage of the components and support for one or more application programs . The application programs can include common mobile computing applications e.g. include email applications calendars contact managers web browsers messaging applications or any other computing application.

The illustrated mobile device can include memory . Memory can include non removable memory and or removable memory . The non removable memory can include RAM ROM flash memory a disk drive or other well known memory storage technologies. The removable memory can include flash memory or a Subscriber Identity Module card which is well known in GSM communication systems or other well known memory storage technologies such as smart cards. The memory can be used for storing data and or code for running the operating system and the applications . Example data can include web pages text images sound files video data or other data sets to be sent to and or received from one or more network servers or other mobile devices via one or more wired or wireless networks.

The mobile device can support one or more input devices such as a touchscreen microphone camera physical keyboard and or trackball and one or more output devices such as a speaker and a display . Other possible output devices not shown can include a piezoelectric or other haptic output device. Some devices can serve more than one input output function. For example touchscreen and display can be combined in a single input output device.

Touchscreen can accept input in different ways. For example capacitive touchscreens detect touch input when an object e.g. a fingertip or stylus distorts or interrupts an electrical current running across the surface. As another example touchscreens can use optical sensors to detect touch input when beams from the optical sensors are interrupted. Physical contact with the surface of the screen is not necessary for input to be detected by some touchscreens.

A wireless modem can be coupled to an antenna not shown and can support two way communications between the processor and external devices. The modem is shown generically and can include a cellular modem for communicating with the mobile communication network and or other radio based modems e.g. Bluetooth or Wi Fi . The wireless modem is typically configured for communication with one or more cellular networks such as a GSM network for data and voice communications within a single cellular network between cellular networks or between the mobile device and a public switched telephone network.

The mobile device can further include at least one input output port a power supply a satellite navigation system receiver such as a global positioning system receiver an accelerometer a transceiver for wirelessly transmitting analog or digital signals and or a physical connector which can be a USB port IEEE 1394 firewall port and or RS 232 port. The illustrated components are not required or all inclusive as components can be deleted and other components can be added.

For the sake of presentation the detailed description uses terms like determine and perform to describe computer operations in a computing environment. These terms are high level abstractions for operations performed by a computer and should not be confused with acts performed by a human being. The actual computer operations corresponding to these terms vary depending on implementation.

Various alternatives to the example implementations presented herein are possible. Many examples presented herein involve key frame animations that are specified using markup language. Alternatively one or more of the described techniques and tools is applied for another type of animation and or for an animation specified in some way other than markup language. Also although many examples presented herein involve a target GUI element and source GUI element the described techniques and tools are more generally applicable for a target object and source.

More generally techniques described with reference to flowchart diagrams can be altered by changing the ordering of stages shown in the flowcharts by repeating or omitting certain stages etc. As another example systems described with reference to system diagrams can be altered by changing the ordering of processing stages shown in the diagrams by repeating or omitting certain stages etc. As another example user interfaces described with reference to diagrams can be altered by changing the content or arrangement of user interface features shown in the diagrams by omitting certain features etc. As another example although some implementations are described with reference to specific devices and user input mechanisms e.g. mobile devices with a touchscreen interface described techniques and tools can be used with other devices and or other user input mechanisms.

In view of the many possible embodiments to which the principles of the disclosed invention may be applied it should be recognized that the illustrated embodiments are only preferred examples of the invention and should not be taken as limiting the scope of the invention. Rather the scope of the invention is defined by the following claims. We therefore claim as our invention all that comes within the scope and spirit of these claims.

