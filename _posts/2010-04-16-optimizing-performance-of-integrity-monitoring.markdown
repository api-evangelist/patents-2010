---

title: Optimizing performance of integrity monitoring
abstract: A system, method and computer program product for verifying integrity of a running application program on a computing device. The method comprises: determining entry points into an application programs processing space that impact proper execution impact program integrity; mapping data elements reachable from the determined entry points into a memory space of a host system where the application to verify is running; run-time monitoring, in the memory space, potential modification of the data elements in a manner potentially breaching program integrity; and initiating a response to the potential modification. The run-time monitoring detects when a data transaction, e.g., a write event, reaches a malicious agent's entry point, a corresponding memory hook is triggered and control is passed to a security agent running outside the monitored system. This agent requests the values of the data elements, and determines if invariants that have been previously computed hold true or not under the set of retrieved data values.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08949797&OS=08949797&RS=08949797
owner: International Business Machines Corporation
number: 08949797
owner_city: Armonk
owner_country: US
publication_date: 20100416
---
The present invention relates to computing systems and performing integrity measurements or monitoring of software applications running one computing systems and more particularly to gathering and use of semantic dependency information and performance monitoring results to derive a balanced software monitoring profile.

Imposing the integrity of running software requires the monitoring of all its data during execution e.g. to ensure it is not modified by a malicious agent. Such integrity monitoring of all data imposes high performance penalties on the protected software and on the execution environment.

Existing techniques that attempt to alleviate the performance impact of integrity measurements or monitoring either resort to sampling of the monitored data See e.g. J. Mai C. N. Chuah A. Sridharan T. Ye and H. Zang Is Sampled Data Sufficient for Anomaly Detection in Proc. ACM SIGCOMM Conf. Internet Measurement 2006 pp. 165 176 or see N. Duffield C. Lund and M. Thorup Properties and Prediction of Flow Statistics from Sampled Packet Streams in Proc. ACM SIGCOMM Wkshp. Internet Measurement 2002 pp. 159 171 or to the use of custom designed hardware See e.g. N. Petroni T. Fraser J. Molina and W. A. Arbaugh Copilot a coprocessor based kernel runtime integrity monitor in Proc. USENIX Security Symp. 2004 and instruction set architectures See e.g. Y. Fei Microarchitectural Support for Program Code Integrity Monitoring in Application specific Instruction Set Processors in Proc. Conf. Design Automation Test in Europe 2007 pp. 1 6 M Milenkovic A. Milenkovic and E. Jovanon Hardware support for code integrity in embedded processors in Proc. Conf. Compilers Architecture and Synthesis for Embedded Systems 2005 pp. 55 65 and W. B. Noble T. W. Bradley and M. W. Autry Integrity checking procedure for high throughput data transformations U.S. Pat. No. 5 586 204 .

In the case of sampling the performance penalty incurred by integrity monitoring is reduced by decreasing the number of trigger events received by the monitor upon data modifications or by decreasing the number of monitored data elements. Either sampling approach results in a reduction of the performance penalty proportional to the reduction in events received by the integrity monitor. Some hardware based techniques propose to employ co processors that can read data from the running software without incurring any additional overhead See Copilo a coprocessor based kernel runtime integrity monitor referenced herein above .

Other techniques extend the instruction set and micro architectures to automatically augment processors with hardware integrity monitors See e.g. Microarchitectural Support for Program Code Integrity Monitoring in Application specific Instruction Set Processors and Hardware support for code integrity in embedded processors referenced herein above .

There are drawbacks associated with these prior art techniques. The sampling technique suffers from weak security guarantees. By reducing the number of data elements monitored or the frequency with which they are monitored the chance of catching an attack while it happens is decreased accordingly. Thus sampling always leads to a reduction in security often in unpredictable ways. Hardware based techniques preserve the security of the system but do so at high incurred costs since new hardware needs to be added to the system and in an application specific way since the hardware has to be adapted to a specific application domain .

A further problem addressed by integrity monitoring systems is the problem of protecting the integrity of running software in the presence of a malicious agent e.g. a malicious agent running at the same privilege level. The malicious agent can modify the data over which the protected software operates thus forcing it to compute incorrect results to allow access to otherwise unauthorized resources or to report to the user a state configuration different from the active one.

Existing solutions are part of one or two categories based on their approach to the problem of runtime integrity protection Anti virus AV See e.g. Symantec AntiVirus http www.symantec.com anti rootkit See e.g. F Secure BlackLight http www.f secure. com blacklight host intrusion detection systems HIDS See e.g. Osiris http osiris.shmoo.com anomaly detection systems ADS See e.g. IBM Proventia Network Anomaly Detection System and information flow tainting systems See e.g. Yin H. Song D. Egele M. Kruegel C. and Kirda E. 2007. Panorama capturing system wide information flow for malware detection and analysis. In Proceedings of the 14th ACM Conference on Computer and Communications Security Alexandria Va. USA Oct. 28 31 2007 . CCS 07 ACM New York NY 116 127 DOI attempt to identify the malicious agent before it starts executing or while it executes. If these solutions identify the malicious agent they can shut it down and remove it from the system. These solutions fall short of the stated problem as they run at the same privilege level as the protected software and the malicious agent. Thus while they might be able to identify and stop the malicious agent before it affects the protected software they are open to directed attacks from the malicious agent. Such solutions do not provide the security guarantees required by the problem of runtime integrity protection. The second set of solutions attempt to reduce the probability of success for an attack by modifying the protected software. Such solutions include memory randomization See e.g. PaX Address Space Layout Randomization data space randomization See e.g. Sandeep Bhatkar R. Sekar. Data Space Randomization. DIMVA 2008 1 22 and stack and heap protection See e.g. Hiroaki Etoh and Kunikazu Yoda. Protecting from stack smashing attacks and Microsoft. A detailed description of the Data Execution Prevention DEP feature in Windows XP Service Pack 2 Windows XP Tablet PC Edition 2005 and Windows Server 2003 .

By their nature these mechanisms are probabilistic protect only against simple attacks and may incorrectly identify benign software as malicious because these solutions are independent of the protected software .

Further existing solutions that share the runtime environment with the protected software can thus be compromised by malicious software rendering them inefficient. Solutions that strengthen the protected software or its runtime environment may suffer from false positives.

Thus it would be highly desirable to address the problem of protecting the integrity of running software in computing or data processing environments e.g. in the presence of a malicious agent running at the same privilege level that can modify the data over which the protected software operates thus forcing it to compute incorrect results to allow access to otherwise unauthorized resources or to report to the user a state configuration different from the active one.

In one aspect there is provided a system method and computer program product that is configured to define automatically characteristics called invariants of a software program and to monitor these characteristics while the program is running in order to identify attacks against the security of the running software program. Further there is provided a system optimization to reduce the number of characteristics to monitor to thereby improve the performance of the runtime monitor without reducing the security guarantees.

According to this aspect the system method and computer program product operates to protect the integrity of running software e.g. in the presence of a malicious agent running at the same privilege level. The malicious agent can modify the data over which the protected software operates thus forcing it to compute incorrect results to allow access to otherwise unauthorized resources or to report to the user a state configuration different from the active one.

In one aspect there is provided a computer implemented method for verifying integrity of a running application program on a computing device the method comprising determining entry points into an application programs processing space that potentially impact data elements of the running application mapping data elements reachable from the determined entry points into a memory space of a host system where the application program to verify is running monitoring during run time the memory space to verify any modification to a data element does not breach a program state and initiating a response to the potential modification when the modification breaches the program state.

Further to this aspect the monitoring comprises checking potential updates to a target data structure relevant for a proper execution of the application program.

Further to this aspect the monitoring comprises checking potential updates to a target data structure relevant for preserving semantic integrity of the program state.

In a further embodiment there is provided a run time software monitoring system comprising a memory a processor in communication with the memory wherein the system is configured for performing a method comprising pre determining data structures that affect the semantics of a program state of a program to be monitored constructing a semantic integrity profile based on a code of an application program the profile comprising constraints that hold true at particular states for semantic integrity to be preserved. Performing run time monitoring of the program to determine when the program enters the particular program state checking the invariants and determining if one or more constraints are not satisfied indicating semantic integrity breach of the program and raising an alert in response to the determining.

There is further provided a method for run time software monitoring comprising pre determining data structures that affect the semantics of a program state of a program to be monitored constructing a semantic integrity profile from the source code or compiled binary code of the core component the profile comprising constraints that hold true at particular states for semantic integrity to be preserved performing run time monitoring of the program to determine when the program enters the particular program state checking the invariants and determining if one or more constraints are not satisfied indicating semantic integrity breach of the program and raising an alert in response to the determining.

In one aspect the system method and computer program product utilizes semantic information from the data of the running software in order to explore informed tradeoffs between acceptable performance penalties and changes in security guarantees. In one embodiment the semantic information includes entry points into the software s data space and dependencies between data elements that are backwards forwards reachable from identified entry points.

A computer program product is for performing operations. The computer program product includes a storage medium readable by a processing circuit and storing instructions run by the processing circuit for running a method. The methods are the same as listed above.

More particularly in first phase existing malicious agents are run operated in some form of a sandbox using a sandboxing technique and the method collects behavior traces for these agents. The collected behavior traces for these agents are then analyzed to detect the agents entry points in the application space.

It is understood that application space entry points will vary from application to application. Thus in one embodiment these application space entry points may be defined by a human expert based on the description of the application and the APIs application programming interfaces defined by the application. For example in the case of an operating system kernel the application space entry points are the system calls defined by the kernel. These entry points may be determined using automated tools.

In a further aspect an analysis performed during processing of the second phase is additionally leveraged to discover new entry points. For example in order to apply this method to an example software application e.g. Linux kernel space several Linux rootkits are run operated on top of a processor emulator e.g. in one example a QEMU processor emulator where binary instrumentation is used to determine rootkit entry points into the kernel space. Each determined entry point is then provided as input to Phase II. A further embodiment for discovery of entry points is described in K Tracer A System for Extracting Kernel Malware Behavior . Andrea Lanzi Monirul Sharif and Wenke Lee. In Proceedings of The 16th Annual Network and Distributed System Security Symposium NDSS 2009 San Diego CA February 2009 incorporated by reference herein .

The second Phase includes a step for building a system dependence graph SDG of the considered application based on a pre determined entry point. The SDG may be generated automatically by implementing a tool for analyzing the code of the application. Tools are implemented that generate the SDG from either the source code of the application or from its binary compiled code. In one embodiment this tool may be performed offline as a preprocessing step before running the program to be monitored. A commercially available program for generating the SDG is the GrammaTech CodeSurfer program incorporated by reference herein.

More particularly the SDG is a collection of dependence graphs derived over each procedure in the application. Edges in the SDG represent both data flow between the graph nodes as well as control conditions on which execution depends. An example SDG is given in starting at procedure detach pid which functions to remove the process descriptor task structure from the hash tables of type type . Graph nodes represented in as nodes represent program statements and interprocedural dependencies and edges show data dependencies and conditional control flow in the application. The method then performs computing interprocedural and intraprocedural data dependencies by performing path sensitive backwards slicing technique on the SDG . Performing path sensitive backwards slicing on the SDG involves traversing the SDG backwards starting from the entry point s defined in Phase I along all likely execution paths in the SDG and identifying data dependencies within derived slices. This is accomplished for instance by traversing all SDG edges incident onto the entry point s in the opposite direction to the direction of the edge and collecting the program variables that are related to the entry point s . illustrates an example SDG and illustrates an example data dependency graph derived therefrom. For example shows the result data dependency graph of computing dependencies between data elements reachable through backwards slicing e.g. from an example entry point link pid defined in SDG of . A result of the backwards slicing over the SDG is the identification of a complete set of program variables that are to be monitored during Phase III.

Then in a further step of the second phase an invariant detector component is implemented to report properties satisfied by a group of data elements computed as part of the data dependence graph in the step of second phase . Invariants are properties or formal specifications that hold at a certain point in a program when a specific execution path is taken. The invariant detector observes data in a program and reports permissible properties i.e. properties that should hold true on data observed along a specific execution path and non permissible properties i.e. properties that should hold false. Multiple forms of invariants over the application data structures may be detected such as invariants depicted in . Invariants include conjunctive invariants disjunctive invariants recursive invariants conditional invariants and associated control conditions and invariants representing relationships e.g. unary binary is pointer between variables.

Thus during Phase II after the backwards slicing of the SDG the invariant detector component analyzes the code of the program to determine how the program variables obtained from the SDG relate to each other. For example variables could be updated in lockstep or they can have the same value or some other mathematical relation that holds between them. This information is captured as logical formulas referred to as program invariants. As implemented herein a program invariant is a logical formula describing a relation between program variables for example that a variable x is equal to a variable y 1 . In this example the runtime monitor continuously collects the values of x and y inserts these values in the formula of the program invariant and check whether the formula is true. An invariant does not hold true if the invariant formula when evaluated over the values collected by the runtime monitor is false.

A third step of second phase involves mapping data elements computed as part of the data dependency graph into the memory space of a host where the software to verify is running. Data elements in this context refer to program variables. As the program invariants generated in Phase II connect program variables using logical formulas written in a symbolic form e.g. x y 1 the runtime monitor has to be able to find these variables in the memory of the running program in order to read their values. Mapping a program variable into memory includes finding the memory address where the program stores this particular variable. This memory address for a variable can vary from execution to execution based on a variety of factors There are multiple possible ways to find this memory address the use of debugging information the use of memory maps or the use of memory introspection. Other pre existing mechanisms may be employed for mapping variables in memory.

As shown in in a next step data comprising the virtual memory addresses of interesting data is extracted. For each named data item also referred to as a program symbol or a program variable its address in memory is determined. In an example application described herein for verifying the integrity of a Linux kernel application there is extracted the virtual addresses of several interesting data structures such as e.g. the system call table init task etc. from the System.map file at the host configuration time. For example in the case of the System.map file the name of a program variable symbol is used to look up in this file its address e.g. expressed as a numeric value. In one embodiment a user e.g. a security expert may decide which of a program s variables symbols are interesting. This decision is made based on previous attacks which affected particular variables symbols and based on knowledge about the application. In general any program variable symbol that directly control the operation of the program is of interest. The derived data elements are then located as offsets from these virtual memory addresses. The method then translates the computed virtual addresses into host physical addresses and places memory hooks at those physical addresses in the monitored system. As known memory hooks are the mechanism through which the runtime monitor observes the value of a variable as this value changes. Once the runtime monitor maps the variables used in invariants to memory addresses it will then install the memory hooks to observe the values that the program places at those memory addresses .

Third phase employs the run time monitoring agent component to monitor memory system in real time as the application executes. In this phase a run time monitoring agent is run to detect when a write event reaches an entry point prior determined as an entry point of a malicious agent e.g. malware kernel module . In response the corresponding memory hook is triggered and control passes to the monitoring agent functioning as a security agent component running outside the monitored memory system . Monitoring agent subsequently requests the values of the data elements on which memory hooks have been placed. If the invariants computed in second Phase do not hold true under the set of retrieved data values a violation is detected and the security agent responds with appropriate measures e.g. raising an alert signal.

In one embodiment the run time monitoring agent is built using a virtual machine and a hypervisor . On write trigger events are signaled to the hypervisor which subsequently retrieves the values of the remaining memory hooks that are part of the data dependence graph by introspection.

In the construction of the Semantic integrity profile there is first performed identifying data structures of interest . In order to derive the set of variables necessary for establishing the state invariants data structures are first determined whose integrity is to be monitored. A data structure used by a core component is a candidate for semantic integrity monitoring if it influences the operation of the program and if its value persists across multiple interactions between the core component and the plugins. That is an extensible program includes a core component that defines its primary functionality and a set of zero or more extensions or plug ins that enhance this primary functionality. The core component starts first when the program is started and loads the extensions plug ins requested by the user. A key characteristic of extensible programs is that the core component and the extensions plugins are created by different parties so they have different trust or security guarantees. In one example the task struct list and runqueue in the Linux kernel fit these characteristics and are candidates for semantic integrity monitoring. Thus in one embodiment these data structures are identified of interest based on knowledge of the Linux kernel and the operation of many kernel rootkits with particular focus on kernel data structures whose contents directly reflect in user space. This basis for this is that the kernel maintains a set of logical data structures that are reflected in user space and all other data structures are internal to the kernel and depend on the primary set. It is understood that techniques exist for automatically determining data structures critical to kernel operation. New data structures may be added to the set of monitored data structures.

In the step of deriving state invariants includes for each data structure of interest the generating of invariants that have to hold when the data structure is modified. In other words each time a data structure of interest is updated the associated invariants must allow verification that the update matches the other variables which are part of the program state. This drives the implementation of the invariant generation algorithm described herein above with respect to which operates by identifying the code locations where a data structure is updated. For complex data structures such as collections of objects updates include additions of new objects to the collection modification of existing objects in the collection modification of the collection metadata e.g. re balancing a binary tree or sorting a list and removal of existing objects from the collection. A pointer analysis may be further integrated into the algorithm. For program paths reaching an identified code location the method includes collecting all the variables that influence the update operation and for each there is derived an invariant that captures them. As multiple paths can usually reach a code location where an update of interest occurs multiple invariants are generated one per path for each possible update.

More particularly as described with respect to there is performed a static analysis of the program source code to compute a control flow graph CFG of the program paths that reach data structure updates. This CFG is inter procedural for handling programs of arbitrary complexity and is an intermediate representation of the program slicing procedure for a variable x that represents the data structure of interest the method includes slicing the program to include only the program variables needed to propagate dependency relationships between the entry point and an update to the variable x . Computing the slice includes steps of generating data flow information from each statement involved in the CFG. Data flow information captures the set of program variables at each node of the CFG. This data flow information is then used to extract a program slice. At each CFG node the slice consists of those variables that affect directly or indirectly the value of target variable x. In one implementation loops may be ignored without a loss of imprecision due to this approximation. Most extensible software does not have a unique entry point as it is usually designed as a reactive system receiving various requests from plug ins and returning responses. One slicing algorithm implemented accounts for this by considering all paths from any entry point to any update of interest. For example in the case of the Linux kernel there is considered the system call handlers the interrupt handlers and the driver support functions as entry points.

The first invariant reads when v is added to the runqueue v must already be present in task struct. The second invariant reads when t is removed from the task struct variable t must have already been removed from runqueue. Note that there is a free variable in each semantic integrity invariant above i.e. v and t respectively . These free variables represent the value at the point of the update. When the runtime monitor checks an invariant the free variable is replaced with the value of the update to the data structure of interest.

As the state invariant derivation step provides a set of state invariants one for each program path that reaches a location that updates a data structure of interest the semantic integrity profile is constructed by attaching state identification predicates to the state invariants. Each state invariant for a data structure of interest x is associated with the state identification predicate of the form Changed x . For instance the two invariants listed above for the Linux kernel example are converted to the following example semantic integrity profile Changed runqueue runqueue t task struct t Changed task struct task struct runqueue t t 

The semantic integrity profile characterizes a program s execution operations and data structures. Violations of the integrity profile reveal incorrect or malicious behavior of a program or its plugins at run time. It is noted that the semantic integrity profile does not contain any information about the program code or the plugin code. It only lists the invariants that must hold when a change in a data structure is observed regardless of the code that caused the change.

As shown in the runtime monitor component observes all changes to the memory of the monitored program regardless of whether a plugin or the core component changed the memory.

In a related aspect of the invention semantic information from the data of the running software is used to explore informed tradeoffs between acceptable performance penalties and changes in security guarantees. The semantic information includes entry points into the software s data space and dependencies between data elements that are backwards forwards reachable from identified entry points. In one embodiment an algorithm for deriving semantic information from the data proceeds as follows 

1. For each data element e.g. program variable determining the performance penalty incurred by monitoring this data element. This determination may be performed by experimental methods i.e. run the program and monitor various data elements to determine the corresponding performance penalties .

2. For each data element determining using the program SDG for example the other data element that can depend on it.

3. Characterizing the tradeoff between performance penalty and security guarantee based on whether each data element is selected for monitoring or not. If a data element is not selected for monitoring security is decreased because an attack could succeed by undetectably modifying this data element and any elements that depend on it. If a data element is selected for monitoring a performance penalty is incurred.

For example as shown in depicting a problem set up data dependencies are illustrated in graph G V E and set H. Vertex set V includes the application s data elements and edge set E represents dependence relationships among those elements. For example setting H h h . . . h represent the integrity profile of the application an example profile of H is shown by example in . Each element hin H reflects a property that is to be satisfied by d . . . d . The element hcorresponds to an invariant derived over d . . . d or to assert statements or to a formal specification of the data elements etc. Based on the problem set up in one alternate embodiment the set of monitored data elements d s in G V E is reduced and consequently the set of h s defined over those data elements with minimal impact on the security guarantees of the integrity monitoring system while maintaining acceptable run time overheads.

Thus according to a further embodiment as shown in after the data dependencies and program invariants are determined and prior to performing run time monitoring to detect potential breach of a semantic integrity program state a method is performed that implements the following 

At of method there is performed determining the monitoring cost of each entry point and each dependent data element therefrom. This step establishes a baseline measurement of the performance penalty were the system to continuously monitor all data elements while the software is running. Then at an analysis of the monitored data elements for overlap in security guarantees is performed. Given the dependencies between data elements the technique infers the elements that for example are updated in lockstep or are always synchronized or are always constant. Data elements that do not offer overlapping security guarantees become candidate monitoring points. That is two data elements that do not depend on each other according to the program SDG are independent and thus offer distinct non overlapping security guarantees. Each data element is a potential candidate for monitoring. For a given set of data elements the corresponding cost of monitoring i.e. performance penalty is determined by running the program and monitoring exactly those data elements. A monitoring profile is a set of data elements chosen based on its low performance penalty as observed experimentally in one embodiment.

Proceeding to there is next performed analyzing a set of potential monitoring points for overhead under different workloads of interest. While step provides a baseline measurement of the performance penalty in step the performance penalty is considered under custom workloads for specific scenarios e.g. a web application server. An acceptable performance penalty depends from application to application. For example for server software the acceptable performance penalty could be quite low milliseconds per request while for interactive desktop software the acceptable penalty could be much higher up to 1 2 seconds .

Then at there is performed selecting the optimal set of monitoring points considering security guarantees and monitoring overhead. Particularly use is made of the semantic dependency information together with the performance numbers from steps and to derive a balanced monitoring profile comprising a set of data elements chosen based on its low performance penalty in one embodiment.

Referring to step in more detail the cost of monitoring each entry point in the application space and all respective dependent elements is determined. In operation during run time the system performs retrieving the content of specific memory pages where data elements of interest reside each time a write event for example hits an entry point. The penalty incurred by continuously monitoring all data dependencies is considered as a baseline measurement of the integrity monitor performance. In case this penalty is acceptable e.g. server software operates at milliseconds per request no further optimizations are needed. Otherwise step is performed where monitored data elements d s and associated hi s are analyzed for overlap in security guarantees. This step includes implementing a theorem prover or any tool that determines the validity of logical formulas. An example of a theorem prover is the STP Constraint Solver. This theorem prover automatically reasons about data elements d s based on set H and eliminate the hi s associated with redundant data elements from set H. Thus the semantic information is formalized from the data of the running software given the set of properties describing dependencies between d s. The theorem prover s built in rules infer data elements that offer same security guarantees e.g. data elements updated in lockstep correlated or synchronized data elements data elements that are always constant etc. Such inferred data elements are reduced to a minimal set and are added with the remaining elements as candidate monitoring points. Then the h s associated with redundant data elements are eliminated from set H.

Continuing in more detail at the performance penalty PerfWi of potential monitoring point s is are measured under specific workloads that the monitored system is running. Example workloads may include but are not limited to web application benchmarks database benchmarks. Additionally a measure of freqWi the frequency of monitoring the value of dunder workload W is computed. Together PerfWi and freqWi measure the performance penalty and the update frequency for a data element during a program execution on a particular workload with PerfWi being the slowdown in program execution time when monitoring the data element versus an execution without monitoring the data element and freqWi describing how many times a change in the value of data element was observed during its monitoring.

Further at there are defined variables alpha and beta such that a ratio alpha beta is the performance detection accuracy ratio used to specify a balanced monitoring profile specific to the monitored system domain. Values of alpha and beta are determined based on the baseline measurements performed at . In one embodiment for example alpha and beta are parameters determined by a security expert to characterize the desired tradeoff between performance penalty and security guarantees. If the performance penalty is not of big concern beta can take a small value close to 0 . If accuracy i.e. security guarantees is not of big concern alpha can take a large value close to 1 . On the other hand assuming that property h holds true only and only if data elements d s over which it is defined assume authentic values then there is set a variable Acci 1 where Acci denotes the detection accuracy of h when associated data elements are compromised. A heuristic estimate of the cost function C is defined according to freqWi beta PerfWi alpha Acci . where Cis associated with each potential monitored point. Then the performance of the heuristic cost estimate is evaluated by selecting the optimal data set through applying a graph traversal technique to yield a minimum cost path to the entry point in the dependence graph.

In an example embodiment a semantic integrity profile was generated by implementing the analysis on top of a C Intermediate Language CIL i.e. a high level representation along with a set of tools that permit easy analysis and source to source transformation of C programs. In one embodiment to analyze the Linux kernel source code CIL was enhanced with support for assembly code. The static analysis was performed across the whole kernel source code in a path sensitive and interprocedural fashion. In one implementation referring to the secure and guest virtual machines run unmodified copies of Linux version 2.6.24 for the x86 architecture. A hypervisor is used that supported VM introspection such that the security VM can observe the guest VM ss address space. In one embodiment the hypervisor runs on two quad core CPUs each running at 2.66 GHz with 18 GB of RAM for example. A 2.6 GHz CPU and 512 MB of RAM was allocated for the security VM and four 2.6 GHz CPUs and 512 MB of RAM was allocated for the guest VM. The runtime monitor runs as process inside the security VM.

In one embodiment the system and method invention advantageously provides efficient protection of program data during execution by reducing the runtime overhead of providing protection to the intermediate data or state of the program from malicious modification during execution. Further the system and method optimizes the protection of program data during execution and optimizes the monitoring of program data during execution e.g. data processed in memory during the execution of a program by taking into account the semantic relationship between data elements. In one aspect the system and method provides protection of program data during execution in software without hardware extensions.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with a system apparatus or device running an instruction.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of foams including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with a system apparatus or device running an instruction. Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may run entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which run via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks. These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which run on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more operable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be run substantially concurrently or the blocks may sometimes be run in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

