---

title: Graphical partitioning for parallel execution of executable block diagram models
abstract: Exemplary embodiments allow executable graphical models, such as block diagram models, to be graphically partitioned for execution on concurrent computing resources. Embodiments allow model components to be grouped into subtasks that are affiliated with tasks associated with concurrent computing resources. Tasks and sub graphs can be mapped to concurrent computing resources according to characteristics, such as sample time, solver type, etc. Embodiments further allow mappings to be visually indicated to a user via various display techniques including color, text, icons, shading, grouping of identifiers, etc. Concurrently executing portions of a model allows model results to be obtained faster than can be obtained when models are executed on a single computing resource, such as a single processor.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08756044&OS=08756044&RS=08756044
owner: The MathWorks, Inc.
number: 08756044
owner_city: Natick
owner_country: US
publication_date: 20100930
---
The present application claims the benefit of U.S. Provisional Patent Application No. 61 349 002 filed May 27 2010 and the benefit of U.S. Utility patent application Ser. No. 11 141 878 filed May 31 2005 the contents of which are incorporated by reference in their respective entireties.

Various classes of graphical models or graphical programming describe computations that can be performed on application specific computational hardware such as a computer microcontroller field programmable gate array FPGA or custom hardware. Graphical models can be complex and computationally intensive. As a result executing the models in real time may not be feasible in conventional processing environments using a single processing device such as a single core.

The following detailed description of implementations consistent with principles of the invention refers to the accompanying drawings. The same reference numbers in different drawings may identify the same or similar elements. Also the following detailed description does not limit the invention. Instead the scope of the invention is defined by the appended claims and their equivalents.

Exemplary embodiments partition executable graphical models into units that can be mapped onto parallel processing resources and then concurrently processed. For example embodiments can identify model components sharing characteristics such as a sample rate and may group the components together into units e.g. sub graphs sub systems modules etc. . These units may be mapped for processing onto a resource e.g. a core processor thread process etc. that can be separate from another processing resource. In addition the units may further be mapped to be processed in parallel with other units in the model. Concurrent processing of the units may allow a model to be executed in a fraction of the time that it would take if the model were executed on a single processing device using conventional techniques.

Embodiments can allow a user to graphically specify how portions of a model should be partitioned and mapped for concurrent processing. And embodiments can be configured to programmatically partition and map models on behalf of the user. For example programmatic partitioning and mapping of models may be particularly beneficial to users when models are large and or complex.

Embodiments can include user interfaces that allow users to identify how a model is partitioned and mapped concurrent computing resources for processing respective portions of a model parameters for code generated from the model etc. Still further embodiments can provide tools that allow users to verify validate test document publish etc. models that interact with concurrent processing resources.

Embodiments allow graphical models such as executable block diagrams to be configured as parallel deployment diagrams. Diagrams operating as parallel deployment diagrams may include components such as 

Computer may include a device that performs processing operations display operations communication operations etc. For example computer may include logic such as one or more processing or storage devices that can be used to perform and or support processing activities on behalf of a user. Embodiments of computer may include a desktop computer a laptop computer a client a server a mainframe a personal digital assistant PDA a web enabled cellular telephone a smart phone smart sensor actuator or another computation or communication device that executes instructions for performing one or more activities and or to generate one or more results.

Computer may further perform communication operations by sending data to or receiving data from another device such as a server not shown in . Data may refer to any type of machine readable information having substantially any format that may be adapted for use in one or more networks and or with one or more devices. Data may include digital information or analog information. Data may further be packetized and or non packetized.

An embodiment of computer may include simulation environment and operating system . Simulation environment may provide a computing environment that allows users to perform simulation or modeling tasks related to disciplines such as but not limited to mathematics science engineering medicine business etc. Simulation environment may support one or more applications that execute instructions to allow a user to construct a model having executable semantics. In an embodiment simulation environment may execute the model to produce a result.

Models used with exemplary embodiments of the invention may include information in a textual or graphical form. For example a model may be a textual model or graphical model that can be a time based model e.g. differential equation models difference equation models discrete time models or continuous time models with or without algebraic constraints etc. event based model state transition model data flow model component diagram entity flow diagram equation based language diagram etc.

In an embodiment simulation environment can include a component such as a software module that partitions graphical models in a manner that supports concurrently processing the partitions. Simulation environment can further provide user interfaces that facilitate user interactions with respect to graphically partitioning and concurrently executing graphical models.

Operating system may manage hardware and or software resources associated with computer . For example operating system may manage tasks associated with receiving user inputs operating computer allocating memory prioritizing system requests etc. In an embodiment operating system may be a virtual operating system. Embodiments of operating system may include Linux Mac OS Microsoft Windows Solaris UNIX etc. Operating system may further run on a virtual machine which can be provided by computer .

Computer can further include one or more display devices for displaying information to a user. In an embodiment the display may include a cathode ray tube CRT plasma display device light emitting diode LED display device liquid crystal display LCD device etc. Embodiments of the display may be configured to receive user inputs e.g. via a touch sensitive screen when desired. In an embodiment the display can provide one or more graphical user interfaces GUIs to a user. The GUIs may display a model inputs for a model e.g. user specified objectives constraints display characteristics task sub graph mappings etc. model outputs graphical representations of registers representations of tasks representations for concurrent computing resources etc.

Input device may include logic to receive input from a user. For example input device may transform a user motion or action into a signal or message that can be interpreted by computer . Input device can include but is not limited to keyboards pointing devices biometric devices accelerometers microphones cameras haptic devices etc.

Network may include any network capable of transferring data e.g. packet data or non packet data . Implementations of network may include local area networks LANs metropolitan area networks MANs and or wide area networks WANs such as the Internet that may operate using substantially any network protocol such as Internet protocol IP asynchronous transfer mode ATM synchronous optical network SONET user datagram protocol UDP IEEE 802.10 etc.

Network may include network devices such as routers switches firewalls and or servers not shown . Network may be a hardwired network using wired conductors and or optical fibers and or may be a wireless network using free space optical radio frequency RF and or acoustic transmission paths. In an implementation network may be a substantially open public network such as the Internet. In another implementation network may be a more restricted network such as a corporate virtual network. Implementations of networks and or devices operating on networks described herein are not limited to any particular data type protocol architecture configuration etc. For example in an embodiment network may be a quantum network that uses quantum compatible networking protocols.

Target environment may include logic that executes instructions to perform one or more operations. In an embodiment target environment can include registers for storing information and processing logic adapted to concurrently execute code generated from one or more models. In an embodiment target environment can include real time logic for performing processing operations in real time using two or more processing devices threads etc. For example target environment may include a real time operating system and hardware that are configured to process received signals or events in real time or to execute simulations in real time.

Exemplary embodiment of target environment can include FPGAs application specific integrated circuits ASICs application specific instruction set processors ASIPs digital signal processors DSPs graphics processor units GPUs programmable logic devices PLDs etc. Target environments can further include a single processor that includes two or more types of logic such as cores. Target environments can be configured to support multi threaded or multi process applications using FPGAs ASICs ASIPs DSPs GPUs PLDs cores etc.

Distributed implementations may allocate processing activities across two or more cores in a single processing device allocate processing across multiple processing devices installed within a single enclosure and or allocate processing across multiple types of processing logic connected by a network. For example a distributed environment may make remote concurrent computing resources available to computer to allow simulation environment to parallel process portions of a graphical model.

Computer and network may be configured as described in connection with . Service provider may include a device that makes a service available to another device. For example service provider may include an entity that provides one or more services to a destination using a server and or other devices. Services may include instructions that are executed by a destination to perform an operation. Alternatively a service may include instructions that are executed on behalf of a destination to perform an operation on the destination s behalf.

Assume for sake of example that a service provider operates a web server that provides one or more web based services to a destination such as computer . The web based services may allow computer to perform distributed processing on behalf of block diagrams. The web based services may also allow computer to view results of the concurrent processing via a display device. In one implementation a customer user may receive services on a subscription basis.

A subscription may include substantially any type of arrangement such as monthly subscription a per use fee a fee based on an amount of information exchanged between service provider and the customer a fee based on a number of processor cycles used by the customer a fee based on a number of processors used by the customer etc.

Remote database may include a device that stores machine readable information for use by other devices such as computer . In one embodiment remote database may include a data store an array or grid of storage devices e.g. hard disks optical disks solid state storage devices etc. for storing information and or data e.g. variables results models generated code specifications constraints application program interfaces APIs processing configurations etc. Units of execution may include applications that are running on computer e.g. copies of a technical computing environment.

Cluster may include a group of processing devices such as units of execution A B and C that can be used to perform remote processing e.g. distributed processing parallel processing etc. . Units of execution may include hardware and or hardware software based logic that perform processing operations on behalf of a requesting device such as computer . In an embodiment units of execution A B and C may each compute a partial result that can be combined into an overall result and or units of execution A B and C may each compute independent results. Devices in cluster may be configured to support virtual machines and or other techniques for making a plurality of processing resources and or applications available over a network.

Exemplary embodiments can make use of computational elements such as processors cores etc. to process portions of a model. Embodiments can further use computing tasks hereinafter tasks such as operating system threads fibers processes etc. to concurrently process portions of a model. Embodiments can further use methodologies for graphically partitioning a model in a way that supports concurrently processing the model faster than if the entire model were processed using a single computational element or task. For example a first methodology can separate a model design into components where the components are coupled together using signal interconnections. Component boundaries can indicate potential points at which the design can be broken into a separate section or partition. In the first methodology respective sections may be deployed to different concurrent computing resources.

Still referring to the first methodology a component can contain a piece of the original block diagram. This diagram piece can include one or more sub graphs where each sub graph in a time based diagram is intended to run at a specified sample time or rate. In the first methodology the block diagram portion within a component may be viewed as being partitioned into sub graphs where each sub graph is contracted to run at a specific rate. This arrangement may be referred to as rate grouping sub graphs and the sub graphs may be considered to be rate grouped sub graphs.

Sub graphs within a particular component may be configured to facilitate concurrent execution using concurrent computing resources. For example if a model includes two components each including a sub graph the components may be configured for concurrent processing using two cores residing in computer . This configuration may allow a model to execute faster than if the entire model were executed using a single core.

A second methodology may include a graphical technique that allows two or more computing elements or tasks to be represented collectively as a task group. In the second methodology a task group can contain tasks that execute synchronously in time based on a single triggering condition such as an event a time etc. For example a triggering condition can include an interrupt from a timer running on a multi core platform an interrupt from an external source such as an external timer circuit interrupt from an external physical source such as the detection of rotation of shaft in an automotive system etc.

A task group further allows specification of task and task group properties useful for scheduling the running of computing resources. For instance each task may be associated with a priority that allows the scheduler to determine execution order. Tasks can also be associated with policies such as tie breaking policies that handle situations where two tasks of identical priority contend for execution. In an embodiment parameters can be used to specify properties for tasks. For example two sets of parameters may be used within a task group to specify task properties. Here a first parameter or a first set of parameters can apply to an entire task group and a second parameter or set of parameters may apply to individual tasks in the group. Examples of a first parameter can include an interrupt source and a contention policy and a second parameter can include timing of execution priority and core affinity.

Model may be considered to include three primary sections namely user inputs to plants the plant which is made up of plants and and the controller which is made up of controllers and . The three sections of model may be allocated to concurrent computing resources to speedup simulation as compared to simulating on a single resource during model design or for real time hardware in the loop HIL simulation setup. In model the plant and the controller are broken into two portions respectively to further exploit parallelism. For example the plant is broken into plant section and plant section . In embodiments sections can be referred to as partitions portions sub graphs etc. without departing from the spirit of the invention.

Plants and each contain a continuous time section and two distinct discrete time sample time sections having sample times of 0.01 sec and 0.001 sec . In these sections form the basis for breaking plants and into 3 different sub graphs. Sections or sub graphs in model may be denoted using icons such as continuous identifier and sample time identifiers and . For example sample time identifiers can represent a first fast sample time of 0.001 sec identifier a second fast sample time identifier of 0.001 sec identifier and a slow sample time identifier of 0.01 sec identifier . Other implementations can use other types of identifiers such as symbols text highlighting shading fading etc. for denoting sections of a model.

Continuous component can be used to model the dynamics of the plant as a set of ordinary differential equations. Solving the set of equations numerically may require executing a solver of a certain type. For example model may use a fixed step or variable step solver. Model may further use solvers that employ Euler s method Heun s method Bogacki Shampine formula Runge Kutta formula Dormand Prince formula etc.

Discrete components such as components and may reside in none some or all sections of a model. For example plants and may share sample times with controllers and such as sample times of 0.01 sec and 0.001 sec. The sample times between plants and controller may match even though identifiers differ in appearance. For example plants include fast identifier and controllers include fast identifier even though both identifiers represent a sample time of 0.001 sec. The different identifiers may be selected to represent distinct concurrent computing resources on which respective portions of model will be run.

Model may include eleven sub graphs i.e. one for each identifier in each subgraph . In model the sub graphs may be generated based on an assumption that the different sub graphs can be run concurrently. In an embodiment the assumption may account for communication between the sub graphs within a component while the model executes. For example an embodiment may assume that communications between sub graphs are protected by rate transition blocks or other mechanisms.

In task group a first task is marked as corresponding to the continuous time section of the model and is represented using identifier . A task corresponding to identifier and representing the continuous time section may ultimately contain a numerical solver that solves the underlying differential equations. When an implementation is configured to solve equations in real time model may utilize a class of solvers known as fixed step solvers. Fixed step solvers can produce solutions of the set of differential equations at fixed time steps and can be mapped to tasks that have a fixed execution period. In model the fixed step solver has a period of 0.0001 sec and is indicated in parenthesis in task group .

In contrast to the continuous task of task group the remaining three tasks are discrete task and are marked as having execution periods of 0.01 0.001 and 0.001 sec using identifiers and respectively. This nomenclature implies that there are two compute elements that execute concurrently at the same rate of 0.001 sec namely those associated with identifier and .

Exemplary embodiments may allow users to enter information related to tasks via user interfaces. In an embodiment a user may select an element of by double clicking on the element. In response to the selecting operation a user interface may open and may be displayed to the user via a display device. In another embodiment a user may make a selection from a drop down menu to access the user interface. In still other embodiments other techniques may be used to launch and access user interfaces such as speech touch sensitive input devices textual interfaces e.g. a command line interface etc.

Task buttons allow a user to create or delete tasks. In an embodiment selecting insert task may insert a row for a task and selecting delete task may delete a row for a task. UI may include an arrangement of information in which each row corresponds to a task such as a continuous task which is indicated using identifier . Tasks can be described using characteristics or parameters such as color name execution period priority and or core affinity. Other embodiments can include additional or fewer characteristics and or parameters depending on user preferences specific parallel platform s etc. Still further other embodiments can employ application programming interfaces APIs which may allows users to script the entry of task information into computer .

Color field may indicate colors used to represent identifiers that reference units into which a model is broken. For example color field may identify colors used to identify sub graphs making up model . The continuous sub graph may be a first color the fast sample time sub graphs may be a second color and the slow sample time may be a third color. In another embodiment the fast sample time sub graphs may be different colors. Other embodiments may further use shading or other techniques for identifying sub graphs or sub graph identifiers.

Name field may include information identifying a sub graph in model . Period identifier may include information identifying sample periods or sample times for sub graphs in model . Priority identifier may include information identifying an execution priority for a sub graph in model a concurrent computing resource etc. Core affinity identifier may identify a processing core a processing device a thread a task etc. on which a sub graph is run. Action buttons may provide a user with access to commonly used functionality such as saving selections canceling selections accessing help resources and applying changes to concurrent computing resources model etc.

Embodiments allow users to identify sub graphs that are unmapped with respect to tasks residing in task group . For example in all sub graphs include a fill color shading or other type of visual identifier that indicates that the respective sub graph is mapped to a task in task group . Embodiments may not fill shade a sub graph identifier until the sub graph identifier is mapped to a task. This approach may allow users to quickly identify sub graphs that are unmapped and therefore will not execute on a current computing resource when a model is simulated.

In an embodiment sample time identifiers such as numbers may be displayed for a sub graph identifier when the identifier is unmapped with respect to a task. When the respective sub graph is mapped the sample time identifier may be replaced with a color a shading pattern or some other type of visual identifier that indicates the sub graph has been mapped to a task. Mapping a sub graph to a task may ensure that the sub graph is allocated to a concurrent computing resource when model is simulated.

Embodiments may employ mapping techniques that enforce desired constraints. For example a mapping tool may prevent mapping of sub graphs whose sample times do not exactly match the rate of execution of the task. Alternately the mapping may allow mapping of sub graphs with a different rate as long as the sample time of the mapped sub graph is a multiple of the task execution period.

Move field may include information that indicates a task on which a sub graph will run. In an embodiment drop down menus may provide a user with available selections about tasks and or whether a sub graph will be executed in a batch mode. Initially move field may be unpopulated and a user may manually populate entries in field . In another embodiment entries in field may be programmatically populated with initial configurations and a user may vary the configurations when desired. UI may include a batch move button that allows the user to move sub graphs associated with a batch mode as a group.

By way of example and referring to sub graphs mapped to a respective task are listed in a separate column with the name of a component and sample time. Additionally unmapped sub graphs are shown as being associated with a special unmapped task. Field may include fields having a pull down menu with task names that allow users to pick which task a specific sub graph should be moved into. For example sub graphs User Controls 0.01 Plant Section 0.01 Controller Section 0.001 are being setup to move to tasks Slow Fast and Fast respectively. Field may further allow users to remap sub graphs from one task to another. In an embodiment UI may be configured in a manner such that only tasks suitable for receiving items are presented in the Move to task pull down menu. For instance the pull down may only show tasks having a same period that matches a sample period of a corresponding sub graph. In sub graphs are indicated using textual names associated with the icons of the respective components.

Exemplary embodiments may allow users to specify mapping arrangements directly on a block diagram model. illustrates model which can be configured to allow a user to map sub graphs to tasks by selecting a sub graph and dragging the sub graph to a location in task group . A user may select sub graph identifier using a pointing device and may drag identifier along path . The user may drop identifier proximate to task identifier and identifier may change appearance to resemble task identifier . The change in appearance of identifier may indicate that the sub graph having an execution period of 0.01 sec is mapped to a task having an execution period of 0.01 sec.

A user may also select task identifier and may drag identifier along path and may drop identifier proximate to unmapped identifier in component . Identifier may change appearance after the drag drop operation to resemble task identifier . The resemblance may indicate that identifier of component is mapped to task identifier . The embodiments of may include help windows and that can provide a user with information or instructions regarding an operation to be performed or with respect to an operation that has been performed. In an embodiment paths and may remain displayed on UI and help windows and may be accessed by hovering a cursor for a pointing device over one of the displayed paths. UI may provide an error indication when a user performs an unauthorized operation such as attempting to mis associate a task with a sub graph.

In an embodiment user interface may be built on top of a get param API of a graphical modeling environment such as Simulink environment. In an embodiment the mapping may be expressed as map get param TaskMappingTable . When a table exists the map may appear as an object that behaves like an object implemented using for example the MATLAB object oriented class system. In an embodiment a user may assign a component s sub graph specified by for example component name sample time to a task specified by its name which may be map.mapSub graphToTask . A programmatic API such as API may allow users to script the entire mapping process and or to explore a design space iteratively. This interactive mapping can include performing a mapping executing the design gathering performance data adjusting the mapping based on the performance data and then refining the mapping for a subsequent iteration.

The task transition property tab may include an entry for specifying a task transition type . In an embodiment a drop down menu may include acceptable selections for task transition type . When a user is satisfied with a configuration of user interface the user may select OK via buttons .

When sub graphs have been mapped to tasks signals in the model may satisfy two use cases when the model is executed. A first use case may occur when the signal facilitates communication between sub graphs that are mapped to the same task. A second use case may occur when a signal facilitates communication between sub graphs that are mapped to separate tasks. In the first case communication may behave as a regular signal in a time based block diagram. In the second case users may want flexibility to change between different forms of communication based upon the requirements of a design. Embodiments allow a model canvas to provide the ability for a user to specify communication modes for signals using both graphical user interface methods and a programmatic API.

By way of example a user can select a signal that represents the second case above and may be presented with a specified UI dialog shown in . Dialog provides users with the ability to default to options including but not limited to 

Other embodiments can allow a user to access the functionality indicated in a e above using APIs if desired. For example when using the Simulink environment a user may use a programmatic API such as set param to a property that is displayed in dialog . With respect to a global overrides dialog allows a user to specify global override settings for all task communication in a model. Allowing use of a global override may prevent users from having to click on each signal and then individually configure the signals. Embodiments may allow users to specify global settings for communication between tasks from different task groups and communication between tasks of the same task group as shown in .

Embodiments may support the use of special markup graphical elements that help users visualize specific communication modes of the signals in a model. illustrates an embodiment that makes use of graphical elements for helping a user understand signal communication modes in a model. In model line styles are used to indicate whether sub graphs mapped to the same task share communication or whether sub graphs mapped to different tasks share communication. Line style indicates the condition where two sub graphs communicate and are mapped to a single task. Line style indicates the condition where two sub graphs communicate and are mapped to separate tasks.

Model may further include techniques for indicating other communication aspects. For example model can include graphical identifiers that indicate communication modes b d described above page 23 . Model may include the identifiers on reading communication ports or writing communication ports. Identifier can indicate case b and the identifier can include textual identifiers such as D residing within the graphical identifier. Case c can be indicated using identifier . This identifier may include two shapes abutting each other. Case d may be indicated using identifier and may include a single rectangular identifier.

Communication modes b through d described above are shown using special markings on the respective writing and reading communication ports. Case a can map to one of the other cases b d on the basis of the setting of the global override and mode and case e is may be a degenerate case and is not further discussed herein.

Embodiments may allow users to inspect models once sub graph to task mappings have been performed. The use of a task color shading fill pattern etc. in a sub graph that is mapped to the task may inform a user about the relationship. For example this technique may show the user how a block diagram is segmented across a concurrent computing resource. This is illustrated in where there are only 4 colors in the entire canvas. Embodiments allow users to visualize exactly how the diagram is divided across the tasks.

Embodiments may also allow a user to interact with model components to identify sub graphs mapped to a specific task. illustrates a model that allows a user to select an affordance to determine which sub graphs are mapped to a task. In model a user may select identifier in task group . In identifier may include an affordance that can be toggled between an OFF state and an ON state. An ON state for affordance may include displaying an X within the affordance to indicate a selection.

When affordance is selected sub graphs mapped to the selected task may be indicated to the user. For example sub graphs may be shaded with a color that is substantially identical to a color of identifier . Model components that include respective sub graphs may be colored shaded or otherwise manipulated to indicate that a sub graph within the component is mapped to a task. Embodiments may allow a user to highlight sub graphs that execute at a specific period by using multiple selections of tasks as illustrated in . For example a user can select affordance and and sub graphs associated with the respective tasks may be highlighted or identified using other techniques.

A model or block diagram canvas can also be used to visualize different properties corresponding to tasks or sub graphs that are overlaid on the canvas. illustrates a model that uses visual techniques to identify task execution periods. For example identifier for task may be a first color such as blue. Lines going to an input port or an output port of a component having a sub graph associated with task may be the same color as the shading for task namely blue.

In lines may be colored blue to correspond with the coloring of task identifier . Lines associated with other tasks may be displayed in colors that differ from the color of lines . For example lines associated with tasks having a period of 0.001 sec may be colored red and may be indicated by lines . Tasks and may have a period of 0.001 sec and may also be red. In task identifier and task identifier may be red to allow a user to determine that lines go with task and task .

Embodiments may also allow core affinities task priorities and other types of task or sub graph characteristics to be indicated using colors. Embodiments may further employ color overlays to identify combinations of information and or other relationships. For example an embodiment can overlay the task color and task execution period as two separate colors on each sub graph and or task identifier to communicate multiple pieces types of information to a user simultaneously. Other embodiments may use numbers text shading patterns differing icons etc. to for example handle situations where tasks may be too numerous to allow for visual contrast using colors and or to accommodate users having color blindness.

Embodiments provide users with convenient interfaces and techniques for graphically mapping sub graphs to tasks and for specifying communication modes among the sub graphs and tasks. A model may be ready for simulation once the user has mapped sub graphs to tasks and addressed communication issues. For example the user may execute the model using specified concurrent computing resources. A user may perform concurrent processing using a single device having multiple processing resources residing therein or the user may employ separate concurrent computing resources that simultaneously perform operations to simulate the model.

Embodiments may allow models to be simulated in an interpretive fashion on a simulation platform that may be employed to build the model. For example a simulation environment such as the Simulink environment may provide interpreted simulation capabilities. In this example tasks specified in a task group may become specific compute elements such as a thread on a target platform. A thread may then execute sub graphs mapped to the thread using an interpretive mode. In this embodiment threads may execute concurrently in accordance with specified parameters such as priority and scheduling policies that might affect thread scheduling.

Embodiments may further generate code configured for execution on a specified concurrent computing resource such as a parallel platform. For example code may be generated for each task. In an embodiment the code for a task can be generated as a thread on the target platform. Here the threads may be part of an application that is compiled and executed on the parallel target.

Embodiments can be configured such that code generated for each sub graph mapped to a task that executes on a parallel target is the same as code generated for use on non parallel targets. In this configuration the specialization that supports parallel targets may consist of code for communication between sub graphs mapped to different tasks.

By way of example the base rate thread posts semaphores for the two 0.001 s threads every 10 times it runs because 10 0.0001 s 0.001 s . In a Simulink environment this can be performed by calling rtmStepTask that determines whether a semaphore should be posted for the specific thread to run. Additionally the base rate thread calls the function AdvanceTaskCounters which updates counters that help the base rate thread determine how the threads operating at different periods should execute.

In the embodiment of the code for each thread executes the sub graphs that are mapped to that task. illustrates code for each of the 4 threads. In the Simulink environment sub graph functions that each thread calls can funnel into the function PlantControllerModel step shown in via code portion . The function of may in turn dispatch to four separate step functions one of which is shown in the righthand portion of via code portion . The function of includes calls to the individual sub graphs mapped to the thread. does not illustrate code for the body of each sub graph to simplify presentation.

Code for the embodiments of and may be produced using APIs that allow specific target platforms to produce desired code for tasks. These APIs can allow a custom parallel target to take functions generated by a code generating product such as for example Real Time Workshop and produce threads illustrated in and .

Embodiments may use deployment diagram specific target language compiler TLC APIs to provide classes of information. For example classes of information can include 

An exemplary API can be based on the TLC language provided by the MathWorks and can include the following TLC functions to get the three classes of information identified above. For example the following TLC function can be used 

APIs through above may be reflections of information that users have entered on a canvas for sub graphs task groups tasks task sub graph mappings etc. An exception can occur with API above which can emit the calls highlighted in within each thread. Embodiments may enable emitting these calls by having a block diagram engine compile the diagram and determine the ordering of sub graph calls within the thread. This ordering is produced for example in the Simulink environment by using the direct feed through setting of individual signals connecting sub graphs across model components. For example the direct feed through setting allows the block diagram engine to sort the individual sub graphs in the order of their data dependencies. As an example the body of function PlantControllerModel step illustrated in is generated by the API.

In addition to generating code for the appropriate compute elements such as threads authors of custom targets can specify correct target specific implementations for the communication modes between sub graphs on different tasks. The various communication modes are generally realized by using target specific implementations of mutual exclusions mutex and semaphores.

Similarly illustrates how communication of the form ensure data integrity only between two sub graphs with identical sample times mapped to different tasks with the identical execution periods can be implemented using mutexes on an Intel target running the Linux operating system using POSIX standard . The mutexes conceptually prevent a read of partially written information from happening when the write operation is in process. This embodiment can also prevent writing data when a read process is operating.

Referring to the blocks may be inserted on the write and read side respectively of communication lines between the sub graphs and . In an embodiment blocks and may be inserted into model and may be written using an S function interface as provided in the Simulink environment. In the S functions are further configured to have communication that ensures data integrity. For example a user can implement an S function by writing code of the form illustrated in for the read and write side. Code portion includes the mdlOutputs function of the S function which performs the appropriate mutex operation based on whether the operation is writing or reading data.

Code portion can be used to derive a TLC implementation for the blocks. The TLC implementation may be provided via code portion of . Code portion can be a file and the TLC file may ensure that appropriate mutex code of the form shown in is emitted by a block during code generation. The example of and B and A and B dealt with a specific communication mode however other communication modes can be realized using the process discussed above or variations of the process discussed above without departing from the spirit of the invention.

Exemplary embodiments have been discussed in context of examples including a single task group within the deployment diagram. Concepts and examples discussed herein can be applied to implementations including multiple task groups within a diagram where each task group can have distinct properties with respect to other tasks in the diagram. For example tasks can have differing interrupt sources that generate a trigger for underlying tasks the scheduling policy of tasks etc.

Model can include a component controller that can include two function call signal inputs alarm f and alaram g . In model input and input can be marked as function calls triggered in an aperiodic fashion. Controller can include a function call subsystem that is an aperiodic sub graph. A user can map the aperiodic sub graphs to task groups explicitly by for example drawing unique identifier lines from task group blocks to the function call inputs on the controller as illustrated in . When model is executed interpretively or using generated code a target specific binding of respective sub graphs to compute elements e.g. concurrent computing resources can be performed as previously described in connection with a single task group.

In some implementations a user may wish to target a model design to more than one target platform that employs concurrent computing resources. By way of example a user may wish to explore mapping on both a 4 core platform and an 8 core platform to compare their performance in terms of speed power consumption cost etc. Exemplary embodiments may allow the user to simultaneously compare different target platforms with respect to one or more models.

In an embodiment a user can create a new mapping and then toggle to the mapping. When this occurs a model may default back to a single task group block having a default configuration. The user may perform a new mapping of sub graphs to tasks using techniques described herein. Embodiments may further allow the user to configure communication between sub graphs that pertain to the new mapping. When the user toggles to a different mapping currently active mapping information e.g. all task groups their mapping to sub graphs sub graph communication modes etc. is saved away and the task groups and corresponding mapping information may switch to the toggled mapping.

In certain situations a user may wish to solve differential equations using a solver when for example modeling a plant controller. The user may need to break the modeling problem into pieces and may need to operate on the pieces simultaneously to obtain solutions of the equations within a determined time interval. Each piece may be a compute element that is operated on to produce a solution. Embodiments may assist the user with solving pieces of a model simultaneously by introducing some approximations into communication between the compute elements running the solver.

By way of example consider the case in which the communication occurs in minor time steps of the solvers. In this case the communication method is designed to be mathematically modeled by a delay in which the delay value is equal to the fixed step size of the fixed step solver. During simulation a user may use a single fixed step solver e.g. one employed in the Simulink environment such that the communication link is replaced by the Simulink environment s transport delay block i.e. a delay value equal to fixed step size .

For parallel execution an exemplary implementation can include one solver instance for the first compute element C and another solver loop for the second compute element C . In one implementation the solver loop may be implemented by producing two instances of the original single fixed step solver. One instance is for C the other is for C .

The implementation may further consist of for example a Simulink S Function block in C which determines that the signal is communicating.

In the j th major step the S Function uses a buffer to record intermediate values of the observed signal V v t v t h 2 v t h in which y denotes the observed signal h is the fixed step size and v t is and approximation of y t which may be obtained by interpolation or extrapolation such as the algorithm used by the Transfer Delay block of Simulink . This vector of values is written to a shared double buffer.

The implementation further consists of a Simulink S Function block in C which determines the vector of values Vin the j th time step by reading from the double buffer. Consequently within C we may now use these values to solve a differential equation Eq. 1 by first computing the coefficients Eq. 2 2 2 2 2 Eq. 3 2 2 2 2 Eq. 4 2 Eq. 5 and such that the solution of z t is given by the 4 th order Runge Kutta method as 1 6 1 2 2 2 3 4 for each 0 1 2 Eq. 6 

With respect to the above example it is noted that the solution identically matches the solution as if a single solver were used in which the communication delay is a mathematical model of a delay.

In the example above the shared double buffer was assumed to be configured to ensure deterministic transfer independently of implementation . The shared double buffer may also be configured for ensure data integrity only in which case the delay model depends on implementation.

The quality of the approximation is determined by how well the computed signal v t approximates the true signal y t . In general this is achieved by using extrapolation methods which perform better by using more memory longer history of the true signal . In the extreme case the extrapolation may be reduced to use only major step data which may reduce the quality of the approximation but improve 1 the amount of memory required to computed the approximation e.g. use less memory and 2 the amount of memory required for communication. In an implementation these tradeoffs may be parameterized by allowing the user to specify a buffer size which would be used by the S Function in C similar to the way the Transport Delay block of Simulink specifies a buffer size .

Processing logic may include a processor microprocessor or other types of processing logic e.g. FPGA GPU DSP ASIC etc. that may interpret and execute instructions. For an implementation processing logic may include a single core processor or a multi core processor. In another implementation processing logic may include a single processing device or a group of processing devices such as a processing cluster or computing grid. In still another implementation processing logic may include multiple processors that may be local or remote with respect each other and may use one or more threads while processing.

Main memory may include a random access memory RAM or another type of dynamic storage device that may store information and instructions for execution by processing logic . ROM may include a ROM device or another type of static storage device that may store static information and or instructions for use by processing logic . Storage device may include a magnetic solid state and or optical recording medium and its corresponding drive or another type of static storage device that may store static information and or instructions for use by processing logic .

Input device may include logic that permits an operator to input information to the entity such as a keyboard a mouse a pen a touchpad an accelerometer a microphone voice recognition camera neural interface biometric mechanisms etc. In an embodiment input device may correspond to input device .

Output device may include a mechanism that outputs information to the operator including a display a printer a speaker a haptic interface etc. In an embodiment output device may correspond to display device coupled to computer . Communication interface may include any transceiver like logic that enables the entity to communicate with other devices and or systems. For example communication interface may include mechanisms for communicating with another device or system via a network.

The entity depicted in may perform certain operations in response to processing logic executing software instructions stored in a computer readable storage medium such as main memory . A computer readable storage medium may be defined as a physical or logical memory device. The software instructions may be read into main memory from another computer readable storage medium such as storage device or from another device via communication interface . The software instructions contained in main memory may cause processing logic to perform techniques described herein when the software instructions are executed on processing logic. Alternatively hardwired circuitry may be used in place of or in combination with software instructions to implement techniques described herein. Thus implementations described herein are not limited to any specific combination of hardware circuitry and software.

Although shows exemplary components of the entity in other implementations the entity may contain fewer different or additional components than depicted in . In still other implementations one or more components of the entity may perform one or more tasks described as being performed by one or more other components of the entity.

The task group may be displayed via a task group component such as task group act . Tasks in the task group may be mapped to compute elements that perform parallel processing of the model when the model is executed act . Embodiments may graphically map tasks to compute elements via user inputs or may use APIs that support programmatic mapping operations. Embodiment can further map tasks to compute elements in a number of ways such as mapping a single task to a single compute element or mapping two or more tasks to a compute element.

Sub graphs may be identified using a user input or programmatically act . For example a user may select a number of model components such as blocks and may graphically group the blocks into a sub graph having a determined sample rate e.g. 0.001 s . The user may perform this operation for other blocks in the model to create additional sub graphs. Sub graphs may be mapped to tasks in the task group act . Embodiments may allow users to map sub graphs to tasks using keyboard inputs drag and drop operations user interfaces scripts etc. Embodiments may further map sub graphs to tasks programmatically using one or more programmatic APIs.

A determination may be made as to whether code should be generated for the model act . When code is not generated concurrent computing elements may be accessed by the model act . The accessed concurrent computing elements may execute tasks when the model is executed act . A concurrent computing result may be produced when the model is executed act .

In contrast when code is generated for the model act concurrent computing elements may be accessed once the code is generated act . The generated code may be executed on the concurrent computing elements act and a concurrent computing result may be produced using the generated code act . In some embodiments generated code may be configured to run on a target environment such as an embedded system that employs two or more processing devices threads etc.

Implementations may allow users to interactively design configure and execute graphical models using concurrent computing resources.

The foregoing description of exemplary embodiments of the invention provides illustration and description but is not intended to be exhaustive or to limit the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practice of the invention. For example while a series of acts has been described with regard to the order of the acts may be modified in other implementations consistent with the principles of the invention. Further non dependent acts may be performed in parallel.

In addition implementations consistent with principles of the invention can be implemented using devices and configurations other than those illustrated in the figures and described in the specification without departing from the spirit of the invention. For example devices and or entities may be added and or removed from the implementations of and depending on specific deployments and or applications. Further disclosed implementations may not be limited to any specific combination of hardware.

Further certain portions of the invention may be implemented as logic that performs one or more functions. This logic may include hardware such as hardwired logic an application specific integrated circuit a field programmable gate array a microprocessor software or a combination of hardware and software.

No element act or instruction used in the description of the invention should be construed as critical or essential to the invention unless explicitly described as such. Also as used herein the article a is intended to include one or more items. Where only one item is intended the term one or similar language is used. Further the phrase based on as used herein is intended to mean based at least in part on unless explicitly stated otherwise.

Headings and sub headings used herein are to aid the reader by dividing the specification into subsections. These headings and sub headings are not to be construed as limiting the scope of the invention or as defining the invention.

