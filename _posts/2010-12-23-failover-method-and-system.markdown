---

title: Failover method and system
abstract: Method and system is provided for performing a failover operation during which a second storage system takes over the management of a storage volume managed by a first storage system. The first storage system may also manage a plurality of replicated copies of the storage volume and maintain metadata for storing information regarding the replicated copies. The failover operation is completed without having the second storage system read all the metadata.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08380954&OS=08380954&RS=08380954
owner: Netapp, Inc.
number: 08380954
owner_city: Sunnyvale
owner_country: US
publication_date: 20101223
---
Storage systems are commonly used for a variety of purposes such as providing multiple users with access to shared data backing up data and others. Various forms of storage systems are used today. These forms include network attached storage NAS systems storage area networks SANs direct attached storage DAS and others.

A storage system typically includes at least one computing system may also be referred to as a server or storage server which is a processing system configured to store and retrieve data on behalf of one or more client computing systems clients at one or more storage devices. Multiple storage systems may be provided to take over operations of a failed storage system when an error event may also be referred to as a failover event occurs.

Conventional systems replicate storage volumes storage space. The replicated copies are managed by a storage system that stores a data structure for describing the replicated copies. If the storage system fails then a failover operation is initiated. Before the new storage system can take over the failed storage system it reads the data structure for various replicated copies. If there are a large number of replicated copies then the failover operation slows down because the new storage system has to read the data structure for all the replicated copies describing the replicated copies. Continuous efforts are being made to efficiently execute a failover operation for continued client access to storage devices.

In one embodiment a method and system is provided for performing a failover operation during which a second storage system takes over the management of a storage volume managed by a first storage system. The first storage system may also manage a plurality of replicated copies of the storage volume. The replicated copies may be referred to as snapshots . The first storage system also maintains metadata regarding the snapshots.

In conventional systems to complete the failover operation the second storage system typically reads metadata for all the snapshots. This delays completion of the failover operation and hence is undesirable.

The method and system disclosed herein completes the failover operation and presents the storage volume to clients without reading the snapshot metadata. The second storage system reads the metadata when an input output request for a particular snapshot is received after the failover operation has been completed. By reading the metadata on as need basis the failover operation is completed earlier.

In another embodiment a machine implemented method is provided. The method includes initiating a failover operation for transferring control of a storage volume from a first storage system to a second storage system. The storage volume representing a segment of storage space at a storage sub system is replicated at a point in time and stored with a data structure having information regarding the replicated copy. The method transfers control of the storage volume to the second storage system that present the storage volume to a client without reading the data structure and accesses the data structure after the failover operation when needed.

In yet another embodiment a machine implemented method is provided. The method includes configuring a storage volume to be managed by a first storage system and in case of an error event be managed by a second storage system after a failover operation passing control of the storage volume from the first storage system to the second storage system without accessing metadata describing a replicated copy of the storage volume that is generated by the first storage system and accessing the data structure in response to an input output request received by the second storage system to access the replicated copy wherein the second storage system accesses the data structure to respond to the input output request.

In another embodiment a machine implemented method is provided. The method includes presenting a storage volume to a client in response to a failover operation without accessing a data structure that describes a replicated copy of the storage volume. The replicated copy and the data structure is generated by a first storage system and the storage volume is presented by a second storage system that is configured to take control of the storage volume after a failover event. The method further includes accessing the data structure in response to an input output I O request to access the replicated copy and the second storage system accesses the data structure to respond to the I O request after the failover operation.

In yet another embodiment a system is provided. The system includes a first storage system for managing a storage volume via a primary path and a second storage system configured to control the storage volume and presenting the storage volume to a client via a secondary path in response to a failover operation without accessing a data structure storing information regarding a replicated copy of the storage volume.

This brief summary has been provided so that the nature of this disclosure may be understood quickly. A more complete understanding of the disclosure can be obtained by reference to the following detailed description of the various embodiments thereof in connection with the attached drawings.

As a preliminary note the terms component module system and the like as used in this disclosure are intended to refer to a computer related entity either software executing general purpose processor hardware firmware and a combination thereof. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer.

By way of illustration both an application running on a server and the server can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers. Also these components can execute from various computer readable media having various data structures stored thereon. The components may communicate via local and or remote processes such as in accordance with a signal having one or more data packets e.g. data from one component interacting with another component in a local system distributed system and or across a network such as the Internet with other systems via the signal .

Computer executable components can be stored for example on computer readable media including but not limited to an ASIC application specific integrated circuit CD compact disc DVD digital video disk ROM read only memory floppy disk hard disk EEPROM electrically erasable programmable read only memory memory stick flash memory device or any other non volatile memory device or any other storage device in accordance with the claimed subject matter.

In one embodiment a method and system is provided for performing a failover operation during which a second storage system takes over the management of a storage space or storage volume managed by a first storage system. The first storage system may also manage a plurality of replicated copies of the storage volume. The replicated copies may be referred to as snapshots . The first storage system also maintains metadata for storing information regarding the snapshots.

In conventional systems to complete the failover operation the second storage system typically reads all the metadata for all the snapshots. This delays completion of the failover operation and hence is undesirable.

The method and system disclosed herein complete the failover operation and presents the storage volume to clients without reading the snapshot metadata. The second storage system reads the metadata when an input output request for a particular snapshot is received after the failover operation has been completed. By reading the metadata on as need basis the failover operation is completed earlier.

In this example storage system operates as a primary storage system for managing storage space within a storage sub system via a primary path may also be referred to as path . Storage system may manage its own storage sub system via a primary path may also be referred to as path .

Storage system may also be operationally coupled to storage sub system via a secondary path may also be referred to as path . The secondary path becomes active when storage system has to take over the management of storage sub system in case there is an error which makes storage system inoperable or for any other reason. The operation by which the storage system takes over storage sub system is referred to as a failover operation the details of which are provided below.

Storage system may also be operationally coupled to storage sub system via a secondary path may also be referred to as path . Secondary path becomes active during a failover operation if storage system has to take over the management of storage sub system

The storage systems and may be operationally coupled to a plurality of clients through a network . Each client may be for example a conventional personal computer PC workstation or the like. The network may be for example a local area network LAN a wide area network WAN a storage area network SAN or any other type of network or a combination of networks. Storage system typically receives and responds to various read and write requests from clients directed to data stored in or to be stored at storage sub system . Storage system performs similar functions with respect to storage sub system

Also connected to the network is a management console that may store and execute a management application may also be referred to as a storage management application . The management console may be for example a conventional PC a workstation or the like.

The processor executable management application may be used by an administrator to configure and manage a pool of storage devices and various components of system . Management application may also be used to generate a data structure that may be used to enable and disable failover operations.

Data structure may include various sub components for example path identifier path components enable failover indicator and disable failover indicator . During a configuration process step an administrator using management application may use path identifier to identify paths and as primary paths and paths and as secondary paths. Management application may discover the paths by sending topology discovery packets to various components of system . The nature and format of the packets will depend on a protocol type. For example the discovery packets may comply with Fibre Channel InfiniBand or any other protocol that is used for communication within system .

Path components is used to identity the components within paths and . The components may be network adapters storage adapters switches or any other component that is used by the paths to transmit information.

Enable failover indicator is set by management application to enable failover under certain conditions. The condition types may vary and may include certain error types. The details of when a failover operation is initiated is not germane to the embodiments disclosed herein and may vary from one storage environment to another.

When indicator is set and if failover conditions are met then secondary path is activated. This allows storage system to take over storage sub system . Secondary path may also be activated in the same manner.

Disable failover indicator may be used to disable a failover operation. If disable failover indicator is set then secondary path is not activated even if the failover conditions are met.

It is noteworthy that the two indicators and may be set by setting a particular value for a single bit. For example a bit value of 1 may mean that failover is enabled and a bit value of 0 may indicate that failover is disabled. These are examples of enabling and disabling failover and are not to be construed as limiting to the disclosure herein.

Data structure is accessible to management application and may be stored at a memory that is local to management console or remote to management console . In another embodiment data structure may be generated and maintained by any other module for example operating system or any other application.

The management application includes a graphical user interface GUI module not shown to generate a GUI e.g. for use by an administrator on a display device not shown . The GUI may be used by an administrator to configure and set various parameters for example to enable or disable failover. In another embodiment the management application may provide a command line interface CLI for use by an administrator for managing and configuring various components of system .

Management application is configured to communicate with operating system and different components of system to obtain information regarding various components for example to generate data structure . To obtain such information communication between the management application clients and storage systems and may be accomplished using any of the various conventional communication protocols and or application programming interfaces APIs the details of which are not germane to the technique being introduced here. This communication can be done through the network or it can be via a direct link not shown between the management console and storage systems and

Storage sub system includes a plurality of mass storage devices for storing information that may be configured to operate in different configurations for example RAID configurations. The mass storage devices may be for example tape drives conventional magnetic disks optical disks such as CD ROM or DVD based storage magneto optical MO storage flash memory storage device or any other type of non volatile storage devices suitable for storing data.

Storage system presents storage space at storage devices as logical volumes to clients . The term volume as used herein means a logical data set which is an abstraction of physical storage combining one or more physical mass storage devices or parts thereof into a single logical storage object. A storage volume from among as presented may appear to be a single storage drive to storage system . However each volume can represent the storage space in one storage device an aggregate of some or all of the storage space in multiple storage devices a RAID group or any other set of storage space.

Storage volumes are managed by storage system . An administrator not shown using management application may configure the storage volumes such that if there is a failure storage system is permitted to take over storage volumes via secondary path for responding to client requests. The nature and type of errors events to trigger a failover operation may be specified by the administrator via management application .

To protect information stored via storage volumes it may be replicated at different times. One methodology to replicate storage volumes is by taking snapshots . The term snapshot as used herein means a point in time copy of a storage file system. The snapshot is a persistent point in time PPT image of a file system that enables quick recovery of data after data has been corrupted lost or altered. Snapshots can be created by copying data at a predetermined point in time to form a consistent image.

If a failover event occurs then a failover operation is initiated during which storage system takes over storage sub system via secondary path . In conventional systems to complete the failover operation and before storage volumes are presented to clients operating system of storage system typically reads the metadata as shown in for each snapshot. The snapshot metadata may include a unique snapshot identifier the date and time the snapshot is taken the snapshot path as presented to clients the snapshot size and any other information . If the storage system is supporting various volumes for example 1500 volumes and there are 4 snapshot of each volume then storage system may have to read metadata for all the 6000 snapshots. Reading all the metadata slows the completion of the failover operation and results in undesirable disruption for clients to access storage space for reading and writing information.

The embodiments disclosed herein provide an efficient methodology for completing a failover operation where storage system does not have to read the metadata for the plurality of snapshots . A processor executable process flow according to one embodiment is now described below with respect to .

The processor executable process begins with a configuration block during which a storage volume is configured for failover. The configuration may be implemented via a user interface presented by management application . During block management application identifies a primary path for example and and a secondary path for example and . The path information may be stored at data structure . Failover may be enabled by setting the enable failover indicator such that a secondary path is activated allowing a storage system to takeover a storage sub system.

A failover operation is initiated in block S when a failover event occurs. The nature and type of failover event is not germane to the embodiments disclosed herein but may include any error type that may render storage system inoperable or incapable of servicing clients .

In block S storage system obtains ownership of volumes via the secondary path . In one embodiment management application when configuring storage volumes may establish which storage system upon a failover event is permitted to assert ownership of volumes . This allows storage system to takeover volumes upon a failover event.

In block S volumes are mounted without reading any metadata . This allows storage system to present volumes efficiently because it does not read the metadata before mounting the volumes. The term mounting as used herein means making the volumes available to clients . Thereafter in block S storage system presents volumes to clients .

The snapshot metadata is read by operating system of storage system on demand i.e. when needed in block S. For example if a client sends a read request to read a particular snapshot for example then storage system reads the metadata associated with snapshot to service the read request. In one embodiment operating system uses an on demand snapshot data structure that is described below with respect to to access metadata for responding to the read request or any other request for a particular snapshot.

Because storage system does not have to read the snapshot metadata the failover operation is conducted efficiently and clients have faster access to storage space.

The various embodiments disclosed herein may be implemented in a cluster environment. A brief description of a cluster environment is now provided.

Nodes of cluster comprise various functional components that cooperate to provide distributed storage system architecture of cluster . Each node is generally organized as a network element N module and a disk element D module . N module includes functionality that enables node to connect to clients over a computer network and to management application while each D module connects to one or more storage devices may generically be referred to as disks or storage array similar to storage subsystem .

Nodes may be interconnected by a cluster switching fabric which in the illustrative embodiment may be embodied as a Gigabit Ethernet switch. The cluster switching fabric may provide primary and secondary paths not shown to storage similar to paths and . A secondary path is activated during a failover operation as described above with respect to . The failover operation is completed without reading any metadata associated with any affected snapshots for example snapshots and 

It should be noted that while there is shown an equal number of N and D modules in the illustrative cluster there may be differing numbers of N and or D modules in accordance with various embodiments of the present invention. For example there may be a plurality of N modules and or D modules interconnected in a cluster configuration that does not reflect a one to one correspondence between the N and D modules. As such the description of a node comprising one N module and one D module should be taken as illustrative only.

Clients similar to clients may be configured to interact with the node in accordance with a client server model of information delivery. That is each client may request the services of the node and the node may return the results of the services requested by the client by exchanging packets over the network .

The client may issue packets using application including file based access protocols such as the CIFS protocol or the NFS protocol over TCP IP when accessing information in the form of certain data containers. Data container means a block a file a logical unit of data or any other information. CIFS means the Common Internet File System Protocol an access protocol that client systems use to request file access services from storage systems over a network. NFS means Network File System a protocol that allows a user to access storage over a network.

Alternatively the client may issue packets using application including block based access protocols such as the Small Computer Systems Interface SCSI protocol encapsulated over TCP iSCSI and SCSI encapsulated over FCP when accessing information in the form of other data containers such as blocks.

A switched virtualization layer including a plurality of virtual interfaces VIFs is provided below the interface between the respective N module and the client systems allowing the storage associated with the nodes to be presented to the client systems as a single shared storage pool.

The cluster access adapter comprises a plurality of ports adapted to couple node to other nodes of cluster . In the illustrative embodiment Ethernet may be used as the clustering protocol and interconnect media although it will be apparent to those skilled in the art that other types of protocols and interconnects may be utilized within the cluster architecture described herein. In alternate embodiments where the N modules and D modules are implemented on separate storage systems or computers the cluster access adapter is utilized by the N D module for communicating with other N D modules in the cluster .

Each node is illustratively embodied as a dual processor storage system executing a storage operating system that preferably implements a high level module such as a file system to logically organize the information as a hierarchical structure of named directories files and special types of files called virtual disks hereinafter generally blocks on storage devices . However it will be apparent to those of ordinary skill in the art that the node may alternatively comprise a single or more than two processor systems. Illustratively one processor A executes the functions of the N module on the node while the other processor B executes the functions of the D module .

The memory illustratively comprises storage locations that are addressable by the processors and adapters for storing programmable instructions and data structures. The processor and adapters may in turn comprise processing elements and or logic circuitry configured to execute the programmable instructions and manipulate the data structures. It will be apparent to those skilled in the art that other processing and memory means including various computer readable media may be used for storing and executing program instructions pertaining to the invention described herein.

The storage operating system portions of which is typically resident in memory and executed by the processing elements functionally organizes the node by inter alia invoking storage operations in support of the storage service implemented by the node. An example of operating system is the DATA ONTAP Registered trademark of NetApp Inc. operating system available from NetApp Inc. that implements a Write Anywhere File Layout WAFL Registered trademark of NetApp Inc. file system. However it is expressly contemplated that any appropriate storage operating system may be enhanced for use in accordance with the inventive principles described herein. As such where the term ONTAP is employed it should be taken broadly to refer to any storage operating system that is otherwise adaptable to the teachings of this invention.

The network adapter comprises a plurality of ports adapted to couple the node to one or more clients over point to point links wide area networks virtual private networks implemented over a public network Internet or a shared local area network. The network adapter thus may comprise the mechanical electrical and signaling circuitry needed to connect the node to the network. Illustratively the computer network may be embodied as an Ethernet network or a FC network. Each client may communicate with the node over network by exchanging discrete frames or packets of data according to pre defined protocols such as TCP IP.

The storage adapter cooperates with the storage operating system executing on the node to access information requested by the clients and management application . The information may be stored on any type of attached array of writable storage device media such as video tape optical DVD magnetic tape bubble memory electronic random access memory flash memory devices micro electro mechanical and any other similar media adapted to store information including data and parity information. However as illustratively described herein the information is preferably stored on the disks of storage array .

The storage adapter comprises a plurality of ports having input output I O interface circuitry that couples to the disks over an I O interconnect arrangement such as a conventional high performance FC link topology. The storage adapter may be a part of a primary or secondary path that is used during a failover operation as described above.

In another embodiment instead of using a separate network and storage adapter a node may use a converged adapter to process both network and storage traffic.

In one example operating system may include several modules or layers executed by one or both of N Module and D Module . These layers include a file system manager that keeps track of a directory structure hierarchy of the data stored in storage devices and manages read write operations i.e. executes read write operations on disks in response to client requests. File system may also maintain snapshot data structure described above with respect to . In another embodiment file system may also maintain data structure described above in detail.

Operating system may also include a protocol layer and an associated network access layer to allow node to communicate over a network with other systems such as clients and management application . Protocol layer may implement one or more of various higher level network protocols such as NFS CIFS Hypertext Transfer Protocol HTTP TCP IP and others as described below.

Network access layer may include one or more drivers which implement one or more lower level protocols to communicate over the network such as Ethernet. Interactions between clients and mass storage devices are illustrated schematically as a path which illustrates the flow of data through operating system .

The operating system may also include a storage access layer and an associated storage driver layer to allow D module to communicate with a storage device. The storage access layer may implement a higher level disk storage protocol such as RAID redundant array of inexpensive disks while the storage driver layer may implement a lower level storage device access protocol such as FC or SCSI.

It should be noted that the software path through the operating system layers described above needed to perform data storage access for a client request received at node may alternatively be implemented in hardware. That is in an alternate embodiment of the disclosure the storage access request data path may be implemented as logic circuitry embodied within a field programmable gate array FPGA or an ASIC. This type of hardware implementation increases the performance of the file service provided by node in response to a file system request issued by client .

As used herein the term storage operating system generally refers to the computer executable code operable on a computer to perform a storage function that manages data access and may in the case of a node implement data access semantics of a general purpose operating system. The storage operating system can also be implemented as a microkernel an application program operating over a general purpose operating system such as UNIX or Windows XP or as a general purpose operating system with configurable functionality which is configured for storage applications as described herein.

In addition it will be understood to those skilled in the art that the invention described herein may apply to any type of special purpose e.g. file server filer or storage serving appliance or general purpose computer including a standalone computer or portion thereof embodied as or including a storage system. Moreover the teachings of this disclosure can be adapted to a variety of storage system architectures including but not limited to a network attached storage environment a storage area network and a disk assembly directly attached to a client or host computer. The term storage system should therefore be taken broadly to include such arrangements in addition to any subsystems configured to perform a storage function and associated with other equipment or systems. It should be noted that while this description is written in terms of a write any where file system the teachings of the present invention may be utilized with any suitable file system including a write in place file system.

The processing system includes one or more processors and memory coupled to a bus system . The bus system shown in is an abstraction that represents any one or more separate physical buses and or point to point connections connected by appropriate bridges adapters and or controllers. The bus system therefore may include for example a system bus a Peripheral Component Interconnect PCI bus a HyperTransport or industry standard architecture ISA bus a small computer system interface SCSI bus a universal serial bus USB or an Institute of Electrical and Electronics Engineers IEEE standard 1394 bus sometimes referred to as Firewire .

The processors are the central processing units CPUs of the processing system and thus control its overall operation. In certain embodiments the processors accomplish this by executing programmable instructions stored in memory . A processor may be or may include one or more programmable general purpose or special purpose microprocessors digital signal processors DSPs programmable controllers application specific integrated circuits ASICs programmable logic devices PLDs or the like or a combination of such devices.

Memory represents any form of random access memory RAM read only memory ROM flash memory or the like or a combination of such devices. Memory includes the main memory of the processing system . Instructions which implements techniques introduced above may reside in and may be executed by processors from memory .

Also connected to the processors through the bus system are one or more internal mass storage devices and a network adapter . Internal mass storage devices may be or may include any conventional medium for storing large volumes of data in a non volatile manner such as one or more magnetic or optical based disks. The network adapter provides the processing system with the ability to communicate with remote devices e.g. storage servers and over a network and may be for example an Ethernet adapter a FC adapter or the like. The processing system also includes one or more input output I O devices coupled to the bus system . The I O devices may include for example a display device a keyboard a mouse etc.

The system and techniques described above are applicable and useful in the upcoming cloud computing environment. Cloud computing means computing capability that provides an abstraction between the computing resource and its underlying technical architecture e.g. servers storage networks enabling convenient on demand network access to a shared pool of configurable computing resources that can be rapidly provisioned and released with minimal management effort or service provider interaction. The term cloud is intended to refer to the Internet and cloud computing allows shared resources for example software and information to be available on demand like a public utility.

Typical cloud computing providers deliver common business applications online which are accessed from another web service or software like a web browser while the software and data are stored remotely on servers. The cloud computing architecture uses a layered approach for providing application services. A first layer is an application layer that is executed at client computers. In this example the application allows a client to access storage via a cloud.

After the application layer is a cloud platform and cloud infrastructure followed by a server layer that includes hardware and computer software designed for cloud specific services. The storage systems described above can be a part of the server layer for providing storage services. Details regarding these layers are not germane to the inventive embodiments.

Thus a failover method and system is provided. Note that references throughout this specification to one embodiment or an embodiment mean that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Therefore it is emphasized and should be appreciated that two or more references to an embodiment or one embodiment or an alternative embodiment in various portions of this specification are not necessarily all referring to the same embodiment. Furthermore the particular features structures or characteristics being referred to may be combined as suitable in one or more embodiments of the invention as will be recognized by those of ordinary skill in the art.

While the present disclosure is described above with respect to what is currently considered its preferred embodiments it is to be understood that the disclosure is not limited to that described above. To the contrary the disclosure is intended to cover various modifications and equivalent arrangements within the spirit and scope of the appended claims.

