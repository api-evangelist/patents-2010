---

title: User interface for a touchscreen display
abstract: A device, which may have a touchscreen display, and methods for its operation are provided using a graphical user interface and an overlay user input interface such as a virtual keyboard. The graphical user interface may include one or more user interface elements displayed in a first region of the display that are actuatable to invoke a corresponding function. When the virtual keyboard is invoked for display in the same region, the underlying graphical user interface is redrawn with a further user interface element corresponding to at least one of the user interface elements previously displayed in the first region, so that the further user interface element is actuatable to invoke a command to carry out the corresponding function. In another embodiment, the virtual keyboard may be modified instead to provide an action key corresponding to a function related to an application executing on the device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09116615&OS=09116615&RS=09116615
owner: BlackBerry Limited
number: 09116615
owner_city: Waterloo, Ontario
owner_country: CA
publication_date: 20101013
---
This application claims priority to U.S. Provisional Application No. 61 251 179 filed on 13 Oct. 2009 and to U.S. Provisional Application No. 61 251 188 filed on 13 Oct. 2009 the entireties of which are incorporated herein by reference.

The present invention relates to user interfaces on a communication device having a touchscreen display.

Communication and data processing devices such as smart phones personal digital assistants PDAs personal computers tablet computers and the like may be provided with a touchscreen display which functions as both a display interface for displaying information to a user and a user input interface for receiving input from the user. Touchscreen displays may include without limitation resistive touchscreens capacitive touchscreens projected capacitive touchscreens infrared touchscreens and surface acoustic wave SAW touchscreens. Input may be detected in response to user manipulation of the touchscreen through the use of presses gestures taps and the like which may be detected as actions operating on graphical elements displayed on the touchscreen interface. These graphical elements can include virtual buttons keys sliders and other such controls. If there are space or size constraints in the communication device design a touchscreen device may not include a physical keyboard for text or numeric data entry. Therefore the device may also be configured to provide a virtual keyboard including graphic elements that may be manipulated by the user to input alphanumeric data.

The embodiments described herein a provided a user interface for a touchscreen display with improved accessibility to graphical user interface features when select views or contexts are invoked in an application executing on a communication device as well as improved accessibility when a virtual keyboard or other similar overlay is enabled on the touchscreen display.

In accordance with the embodiments described herein there is provided a device comprising a touchscreen display adapted to present a graphical user interface the graphical user interface comprising one or more user interface elements each said user interface element being actuatable using the touchscreen display to invoke a corresponding function wherein the device is adapted to display an overlay user input interface such that said one or more user interface elements are not actuatable and while said overlay user input interface is displayed display a modified graphical user interface wherein at least one of said one or more user interface elements is presented such that said at least one user interface element is actuatable.

In a further aspect the one or more user interface elements comprised in the graphical user interface is displayed in a first location of the touchscreen display the overlay user input interface is displayed in an area of the touchscreen display comprising the first location and the at least one of said one or more user interface elements is displayed in a second location of the touchscreen display outside said area. In a further aspect the first location is proximate a first end of the touchscreen display and the second location is proximate an opposing end of the touchscreen display.

In a still further aspect the at least one user interface element is actuatable to invoke a primary function. The primary function may be determined by detected use of functions associated with the graphical user interface and may be a most frequently used function associated with the graphical user interface. The primary function may also be determined by correlating at least one state of an application associated with the graphical user interface to a detected input command and upon invocation of the overlay user input interface determining a current state of the application and defining the primary function as an action associated with said current state. Alternatively the primary function may be determined by correlating at least one detected input command with a state of an application associated with the graphical user interface and upon invocation of the overlay user input interface determining a current state of the application and defining the primary function as a most frequently used action associated with said current state.

There is also provided a method for operating a device comprising a touchscreen display the method comprising presenting a first graphical user interface at the touchscreen display the first graphical user interface comprising one or more user interface elements each said user interface element being actuatable using the touchscreen display to invoke a corresponding function displaying an overlay user input interface at the touchscreen display such that said one or more user interface elements are not actuatable and while said overlay user input interface is displayed displaying a modified graphical user interface at the touchscreen display wherein at least one of said one or more user interface elements is presented such that said at least one user interface element is actuatable. The overlay user input interface may be a virtual keyboard and the user interface element may be actuatable to invoke a primary function.

In a further aspect of the foregoing method presenting the first graphical user interface comprises displaying the one or more user interface elements in a first location of the touchscreen display displaying the overlay user input interface comprises displaying the overlay user input interface in an area of the touchscreen display comprising the first location and in the modified graphical user interface the at least one of said one or more user interface elements is displayed in a second location of the touchscreen display outside said area.

In still a further aspect of the foregoing method the first location is proximate a first end of the touchscreen display and the second location is proximate an opposing end of the touchscreen display.

Still further aspects of the foregoing method include determining the primary function by detected use of functions associated with the graphical user interface. The primary function may be a most frequently used function associated with the graphical user interface. The primary function may be determined by correlating at least one state of an application associated with the graphical user interface to a detected input command and upon invocation of the overlay user input interface determining a current state of the application and defining the primary function as an action associated with said current state. In still a further aspect of the method the primary function is determined by correlating at least one detected input command with a state of an application associated with the graphical user interface and upon invocation of the overlay user input interface determining a current state of the application and defining the primary function as a most frequently used action associated with said current state. The state of the application may comprise an identification of an application view currently displayed and whether data has been input using the graphical user interface.

There is also provided a computer readable medium comprising computer executable instructions which when executed on one or more processors of a computing system cause the system to carry out the method described herein.

These embodiments will be described in relation to a mobile wireless communication device hereafter referred to as a communication device. It will be appreciated by those skilled in the art however that this description is not intended to limit the scope of the described embodiments to communication devices. The methods and systems described herein may be applied to any appropriate communication or data processing device whether portable or wirelessly enabled or not including without limitation cellular phones smartphones wireless organizers personal digital assistants desktop computers terminals laptops tablets handheld wireless communication devices wirelessly enabled notebook computers and the like having a touchscreen display. The touchscreen display may be actuatable by the user using the touch of a finger or alternatively using a stylus or other pointing device. The graphical user interface implemented with the touchscreen display may be configured to respond to different types of touches or contact such as multi tap long press drag scroll and zoom. Such communication devices may also be provided with alternate user input devices such as a touchpad scroll wheel trackball clickable trackball portable mouse or joystick that permits the user to position a cursor or other visible indicator on a user display such as the touchscreen to actuate and trigger functions represented via a graphical user interface or permits the focus in an application to move from one focus point to another so as to allow the user to actuate and trigger such functions.

The embodiments described herein may be implemented on a communication device such as that illustrated in . The communication device may communicate with other devices over a wireless communication system or enterprise system as illustrated in . The communication device may be a mobile device with two way communication and advanced data communication capabilities including the capability to communicate with other mobile devices or computer systems through a network of transceiver stations. The communication device can also have voice communication capabilities. Throughout the specification terms such as may and can are used interchangeably and use of any particular term should not be construed as limiting the scope or requiring experimentation to implement the claimed subject matter or embodiments described herein.

The communication subsystem receives messages from and sends messages to a wireless network . In this exemplary embodiment of the communication device the communication subsystem is configured in accordance with one or more of Global System for Mobile Communication GSM General Packet Radio Services GPRS standards Enhanced Data GSM Environment EDGE and Universal Mobile Telecommunications Service UMTS . New standards are still being defined but it is believed that they will have similarities to the network behavior described herein and it will also be understood by persons skilled in the art that the embodiments described herein are intended to use any other suitable standards that are developed in the future. The wireless link connecting the communication subsystem with the wireless network represents one or more different Radio Frequency RF channels operating according to defined protocols specified for GSM GPRS EDGE or UMTS and optionally other network communications. With newer network protocols these channels are capable of supporting both circuit switched voice communications and packet switched data communications.

Other wireless networks can also be associated with the communication device in variant implementations. The different types of wireless networks that can be employed include for example data centric wireless networks voice centric wireless networks and dual mode networks that can support both voice and data communications over the same physical base stations. Combined dual mode networks include but are not limited to Code Division Multiple Access CDMA or CDMA2000 networks GSM GPRS networks third generation 3G networks like EDGE HSPA HSPA EVDO and UMTS or fourth generation 4G networks such as LTE and LTE Advanced. Some other examples of data centric networks include WiFi 802.11 Mobitex and DataTAC network communication systems. Examples of other voice centric data networks include Personal Communication Systems PCS networks like GSM and Time Division Multiple Access TDMA systems. The mobile device may be provided with additional communication subsystems such as the wireless LAN WLAN communication subsystem also shown in . The WLAN communication subsystem may operate in accordance with a known network protocol such as one or more of the 802.11 family of standards developed by IEEE. The communication subsystem may be separate from or integrated with the communication subsystem or with the short range communications module . The main processor also interacts with additional subsystems such as a Random Access Memory RAM a flash memory a display an auxiliary input output I O subsystem a data port a keyboard a speaker a microphone short range communications and other device subsystems . The communication device may also be provided with an accelerometer which may be used to detect gravity or motion induced forces and their direction. Detection of such forces applied to the device may be processed to determine a response of the device such as an orientation of a graphical user interface displayed on the display assembly in response to a determination of the current orientation of which the device .

Some of the subsystems of the communication device perform communication related functions whereas other subsystems can provide resident or on device functions. By way of example the display and the keyboard can be used for both communication related functions such as entering a text message for transmission over the network and device resident functions such as a calculator or task list.

A rendering circuit is included in the device . When a user specifies that a data file is to be viewed on the display the rendering circuit analyzes and processes the data file for visualization on the display . Rendering data files originally optimized or prepared for visualization on large screen displays on a portable electronic device display often requires additional processing prior to visualization on the small screen portable electronic device displays. This additional processing may be accomplished by the rendering engine . As will be appreciated by those of skill in the art the rendering engine can be implemented in hardware software or a combination thereof and can comprise a dedicated image processor and associated circuitry or can be implemented within main processor .

The communication device can send and receive communication signals over the wireless network after required network registration or activation procedures have been completed. Network access is associated with a subscriber or user of the communication device . To identify a subscriber the communication device requires a SIM RUIM card i.e. Subscriber Identity Module or a Removable User Identity Module to be inserted into a SIM RUIM interface in order to communicate with a network. The SIM RUIM card is one type of a conventional smart card that can be used to identify a subscriber of the communication device and to personalize the communication device among other things. Without the SIM RUIM card the communication device is not fully operational for communication with the wireless network . By inserting the SIM RUIM card into the SIM RUIM interface a subscriber can access all subscribed services. Services can include web browsing and messaging such as e mail voice mail Short Message Service SMS and Multimedia Messaging Services MMS . More advanced services can include point of sale field service and sales force automation. The SIM RUIM card includes a processor and memory for storing information. Once the SIM RUIM card is inserted into the SIM RUIM interface it is coupled to the main processor . In order to identify the subscriber the SIM RUIM card can include some user parameters such as an International Mobile Subscriber Identity IMSI . An advantage of using the SIM RUIM card is that a subscriber is not necessarily bound by any single physical mobile device. The SIM RUIM card can store additional subscriber information for a mobile device as well including datebook or calendar information and recent call information. Alternatively user identification information can also be programmed into the flash memory .

The communication device may be a battery powered device including a battery interface for receiving one or more rechargeable batteries . In at least some embodiments the battery can be a smart battery with an embedded microprocessor. The battery interface is coupled to a regulator not shown which assists the battery in providing power V to the communication device . Although current technology makes use of a battery future technologies such as micro fuel cells can provide the power to the communication device .

The communication device also includes an operating system and software components to which are described in more detail below. The operating system and the software components to that are executed by the main processor are typically stored in a persistent store such as the flash memory which can alternatively be a read only memory ROM or similar storage element not shown . Those skilled in the art will appreciate that portions of the operating system and the software components to such as specific device applications or parts thereof can be temporarily loaded into a volatile store such as the RAM . Other software components can also be included as is well known to those skilled in the art.

The subset of software applications that control basic device operations including data and voice communication applications will normally be installed on the communication device during its manufacture. Other software applications include a message application that can be any suitable software program that allows a user of the communication device to send and receive electronic messages. Various alternatives exist for the message application as is well known to those skilled in the art. Messages that have been sent or received by the user are typically stored in the flash memory of the communication device or some other suitable storage element in the communication device . In at least some embodiments some of the sent and received messages can be stored remotely from the device such as in a data store of an associated host system that the communication device communicates with.

The software applications can further include a device state module a Personal Information Manager PIM and other suitable modules not shown . The device state module provides persistence i.e. the device state module ensures that important device data is stored in persistent memory such as the flash memory so that the data is not lost when the communication device is turned off or loses power.

The PIM includes functionality for organizing and managing data items of interest to the user such as but not limited to e mail contacts calendar events voice mails appointments and task items. A PIM application has the ability to send and receive data items via the wireless network . PIM data items can be seamlessly integrated synchronized and updated via the wireless network with the mobile device subscriber s corresponding data items stored and or associated with a host computer system. This functionality creates a mirrored host computer on the communication device with respect to such items. This can be particularly advantageous when the host computer system is the mobile device subscriber s office computer system. Some or all of the data items stored at the communication device may be indexed for searching on the device either through a corresponding application such as the PIM or another suitable module. In addition the items may be searchable using a unified search process implemented in the device operating system . For example application data items can be encapsulated in a searchable entity class and registered with a unified search engine on the device that executes searches against all registered data repositories on the device based on received queries. The search engine can also be configured to invoke a search process of external resources such as Internet search engines or remote databases.

The communication device also includes a connect module and an information technology IT policy module . The connect module implements the communication protocols that are required for the communication device to communicate with the wireless infrastructure and any host system such as an enterprise system that the communication device is authorized to interface with. Examples of a wireless infrastructure and an enterprise system are given in which are described in more detail below.

The connect module includes a set of Application Programming Interfaces APIs that can be integrated with the communication device to allow the communication device to use any number of services associated with the enterprise system or with other systems accessible over the network . The connect module allows the communication device to establish an end to end secure authenticated communication pipe with the host system. A subset of applications for which access is provided by the connect module can be used to pass IT policy commands from the host system to the communication device . This can be done in a wireless or wired manner. These instructions can then be passed to the IT policy module to modify the configuration of the device . Alternatively in some cases the IT policy update can also be done over a wired connection.

Other types of software applications can also be installed on the communication device . These software applications can be third party applications which are added after the manufacture of the communication device . Examples of third party applications include games calculators utilities etc.

The additional applications can be loaded onto the communication device through at least one of the wireless network the auxiliary I O subsystem the data port the short range communications subsystem or any other suitable device subsystem . This flexibility in application installation increases the functionality of the communication device and can provide enhanced on device functions communication related functions or both. For example secure communication applications can enable electronic commerce functions and other such financial transactions to be performed using the communication device .

The data port enables a subscriber to set preferences through an external device or software application and extends the capabilities of the communication device by providing for information or software downloads to the communication device other than through a wireless communication network. The alternate download path can for example be used to load an encryption key onto the communication device through a direct and thus reliable and trusted connection to provide secure device communication. The data port can be any suitable port that enables data communication between the communication device and another computing device. The data port can be a serial or a parallel port. In some instances the data port can be a USB port that includes data lines for data transfer and a supply line that can provide a charging current to charge the battery of the communication device .

The short range communications subsystem provides for communication between the communication device and different systems or devices without the use of the wireless network . For example the subsystem can include an infrared device and associated circuits and components for short range communication. Examples of short range communication standards include standards developed by the Infrared Data Association IrDA Bluetooth and the 802.11 family of standards developed by IEEE.

In use a received signal such as a text message an e mail message or web page download will be processed by the communication subsystem and input to the main processor . The main processor will then process the received signal for output to the display or alternatively to the auxiliary I O subsystem . A subscriber can also compose data items such as e mail messages for example using the keyboard in conjunction with the display and possibly the auxiliary I O subsystem . The auxiliary subsystem can include devices such as a touchscreen mouse track ball infrared fingerprint detector or a roller wheel with dynamic button pressing capability. The keyboard is preferably an alphanumeric keyboard and or telephone type keypad. However other types of keyboards can also be used. A composed item can be transmitted over the wireless network through the communication subsystem . It will be appreciated that if the display comprises a touchscreen which provides both an interface both for displaying information and presenting graphical user interfaces and an input subsystem for detecting user input that may be converted to instructions for execution by the device then the auxiliary subsystem may still comprise one or more of the devices identified above.

In a touchscreen device the device may comprise a housing in which the display is mounted. Generally construction of the touchscreen and its implementation in the communication device will be understood by those skilled in the art. Examples in the art include commonly owned U.S. Patent Application Publication Nos. 2004 0155991 2009 0244013 2010 0128002 and 2010 0156843 the entireties of which are herein incorporated by reference. Briefly a touch sensitive display may comprise suitable touch sensitive screen technology such as a capacitive resistive infrared surface acoustic wave SAW touch sensitive display strain gauge optical imaging dispersive signal technology acoustic pulse recognition and so forth as known in the art. The touchscreen display may comprise an assembly of multiple layers including a substrate ground shield layer barrier layer one or more capacitive touch sensor layers separated by a substrate or other barrier and a cover. An example of such a touchscreen display is described in aforementioned U.S. Patent Application No. 2010 0128002. Optionally the device may also provide haptic or tactile feedback through the housing of the device or through the touchscreen itself.

In one embodiment a transmissive TFT LCD screen is overlaid with a clear touch sensor assembly that supports single and multi touch actions such as tap double tap tap and hold tap and drag scroll press flick and pinch. The touchscreen display detects these single and multi touch actions for example through the generation of a signal or signals in response to a touch which may then be processed by the processor or by an additional processor or processors in the device to determine the location of the touch action whether defined by horizontal and vertical screen position data or other position data. The touchscreen display may be provided with separate horizontal and vertical sensors or detectors to assist in identifying the location of a touch. The detected touch actions are then correlated both to user commands and to an element or elements displayed on the display screen comprised in the display . Thus in response to the correlated user command the processor can execute an action in respect of the identified element or elements. Touches that are capable of being detected may be made by various contact objects such as thumbs fingers styli pens pointers and the like although the selection of the appropriate contact object and its construction will depend on the type of touchscreen display implemented on the device. Depending on the technology selected for the touchscreen display the display by itself may be configured to detect contact events on its surface irrespective of the degree of pressure applied at the time of contact.

Pressure events and varying degrees of pressure applied to the touchscreen display may be detected using force sensors not shown which are disposed beneath the display . The construction and implementation of the force sensors will also be understood by those skilled in the art. The force sensor or sensors may include force sensitive resistors strain gauges capacitive piezoelectric or piezoresistive devices pressure sensors or other suitable devices. For example each force sensor may comprise a piezoelectric sensor which when deformed due to force applied through contact by the touchscreen display when pressure is applied to the display surface transmits an electrical signal to the controller or processor . If the signal is determined to be above a predetermined threshold the signal may be interpreted as application of pressure on the touchscreen display associated with particular actions or responses at the device such as actuating a user interface element determined to be located at the point at which the display was depressed . Thus with a touchscreen display that is sensitive to contact by a contact means the device may be configured to detect not only contact i.e. comparatively light pressure at the touchscreen surface using an overlying touch sensing layer but also heavier pressure applied to the touchscreen using the one or more force sensors.

For voice communications the overall operation of the communication device is substantially similar except that the received signals are output to the speaker and signals for transmission are generated by the microphone . Alternative voice or audio I O subsystems such as a voice message recording subsystem can also be implemented on the communication device . Although voice or audio signal output is accomplished primarily through the speaker the display can also be used to provide additional information such as the identity of a calling party duration of a voice call or other voice call related information.

Signals received by the antenna through the wireless network are input to the receiver which can perform such common receiver functions as signal amplification frequency down conversion filtering channel selection and analog to digital A D conversion. A D conversion of a received signal allows more complex communication functions such as demodulation and decoding to be performed in the DSP . In a similar manner signals to be transmitted are processed including modulation and encoding by the DSP . These DSP processed signals are input to the transmitter for digital to analog D A conversion frequency up conversion filtering amplification and transmission over the wireless network via the antenna . The DSP not only processes communication signals but also provides for receiver and transmitter control. For example the gains applied to communication signals in the receiver and the transmitter can be adaptively controlled through automatic gain control algorithms implemented in the DSP .

The wireless link between the communication device and the wireless network can contain one or more different channels typically different RF channels and associated protocols used between the communication device and the wireless network . An RF channel is a limited resource that should be conserved typically due to limits in overall bandwidth and limited battery power of the communication device . When the communication device is fully operational the transmitter is typically keyed or turned on only when it is transmitting to the wireless network and is otherwise turned off to conserve resources. Similarly the receiver is periodically turned off to conserve power until it is needed to receive signals or information if at all during designated time periods.

In a GSM network the MSC is coupled to the BSC and to a landline network such as a Public Switched Telephone Network PSTN to satisfy circuit switched requirements. The connection through the PCU the SGSN and the GGSN to a public or private network Internet also referred to herein generally as a shared network infrastructure represents the data path for GPRS capable mobile devices. In a GSM network extended with GPRS capabilities the BSC also contains the Packet Control Unit PCU that connects to the SGSN to control segmentation radio channel allocation and to satisfy packet switched requirements. To track the location of the communication device and availability for both circuit switched and packet switched management the HLR is shared between the MSC and the SGSN . Access to the VLR is controlled by the MSC .

The station is a fixed transceiver station and together with the BSC form fixed transceiver equipment. The fixed transceiver equipment provides wireless network coverage for a particular coverage area commonly referred to as a cell . The fixed transceiver equipment transmits communication signals to and receives communication signals from mobile devices within its cell via the station . The fixed transceiver equipment normally performs such functions as modulation and possibly encoding and or encryption of signals to be transmitted to the communication device in accordance with particular usually predetermined communication protocols and parameters under control of its controller. The fixed transceiver equipment similarly demodulates and possibly decodes and decrypts if necessary any communication signals received from the communication device within its cell. Communication protocols and parameters can vary between different nodes. For example one node can employ a different modulation scheme and operate at different frequencies than other nodes.

For all communication devices registered with a specific network permanent configuration data such as a user profile is stored in the HLR . The HLR also contains location information for each registered mobile device and can be queried to determine the current location of a mobile device. The MSC is responsible for a group of location areas and stores the data of the mobile devices currently in its area of responsibility in the VLR . Further the VLR also contains information on mobile devices that are visiting other networks. The information in the VLR includes part of the permanent mobile device data transmitted from the HLR to the VLR for faster access. By moving additional information from a remote HLR node to the VLR the amount of traffic between these nodes can be reduced so that voice and data services can be provided with faster response times and at the same time requiring less use of computing resources.

The SGSN and the GGSN are elements added for GPRS support namely packet switched data support within GSM. The SGSN and the MSC have similar responsibilities within the wireless network by keeping track of the location of each communication device . The SGSN also performs security functions and access control for data traffic on the wireless network . The GGSN provides internetworking connections with external packet switched networks and connects to one or more SGSNs via an Internet Protocol IP backbone network operated within the network . During normal operations a given communication device must perform a GPRS Attach to acquire an IP address and to access data services. This requirement is not present in circuit switched voice channels as Integrated Services Digital Network ISDN addresses are used for routing incoming and outgoing calls. Currently all GPRS capable networks use private dynamically assigned IP addresses thus requiring the DHCP server connected to the GGSN . There are many mechanisms for dynamic IP assignment including using a combination of a Remote Authentication Dial In User Service RADIUS server and a DHCP server. Once the GPRS Attach is complete a logical connection is established from a communication device through the PCU and the SGSN to an Access Point Node APN within the GGSN . The APN represents a logical end of an IP tunnel that can either access direct Internet compatible services or private network connections. The APN also represents a security mechanism for the network insofar as each communication device must be assigned to one or more APNs and communication devices cannot exchange data without first performing a GPRS Attach to an APN that it has been authorized to use. The APN can be considered to be similar to an Internet domain name such as myconnection.wireless.com .

Once the GPRS Attach operation is complete a tunnel is created and all traffic is exchanged within standard IP packets using any protocol that can be supported in IP packets. This includes tunneling methods such as IP over IP as in the case with some IPSecurity Ipsec connections used with Virtual Private Networks VPN . These tunnels are also referred to as Packet Data Protocol PDP Contexts and there are a limited number of these available in the network . To maximize use of the PDP Contexts the network will run an idle timer for each PDP Context to determine if there is a lack of activity. When a communication device is not using its PDP Context the PDP Context can be de allocated and the IP address returned to the IP address pool managed by the DHCP server .

The host system comprises a number of network components connected to each other by a network . For instance a user s desktop computer with an accompanying cradle for the user s communication device is situated on a LAN connection. The cradle for the communication device can be coupled to the computer by a serial or a Universal Serial Bus USB connection for example. Other user computers are also situated on the network and each can be equipped with an accompanying cradle . The cradle facilitates the loading of information e.g. PIM data private symmetric encryption keys to facilitate secure communications from the user computer to the communication device and can be particularly useful for bulk information updates often performed in initializing the communication device for use. The information downloaded to the communication device can include certificates used in the exchange of messages.

It will be understood by persons skilled in the art that the user computers are typically also connected to other peripheral devices such as printers etc. which are not explicitly shown in . Furthermore only a subset of network components of the host system are shown in for ease of exposition and it will be understood by persons skilled in the art that the host system will comprise additional components that are not explicitly shown in for this exemplary configuration. More generally the host system can represent a smaller part of a larger network not shown of the organization and can comprise different components and or be arranged in different topologies than that shown in the exemplary embodiment of .

To facilitate the operation of the communication device and the wireless communication of messages and message related data between the communication device and components of the host system a number of wireless communication support components can be provided. In some implementations the wireless communication support components can include a message management server a mobile data server a web server such as Hypertext Transfer Protocol HTTP server a contact server and a device manager module . HTTP servers can also be located outside the enterprise system as indicated by the HTTP server attached to the network . The device manager module includes an IT Policy editor and an IT user property editor as well as other software components for allowing an IT administrator to configure the communication devices . In an alternative embodiment there can be one editor that provides the functionality of both the IT policy editor and the IT user property editor . The support components also include a data store and an IT policy server . The IT policy server includes a processor a network interface and a memory unit . The processor controls the operation of the IT policy server and executes functions related to the standardized IT policy as described below. The network interface allows the IT policy server to communicate with the various components of the host system and the communication devices . The memory unit can store functions used in implementing the IT policy as well as related data. Those skilled in the art know how to implement these various components. Other components can also be included as is well known to those skilled in the art. Further in some implementations the data store can be part of any one of the servers.

In this exemplary embodiment the communication device communicates with the host system through node of the wireless network and a shared network infrastructure such as a service provider network or the public Internet. Access to the host system can be provided through one or more routers not shown and computing devices of the host system can operate from behind a firewall or proxy server . The proxy server provides a secure node and a wireless internet gateway for the host system . The proxy server intelligently routes data to the correct destination server within the host system .

In some implementations the host system can include a wireless VPN router not shown to facilitate data exchange between the host system and the communication device . The wireless VPN router allows a VPN connection to be established directly through a specific wireless network to the communication device . The wireless VPN router can be used with the Internet Protocol IP Version 6 IPV6 and IP based wireless networks. This protocol can provide enough IP addresses so that each mobile device has a dedicated IP address making it possible to push information to a mobile device at any time. An advantage of using a wireless VPN router is that it can be an off the shelf VPN component and does not require a separate wireless gateway and separate wireless infrastructure. A VPN connection can preferably be a Transmission Control Protocol TCP IP or User Datagram Protocol UDP IP connection for delivering the messages directly to the communication device in this alternative implementation.

Messages intended for a user of the communication device are initially received by a message server of the host system . Such messages can originate from any number of sources. For instance a message can have been sent by a sender from the computer within the host system from a different mobile device not shown connected to the wireless network or a different wireless network or from a different computing device or other device capable of sending messages via the shared network infrastructure possibly through an application service provider ASP or Internet service provider ISP for example.

The message server typically acts as the primary interface for the exchange of messages particularly e mail messages within the organization and over the shared network infrastructure . Each user in the organization that has been set up to send and receive messages is typically associated with a user account managed by the message server . Some exemplary implementations of the message server include a Microsoft Exchange server a Lotus Domino server a Novell Groupwise server or another suitable mail server installed in a corporate environment. In some implementations the host system can comprise multiple message servers . The message server can also be adapted to provide additional functions beyond message management including the management of data associated with calendars and task lists for example.

When messages are received by the message server they are typically stored in a data store associated with the message server . In at least some embodiments the data store can be a separate hardware unit such as data store with which the message server communicates. Messages can be subsequently retrieved and delivered to users by accessing the message server . For instance an e mail client application operating on a user s computer can request the e mail messages associated with that user s account stored on the data store associated with the message server . These messages are then retrieved from the data store and stored locally on the computer . The data store associated with the message server can store copies of each message that is locally stored on the communication device . Alternatively the data store associated with the message server can store all of the messages for the user of the communication device and only a smaller number of messages can be stored on the communication device to conserve memory. For instance the most recent messages i.e. those received in the past two to three months for example can be stored on the communication device .

When operating the communication device the user may wish to have e mail messages retrieved for delivery to the communication device . The message application operating on the communication device can also request messages associated with the user s account from the message server . The message application can be configured either by the user or by an administrator possibly in accordance with an organization s IT policy to make this request at the direction of the user at some pre defined time interval or upon the occurrence of some pre defined event. In some implementations the communication device is assigned its own e mail address and messages addressed specifically to the communication device are automatically redirected to the communication device as they are received by the message server .

The message management server can be used to specifically provide support for the management of messages such as e mail messages that are to be handled by mobile devices. Generally while messages are still stored on the message server the message management server can be used to control when if and how messages are sent to the communication device . The message management server also facilitates the handling of messages composed on the communication device which are sent to the message server for subsequent delivery.

For example the message management server can monitor the user s mailbox e.g. the message store associated with the user s account on the message server for new e mail messages and apply user definable filters to new messages to determine if and how the messages are relayed to the user s communication device . The message management server can also through an encoder not shown associated therewith compress message data using any suitable compression decompression technology e.g. YK compression JPEG MPEG x H.26x and other known techniques and encrypt messages e.g. using an encryption technique such as Data Encryption Standard DES Triple DES or Advanced Encryption Standard AES and push them to the communication device via the shared network infrastructure and the wireless network . The message management server can also receive messages composed on the communication device e.g. encrypted using Triple DES decrypt and decompress the composed messages re format the composed messages if desired so that they will appear to have originated from the user s computer and re route the composed messages to the message server for delivery.

Certain properties or restrictions associated with messages that are to be sent from and or received by the communication device can be defined e.g. by an administrator in accordance with IT policy and enforced by the message management server . These may include whether the communication device can receive encrypted and or signed messages minimum encryption key sizes whether outgoing messages must be encrypted and or signed and whether copies of all secure messages sent from the communication device are to be sent to a pre defined copy address for example.

The message management server can also be adapted to provide other control functions such as only pushing certain message information or pre defined portions e.g. blocks of a message stored on the message server to the communication device . For example in some cases when a message is initially retrieved by the communication device from the message server the message management server can push only the first part of a message to the communication device with the part being of a pre defined size e.g. 2 KB . The user can then request that more of the message be delivered in similar sized blocks by the message management server to the communication device possibly up to a maximum pre defined message size. Accordingly the message management server facilitates better control over the type of data and the amount of data that is communicated to the communication device and can help to minimize potential waste of bandwidth or other resources.

The mobile data server encompasses any other server that stores information that is relevant to the corporation. The mobile data server can include but is not limited to databases online data document repositories customer relationship management CRM systems or enterprise resource planning ERP applications. The mobile data server can also connect to the Internet or other public network through HTTP server or other suitable web server such as a File Transfer Protocol FTP server to retrieve HTTP webpages and other data. Requests for webpages are typically routed through mobile data server and then to HTTP server through suitable firewalls and other protective mechanisms. The web server then retrieves the webpage over the Internet and returns it to mobile data server . As described above in relation to message management server mobile data server is typically provided or associated with an encoder that permits retrieved data such as retrieved webpages to be decompressed and compressed using any suitable compression technology e.g. YK compression JPEG MPEG x H.26x and other known techniques and encrypted e.g. using an encryption technique such as DES Triple DES or AES and then pushed to the communication device via the shared network infrastructure and the wireless network . While encoder is only shown for mobile data server it will be appreciated that each of message server message management server and HTTP servers and can also have an encoder associated therewith.

The contact server can provide information for a list of contacts for the user in a similar fashion as the address book on the communication device . Accordingly for a given contact the contact server can include the name phone number work address and e mail address of the contact among other information. The contact server can also provide a global address list that contains the contact information for all of the contacts associated with the host system .

It will be understood by persons skilled in the art that the message management server the mobile data server the HTTP server the contact server the device manager module the data store and the IT policy server do not need to be implemented on separate physical servers within the host system . For example some or all of the functions associated with the message management server can be integrated with the message server or some other server in the host system . Alternatively the host system can comprise multiple message management servers particularly in variant implementations where a large number of mobile devices need to be supported.

The device manager module provides an IT administrator with a graphical user interface with which the IT administrator interacts to configure various settings for the communication devices . As mentioned the IT administrator can use IT policy rules to define behaviors of certain applications on the communication device that are permitted such as phone web browser or Instant Messenger use. The IT policy rules can also be used to set specific values for configuration settings that an organization requires on the communication devices such as auto signature text WLAN VoIP VPN configuration security requirements e.g. encryption algorithms password rules etc. specifying themes or applications that are allowed to run on the communication device and the like.

Applications executing on the communication device often necessitate text input from a user for example for the purpose of composing messages such as electronic mail e mail short message service SMS messages instant messages IM and the like or for inputting data whether for the purpose of entering information for storage at or transmission from the device such as address book contacts notes task lists and also while browsing the web or for the purpose of inputting a command to cause the device to execute a function such as searching for content or initiating a transmission from the device. For example to search for an address book contact the user can enter one or more alphanumeric characters in an input field which can then be used to filter entries in an address book data store for display in a user interface. Similarly text input is generally required to enter or edit an address book entry at the device . Text input from a user may also be required for other applications and functions such as notes task lists and browsing the World Wide Web or other resources over a network connection using a browser client.

While the communication device may be provided with additional physical user input means such as keyboards trackballs touchpads and scroll wheels on a device equipped with a touchscreen interface the device s operating system or applications may be configured to present the user with a virtual keyboard via the touchscreen display when a text entry area of an application or webpage is in focus. The virtual keyboard when invoked in an application may include keys or buttons actuatable by a user s touch or press with a finger stylus or other pointer as described above. These keys or buttons may represent a complete or partial set of alphanumeric characters and punctuation laid out in arrangements similar to a conventional QWERTY layout or in specialized keyboard layouts designed for use on smaller devices such as smartphones.

It can be seen that in the example of the virtual keyboard does not display all possible keys or functions at once like a physical keyboard. The virtual keyboard in a first view is provided with lower case letter keys . Other characters that may be needed by the user are available through keystroke combinations or by invoking an alternate view of the virtual keyboard . For example the user may actuate the punctuation numeric key to change the view of the virtual keyboard to a combination numeric and punctuation keypad not shown in which the letter keys are replaced by keys denoting numbers and or punctuation actuation of the shift key changes the view of the virtual keyboard to a keypad of upper case letters also not shown . Actuating the symbol key invokes the display of keys denoting additional symbols. Overall it will be appreciated that the general configuration of the virtual keyboard and its alternate views reflect the arrangement and function of conventional physical keyboards for example the virtual keyboard arranges letters in the same general arrangement as a standard QWERTY keyboard although in the example of which shows the graphical user interface displayed in a portrait mode most letters are paired on a single key to reduce the number of keyboard keys displayed on the touchscreen display . If the device is capable of displaying a graphical user interface in landscape mode not shown an alternate keyboard arrangement may be implemented to take advantage of the additional width of the display such as a full QWERTY keyboard with a single virtual key corresponding to a single letter. The implementation of other virtual keyboard arrangements will be understood by those skilled in the art and are considered to be within the scope of this disclosure.

The keyboard thus provides the user with a graphical user interface environment evocative of a traditional physical keyboard on a communication device even if the device lacks a physical keyboard. However in a smartphone or similar communication device the device may provide functionality that other computing devices e.g. laptop and desktop computers do not such as voice and SMS messaging. Applications providing these functions may still require text or keyboard input from the user but when the typical virtual keyboard such as the keyboard is invoked on the device the layout and the keys of the virtual keyboard may not correspond to the expected functions of the application. The lack of correspondence between the keyboard keys and the available functions of the application executing on the device can be confusing for the user since it may not be evident that specific keys on the virtual keyboard can be actuated to carry out application related functions.

For example illustrates a phone application user interface displayed on a device . While the user may simply input using a numeric keypad whether virtual or physical a telephone number to be dialled in some circumstances the user may wish to search for a telephone number in an address book or contacts data store at the device prior to dialling. The phone application illustrated in includes a contacts view invoked when the tab is actuated in the user interface displayed on the device . The contacts view includes a data entry area in which may be input an alphanumeric string which as described above may be used to filter the entries in the address book for display to and selection by the user. The alphanumeric information may be input using the virtual keyboard which may be invoked for example when focus is moved to the data entry . The user interface includes a display area which lists contacts matching the filter defined by the text entered in the data entry area . In this example a list of entries beginning with A is displayed in the display area and one particular entry in the list is highlighted. The entry may be highlighted in response to a selection or hover command detected via a user interface such as the touchscreen display .

It can be seen that the keyboard in has the same keys as in . Once the user has identified the correct contact in the contact user interface many of the keys of the virtual keyboard may be irrelevant as no further text entry is necessary typically once the contact is found the next action on the part of the user will be to initiate a dialling function to call the selected contact. On a smartphone device with additional external hardware buttons one of the external buttons may be configured as a dialling button once the contact is selected detection of a button press can initiate a dialling sequence. If there are no such physical buttons on the device as may be the case with a communication device with a touchscreen interface then the user may need to actuate a virtual button or other user interface element via the display to invoke the dialling function. While one or a number of different input gestures could be input by the user to invoke the dialling function there is nothing apparent from the user interface of to indicate how dialling may be accomplished. For example the return key in the virtual keyboard while it may be actuatable to invoke dialling does not readily convey to the user that it may be actuated for that purpose. It is therefore desirable to provide an improved virtual keyboard that is invoked to overlay an application s graphical user interface displayed on a touchscreen display.

As shown in a graphical user interface with a modified virtual keyboard is provided. The interface has a similar contacts view to that of . Again the interface includes a data entry area a list of contacts with one highlighted contact and a modified virtual keyboard including an action key in place of the return key shown in . In operation a user desiring to place a voice call to a contact stored in the address book of the communication device may invoke the contacts view of the telephone application as described above and initiate a search of a contact list or address book. While this could be accomplished by scrolling through a list of all contacts the user may be provided with the option to search for an individual address book record. To search the virtual keyboard would be invoked for example by a specific command or by moving a pointer or focus to the data entry area . The virtual keyboard as shown in partially overlays the contacts view graphical user interface in part thus potentially overlaying other elements displayed in the graphical user interface . With the data entry area in focus the user can then use the virtual keyboard and the touchscreen display to enter one or more characters e.g. at least a partial name of a target contact using the virtual keyboard to locate a matching address book record. In response to the entry of characters in the data entry area a list of contacts matching the search string is displayed at . In this example a contact is determined to match the input characters if the beginning of the contact s common or friendly name or alternatively a contact address matches the input characters. In response to a user command received either via the touchscreen display or through another input means focus may be moved to one of these listed records so that the user may select one of the listed address book records. Record in the list in is shown to be highlighted indicating that it is in focus in the list.

Once the target contact s address book record has been identified in this manner the virtual keyboard may no longer be required by the user. The user may therefore dismiss the keyboard by means of an input command in which case the graphical user interface can be redrawn on the display without the keyboard and elements that may have been overlaid by the keyboard will again be visible. This additional step of dismissing the keyboard thus requires use of device resources to process and re render the graphical user interface such as the rendering engine and processor . Further select keys of the virtual keyboard may be associated with relevant functions for the current view that the user may wish to invoke. This association may not be apparent given a virtual keyboard of the type depicted in because the keys displayed in the virtual keyboard of are not specific to the telephone application context of .

Thus the modified virtual keyboard of provides an action key . The action key is associated with a function relevant to the current application view in this case the contacts view of the telephone application. In the example of the action key is depicted as a phone key with an icon or indicator illustrating a telephone handset and is associated with a telephone calling function. When the action key is actuated by the user a call is placed to the contact whose address book record is highlighted in the graphical user interface . The association between the action key and its related telephone calling function is easily identifiable by the user because the icon or indicator provided on action key is relevant to the telephone application context.

The embodiment described above thus provides a user with a contextually relevant user interface element here a key or button provided in a virtual keyboard associated with a function of the application in the context of which the virtual keyboard is invoked. In the example of the contextually relevant action key replaces the less relevant return key of . By replacing the return key in this embodiment the action key no additional space is required to display the virtual keyboard compared to the keyboard . Further it is not necessary to reduce the size of the individual keys compared to the keyboard to accommodate the action key

It will be readily appreciated by those skilled in the art that the virtual keyboard may be provided with additional contextually relevant action keys in addition to or in replacement of other less relevant keys. Each of said additional contextually relevant keys may be provided with indicia for identifying the application function associated with that key. It will also be appreciated that while the foregoing example has been described in the context of a telephone application and a contacts view the modified virtual keyboard and action key may be implemented in the context of other applications and other views. For example when a voice call is in progress the virtual keyboard may still be displayed in the graphical user interface if the display remains activated or is activated during the call but an additional contextually relevant action key associated with disconnecting the call may be implemented in the virtual keyboard

As another example in a calendar application a contextually relevant action key may be a save button for saving appointment data to a calendar store on the communication device . illustrates a further graphical user interface comprising an edit screen for creating a new calendar appointment with various data entry fields . In this example the virtual keyboard is invocable by the user either upon an input command or else automatically when focus is moved to one of the fields . In place of the return key the virtual keyboard includes a contextually relevant action key here a save button labelled with an indicator signifying its relevance to the edit user interface . Actuation of the save button may result in the device saving the input data as a calendar event in the calendar data store of the device and dismissing the edit screen as well as the virtual keyboard or else may simply save the input data without dismissing the edit screen or keyboard

A process for invoking the virtual keyboard having one or more contextually relevant keys is illustrated in . At while an application is executing on the device and a graphical user interface is displayed in the context of that application an instruction is detected to invoke a virtual keyboard. As noted above this instruction may be the result of an express command by the user to invoke the keyboard or else the keyboard may be automatically displayed when focus is moved to a select region of the user interface such as a data entry field. Upon detection of the command at a virtual keyboard object associated with the user interface screen currently displayed on the device is retrieved and then displayed at .

In addition to the contextually relevant action keys that are provided on a modified virtual keyboard as described above a graphical user interface on a touchscreen device may include user interface elements such as buttons or user interface controls displayed independently of a virtual keyboard. Turning to an exemplary graphical user interface displayed on a display of a communication device is shown. The display may be a touchscreen display. Other possible features of the communication device such as device subsystems are not shown in the figures. The graphical user interface in depicts an interface for use with a contacts application or function within an address book application in which a user may enter edit or delete contact data stored in an address book or other PIM store on the communication device . The interface includes one or more data entry areas a banner or status bar indicating the activity represented by the current view of the application and its data in the graphical user interface here Edit Contact and one or more user interface elements such as buttons or other virtual controls. These user interface elements may be presented in a toolbar form in this case in a row across a lower region of the display are each associated with a possible action operating on or in relation to content entered in the data entry areas . Actuating a user interface element triggers the action. One user interface element may represent an action invoking a further user interface such as a virtual keyboard for use in entering data in one or more of the data entry areas . Another user interface element may represent an action of saving data entered in the data entry areas in the appropriate data store. The third user interface element represents an action of either discarding changes made to the contact data after the data was last saved or discarding the contact entry altogether. The user interface elements may be presented in the graphical user interface with icons or other indicia for signifying the related action to the user. Other possible actions and corresponding user interface elements that may be presented in the same screen area of the graphical user interface will be known to those skilled in the art. For example the horizontal region of the graphical user interface comprising the user interface elements may also comprise other user actuatable elements corresponding to actions such as switch application etc. The user interface elements may be invoked by the application executing on the device whose screen or graphical user interface is in focus. While some or all of these actions may be invoked using a menu system invocable in the graphical user interface the provision of the user interface elements in the user interface itself in the example of across the bottom of the graphical user interface and positioned in a location that is likely easily reachable by a user s fingers or thumbs as he or she operates the device permits the user to invoke various commands without taking extra steps to instruct the device to display a menu system.

As can be seen in the examples of when the virtual keyboard is presented on the display it may overlay content already displayed on the touchscreen display. The virtual keyboard may be partially transparent allowing at least some of the underlying content to be at least partially visible. However if the underlying content includes a user interface component of a graphical user interface such as a virtual button or other control that component will not longer be actuatable by the user because it is overlaid by the virtual keyboard and gestures or other input detected at the touchscreen display correlating to that area of the screen will be interpreted as a command actuated on the user interface elements of the virtual keyboard itself. The device and methods described herein therefore provide a solution to the problem of inaccessibility of user interface elements in an application s graphical user interface when an overlay user interface such as a virtual keyboard is invoked for use with the data entry features of the application s graphical user interface. By providing for modification of either the overlay user interface or the application graphical user interface the user interface controls that are most useful to the user remain accessible even though the standard design of the application graphical user interface or of the device operating system normally positions these user interface controls in the region covered by the overlay user interface.

In a first embodiment the overlay user interface itself is modified by replacing a virtual key with a primary function key associated with a primary or preferred action for the application. Replacing an existing key of the virtual keyboard avoids the need to increase the screen real estate required by the keyboard when displayed. In a second embodiment the application graphical user interface is adapted to include a primary function key associated with a primary or preferred action when the overlay user interface is invoked and is displayed in the region normally occupied by the user interface control for that particular action. The application graphical user interface thus modified may therefore incorporate a user interface element representative of an operating system level or application level action that was not previously incorporated in said application graphical user interface.

In the example of the user interface element is actuatable to invoke a further user interface and in particular a virtual keyboard. An example of such a further user interface is shown in in which an overlay interface for receiving user input is provided in response to actuation of the user interface element . In the overlay user input interface or overlay interface is depicted as a virtual keyboard. The virtual keyboard shown in the accompanying drawings is only one example of a possible keyboard layout a modified QWERTY layout such as that shown in the drawings may be implemented although other keyboard layouts that are known in the art may be used as noted above. It will also be appreciated by those skilled in the art that while the embodiments described herein are shown with a virtual keyboard overlay the overlay interface may comprise other user touch controls including but not restricted to virtual numeric keypads gaming controls sliders or mixing board controls touchpads and the like. The overlay interface may not have user input as a primary function the overlay interface may instead function primarily as a media display for example displaying text still pictures or video optionally with accompanying user controls.

The overlay user input interface is enabled and displayed in the graphical user interface either in response to the user actuation of the user interface element or because the application is configured to expect text input by the user so the device may automatically enable and display the overlay interface upon a predetermined event. The overlay interface may be invoked upon detection that focus has been set on or moved to a data entry area a cursor in indicates that focus is currently in the visible data entry area by another user actuated instruction whether input via a gesture or tap on the touchscreen display or a physical key press on the device or automatically when the application or view within the application is launched.

Once any user input is complete it is generally expected that the user will wish to save any changes made to the contact entry. Alternatively the user may wish to discard any changes delete the record altogether or carry out another function such as a search. The graphical user interface in however does not include any additional user interface elements for carrying out such activities save discard changes delete search etc. . On portable communication devices particularly smartphone and other small form factor devices screen area is limited and overlapping of user interface elements may result when further user interfaces are invoked. In the overlay interface is displayed in the screen area where the user interface elements and one of the data entry areas of previously appeared. Even if the overlay interface were partially transparent so that elements of the graphical user interface beneath were visible those elements would not be actuatable by the user because the overlay interface overlaps those elements either wholly or partially.

Accordingly as shown in a graphical user interface is provided for the touchscreen display of the communication device . The graphical user interface again may comprise a banner or status bar at least one data entry area and the overlay user input interface . In addition however the graphical user interface also comprises a primary function user interface element here depicted as a button that may be actuated with a tap or touch via the touchscreen . The primary function user interface element is configured to trigger one particular function associated with the application or the current view represented by the user interface . In the example shown in the element is a save button which may be actuated to trigger to save the contact record currently displayed in the graphical user interface including any changes made by the user. The element is positioned in the graphical user interface such that it is not overlaid by the overlay interface when the overlay interface is invoked for display in its default location here positioned across a lower portion of the display such that a portion of the user interface adapted to receive user input such as the data entry area is visible. The presentation of the primary function user interface element in this position in may be accomplished by repositioning other graphical user interface elements such as the data entry area which as can be seen by comparison to the user interface of is positioned slightly lower on the display than the data entry area . The distance by which the data entry area is shifted to accommodate the primary function user interface element will depend on the relative size of the primary function user interface element and optionally on the positioning and formatting of other user interface elements in the user interface

The element thus provides the user with access to a function to which access is typically provided in the graphical user interface but is temporarily obscured by the overlay interface as shown in .

The function associated with the primary function user interface element may be predetermined for each application and corresponding view. For example as shown in the predetermined function is the save function which was one of a plurality of functions represented by the user interface elements in . The identification of the predetermined function may be configured within the application itself or as a user or administrator configurable setting for the application or operating system. Each application e.g. a contacts or PIM data management application a phone application e mail application and so forth or view provided by an application e.g. the contacts view provided in the phone application of may have a predetermined primary function user interface element that is automatically displayed whenever the overlay interface is invoked in that application or view.

Therefore as shown in in the user interface the overlay user input interface is invoked so that the user may enter details concerning a new appointment. A primary function user interface element is provided in the area of the display above the data entry areas where it is not obscured by the overlay interface . The primary function user interface element provided in this example is a save button associated with a save function so that the user may save the data entered in the data entry areas as an appointment in a calendar store on the communication device. In the user interface the primary function user interface element is still positioned near the top of the display where it is not obscured by the keyboard but to avoid displacing the data entry areas downwards the first data entry area is truncated and the primary function user interface element disposed next to it. The overlay interface may have been invoked as a result of focus moving to one of the data entry areas such as as shown by the cursor . As a portion of the original user interface shown in is obscured by the keyboard in a scroll user interface element is provided indicating to the user that additional content or data entry areas are available. The scroll user interface element may be actuated in some embodiments to scroll to this portion of the user interface

In an alternate appointment view shown in a graphical user interface with one data entry area and overlay interface is provided. The primary user interface element remains a save button but in this example no data entry field e.g. data entry field is truncated. Again in this view because the overlay interface overlaps at least a portion of the previously displayed elements in the graphical user interface additional scrolling interface elements indicating the continuation of content may be provided. In a downwards scroll arrow is displayed near the end of the content displayed in the viewable data entry area indicating that additional content will be viewable by moving the focus downwards or by actuating a user interface element such as the element to scroll down through the content. The overlay interface may still continue to be displayed in the lower region of the display . Similarly the upwards scroll arrow indicates that further content is viewable if the focus is moved in that direction or if the element is actuated.

In a further appointment view shown in the primary function user interface element is now a send button associated with a send function permitting the user to send the appointment data to an invitee. Information about invitees may be entered by the user in a designated data entry area such as the data entry area of .

Thus when the appointment view of the calendar application is invoked the primary function user interface element may be displayed in the graphical user interface thus providing the user with easy access to the save function to save the appointment data in the calendar store since this is the most likely action the user would take but if the user enters information about an invitee in a data entry area using the overlay user input interface then the primary function user interface element may change to the element shown in to provide the user with easy access to the send function so that a meeting invitation may be sent to the invitee. The send function may also cause the data to be saved in the calendar store on the communication device . In this way the user is able to trigger the most commonly used function associated with a particular view even though the overlay interface may be obscuring a portion of the touchscreen normally displaying controls associated with those functions.

Turning to a further example of a graphical user interface for a memo or note taking application is shown with user interface elements corresponding again to the actions of invoking a virtual keyboard saving the memo file created in the user interface and discarding or deleting the memo file together with a data entry area and . When the virtual keyboard is invoked as shown in the primary function user interface element may be a save button for saving the entered data to a memory store on the communication device.

The graphical user interface of again illustrates the message composition view and includes an overlay interface . In it can be seen that in the data entry area no data has been entered identifying a recipient of a message although data has been entered in data entry area regarding a subject line and the data entry area regarding message content. The primary function user interface element in this view is therefore a save button enabling the user to save the message in draft form. The primary function user interface element may be accompanied by a caption providing further information regarding the action associated with the interface element . The caption may be presented above the element at all times or may appear only when the element is in focus. An alternate view is shown in in which there is a composed message but no recipient identified in the data entry area . In this embodiment the virtual keyboard has been altered to replace the return key with a save button .

If the user enters recipient information as shown in data entry area of the user interface shown in then the message may be sent to a recipient. Therefore the primary function user interface element is changed to a send button enabling the user to send the message to the designated recipient s . Thus the user is able to trigger the most commonly used function associated with a particular view and as determined by the availability of particular data in a message composition view if no recipient data is entered the user is more likely to save a draft message but if recipient data is entered then the user is likely to send the message to the recipient. The primary function user interface element is thus automatically selected to reflect the likeliest user action and is displayed in the graphical user interface so that it is accessible to the user even though the overlay interface used for data entry may be obscuring a portion of the touchscreen normally displaying controls associated with those functions. Again the determination of the likeliest user action may be predefined within the application data itself or may be configurable. In a further embodiment the function associated with the primary function user interface element for a given application view does not change but the user interface element remains inactivated in the graphical user interface until relevant data is entered. In the example of the user interface element of the first graphical user interface may be a send button rather than a save button but configured so as to be incapable of being actuated by the user until such time that recipient data has been entered into the address field . Once data has been detected in the field the primary function user interface element is activated or enabled so as to be capable of being actuated by the user. The inactivated and activated states may be indicated visually on the display for example the send button may be displayed in a greyed out or low contrast mode while inactivated and displayed in full colour or regular contrast mode when activated or enabled.

The primary function user interface elements may be predetermined as explained above. Generally the application executing on the device may carry out the process illustrated in the flowchart of . At a particular view or graphical user interface of the application is invoked. At a command to invoke the virtual keyboard is detected which as discussed above may be due to an express user instruction or in response to detecting that focus has been moved in the graphical user interface to a field requiring text input. At a default primary function such as save or send is determined At the virtual keyboard and the primary function user interface element corresponding to the default primary function are displayed on the display .

In an alternate embodiment the selection of the primary function user interface element may be configurable either manually or automatically. For example if a user generally saves all composed e mail messages as drafts before sending them even after the message is addressed to a recipient the element shown in may be configured as a save button instead so that the user is provided with easy access to the save function. The type of element may be configured either through an option in the communication device s operating system or as a configurable preference in the application itself. In a further embodiment the application or operating system of the communication device may be configured to learn the user s behaviour and to adapt the primary function user interface elements according to the user s previous use of the functions or commands associated with the application whether through the user interface elements through or other means such as context menus. For example the application or operating system may track the frequency with which the user selects a save option when composing an e mail addressed to a recipient if it is determined that the user actuates a save function more frequently than a send function then the application or operating system may configure the primary function user interface element as a save button rather than a send button. An exemplary process for this feature is illustrated in . At the particular view or graphical user interface of the application is invoked. At a user command is detected such as a save or send command. At the current state of the application is determined for example whether the application is in an edit mode e.g. an edit appointment graphical user interface or in a different mode. This state is then correlated to the detected input command at and a count associated with this correlated input command and state is stored at if frequency of use of that input command is to be stored. Turning to the next time the application is invoked at and an invoke virtual keyboard command is detected at the current state of the application is determined at which may include determining what application view is currently displayed and whether certain content has been input by the user e.g. in the case of an e mail composition screen it may be determined whether recipient data has been entered via the graphical user interface as described with reference to above . Based on the determined state the primary function for the primary function user interface element is determined at as the action associated with the detected input command associated with that state. If the aforementioned count is stored in association with each correlated input command and application state then the primary function may be determined as that command having the greatest count associated with that application state or else determine by other means which is the most frequently used function associated with the graphical user interface. This primary function user interface element and the virtual keyboard are then displayed at .

In a further embodiment if sufficient space is available in the graphical user interface additional user interface elements may be added to the graphical user interface along with the primary user interface element. These additional elements may be associated with other functions that are not as frequently used but are consistently used by the user. Thus for example the element of may be provided next to the element of in a message composition view of the messaging application to provide easy user access to both the save and send functions. As an alternative the single primary user interface element that is displayed may provide for the selection of different functions by the user. For example actuating element by a first user action such as a single short tap or press may trigger the function associated with that element while a longer press on the element may invoke a drop down list of alternate functions associated with the application or view that may be selected by the user. An example of this process is illustrated in . The virtual keyboard and the primary function user interface element are displayed in the user interface at . At an input is detected in relation to the primary function element. At it is determined what type of input was received for example whether the input may be characterized as a long press rather than a tap. If it is determined that the input was a long press then a list of alternative functions is displayed at for selection and actuation by the user. If the input was not a long press then at the action associated with the primary function of the user interface element is executed. Alternatively or additionally the drop down list may be invoked through a separate user interface element displayed in the graphical user interface along with the primary function user interface element.

The embodiments described above therefore provide a user with easier access to frequently used functions associated with a particular application or with a particular view of an application by providing at least a primary function user interface element actuatable by the user to trigger that function even though buttons or other controls normally used to trigger that function are unavailable because they are overlaid by another interface such as the overlay interface . The selection of functions made available to the user in a given view may be determined at least in part by the type of data entered in a data entry area via the graphical user interface and the type of overlay interface. By providing the primary function user interface element it is not necessary for the user to close or disable the overlay interface in order to invoke a desired function thus reducing processor use and delay in redrawing the graphical user interface once the keyboard is dismissed.

It will be appreciated that the above embodiments may also apply to other applications or overlay input interfaces on the communication device. For example as discussed above although the accompanying drawings depict a virtual keyboard that may be overlaid on the touchscreen s graphical user interface the overlaid input interface may comprise different virtual input controls such as a touchpad numeric keypad mixing board and the like. Similarly it will be appreciated that the primary function user interface element need not be presented in the graphical user interface as a button but may take the form of another user interface element. The applications and views described herein are generally directed to personal information management and messaging but may also be directed to other activities such as Internet browsing.

The systems and methods disclosed herein are presented only by way of example and are not meant to limit the scope of the invention. Other variations of the systems and methods described above will be apparent to those skilled in the art and as such are considered to be within the scope of the invention. For example it should be understood that steps and the order of the steps in the processing described herein may be altered modified and or augmented and still achieve the desired outcome.

The systems and methods data may be stored in one or more data stores. The data stores can be of many different types of storage devices and programming constructs such as RAM ROM flash memory programming data structures programming variables etc. It is noted that data structures describe formats for use in organizing and storing data in databases programs memory or other computer readable media for use by a computer program.

Code adapted to provide the systems and methods described above may be provided on many different types of computer readable media including computer storage mechanisms e.g. CD ROM diskette RAM flash memory computer s hard drive etc. that contain instructions for use in execution by a processor to perform the methods operations and implement the systems described herein.

The computer components software modules functions and data structures described herein may be connected directly or indirectly to each other in order to allow the flow of data needed for their operations. It is also noted that a module or processor includes but is not limited to a unit of code that performs a software operation and can be implemented for example as a subroutine unit of code or as a software function unit of code or as an object as in an object oriented paradigm or as an applet or in a computer script language or as another type of computer code.

A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by any one of the patent document or patent disclosure as it appears in the Patent and Trademark Office patent file or records but otherwise reserves all copyrights whatsoever.

