---

title: Intelligent determination of replays based on event identification
abstract: A system for intelligently determining replay locations in a multimedia content stream based on identifying events in the multimedia content stream is provided. In one embodiment, events in the multimedia content stream are identified by analyzing information in the multimedia content stream, in real time. In another embodiment, events in the multimedia content stream are identified by analyzing the viewing behavior and an emotional response from users viewing the multimedia content, in real time. One or more replay locations in the multimedia content stream are determined based on the events identified in the multimedia content stream. The multimedia content stream with the replay locations are displayed to a user via a user interface in the user's processing device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09484065&OS=09484065&RS=09484065
owner: Microsoft Technology Licensing, LLC
number: 09484065
owner_city: Redmond
owner_country: US
publication_date: 20101015
---
Digital video recorders deliver video motion graphics audio and other multimedia content on displays such as televisions monitors or mobile computing devices. A user viewing multimedia content on the display can typically access different parts of the multimedia content by utilizing one or more controls in the digital video recorder. For example a user may utilize a replay control in the digital video recorder to re watch a segment of a video or audio recording. Replaying a recorded segment typically involves changing the user s current viewing position to some time prior to the current viewing position in the multimedia content stream. This time is usually arbitrary and fixed and typically does not reflect the user s true intent resulting in the user having to re watch content that the user had no intention of watching again. The user may have to utilize a combination of other media device controls such as a fast forward control or a rewind control to manually determine the viewing position in the multimedia content stream that the user actually intended to re watch.

Disclosed herein is a method and system which performs the intelligent determination of replay locations in a multimedia content stream by identifying events in the multimedia content stream. An event is an interesting occurrence in the multimedia content stream that a viewer may wish to replay at a future time. In one embodiment events in the multimedia content stream are identified by analyzing information in the multimedia content stream in real time. In one example an event is identified by detecting audio or visual cues in the multimedia content stream. The cues may include for example applause a cheer a remark a score update or a commentary update from one or more entities in an audio or video sequence in the multimedia content stream. In another embodiment an event in the multimedia content stream is identified based on user feedback information received from users viewing the multimedia content. For example an event may be identified based on a user s viewing behavior by monitoring one or more controls utilized by the user while viewing the multimedia content. An event in the multimedia content stream may also be identified based on a user s emotional response to the multimedia content by tracking the user s facial expressions vocal responses gestures and movements using a visual detection or motion tracking device. Replay locations in the multimedia content stream are determined based on the identified events. The multimedia content stream with the replay locations is delivered to the user. The user may re watch one or more of the identified events in the multimedia content stream from one or more of the replay locations. The multimedia content stream is displayed to the user via a user interface in the user s processing device.

In one embodiment a method for determining one or more replay locations in a multimedia content stream is disclosed. The method includes receiving a multimedia content stream related to a current broadcast. The method then includes analyzing the multimedia content stream in real time to identify one or more events in the multimedia content stream and determining one or more replay locations in the multimedia content stream based on the events. In one embodiment the method includes receiving an input from one or more users to replay the multimedia content stream. The method then includes displaying a portion of the multimedia content stream from one or more of the replay locations to the users.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the detailed description. This summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

Technology is disclosed which provides a system and a method for intelligently determining replay locations in a multimedia content stream based on identifying events in the multimedia content stream is disclosed. An event is an interesting occurrence in the multimedia content stream that a viewer may wish to replay at a future time. For example events in a multimedia content stream corresponding to a football game may include touchdowns big plays goals free kicks and so forth. In one embodiment the identification of events in the multimedia content stream and the determination of replay locations based on the identified events may be performed automatically by analyzing information in the multimedia content stream or by analyzing user feedback information received from one or more users in real time. In another embodiment the identification of events in the multimedia content stream and the determination of replay locations based on the identified events may be performed manually. The multimedia content stream with one or more replay locations is provided to one or more users. A user may re watch an identified event in the multimedia content stream from one or more of the replay locations via a user interface in the user s processing device.

As shown in the tracking system may further include a capture device . The capture device may be for example a camera that may be used to visually monitor one or more users such as users and in a field of view such that movements gestures and audio responses from the users may be captured and tracked by the capture device . Lines and denote a boundary of the field of view .

According to one embodiment computing device may be connected to an audiovisual device such as a television a monitor a high definition television HDTV or the like that may provide visuals and or audio to users and . For example the computing device may include a video adapter such as a graphics card and or an audio adapter such as a sound card that may provide the audiovisual signals to an output device. The audiovisual device may receive the audiovisual signals from the computing device and may output visuals and or audio associated with the audiovisual signals to users and . According to one embodiment the audiovisual device may be connected to the computing device via for example an S Video cable a coaxial cable an HDMI cable a DVI cable a VGA cable or the like.

In one embodiment computing device receives a multimedia content stream from a remote computing system and provides the multimedia content stream to one or more users via the audiovisual device . The multimedia content stream can include any type of audio video and or image media content received from media content sources such as content providers broadband satellite and cable companies advertising agencies the internet or a web server. As described herein the multimedia content stream can include recorded video content video on demand content television content television programs advertisements commercials music movies video clips and other on demand media content. The multimedia content stream can also include interactive games network based applications and any other content or data e.g. program guide application data user interface data advertising content closed captions content metadata search results and or recommendations etc. . The operations performed by the computing device are discussed in detail below.

In step the multimedia content stream is analyzed to identify one or more events in the multimedia content stream. As described herein an event is an interesting occurrence in the multimedia content stream that a viewer may wish to replay at a future time. In one approach the step of identifying events in the multimedia content stream includes automatically analyzing information in the multimedia content stream. For example an event may be identified by detecting audio or visual cues such as applause a cheer a remark a score update or a commentary update in the multimedia content stream. In another approach the step of identifying events in the multimedia content stream includes automatically analyzing user feedback information received from one or more users. For example an event may be identified based on a user s viewing behavior by monitoring one or more controls utilized by the user while viewing the multimedia content. An event in the multimedia content stream may also be identified based on a user s emotional response to the multimedia content by tracking the user s facial expressions vocal responses gestures and movements using a visual detection or motion tracking device as shown in .

In step one or more replay locations in the multimedia content stream are determined based on the identified events. describes a process by which a replay location in a multimedia content stream can be determined automatically by analyzing information in multimedia content stream. describes a process by which a replay location in a multimedia content stream can be determined automatically by analyzing user specific information received from one or more users.

In another approach the identification of events in the multimedia content stream and the determination of replay locations based on the identified events may also be performed manually. describes a system for performing the intelligent identification of replay locations in a multimedia content stream based on the above mentioned approaches in more detail.

In step the multimedia content stream with one or more replay locations is provided to the users. In one embodiment and as discussed in detail in the multimedia content stream is marked with one or more replay locations by embedding information about the replay locations into a metadata stream associated with the multimedia content stream.

Centralized multimedia content streaming service may include one or more server s capable of receiving information from and transmitting information to processing devices A B . . . X and provides a collection of services that applications running on processing devices A B . . . X may invoke and utilize. For example server s in the centralized multimedia content streaming service may manage a plurality of activities concurrently by aggregating information from users executing one or more game or non game applications shown in in the processing devices A B . . . X. Centralized multimedia content streaming service may also include a multimedia content database for storing multimedia content streams received from a media provider . Media provider can include for example any entity such as a content provider a broadband provider or a third party provider that can create structure and deliver multimedia content to the centralized multimedia content streaming service . As discussed above multimedia content can include recorded video content video on demand content television content television programs advertisements commercials music movies video clips and other on demand media content. In one embodiment centralized multimedia content streaming service receives a multimedia content stream associated with a current broadcast which may be a live on demand or pre recorded broadcast from the content provider and provides the multimedia content stream to one or more users at processing devices A B . . . X in real time.

As will be discussed in detail below in one approach centralized multimedia content streaming service may analyze the multimedia content stream and provide the result of the analysis to all users viewers of the multimedia content stream at processing devices A B . . . X. Alternatively the analysis of the multimedia content stream may also be performed by each of the individual processing devices A B . . . X. In another approach individual processing devices A B . . . X may collect user feedback information received from users at the processing devices and then provide the user feedback information to the centralized multimedia content streaming service for further analysis.

In one embodiment centralized multimedia content streaming service analyses the multimedia content stream to identify events in the multimedia content stream perform the intelligent determination of replay locations based on the identified events and provide the multimedia content stream with the replay locations to the users at processing devices A B . . . X all in real time. In one approach the identification of events in the multimedia content stream and the determination of replay locations based on the identified events may be performed automatically by one or more software modules such as an event recognition engine and a replay location marking engine in the centralized multimedia content streaming service by analyzing information in the multimedia content stream or by analyzing user feedback information received from one or more users at one or more processing devices A B . . . X. In another approach the identification of events in the multimedia content stream and the determination of replay locations based on the identified events may be performed manually by a production person who may be a part of the current or live broadcast at the centralized multimedia content streaming service or at the media provider . The operations performed by the centralized multimedia content streaming service are discussed in detail below.

As illustrated in centralized multimedia content streaming service includes an event recognition engine and a replay location marking engine . In one embodiment event recognition engine identifies events in the multimedia content stream by analyzing information in the multimedia content stream. As discussed above an event is an interesting occurrence in the multimedia content stream that a viewer may wish to replay at a future time. For example events in a multimedia content stream corresponding to a football game may include touchdowns big plays goals free kicks and so forth. Event recognition engine identifies one or more events in the multimedia content stream by comparing information in the multimedia content stream to one or more events in an events library in the event recognition engine . Events library may include a collection of events comprising information concerning an event in the multimedia content stream.

In another embodiment event recognition engine also identifies one or more events in the multimedia content stream by analyzing user feedback information received from users at processing devices A B . . . X. User feedback information may be generated by processing devices A B . . . X. The manner in which user feedback information is generated by processing devices A B . . . X is discussed in detail in . In one embodiment user feedback information may include information about a user s viewing behavior. Information about a user s viewing behavior may include for example one or more controls utilized by the user on a processing device such as a pause forward rewind jump or a stop control while viewing multimedia content via the processing device. In another embodiment user feedback information may include information about a user s emotional response to the multimedia content viewed by the user. Information about a user s emotional response may include facial expressions vocal responses gestures or movements performed by the user while a user views multimedia content. Facial expressions may include for example smiles laughter cries frowns yawns or applauses from the user while the user views the multimedia content. Vocal responses may include sounds of laughter or applause associated with a facial expression. Gestures and movements may include a user s movement away from a field of view a user facing the audiovisual device leaning forward or talking to the audio visual device while viewing the multimedia content.

User feedback information may also include specific actions obtained from a user such as the user s vote while viewing multimedia content via the user s processing device. User feedback information may also include information obtained from user interface interaction performed by the user or based on the user s interaction with an input device such as a controller remote control mouse or keyboard connected to the user s processing device. For example the user may interact with an application executing in the user s processing device via a user interface to manually specify points of interest or events while viewing multimedia content via the user s processing device.

In one embodiment event recognition engine identifies one or more events in the multimedia content stream by comparing the user feedback information received from processing devices A B . . . X to one or more events in the events library in the event recognition engine . Events library may also include a collection of events comprising information concerning events related to user specific information. For example an event may be identified based on viewing behavior information such as one or more controls utilized by the user while viewing the multimedia content. An event may also be identified based on emotional response information such as the user s facial expressions vocal responses gestures and movements while viewing the multimedia content. In one embodiment event recognition engine may determine if the user specific feedback information from a threshold percentage of users corresponds to a recognized event in the events library . The threshold percentage may be pre determined by the event recognition engine in one embodiment. For example if the event recognition engine receives user feedback information that includes an emotional response of no reaction from 20 of the users and an emotional response of applause from 80 of the users while viewing the multimedia content during a specific time interval the event recognition engine may identify that the user feedback information corresponds to an event such as a recognized player s entry into the field that occurred at a specific point in time in the multimedia content stream. Or for example if the event recognition engine receives user feedback information that includes a rewind action to a specific point in time in the multimedia content stream from 80 of the users viewing the multimedia content stream and no action from 20 of the users the event recognition engine may identify that the user feedback information corresponds to a touchdown event that occurred at a specific point in time in the multimedia content stream.

In one embodiment event recognition engine provides the identified event and the time of occurrence of the identified event to a replay location marking engine for further analysis. Replay location marking engine performs the intelligent determination of replay locations in the multimedia content stream based on the events identified by the event recognition engine . In one embodiment replay location marking engine may use the time of occurrence of the identified event as a replay location in the multimedia content. In another embodiment replay location marking engine may use some other point of interest related to the identified event as a replay location in the multimedia content stream. In one example the point of interest may be identified by determining if the identified event was caused by a cue such as the start of motion of a sports play at a point in time prior to the identified event in the multimedia content stream. For example if the multimedia content stream comprises sports content and the event identified is a touchdown event the replay location marking engine may determine that the touchdown event relates to a point of interest in the multimedia data stream where a recognized player enters the game and may determine the time of occurrence of the point of interest the duration of the point of interest or the type of the point of interest as a replay location in the multimedia content stream.

Upon identification of the replay location replay location marking engine also determines the duration of time to replay the multimedia content stream from the replay location. In one example the duration of time to replay the multimedia content stream may be pre determined by the replay location marking engine . The multimedia content stream with one or more replay locations is then provided to one or more users at processing devices A B . . . X.

In one embodiment replay location marking engine marks the multimedia content steam with the replay locations in real time while the multimedia content stream is provided to the users by embedding information about the replay locations into a metadata stream associated with the multimedia content stream. For example information about a replay location may include information about the event the time of occurrence of the event the point of interest related to the event the time of occurrence of the point of interest the start time of the replay location and the duration of time to replay the multimedia content stream from the replay location. In one example the metadata stream associated with a multimedia content stream may be implemented as a configuration file such as an Extensible Markup Language XML configuration file. An exemplary illustration of a data structure of a configuration file associated with a metadata stream is illustrated below.

The configuration file illustrated above describes an exemplary metadata stream associated with a Football Game . MMContentDesc is a tag that describes the multimedia content stream Title is a tag that describes the title field in the multimedia content stream and VideoFormat is a tag that describes the video format of the multimedia content stream. The tags Title VideoFormat represent general information about the multimedia content stream and may be specified by the content provider prior to providing the multimedia content stream to the centralized multimedia content streaming service or to the processing devices A B . . . X. It is to be appreciated that any number and type of tags representing general information about the multimedia content stream may be specified in the metadata stream in other embodiments.

 ReplayLocation 1 and ReplayLocation 2 describe information about replay locations in the multimedia content stream that are embedded into the metadata stream by the replay location marking engine . In one embodiment ReplayLocation 1 and ReplayLocation 2 represent configurable parameters in the metadata stream that include tags that describe the type of the event EventType information about the event EventInfo the time of occurrence of the event EventTimeOfOccurence information about the point of interest related to the identified event EventPointOfInterest the start time of the replay location EventReplayLocation and the duration of time to replay the multimedia content stream from the replay location EventDuration .

 ReplayLocation 1 includes information about a replay location determined based on the identification of a Touchdown event at time 14 15 00 in the multimedia content stream. In the illustrated example replay location marking engine determines that the Touchdown event at 14 15 00 relates to a point of interest related to the event such as a recognized player s entry into the game that occurred at a prior time 14 10 00 in the multimedia content stream and determines the time of occurrence of the point of interest as a replay location in the multimedia content stream. ReplayLocation 2 includes information about a replay location determined based on the identification of a Touchdown event at time 14 30 45 in the multimedia content stream. In the illustrated example multimedia content replay location marking engine determines the time of occurrence of the Touchdown event as the replay location in the multimedia content stream. It is to be appreciated that any number and type of the replay location tags may be specified in the metadata stream in other embodiments.

A multimedia content stream time stamped or marked with one or more replay locations determined as discussed above is provided to one or more users at processing devices A B . . . X in real time. A user at processing devices A B . . . X may re watch an event from any one of the replay locations by invoking an option via a user interface in processing devices A B . . . X. A segment of the multimedia content stream is replayed to the user via the user interface. The manner in which a user may interact with a user interface in processing devices A B . . . X to replay portions of the multimedia content stream to re watch an event is discussed in detail in .

In another approach and as discussed above the identification of events and the intelligent determination of replay locations based on the identified events in the multimedia content stream may also be performed manually by a production person who may be part of the current or live broadcast at the centralized multimedia content streaming service or at the media provider . In one embodiment the production person may manually analyze information such as audio or visual cues in the multimedia content stream to identify one or more events in the multimedia content stream. The production person may also receive user feedback information from one or more users at processing devices A B . . . X as discussed above to identify one or more events in the multimedia content stream. The production person may then manually mark the multimedia content stream with the one or more replay locations based on the identified events for example based on either the time of occurrence of the identified event or based on a time of occurrence of a point of interest related to the identified event as discussed above. The multimedia content stream with one or more replay locations determined by the production person may then be directly provided to the users at processing devices A B . . . X via the media provider or via the centralized multimedia content streaming service .

As shown in the capture device may include an image camera component . According to one embodiment the image camera component may be a depth camera that may capture a depth image of a scene. The depth image may include a two dimensional 2 D pixel area of the captured scene where each pixel in the 2 D pixel area may represent a depth value such as a distance in for example centimeters millimeters or the like of an object in the captured scene from the camera.

As shown in the image camera component may include an IR light component a three dimensional 3 D camera and an RGB camera that may be used to capture the depth image of a capture area. For example in time of flight analysis the IR light component of the capture device may emit an infrared light onto the capture area and may then use sensors to detect the backscattered light from the surface of one or more targets and objects in the capture area using for example the 3 D camera and or the RGB camera . In some embodiments pulsed infrared light may be used such that the time between an outgoing light pulse and a corresponding incoming light pulse may be measured and used to determine a physical distance from the capture device to a particular location on the targets or objects in the capture area. Additionally the phase of the outgoing light wave may be compared to the phase of the incoming light wave to determine a phase shift. The phase shift may then be used to determine a physical distance from the capture device to a particular location on the targets or objects.

According to one embodiment time of flight analysis may be used to indirectly determine a physical distance from the capture device to a particular location on the targets or objects by analyzing the intensity of the reflected beam of light over time via various techniques including for example shuttered light pulse imaging.

In another example the capture device may use structured light to capture depth information. In such an analysis patterned light i.e. light displayed as a known pattern such as grid pattern or a stripe pattern may be projected onto the capture area via for example the IR light component . Upon striking the surface of one or more targets or objects in the capture area the pattern may become deformed in response. Such a deformation of the pattern may be captured by for example the 3 D camera and or the RGB camera and may then be analyzed to determine a physical distance from the capture device to a particular location on the targets or objects.

According to one embodiment the capture device may include two or more physically separated cameras that may view a capture area from different angles to obtain visual stereo data that may be resolved to generate depth information. Other types of depth image sensors can also be used to create a depth image.

The capture device may further include a microphone . The microphone may include a transducer or sensor that may receive and convert sound into an electrical signal. According to one embodiment the microphone may be used to reduce feedback between the capture device and the computing device in the target recognition analysis and tracking system . Additionally the microphone may be used to receive audio signals that may also be provided by the user to control an application such as a game application or a non game application or the like that may be executed by the computing device .

In one embodiment capture device may further include a processor that may be in operative communication with the image camera component . The processor may include a standardized processor a specialized processor a microprocessor or the like that may execute instructions that may include instructions for storing profiles receiving the depth image determining whether a suitable target may be included in the depth image converting the suitable target into a skeletal representation or model of the target or any other suitable instruction.

The capture device may further include a memory component that may store the instructions that may be executed by the processor images or frames of images captured by the 3 D camera or RGB camera user profiles or any other suitable information images or the like. According to one example the memory component may include random access memory RAM read only memory ROM cache Flash memory a hard disk or any other suitable storage component. As shown in the memory component may be a separate component in communication with the image capture component and the processor . In another embodiment the memory component may be integrated into the processor and or the image capture component . In one embodiment some or all of the components and of the capture device illustrated in are housed in a single housing.

The capture device may be in communication with the computing device via a communication link . The communication link may be a wired connection including for example a USB connection a Firewire connection an Ethernet cable connection or the like and or a wireless connection such as a wireless 802.11b g a or n connection. The computing device may provide a clock to the capture device that may be used to determine when to capture for example a scene via the communication link .

The capture device may provide the depth information and images captured by for example the 3 D or depth camera and or the RGB camera including a skeletal model that may be generated by the capture device to the computing device via the communication link . The computing device may then use the skeletal model depth information and captured images to control an application such as a game application or a non game application or the like that may be executed by the computing device .

In one embodiment capture device may automatically track a user s emotional response to multimedia content being viewed by the user by detecting the user s facial expressions and or vocal responses. In one example capture device may detect facial expressions and or vocal responses such as smiles laughter cries frowns yawns or applauses from the user. In one embodiment facial recognition engine in the computing device may identify facial expressions performed by a user by comparing the data captured by the cameras e.g. depth camera and or visual camera in the capture device to one or more facial expression filters in a facial expressions library in the facial recognition engine . Facial expressions library may include a collection of facial expression filters each comprising information concerning a user s facial expression. In another example facial recognition engine may also compare the data captured by the microphone in the capture device to the facial expression filters in the facial expressions library to identify one or more vocal responses such as for example sounds of laughter or applause associated with a facial expression.

In one embodiment capture device may also track a user s emotional response to the multimedia content being viewed by tracking the user s gestures and movements. In one example movements tracked by the capture device may include detecting if a user moves away from the field of view of the capture device or stays within the field of view of the capture device while viewing the multimedia content. Gestures tracked by the capture device may include detecting a user s posture while viewing the multimedia program such as if the user turns away from the audio visual device faces the audio visual device or leans forward or talks to the display device e.g. by mimicking motions associated with an activity displayed by the multimedia content while viewing the multimedia content. In one embodiment gesture recognition engine in the computing device may identify gestures and movements performed by a user by comparing the data captured by the cameras e.g. depth camera and or visual camera in the capture device to one or more gesture filters in a gestures library in the gesture recognition engine . Gestures library may include a collection of gesture filters each comprising information concerning a user s gesture or movement. More information about recognizing gestures can be found in U.S. patent application Ser. No. 12 391 150 Standard Gestures filed on Feb. 23 2009 and U.S. patent application Ser. No. 12 474 655 Gesture Tool filed on May 29 2009 both of which are incorporated by reference herein in their entirety.

In one embodiment computing device also includes a user behavior recognition engine . User behavior recognition engine tracks a user s viewing behavior while viewing multimedia content via the audiovisual device in the computing device . Viewing behavior may include for example a list of controls such as a pause forward rewind jump or a stop action that may be performed by a user while viewing multimedia content via the audiovisual device .

In one embodiment computing device provides information about the user s emotional response including the user s facial expressions vocal responses gestures movements and information about the user s viewing behavior to the centralized multimedia content streaming service for analysis. The centralized multimedia content streaming service may utilize this information to identity events and perform the intelligent determination of replay locations based on the identified events in the multimedia content stream as discussed in above.

The user s facial expressions vocal responses movements gestures and the user s viewing behavior may be stored in a user profile database in one embodiment. In one example the tracking and identification of a user s facial expressions vocal responses movements and gestures may be performed at pre programmed intervals of time while the user views the multimedia content. The pre programmed intervals of time may be determined by the computing device . It is to be appreciated that the tracking and identification of a user s facial expressions movements and gestures at pre programmed intervals of time enables the determination of the user s emotional response to the viewed multimedia content at different points in time. In one embodiment the disclosed technology may provide a mechanism by which a user s privacy concerns are met while interacting with the target recognition and analysis system . In one example an opt in by the user to the tracking of the user s facial expressions movements gestures and the user s viewing behavior while the user views multimedia content is obtained from the user before implementing the disclosed technology.

Display module in the computing device displays the multimedia content stream to a user via the audiovisual device . In one embodiment display module replays a portion of the multimedia content stream to the user when the user invokes an option via a user interface in the audiovisual device . The manner in which a user may interact with a user interface in the audiovisual device to replay a portion of the multimedia content stream is discussed in detail in .

CPU memory controller and various memory devices are interconnected via one or more buses not shown . The details of the bus that is used in this implementation are not particularly relevant to understanding the subject matter of interest being discussed herein. However it will be understood that such a bus might include one or more of serial and parallel buses a memory bus a peripheral bus and a processor or local bus using any of a variety of bus architectures. By way of example such architectures can include an Industry Standard Architecture ISA bus a Micro Channel Architecture MCA bus an Enhanced ISA EISA bus a Video Electronics Standards Association VESA local bus and a Peripheral Component Interconnects PCI bus also known as a Mezzanine bus.

In one implementation CPU memory controller ROM and RAM are integrated onto a common module . In this implementation ROM is configured as a flash ROM that is connected to memory controller via a PCI bus and a ROM bus neither of which are shown . RAM is configured as multiple Double Data Rate Synchronous Dynamic RAM DDR SDRAM modules that are independently controlled by memory controller via separate buses not shown . Hard disk drive and portable media drive are shown connected to the memory controller via the PCI bus and an AT Attachment ATA bus . However in other implementations dedicated data bus structures of different types can also be applied in the alternative.

A graphics processing unit and a video encoder form a video processing pipeline for high speed and high resolution e.g. High Definition graphics processing. Data are carried from graphics processing unit to video encoder via a digital video bus not shown . An audio processing unit and an audio codec coder decoder form a corresponding audio processing pipeline for multi channel audio processing of various digital audio formats. Audio data are carried between audio processing unit and audio codec via a communication link not shown . The video and audio processing pipelines output data to an A V audio video port for transmission to a television or other display. In the illustrated implementation video and audio processing components are mounted on module .

In the implementation depicted in console includes a controller support subassembly for supporting four controllers . The controller support subassembly includes any hardware and software components needed to support wired and wireless operation with an external control device such as for example a media and game controller. A front panel I O subassembly supports the multiple functionalities of power button the eject button as well as any LEDs light emitting diodes or other indicators exposed on the outer surface of console . Subassemblies and are in communication with module via one or more cable assemblies . In other implementations console can include additional controller subassemblies. The illustrated implementation also shows an optical I O interface that is configured to send and receive signals that can be communicated to module .

MUs and are illustrated as being connectable to MU ports A and B respectively. Additional MUs e.g. MUs are illustrated as being connectable to controllers and i.e. two MUs for each controller. Controllers and can also be configured to receive MUs not shown . Each MU offers additional storage on which games game parameters and other data may be stored. In some implementations the other data can include any of a digital game component an executable gaming application an instruction set for expanding a gaming application and a media file. When inserted into console or a controller MU can be accessed by memory controller . A system power supply module provides power to the components of gaming system . A fan cools the circuitry within console .

An application comprising machine instructions is stored on hard disk drive . When console is powered on various portions of application are loaded into RAM and or caches and for execution on CPU wherein application is one such example. Various applications can be stored on hard disk drive for execution on CPU .

Gaming and media system may be operated as a standalone system by simply connecting the system to an audiovisual device a television a video projector or other display device. In this standalone mode gaming and media system enables one or more players to play games or enjoy digital media e.g. by watching movies or listening to music. However with the integration of broadband connectivity made available through network interface gaming and media system may further be operated as a participant in a larger network gaming community.

Computer typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by computer and includes both volatile and nonvolatile media removable and non removable media. By way of example and not limitation computer readable media may comprise computer storage media and communication media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can accessed by computer . Communication media typically embodies computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.

The system memory includes computer storage media in the form of volatile and or nonvolatile memory such as read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. By way of example only illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that can be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive is typically connected to the system bus through a non removable memory interface such as interface and magnetic disk drive and optical disk drive are typically connected to the system bus by a removable memory interface such as interface .

The drives and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components can either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers here to illustrate that at a minimum they are different copies. A user may enter commands and information into the computer through input devices such as a keyboard and pointing device commonly referred to as a mouse trackball or touch pad. Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are often connected to the processing unit through a user input interface that is coupled to the system bus but may be connected by other interface and bus structures such as a parallel port game port or a universal serial bus USB . A monitor or other type of display device is also connected to the system bus via an interface such as a video interface . In addition to the monitor computers may also include other peripheral output devices such as speakers and printer which may be connected through an output peripheral interface .

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to the computer although only a memory storage device has been illustrated in . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer is connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external may be connected to the system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. By way of example and not limitation illustrates remote application programs as residing on memory device . It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

The control circuitry may include a communication interface that controls the transmission and reception of signals between the mobile computing device and other devices wirelessly or via a wired connection. As illustrated in one embodiment communication interface may include Radio Frequency RF transmit receive circuitry and or Infrared transmit receive circuitry for the transmission and reception of wireless signals. During a transmission mode the control circuitry may provide voice and other data signals to the transmit receive circuitry . The transmit receive circuitry may transmit the signal to a remote station e.g. a fixed station operator other mobile computing devices etc. via antenna .

Control circuitry may also communicate with one or more sensor s a user interface keypad screen an audio interface and a video interface . The sensor s may include for example motion detection sensors such as accelerometers pressure sensors proximity sensors capacitive touch sensors and the like. Accelerometers have been incorporated into mobile devices to enable applications such as intelligent user interfaces that let users input commands through gestures indoor GPS functionality which calculates the movement and direction of the mobile device after contact is broken with a GPS satellite and to detect the orientation of the device and automatically change the display from portrait to landscape when the mobile device is rotated. An accelerometer may be provided e.g. by a micro electromechanical system MEMS which is built onto a semiconductor chip. Acceleration direction as well as orientation vibration and shock can be sensed via the accelerometers.

The User Interface keypad screen may include a keypad such as a push button numeric dialing pad such as on a typical telephone or a multi key keyboard such as a conventional keyboard . The UI keypad screen may also be touch sensitive and include a liquid crystal display LCD or any other type of display commonly used in mobile devices. Audio interface may be used to provide audible signals to and receive audible signals from the user. Audio interface may be coupled to a speaker a microphone and a ringer vibrator . The ringer vibrator may be used to signal an incoming call text message calendar reminder alarm clock reminder or other notification to the user. The ringer vibrator can emit one or more ring tones which are selected by the user and or tactile vibrations. During a receiving mode the transmit receive circuitry receives a voice or other data signal from a remote station through the antenna . A received voice signal may be provided to the speaker while other received data signals are also processed appropriately. The microphone may include a transducer that may receive and convert sound into an electrical signal. The microphone may also include a pressure sensor or an audio sensor to facilitate the sensing of user gestures and the control of notifications.

Video interface may be used to provide video images and other signals to users. Video interface may also be used to receive video images and other signals from camera . Camera may be used to capture images and or video that may be displayed on the user interface screen . Camera may also include one or more depth sensors that may capture sense or detect a user s actions or gestures in a field of view of the mobile computing device.

System may include a power supply which may be implemented as one or more batteries. Power supply may further include an external power source such as an AC adapter or a powered docking cradle that supplements or recharges the batteries. A mobile computing device implementing system may have additional features or functionality. For example the device may also include additional data storage devices removable and or non removable such as magnetic disks optical disks or tape. Computer storage media may include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data.

The hardware devices of discussed above can be used to implement a system that intelligently determines replay locations in a multimedia content stream by identifying events in the multimedia content stream. are flowcharts describing one embodiment of a process for performing the intelligent determination of replay locations in a multimedia content stream by identifying events in the multimedia content stream. In one embodiment the steps of may be performed by software modules for example the event recognition engine and the replay location marking engine in the centralized multimedia content streaming service . describes one embodiment of a process by which a replay location in a multimedia content stream may be determined e.g. more details of step of . In step information in the multimedia content stream is analyzed to detect audio or visual cues in the multimedia content stream. The cues may include for example applause a cheer a remark a commentary update or a score update from one or more entities in an audio or video sequence in the multimedia content stream. In step it is determined if an audio or a visual cue is detected in the multimedia content stream. If it is determined that an audio or a visual cue is detected then an event based on the audio or visual cue is identified in the multimedia content stream at step . For example events that may be identified based on audio or visual cues detected in a multimedia content stream corresponding to a football game may include touchdowns runner downs goals free kicks and so forth.

In step if it is determined that an audio or visual cue is not detected in the multimedia content stream then it is determined if the current broadcast has ended in step . If the current broadcast has not yet ended then the time t is incremented in step and the analysis of the information in the multimedia content stream at the updated time t is performed as discussed in step . If the current broadcast has ended then the multimedia content stream is provided to one or more users at processing devices A B . . . X in real time in step .

In step the time of occurrence of the identified event in the multimedia content stream is determined. In step it is determined if the identified event relates to a point of interest in the multimedia content stream. In one example the point of interest may be identified by determining if the identified event was caused by a start of an activity or a start of motion at a prior point in time in the multimedia content stream. For example an identified event such as a touchdown may relate to a point of interest in the multimedia data stream where a recognized player enters the game.

If it is determined in step that the identified event relates to a point of interest in the multimedia content stream then the time of occurrence of the point of interest is determined to be a replay location in the multimedia content stream in step . If it is determined that the identified event does not relate to a point of interest in the multimedia content stream then the time of occurrence of the identified event is determined to be a replay location in the multimedia content stream in step .

In step the duration of time to replay the multimedia content stream from the replay location is determined. In one example the duration of time to replay the multimedia content stream may be pre determined to be in the range of about 45 seconds to about 120 seconds. In step the multimedia content stream is marked with the replay location in real time by embedding information about the replay location into a metadata stream associated with the multimedia content stream. In step the marked multimedia stream is provided to the users. describes a process for determining a single replay location in a multimedia content stream. It will be appreciated that the process of may be performed multiple times to determine multiple replay locations in the multimedia content stream although the determination of a single replay location is described in the particular example. In addition the described process may be performed in parallel or in sequence to determine multiple replay locations in the multimedia content stream.

In one embodiment the process described in may be performed in parallel with the process of identifying an event in the multimedia content stream based on analyzing information in the multimedia content stream described in . In step it is determined if the identified event identified in step already corresponds to an identified event with a marked replay location in the multimedia content stream as determined by the process of . For example if the identified event detected in step corresponds to a touchdown event at a specific replay location in the multimedia content stream it may be determined that the touchdown event has already been identified in the specific replay location in the multimedia content stream by analyzing the multimedia content stream in step of . If it is determined that the identified event already corresponds to a marked replay location in the multimedia content stream then the marked multimedia content stream is provided to the users in step .

If it is determined that the identified event does not correspond to a marked replay location in the multimedia content stream then the time of occurrence of the identified event in the multimedia content stream is determined in step . Steps are similar to steps discussed in . In step it is determined if the identified event relates to a point of interest in the multimedia content stream. If it is determined in step that the identified event relates to a point of interest in the multimedia content stream then the time of occurrence of the point of interest is determined to be a replay location in the multimedia content stream in step . If it is determined that the identified event does not relate to a point of interest in the multimedia content stream then the time of occurrence of the identified event is determined to be a replay location in the content stream in step . In step the duration of time to replay the multimedia content stream from the replay location is determined. In step the multimedia content stream is marked with the replay location in real time by embedding information about the replay location into a metadata stream associated with the multimedia content stream. In step the marked multimedia stream is provided to the users.

In another embodiment and as illustrated in a user may be shown information about a list of replay locations in the multimedia content stream when the user selects the Instant Replay option . The user may choose to view any of the replay locations by selecting one of the replay locations from the list . In the illustrated example a selection by the user transports the user to Replay Location 2 in the multimedia content stream as illustrated in . As further illustrated the user is also provided with information about the replay location . This information may include the time of occurrence of the event a description of the event and the duration of time that the user will watch the event. A user may return to watch the current broadcast by selecting the Return to current broadcast option . In another embodiment the user may be provided with a compressed view of events identified in the multimedia content stream when the user selects the Instant Replay option . For example the user may be provided with the highlights of a sports game when the user selects the Instant Replay option so that the user may just watch the highlights of the game without performing further interaction with the processing device. In addition a user may also replay any of the replay locations and with voice gestures and using on screen controls.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims. It is intended that the scope of the invention be defined by the claims appended hereto.

