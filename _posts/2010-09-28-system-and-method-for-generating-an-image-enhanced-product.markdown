---

title: System and method for generating an image enhanced product
abstract: A system for generating an image enhanced output product and method for operating the same are provided. An image enhanceable product is identified having a tangible surface and a printing map is defined that defines a plurality of window areas in which images are to be printed on the tangible surface. A desired visual impact characteristic is determined based upon the appearance of the image enhanceable product and the printing map and a selection of a plurality of digital images are received. An image processing method is selected method based upon the determined visual impact characteristic and at least one of the digital images is automatically processed in accordance with the selected image processing method. At least some of the digital images, including the automatically processed image, are provided on the tangible surface according to the printing map.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08224113&OS=08224113&RS=08224113
owner: Eastman Kodak Company
number: 08224113
owner_city: Rochester
owner_country: US
publication_date: 20100928
---
This application is a continuation of prior U.S. patent application Ser. No. 12 024 665 filed Feb. 1 2008 now U.S. Pat. No. 8 086 064 which is hereby incorporated herein by reference in its entirety.

The present invention relates to the field of usering works of communication and in particular the creation sharing and production of works of communication.

Personalized image collages clothing albums and other image enhanced items are becoming increasingly more accessible at the retail level as printing and digital technologies improve and drop in cost. However as the ability to deliver a personalized image bearing product has become more accessible the novelty and perceived value of such gifts has diminished and consumers have become more discriminating. In particular consumers now seek items that bear customized images in a more seamless and integrated manner. However few consumers are equipped with the combination of artistic aesthetic and technical gifts necessary to successfully master such items. Further those who are so equipped often lack the time necessary to do this task effectively.

Accordingly while becoming somewhat more common many items having customized images are still considered novelties. What is needed in the art is a new paradigm to help consumers generate more valuable image item combinations particularly where a plurality of images will be incorporated into a single item.

A system for generating an image enhanced output product and method for operating the same are provided. In accordance with the method the following steps are performed identifying an image enhanceable product having a tangible surface on which a plurality of images can be provided determining a printing map that defines a plurality of window areas in which images are to be printed on an image receiving medium with each window being defined at least by a window shape and location information defining a location of the window area relative to the tangible surface automatically determining at least one desired visual impact characteristic for the image enhanced product based upon the appearance of the image enhanceable product and the printing map receiving a selection of a plurality of digital images that are available for use in the image product automatically selecting at least one image processing method for processing at least one of the plurality of digital images for inclusion in the image enhanced product based upon the determined visual impact characteristic for the image enhanced product automatically processing at least one of the digital images in accordance with the automatically selected image processing method and providing at least some of the digital images including the automatically processed image on the tangible surface according to the printing map in a form that can be used to create the image enhanced output product.

The source of content data files can include any form of electronic or other circuit or system that can supply digital data to processor from which processor can derive images for use in forming an image enhanced item. In this regard the content data files can comprise for example and without limitation still images image sequences video graphics and computer generated images. Source of content data files can optionally capture images to create content data for use in content data files by use of capture devices located at electronic system and or can obtain content data files that have been prepared by or using other devices. In the embodiment of source of content data files includes sensors a memory and a communication system .

Sensors are optional and can include light sensors biometric sensors and other sensors known in the art that can be used to detect conditions in the environment of system and to convert this information into a form that can be used by processor of system . Sensors can also include one or more video sensors that are adapted to capture images. Sensors can also include biometric or other sensors for measuring involuntary physical and mental reactions such sensors including but not limited to voice inflection body movement eye movement pupil dilation body temperature and p4000 wave sensors.

Memory can include conventional memory devices including solid state magnetic optical or other data storage devices. Memory can be fixed within system or it can be removable. In the embodiment of system is shown having a hard drive a disk drive for a removable disk such as an optical magnetic or other disk memory not shown and a memory card slot that holds a removable memory such as a removable memory card and has a removable memory interface for communicating with removable memory . Data including but not limited to control programs digital images and metadata can also be stored in a remote memory system such as a personal computer computer network or other digital system.

In the embodiment shown in system has a communication system that in this embodiment can be used to communicate with an optional remote memory system an optional a remote display and or optional remote input . A remote input station including a remote display and or remote input controls also referred to herein as remote input can communicate with communication system wirelessly as illustrated or can communicate in a wired fashion. In an alternative embodiment a local input station including either or both of a local display and local input controls also referred to herein as local user input can be connected to communication system using a wired or wireless connection.

Communication system can comprise for example one or more optical radio frequency or other transducer circuits or other systems that convert image and other data into a form that can be conveyed to a remote device such as remote memory system or remote display using an optical signal radio frequency signal or other form of signal. Communication system can also be used to receive a digital image and other data from a host or server computer or network not shown a remote memory system or a remote input . Communication system provides processor with information and instructions from signals received thereby. Typically communication system will be adapted to communicate with the remote memory system by way of a communication network such as a conventional telecommunication or data transfer network such as the internet a cellular peer to peer or other form of mobile telecommunication network a local communication network such as wired or wireless local area network or any other conventional wired or wireless data transfer system.

User input system provides a way for a user of system to provide instructions to processor . This allows such a user to make a designation of content data files to be used in generating an image enhanced output product and to select an output form for the output product. User input system can also be used for a variety of other purposes including but not limited to allowing a user to arrange organize and edit content data files to be incorporated into the image enhanced output product to provide information about the user or audience to provide annotation data such as voice and text data to identify characters in the content data files and to perform such other interactions with system as will be described later.

In this regard user input system can comprise any form of transducer or other device capable of receiving an input from a user and converting this input into a form that can be used by processor . For example user input system can comprise a touch screen input a touch pad input a 4 way switch a 6 way switch an 8 way switch a stylus system a trackball system a joystick system a voice recognition system a gesture recognition system a keyboard a remote control or other such systems. In the embodiment shown in user input system includes an optional remote input including a remote keyboard a remote mouse and a remote control and a local input including a local keyboard and a local mouse

Remote input can take a variety of forms including but not limited to the remote keyboard remote mouse or remote control handheld device illustrated in . Similarly local input can take a variety of forms. In the embodiment of local display and local user input are shown directly connected to processor .

As is illustrated in local user input can take the form of an editing studio or kiosk hereafter also referred to as an editing area . In this illustration a user is seated before a console comprising local keyboard and mouse and a local display which is capable for example of displaying multimedia content. As is also illustrated in editing area can also have sensors including but not limited to video sensors audio sensors and other sensors such as multispectral sensors that can monitor user during a usering or production session.

Output system is used for rendering images text or other graphical representations in a manner that allows image enhanceable item to be converted into an image enhanced product. In this regard output system can comprise any conventional structure or system that is known for printing or recording images including but not limited to printer . Printer can record images on a tangible surface using a variety of known technologies including but not limited to conventional four color offset separation printing or other contact printing silk screening dry electrophotography such as is used in the NexPress 2100 printer sold by Eastman Kodak Company Rochester N.Y. USA thermal printing technology drop on demand ink jet technology and continuous inkjet technology. For the purpose of the following discussions printer will be described as being of a type that generates color images. However it will be appreciated that this is not necessary and that the claimed methods and apparatuses herein can be practiced with a printer that prints monotone images such as black and white grayscale or sepia toned images.

In certain embodiments the source of content data files user input system and output system can share components.

Processor operates system based upon signals from user input system sensors memory and communication system . Processor can include but is not limited to a programmable digital computer a programmable microprocessor a programmable logic processor a series of electronic circuits a series of electronic circuits reduced to the form of an integrated circuit or a series of discrete components.

Turning now to what is illustrated is a first embodiment of a method for using an image enhanceable item to generate an image enhanced output product that can be executed for example by the system of .

As is shown in the embodiment of in a first step of the method an image enhanceable product is identified step . Typically this is done when a user input system detects that user has made a user input action that can be interpreted by processor as a selection of one of a plurality of possible image enhanceable items. Alternatively the type of image enhanceable item can be identified based upon stored information regarding user or some other person including but not limited to user preferences past user interactions and other factors. It will be appreciated that such an identification can be made automatically when for example it is determined that system is optimized or otherwise configured to generate only one type of image enhanced output product.

As used herein the term image enhanceable item includes anything that has a tangible surface on which a plurality of images can be formed located placed or otherwise provided. For example and without limitation an image enhanceable item can take the form of a collage photo book scrap book photo calendar mug stein cup stemware jewelry tile mosaic home decor mousepads pillowcases pen pencil holders a simulated or actual bushstroke image on canvas a photo realistic image on a canvas a keepsake box a fleece blanket coasters frames ornaments round ornament snowflake ornament filigree ornament pewter ornament holiday ornament set annual ornament set playing cards puzzle teddy bear or other stuffed animal wall paper packaging apparel accessories including but not limited to a T shirt a tie a tote bag apron baby onesie performance shirt and or frame matte and image combinations and collages mailing labels gift tags stamps or any other tangible thing.

In one example ambient or other light passes through light transmissive area travels to framing matte or onto tangible surface . This light is reflectively modulated by images and and or inter window areas of framing matte and returns through light transmissive area so that the modulated light is viewable outside of framing system . In this regard light transmissive area can comprise for example and without limitation an opening between an observer and framing matte and tangible surface .

In the embodiment of internal area is also sized and shaped to hold an optional backing support which can have for example mounting structures not shown such as hook mountings and the like defined therein. In other embodiments internal area can optionally be sized to hold a protection layer such as a glass or other transparent or semitransparent sheet not shown of conventional design to protect and or hold framing matte and tangible surface .

A printing map is then determined step that defines a plurality of window areas in which images are to be printed on tangible surface . Each window is defined at least by a window shape optionally an available image resolution and location information defining a location of the image window relative to tangible surface .

The window shape can be defined using any known logical system for defining shapes. For example and without limitation the window shapes can be defined by reference to well known geometric constructs mathematical algorithms or in any other form or manner of defining a shape known in the art of image processing geometry computer science or other relevant arts.

The optional available image resolution for a particular window characterizes or identifies the extent to which image picture elements can be recorded within the window shape by output system . Typically this available image resolution will be determined based upon a size and shape of a window and the density of picture elements that output system can record on tangible surface .

The location information defines in some manner a location or position on tangible surface in which the window shapes are to be defined. The location information can be located in any known fashion. For example and without limitation the location information can define a location of the window shape relative to the tangible surface based upon predetermined characteristics of the tangible surface such as perforations edge locations or margins of the tangible surface or it can define the location of the window shape based upon markers watermarks printed text printed images seam locations fabric patterns or other visible features on tangible surface . In other non limiting examples the location information can define a location for the a window based upon the location of other surfaces that are joined to tangible surface such as for example and without limitation straps .

In certain embodiments the printing map can be determined at least in part by obtaining an image enhanceable product identification and determining the printing map by using the product identification to obtain a stored printing map or to obtain previously stored information that can be used to create a printing map including but not limited to pre stored image shape information image location information pattern information and or algorithms that can be used to determine such information. For example most consumer goods are associated with identification such as bar codes watermarks text codes and or radio frequency identifiers that uniquely identify the good being sold. Where system is used in conjunction with products that are associated with such product identification a user input system or sensor can include an appropriate reader of conventional design to read the identification. Alternatively a user can enter an identification into user input manually.

In other embodiments system can have a user input system or sensors that incorporate an image input source such as a scanner or image capture device of conventional design that can be arranged to capture an image of image enhanced product including tangible surface or a framing or matting system into which tangible surface is to be placed. This image can be examined to determine a product identification for the image enhanced product that can then be used as noted above to identify the image enhanced product. Alternatively system can execute algorithms to identify portions of tangible surface that are available window areas on tangible surface . This analysis can be done automatically based upon rules for identifying image bearing areas of the article. For example areas of continuous background color in the captured image can be identified as one or more potential window areas and used to form one or more printing maps. Similarly areas of continuous areas on tangible surface can be identified as window areas and used to form a printing map. Any known algorithm that is suitable for identifying printable areas on a tangible surface can be used for the purpose of generating a printing map.

Where more than one printing map is available system can request that a user make an input using user input system to select from among the plurality of available printing maps. In one embodiment illustrated in system shows a screen shot on local display of a user a plurality of available printing maps and that can be used to print on tangible surface as well as the option to seek additional printing map options. In the illustrated embodiment printing map one includes one large vertically oriented image and two small images while printing map two includes one large vertically oriented image and four small images and printing map three incorporates four small images and one landscape or wide aspect ratio image . A user who is not satisfied with the selection of options can make a more options selection using for example button which can obtain additional printing maps from those that may be associated with the image enhanced item. Where more than three printing maps are available the additional options button can be omitted from presentation by system .

As is illustrated in a user can then use user input to drag and or drop a selected template on to a drawing map picture or other representation of tangible surface or take such other user input actions as are necessary to indicate that user wished to select one of the templates. In the example shown the user has selected template and has used a drag and drop technique to indicate that this template is to be generally center mounted with in a representation of the sheet type image enhanceable product of .

At least one visual impact characteristic for the image enhanced output products then determined based upon the appearance of image enhanceable item and the printing map step . Generally speaking the visual impact characteristic for image enhanceable item will be defined based upon an overall combination of visual features of the image enhanceable item that can be observed by a viewer who is positioned to view at least one of the windows identified by the printing map.

It will be appreciated that an observer of a finished image enhanced product will observe a product that has a number of visual components. These visual components can include but are not limited to tangible surface framing matte and the overall appearance of any other structures of image enhanceable item that will be visible when images are provided therewith in accordance with the printing map. illustrates one example of an image enhanced output product that is formed based upon the image enhanceable product that is illustrated in the embodiment of . As is shown in the overall appearance is dictated by the appearance of the inter window area as well as images that are recorded in window areas and .

Similarly illustrates one example of an image enhanced output product that is formed based upon the frame and matting combination that is illustrated in the embodiment of . As is shown in the visual impact of the image enhanced object includes the appearance of images and the appearance of framing matte and the appearance of structural frame . Further the visual components of the embodiment of can include the visual appearance of any material in light transmissive area or in windows or .

It will also be appreciated that visual impact of an image enhanceable item will similarly be influenced by any feature of an image enhanceable item that is inherently visible when the images to be printed are visible. For example illustrates an example of an image enhanced output product formed comprising a conventional tote bag having tangible surface in the form of image bearing surface with window areas and in which images and have been provided. Here it will be also observed that tote bag has straps pocket area and seams and that are visible image bearing surface the appearance of which should be considered when determining the visual impact of an image enhanced output product that will be formed therefrom.

In sum the examples of and make it clear that the visual impact of an image enhanced output product will be influenced at least by the appearance of tangible surface as well as any other portions of image enhanceable item that are visible when viewed from a perspective that also allows a viewer to observe images that are recorded in the pattern of windows called for by the printing map. All of these factors deserve consideration in determining how to process images for use on the image enhanced item.

A pattern analysis step is then performed. The pattern analysis evaluates shapes patterns and forms on at least those portions of the image enhanceable item that will be visible when images are recorded on the image enhanceable item in accordance with the selected printing map. Pattern information can then be provided that characterizes the nature of the pattern the frequency of the patterns the shapes sizes and locations of existing patterns on the image enhanceable product. In one embodiment the step of performing pattern analysis comprises executing an automated pattern classification algorithm.

Optionally the pattern analysis step can be performed before the step of color analysis so that the color analysis is performed according to the patterns so that for example the colors of particularly important patterns and shapes are tracked with precision and so that color analysis can be made in a more accurate fashion by allowing color analysis to be organized in accordance with the tracked patterns so as to prevent misinterpretation of color data. For example where straps on tote bag are detected using a pattern detection scheme color analysis of straps can be performed separately from color analysis of tangible surface . This can result in better color analysis of both portions of the tote bag .

A multi dimensional analysis step can also be performed that looks for variations in depth on at least those portions of the image enhanceable product that will be visible when images are recorded on the image enhanceable product in accordance with the printing map. It will be appreciated that such contours can also exert a significant influence on the overall appearance of the image enhanceable product. In one embodiment such multi dimensional analysis considers the extent to which contours influence the apparent colors and or distribution of images that will be provided according to the printing map.

A transmissivity reflectance analysis step can also be performed that indicates the refection and transmission characteristics of image enhanceable item so the reflectivity or transmissivity of a protective layer or matte system or a framing system can be characterized automatically to identify whether an image enhanceable item is adapted to present images in a form that will be modified or that will have certain characteristics such as diffused imagery or highly transmissive or reflective imagery. For example it will be appreciated a particular framing system such as the framing system of has a plurality of components such as structural frame light transmissive area or other regions that can vary in reflectance and or in light diffusion characteristics. A light reflectance analysis can determine different information when these components are defined in a manner that softens the light or conversely when such components are defined in a manner that provides for high transmission or reflectance. This provides information can be used in determining the visual impact characteristic for the image enhanceable item.

The visual impact characteristic is further defined by the selected printing map. In particular it will be recalled that the printing map defines window shapes image resolutions and locations that will be used in printing images on tangible surface . It will also be appreciated that factors such as image size image shape image resolution and image arrangement can also influence the desired visual impact of an image enhanced product by defining an overall arrangement of patterns of windows which can create any number of different effects. Specifically it will be appreciated that the arrangement of window areas defined by the printing map can exert a wide range of influences on the overall appearance of the image enhanced output product . For example differences in the size of the windows the shape of the windows the relative geometric arrangement of the windows and the arrangement of the windows relative to other visual features of the image enhanced product can cause the same image enhanceable product to have a vastly different appearance when printed with an orderly arrangement of uniformly shaped windows as compared to the appearance of the same image enhanceable product when printed with a disorderly arrangement of differently shaped windows.

Accordingly a printing map analysis step or steps can be executed to identify information that can be used in determining the visual impact characteristic. provides a non limiting example of some of these steps.

As illustrated in in one embodiment the printing map is analyzed to determine a uniformity factor step . The uniformity factor examines the extent to which window shapes and optionally sizes defined by the printing map are consistent across the printing map. This analysis can for example yield a uniformity score histogram or other form of output.

A pattern coherency analysis can also be performed on the printing map to determine the extent to which window shapes are arranged in an orderly fashion in the selected printing map step . This analysis can for example yield a coherency score shape identification or other known information that characterizes the arrangement of the pattern of window shapes.

A pattern interpretation analysis can further be performed which analyzes the arrangement of windows to identify the extent to which archetypical patterns that may be present in the selected printing map step . In this step the arrangement of windows provided in the printing map is compared to a plurality of archetypical patterns. A pattern interpretation analysis category is then identified that identifies whether the overall distribution of window areas is suggestive of a particular visual archetype such as a regular geometric configuration such as a square circular oval or the like a complex geometric configuration such as a combination of basic geometric configurations or complex configurations such as a Swiss or Maltese cross a basic educational configuration such as the shape of readily recognizable object such as a car boat animal or the like an advanced or abstract pattern that is merely suggestive of a recognizable pattern or that is suggestive of abstract concepts such as motion rest peace and the like.

The visual impact characteristic is then determined as a function of the analysis of the visual characteristics of the image enhanceable item and the selected printing map.

Once determined the visual impact characteristic can be stored in the form of digital data as desired visual impact information in system and can be expressed in any of a variety of forms. The exact form is not critical.

System then receives a selection of a plurality of digital images that are available for use in converting the image enhanceable item into the image enhanced output product Step . This can occur in any number of conventional fashions. For example and without limitation where a user of system has digital images that are stored in a memory that is integral to system or that can be connected to system such as a memory card user can use user input system to identify which of the digital images are to be used in the system. Alternatively user input system can direct system to externally stored data bases of images for use in making the image enhanced product .

In one embodiment the steps of receiving images and determining a printing map can be combined. In one non limiting example of this type a user can be provided with a template drawing or other visual representation of a selected image enhanceable item onto which the user can drag and drop or otherwise place and size selected images in order to prove a uniquely defined arrangement of images relative to the image enhanceable item .

At least one image processing method is automatically selected for processing at least one of the plurality of digital images for inclusion in the image enhanced product based upon the determined visual impact characteristic for the image enhanceable product and the determined printing map. Step In one embodiment this can be done by logically associating each possible visual impact characteristic with a set of at least one image processing method. For example the visual impact characteristics of Table I can be logically associated with particular sets of visual impact characteristics as follows 

At least one of the digital images is then processed in accordance with the automatically selected image processing method to form an automatically processed image for recording in one of the windows of the image enhanced product step and at least some of the digital images including the automatically processed image are provided on the tangible surface according to the printing map in a form that can be used to create the image enhanced output product step . In certain embodiments this can involve recording the images directly onto a tangible surface that is integral to the output product however in other cases such as the where tangible surface is separable from image enhanceable output product the image enhanceable output product can be printed on a tangible medium in a manner that allows tangible surface to be assembled into or otherwise physically associated with image enhanceable item .

Such subsequent assembly steps can involve simply recording the images on a an optional step of forming an image enhanced output product can be performed to provide an optional step of assembly tangible surface to image enhanceable item . Any other operations that are necessary to enable completion of an image enhanced output product are reflected in the optional step of forming an image enabled output product shown in step .

It will be appreciated that in other embodiments additional factors can be considered in determining the visual impact characteristic step in determining an image processing method based upon the visual impact characteristic step or performing the determining image processing step . For example a single image enhanceable item is potentially capable of being associated with more than one type of visual impact characteristic as for example a tote bag of can have one type of visual impact characteristic for athletic use as opposed to academic use. In another example an individual visual impact characteristic can be associated with any of a number of image processing steps and the additional factors can be used to select between individual ones of the image processing steps to determine an emphasis between individual image processing steps and to help to selectively omit particular image processing steps or to add additional image processing steps. Alternatively such additional factors can be used to influence the way in which image processing steps that have been selected based upon the visual impact characteristics are executed such as by adjusting the intensity of other characteristics of such changes.

In one embodiment system is adapted to allow user to make a manual entry of a preference that will impact the selection of the visual impact characteristic

In another embodiment an emotional context can also be manually entered by a user that can be used in forming the image enhanced output product . Table II provides a non limiting example of emotional context information that can be supplied by a user .

Such emotional context information can be associated with particular image processing steps that can supplement supplant or modify image processing steps that are identified based upon the visual impact characteristic in step . Table III shows some examples of this.

In still another example of the use of additional information the step of automatically selecting at least one image processing method for processing at least one of the plurality of digital images for inclusion in the image enhanced product step can further include the steps of extracting portions of an image that depict a subject of the image wherein said subject is identified based upon the identification of an event. The event identification can be manual with a user of system using user input system to select an event from a menu of events provided by system . Each event is associated with rules for identifying subject areas that are depicted in the selected set of images.

This can be done for example by identifying a particular graphical aspects of particular subjects that may appear in a set of images that depict an event. For example a wedding typically has a well recognized set of characters that can be easily identified by their manner of dress and positioning as the subject of an image. Similarly images of other well defined events such as athletic events performances graduations and the like are all typically associated with particular images or image components that can be used to help to automatically identify the subject of particular scenes. Similar analyses and processing can be performed based upon an identified subject or based upon a common object in the images. There are a wide variety of known algorithms that can be used for this purpose.

Such determinations can be used to inform a step of automatically selecting at least one image processing method for processing at least one of the plurality of digital images for inclusion in the image enhanced output product can be performed such that images are automatically incorporated or cropped based upon such determinations.

Similarly the step of automatically selecting at least one image processing method for processing at least one of the plurality of digital images for inclusion in the image enhanced output product can be performed by determining a context for the selected images and modifying images or information in the processed image s based upon the determined context. Similarly the step of automatically selecting at least one image processing method for processing at least one of the plurality of digital images for inclusion in the image enhanced product step can comprise identifying additional content to be incorporated with the digital image. Such context can be determined automatically or manually.

It will be appreciated that many of the possible image enhanceable items have a plurality of tangible surfaces with more than one tangible surface having a visual appearance area having a plurality of locations in which images can be provided. In such situations an overall appearance of the image enhanceable item can be determined and a map of potential areas that can support printing maps can be created from which an overall visual impact characteristic can be determined. Where this is done said step of determining a visual impact characteristic can be repeated for each tangible surface and the determination of a visual impact characteristic for each tangible surface can further be determined at least in part based upon the overall visual impact characteristic.

The invention has been described in detail with particular reference to certain preferred embodiments thereof but it will be understood that variations and modifications can be effected within the spirit and scope of the invention.

