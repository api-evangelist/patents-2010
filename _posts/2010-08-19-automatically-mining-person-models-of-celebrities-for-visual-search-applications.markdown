---

title: Automatically mining person models of celebrities for visual search applications
abstract: Methods and systems for automated identification of celebrity face images are provided that generate a name list of prominent celebrities, obtain a set of images and corresponding feature vectors for each name, detect faces within the set of images, and remove non-face images. An analysis of the images is performed using an intra-model analysis, an inter-model analysis, and a spectral analysis to return highly accurate biometric models for each of the individuals present in the name list. Recognition is then performed based on precision and recall to identify the face images as belonging to a celebrity or indicate that the face is unknown.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08605956&OS=08605956&RS=08605956
owner: Google Inc.
number: 08605956
owner_city: Mountain View
owner_country: US
publication_date: 20100819
---
This application claims the benefit under 35 U.S.C. 119 e of U.S. Provisional Application No. 61 272 912 filed Nov. 18 2009 which is incorporated by reference herein in its entirety.

The Internet hosts vast amounts of content of different types including text images and video. Leveraging this content requires the content to be searchable and organized. Images are generally searched and organized based on identifiers that are manually assigned by users.

In particular when an image is that of a person s face the recognition of that face by a person can be done with extremely high accuracy despite large variations in appearance lighting and expressions. Computer vision systems on the other hand have had a difficult time in performing recognition at the level of accuracy of a human being. Although face recognition has been a long standing problem in computer vision and other domains the main focus of the industry has been the recognition of faces in controlled environments with fairly small datasets. As the datasets increase into the thousands each with appearance variations due to illumination pose and expression the task of successful verification and recognition has been lacking.

As small datasets of famous people have become available an effort to recognize celebrities in the news has also occurred. Algorithms for face identification verification and recognition have been developed that typically contain datasets constrained to news pictures that are usually of high quality taken in controlled environments and in controlled poses. In contrast generic images of people of interest in uncontrolled environments lack the ability to be automatically recognized and verified.

Therefore what are needed are methods and systems to automatically mine person models of celebrities for visual search applications.

In one embodiment a computer implemented method is provided for identifying celebrity face images that generates a name list of prominent celebrities obtains a set of images and corresponding feature vectors for each name detects faces within the set of images and removes non face images. An analysis of the images is performed using an intra model analysis an inter model analysis and a spectral analysis to return highly accurate biometric models for each of the individuals present in the name list. Recognition is then performed based on precision and recall to identify the face images as belonging to a celebrity or that the face is unknown.

In another embodiment a system for identifying faces of celebrities is provided that includes a name list generator that produces names of prominent celebrities a face signature detector that obtains a set of images and corresponding feature vectors for each name detecting faces within the set of images and removing non face images. A person model learning system performs an analysis of the images using intra model inter model analysis and spectral analysis to return highly accurate biometric models for each face image. Recognition is then performed based on precision and recall to identify the face images as belonging to a celebrity or to indicate that the face is unknown.

Further features and advantages of the present invention as well as the structure and operation of various embodiments thereof are described in detail below with reference to the accompanying drawings. It is noted that the invention is not limited to the specific embodiments described herein. Such embodiments are presented herein for illustrative purposes only. Additional embodiments will be apparent to persons skilled in the relevant art s based on the teachings contained herein.

While the present invention is described herein with reference to illustrative embodiments for particular applications it should be understood that the invention is not limited thereto. Those skilled in the art with access to the teachings herein will recognize additional modifications applications and embodiments within the scope thereof and additional fields in which the invention would be of significant utility.

Increasingly larger collections of images are becoming available with the proliferation of content spurred by the widespread availability of image capture devices and the connectivity offered by the Internet. Through the use of interconnected networks and shared image collections at any instant a single user may have access to a large collection of content on various subjects authored by persons spread throughout the world. A system that can automatically identify and recognize faces in datasets containing tens of thousands of individuals in a natural environment is very useful. The methods and systems described herein make use of large article and image corpora available for example on the Internet to automatically associate names and faces of celebrities. In an embodiment of the present invention the system can learn biometric models and recognize faces by crawling the web and learning from images of faces and their annotations. Such images can be obtained from any type of image content including still images videos holograms and other media type or rendering methodology. Utilizing the framework of cloud computing a query image can be acquired with a mobile device where the name of a queried face in the image is returned to the device.

In an embodiment of the present invention an unsupervised face recognition system uses a training set generation that is generated without manual interaction. The only input to the system is a list of names of prominent celebrities that the system attempts to recognize. Such a list of names can be obtained from multiple sources such as articles available over the Internet e.g. Wikipedia where the articles are filtered to retain only those articles that mention the names of people. The various names can then be associated with images available through the Internet using any available service such as the Google Image Search GIS produced by Google Inc. of Mountain View Calif. Using such a service face images can be retrieved and associated with the list of names found in the article. The names within the list can then be ranked based on the number of face images returned by the image search for each name.

In such an embodiment once the name list is defined the first step is to collect a set of images and corresponding feature vectors for each name on the list. This may be accomplished by issuing a query to an available Internet image search system such as the Google Image Search and recording a threshold number of images returned for each query detecting faces and extracting feature vectors from the images and putatively labeling each feature vector with the query from which it was obtained. Given the possibility of mistakes inherent in Internet based image searches a subset of the initial set of feature vectors will be labeled incorrectly. In an embodiment further training seeks to improve the quality of the training data by identifying and discarding incorrectly labeled entries. In another embodiment if an image is returned for more than one celebrity name query then multiple copies of the resulting feature vectors can be stored with each copy and labeled with the query that produced it. In a similar fashion if an image contains two or more faces then all of the faces are putatively labeled with the query name. However in both cases resolving which face is actually the celebrity in question will be handled at a later stage.

In an embodiment of the present invention to avoid obvious outliers returned by the image search a face detector is used to remove non face images from the initial results. The detector uses for example a fast sliding window approach over a range of window sizes. In an embodiment the detector employs a linear combination of a heterogeneous set of feature detectors which are based on families of features of varying complexity encompassing 1 simple but fast features such as bit features as well as 2 more expensive but more informative features such as Gabor wavelets. The detector is trained by minimizing an objective function that employs a logistic loss term and Lregularization. The output can be a score assigned to each window in the range 0 1 . When all scales are processed the remaining windows are filtered and merged according to their scores and overlap across scales. The detector parameters can include a tilt pitch angle set to a threshold level such as 30 degrees and a minimum boxsize such as 40 pixels. In another embodiment the face detection score can be further refined by adding a landmarker sub system that pinpoints facial feature locations within a face bounding box. Features extracted at those locations can then be used to obtain a refined score that indicates the probability of a face being present. One embodiment uses a detection algorithm that belongs to a large family of sliding window detectors such as the seminal Viola and Jones detectors. Extracted feature vectors can be further processed by reducing the dimensionality using principal component analysis PCA and a weighted dot product can be used to measure the similarity between two features vectors.

A person of ordinary skill in the art will recognize that an embodiment can be built upon any detector of high precision and recall.

This section describes according to an embodiment of the present invention the overall pipeline that takes raw image search results as input and returns highly accurate biometric models for tens of thousands of individuals present in a name list.

In an embodiment of the present invention a large name list such as with a set of 30 000 names e.g. Q 30 000 can be used to generate training data. In one embodiment the variable Mis a set of at most 1000 images returned by the image search for q 1 Q with the first phase of removing incorrectly labeled training examples e.g. M from Mdone by analyzing Mitself. In particular each of the feature vectors are examined right arrow over within M discarding those images with low affinity to the remaining vectors in M. In this stage each Mis analyzed individually such that the similarity between faces images returned for different names q is not yet considered.

In an embodiment for each image Iin Mrepresented by right arrow over a nearest neighbor grouping can be performed by counting the number of neighbors and the number of near duplicates in the group where a neighbor is defined as a face with right arrow over right arrow over and a near duplicate as with right arrow over right arrow over with 0 1 . In an embodiment the similarity function can be learned using images and labels from the image search however alternative distance metrics are plausible for this framework.

Images with fewer than k nearest neighbors can then be removed from M. To reduce redundancies all near duplicates of an image represented by Ican be removed. Elements of Mcan then be sorted in decreasing order of near duplicate counts. Each face in the sorted list if it has a near duplicate image appearing earlier in the list can be discarded otherwise it can be retained. It can be noted that such a local outlier removal approach can aid in high recall that is important for reducing false negatives. Through this process an initial collection of labeled faces corresponding to a given face model can be identified.

In an embodiment of the present invention this phase starts with the collection of labeled faces remaining after intra model analysis and seeks to further remove incorrectly labeled entries by comparing faces from different models e.g. annotated with different names. If a collection contains two near duplicate faces with different labels then almost certainly one or both of the labels is incorrect and the face cannot be used to reliably label incoming query faces. The inter model analysis stage aims to resolve near duplicate faces by considering all faces in the collection in a pairwise manner. For each pair right arrow over right arrow over if right arrow over right arrow over e.g. faces i and j have a similarity more than and the labeled celebrity names disagree then the face with the smallest near duplicate count as calculated during intra model analysis is marked for later removal. Once all face pairs have been considered the faces marked for removal are discarded from the collection and removed from the set Mto which they belonged. Note this formulation compares each face against every other face in the collection thus it is possible for a single face to lose during some comparisons or be marked for removal and win others. In either case feature vectors are discarded from the collection if they lose during any comparison.

In an embodiment of the present invention the spectral analysis stage unlike the intra model and inter model analysis stages where individual face e.g. near duplicate and nearest neighbor statistics were considered this stage aims to evaluate the global statistics of individual models. At the start of the Spectral Analysis stage each set Mof face feature vectors contains only those elements that were not already discarded during Intra model or Inter model analysis.

For each model M a set of feature vectors right arrow over with i 1 . . . M the goal is to cluster the right arrow over into k groups and to remove one of the groups as an outlier class. In an embodiment this begins by computing a similarity S right arrow over right arrow over that measures with S 0 1 for each pair of right arrow over right arrow over in M. The similarities Scan be viewed as weights of an undirected graph G over model M. The Matrix S plays the role of a real valued adjacency matrix for G. Next let d Sbe the degree of node i and D be the diagonal matrix with das its diagonal. Finally a graph Laplacian of G is defined as L DSDensuring that the eigenvalues range between 0 1 with the largest eigenvalue equaling one. In an embodiment some traditional spectral clustering algorithms proceed by choosing k dominant eigenvectors of L based on their eigenvalues and project the original data in n M onto these k eigenvectors thus mapping . However with a high degree of confidence it is believed that the clusters that comprise Mare spherical as seen in and data in Mdoes not require the projection. In an embodiment represents mapping to of pairwise similarities of one s face signatures. Plot represents 71 images in Britney Spears face model. Plot represents 141 images in Barack Obama s face model. In this embodiment it is evident that Britney Spears has either various canonical appearances or her model is consistently polluted as the distribution for Barack Obama indicates that images of him are mostly similar are changing slightly from one to another and are usually the same appearance.

As such the graph Laplacian L is used only to determine the model order k. The eigenvalues of L are sorted in descending order with 1 1 and the rest of eigenvalues decrease to zero. The distribution of eigenvalues is used as an estimate of the distortion or pollution of the model M. If the remaining eigenvalues fall off too quickly then it is assumed that Mis not polluted and all of its members have strong support among its neighbors. If however some eigenvalues are indeed large e.g. then k is determined by the number of eigenvalues that are greater than .

In an embodiment with the appropriate model order k the entries in Mare clustered using agglomerative clustering. Iterative binary clustering can be chosen over k way clustering since multiway performs better only when the original data is not noisy and the chosen k k. Since the data can be wrongly labeled iterative binary clustering is more appropriate in this case. Faces in Mcan be clustered using hierarchical clustering with average linking using the following similarity function 

Instead of simply using a pairwise similarity S in an embodiment a more global similarity metric can be used that considers a cumulative similarity between right arrow over and the rest of faces in M.

Once Mis partitioned into clusters C. . . C an outlier cluster is chosen. The outlier selection may be done either by the statistics of the clusters e.g. cluster size entropy average cluster image rank or average duplicate count computed in the previous stages or by comparing to the model M where q q . Mainly the cluster that is most similar to M 

In an embodiment of the present invention a representative image of a person is automatically selected. A representative image of a person is defined by a set of similarity features e.g. face signatures clothing sunglasses hair color backdrop etc. from the set of images and corresponding feature vectors discussed above.

Selecting a representative image based on facial features can be accomplished by first clustering the facial images of the person of interest based on face similarity. As known to one of skill in the art any of several clustering algorithms can be used e.g. any pairwise or central method to create the clusters. As an example a mean shifting clustering can be used to first create clusters using each of the faces as a pivot. All faces with at least a threshold similarity e.g. 90 to the pivot face would be added to that cluster. Such a process can result in the same face being present in multiple clusters. Duplicate faces can be removed from a smaller cluster while clusters that include a number of faces exceeding a minimum threshold e.g. 10 can be referred to as good clusters. Further discussion of clustering techniques are described in greater detail in U.S. patent application Ser. No. 12 172 939 entitled Method And System For Automated Annotation Of Persons In Video Content which is incorporated by reference herein in it entirety.

An image from the largest cluster or any of the good clusters can then be identified as a representative image. In the case where there are no good clusters a representative image can be chosen from the largest cluster.

In an embodiment a representative image is configured to include only a headshot image e.g. not a full body image or group image. The selection of a headshot representative image is based on a scoring algorithm. For example when a cropping of an image is not allowed or not possible each image is given a noimalized headshot score based on the portion of the image that depicts the face of the person of interest. Therefore a group photo will have a smaller score than that of a portrait photo. Further if a particular image aspect ratio is desired then the chosen image is extended along one of the dimensions to fit the desired aspect ratio. The extended image dimensions are used in the headshot score computation. A representative headshot image is chosen based on the highest scoring image where the optimal choice is an image taken from among the good clusters. However if no good clusters are available then the highest scoring image from all images is selected. If there are several images with the same highest score then the image from the largest cluster is selected.

This section describes according to an embodiment of the present invention the process of recognition using the constructed biometric models. In an embodiment a classification approach is chosen that is able to pass through an entire training dataset in close to real time. As latency is an issue for large scale datasets recognition can be performed with a variant of the nearest neighbor classifier.

In an embodiment given a query image I the feature vector right arrow over is compared to all images in the training data. With the same similarity metric as in training the first k most similar images for all Q categories are chosen. The final selection of face label for the query is based on the following assumptions. First since the training data is not guaranteed to be accurate there may be incorrectly labeled images that would have a very high similarity with the query image thus finding a single most similar image in training and transferring its label is not optimal. Second if the model Mis chosen to identify with the highest average similarity to right arrow over then due to variable model sizes and uncertainty of training labels the average similarity across all models is almost uniform. Thus in an embodiment a distance function is chosen that is in between the two extremes 

Recognition of faces in the wild is inherently an open set problem where the celebrity depicted in a query image might not be amongst those known by the recognition system. To address this in an embodiment a recognition likelihood threshold is introduced. If the similarity with the best matching celebrity model does not exceed this threshold sim I q 

In an experiment corresponding to an exemplary embodiment in order to evaluate the performance of the recognizer a set of manually annotated query images was selected and the recognizer was used to propose either a celebrity name or unknown for each image. The performance was measured using two numbers precision the fraction of proposed names that were correct and recall the fraction of correct names proposed from amongst all images belonging to a celebrity known by the recognizer . Precision and recall vary depending on the choice of a recognition likelihood threshold e.g. a higher threshold produces higher precision but lower recall. Thus the precision and recall was evaluated for a range of thresholds. The result is summarized with precision versus recall plots in .

The goal of the experiment was to recognize faces of people using ordinary images including those with low resolution and poor imaging conditions. Therefore experimentation was done on three different and natural datasets. As described herein the performance of the exemplary embodiment will be compared to state of the art approaches using a test set of images using a mobile device with a 1 mega pixel camera to replicate real life user experiences and report recognition results of various stages of the exemplary embodiment as well as other approaches. The performance of the exemplary embodiment will also be compared to that of the most related work and test data of Names and Faces by Berg Berg Edwards Maire Teh Learned Miller and Forsyth Berg et al. .

In accordance with an embodiment of the present invention in order to determine the scalability and realistic performance of the algorithms presented above a list of approximately 30 000 names was constructed. For a test over 1000 names were picked from the list and face images were acquired for each corresponding name. Purposefully the images were acquired in variable lighting and poses ranging from face shots on magazine covers to television screens. All images were taken with a mobile phone having a 1 mega pixel camera. In the test the performance of the approach was compared at various stages of the pipeline and was also compared to the raw output from the image system which in this test was Google Image Search GIS . In particular models were compared that were built using 20 and 50 results from GIS with face filter turned on GIS top 20 50 faces models built only using the first stage of the pipeline nearest neighbor grouping Intra model models built using first two stages of the pipeline that includes duplicate removal Inter model and finally models built using the entire pipeline Spectral . In addition the performance was compared using an algorithm on the same dataset developed by Zhao et al. In 20082008. 8. on 2008 incorporated herein by reference in its entirety. The precision recall curves are shown in with line indicating GIS top 20 faces line indicating GIS top 50 faces line indicating consistency line indicating consistency with neardupes line indicating inter model line indicating spectral and line indicating intra model.

In comparison with the raw output of GIS it is evident that varying the size 20 or 50 of the GIS output does not result in substantial input. In fact increasing GIS output only decreases the signal to noise ratio and leads to less accurate biometric models and worse recognition. Using the presented pipeline however as many images as possible were extracted from GIS with the upper limit of 1000 using the various stages of the pipeline to eliminate falsely labeled images.

Aside from comparing the contributions of each stage of the pipeline to the recognition accuracy the time required to train each stage and the resultant model size delivered by each stage were considered. The runtime and size are given below in Table 1. The consistency learning of Zhao et al. has the same order of complexity O n as the Inter model stage of the pipeline where n is the number of faces. However due to its sampling strategy that may be O 1000 n where 1000 is the number of random samples while Inter model analysis is O 1 n . More importantly the Inter model analysis is deterministic unlike the consistency learning scheme. In practice consistency learning the only other approach for large scale face recognition is over 3 fold slower than the approach in this exemplary embodiment combining Intra model Inter model and Spectra and results in over 11 worse recognition rate improvement in F measure .

To compare the performance of the approach in the exemplary embodiment to other methods and test sets the recognition experiment of Berg et al. was repeated. Berg et al. selected 1000 random images from their dataset with associated news captions. Using a language model coupled with a face recognizer a name from the caption was chosen as the label for the given face. To mimic this experiment it was required that all true names in test data are present in the name list for training. Two different versions of training data were used generic and specific. The generic training included a name list of approximately 30 000 names to train the respective biometric models without any supervision while the specific training only contained the names that were present in the test set the standard in the computer vision community. For the test data two versions were also created test 1 and test 2. Some of the labels for test images provided by Berg et al. were of the form christian palestinian and young afghan. These labels are not unique names of people and clearly do not produce a deterministic set of results if used as a query to GIS. Therefore a few test images with such labels were removed from the test data for test 1. In test 2 images with labels that did not produce significant response in GIS were also removed. illustrates the ROC curves and shows the performance of the two training and test sets described above with line illustrating the Berg only training test 1 line illustrating the Berg only training test 2 line illustrating the generic training test 1 and line illustrating the generic training test 2. A summary of the performance statistics is shown below in Table 2.

If however reversion is made to the traditional training schemes and guarantees that the training set contains exactly the categories that are present in the test Specific Training test 1 then the exemplary embodiment performs equally well with Berg et al. while solving a more general problem that is not constrained by the news captions and language models. Finally if it is required that there must exist training data for all test categories a fair requirement then test 2 is defined. In this case the exemplary embodiment significantly outperformed Berg et al. and yielded a recognition system whose precision dropped only 10 throughout the entire recall domain.

Due to the statistical nature of the presented algorithms and the reliance on an imperfect source of annotated images e.g. GIS there are a number of avenues by which mistakes can enter the instant trained celebrity models thereby producing incorrect recognition results.

The first and most common of these is the problem of models for less famous celebrities becoming polluted with faces of more famous celebrities with whom they are closely associated. For example while the model for Sarah Palin is clean containing 78 images without mistakes the model for her less notable daughter Bristol Palin contains 7 images of her mother. As a result some query images of Sarah Palin will be incorrectly recognized as Bristol not because there is any problem with Sarah Palin s model but rather because another model has mistakes. This problem can be attributed to the fact that in this example GIS results for less notable people are inherently noisier. Interestingly models of two strongly associated but extremely famous celebrities such as Brad Pitt and Angelina Jolie do not show this problem likely due to the high signal to noise ratio in their individual GIS results.

A second issue is the use of canonical names when issuing GIS queries. For example Prince Henry of Wales returns relatively few noisy results producing a model that contains only a single face whereas the more colloquial Prince Harry would return a significantly more comprehensive collection. As a result of this impoverished model inter model analysis is unable to remove faces of the Prince from the model of his love interest Chelsy Davy. This problem could be caused by collecting GIS results for each of a celebrity s aliases and selecting the best model or aggregating the results.

Other categories which can be problematic include fashion designers whose GIS results are dominated by photos of others wearing their creations and celebrities wearing sunglasses which can occasionally be confused by the face similarity function.

System interface can exist on a device that includes at least one processor at least one memory and at least one network interface. For example system interface can be implemented on a personal computer handheld computer personal digital assistant a mobile communication device a game console digital entertainment system set top box and the like.

Face recognition detector can exist on a server and can include a web server such as the Google Web Server from Google Inc. Apache Web Server from the Apache foundation Internet Information Services from Microsoft and the like. Face recognition detector can provide access to web content stored locally or on coupled storage devices not shown . Face recognition detector typically includes at least one server computer connected to a network. Example server computers include but are not limited to a computer workstation distributed computing system computer cluster embedded system stand alone electronic device networked device mobile device e.g. mobile phone or mobile computing device rack server set top box or other type of computer system having at least one processor memory and network interface.

Face recognition detector can also access an image video corpus and an article corpus . Some or all of corpora and may be accessible through a network such as for example a wide area network WAN like the Internet or a local area network LAN or may be located locally on a user s own system. Corpora and may each include one or more storage devices that are co located or distributed. In some embodiments corpora and may be co located in part or in whole. Face recognition detector may be coupled to network through any connection including for example and without limitation a communications bus Ethernet and a wireless communication standard. Image video corpus may include images in any image format such as JPEG Exif TIFF RAW PNG GIF BMP PPM CGM SVG PNS JPS and MPO. Image video corpus includes images of persons. Article corpus includes for example article archives web based services and repositories accessible locally and or over the Internet. Available article archives may include for example and without limitation ASCII text PDF text and other forms of text.

Face recognition detector is also coupled to a name database and an image database over connections and respectively. Name database includes name lists of celebrities identified and ranked by face recognition detector based on at least names identified in articles available in article corpus . Such generation of name lists will be further described with respect to below. Image database includes face images from any type of image content including still images and video images for persons in a name list of celebrities represented in name database . Face images in image database are generated and identified at least on images found in image video corpus . As used in this disclosure database refers to any collection of data elements and associated storage and access mechanisms. Connections may use one or more connection methods such as for example a communications bus Ethernet and wireless communications standards.

Face recognition detector can include several components including a name list generator a face signature detector and a person model learning system . Face recognition detector and some or all of the sub systems and may be implemented in software hardware or any combination thereof. For example face recognition detector may be implemented as executable code on a central processor unit not shown in . In another embodiment face recognition detector may be implemented in a hardware component such as a Field Programmable Gate Array. A person skilled in the art would understand that face recognition detector may be implemented in one or more platforms.

Name list generator generates a list of names of prominent celebrities that the system will attempt to recognize. The list of names or name list is generated based on articles from article corpus . Name list generator filters the articles from article corpus to only include those articles that describe people. Name list generator ranks the names in the name list based on the number of face images returned by an image search that is described in more detail below.

Face signature detector removes non face images from the initial images generated by name list generation detector and is described in more detail below.

Person model learning system takes as input the face images produced by face signature detector and generates highly accurate biometric models for the individuals identified in the name list. Person model learning system uses a series of analysis sub systems to further refine the name and image association that ultimately generates a name associated with a queried face or indicates that the queried face is unknown. 

Name list generator sub system generates a list of names based on articles found in article corpus . Name list generator sub system identifies articles in article corpus selecting and filtering only those articles that contain names of people. Once a list of names is obtained image collector collects a set of images from any type of image content e.g. still and or video and corresponding feature vectors for each name. This is accomplished for example by issuing an image search to image video corpus . In an embodiment image collector contains a threshold value of the number of images returned for each query which it will not exceed. Image collector detects faces in each image extracting feature vector and putatively labels each feature vector with the query from which it was obtained. Name ranker then ranks the names in the name list based on the number of face images identified by image collector .

Feature detection sub system uses for example a fast sliding window approach over a range of window sizes employing a linear combination of a heterogeneous set of feature detectors as previously discussed. In an embodiment landmarker sub system can be used to further refine face detection by pinpointing facial feature locations within a face bounding box. Face probability sub system then extracts features at the locations identified by landmarker sub system in order to obtain a refined score that indicates the probability of a face being present. Face detection sub system then determines based on at least the detected features and probabilities of a face being present that a face has indeed been detected.

Intra model analyzer sub system effects the first phase of removing incorrectly labeled face signatures from face signature detector . Intra model analyzer sub system examines all the face images associated with a single name in the name list deciding which faces to discard without considering the faces belonging to other names. The task of intra model analyzer sub system is to remove obvious outliers where faces that are very dissimilar from the majority of other faces associated with a particular name are removed.

Given a group of face signatures all labeled with the same celebrity name intra model analyzer sub system for each face counts the number of neighbors and the number of near duplicates in the group. In an embodiment a neighbor is defined as a face with distance less than a value e.g. 0.2 and a near duplicate has a distance less than a second value e.g. 0.01 where distances range from a minimum of 0.0 to a maximum of 1.0. Intra model analyzer then discards all faces with less than a third value e.g. 10 neighbors. Finally intra model analyzer sub system removes near duplicate faces from the group by sorting the faces in decreasing order based on the number of near duplicates it has in the group. For each face in the sorted list the decision is made to discard it if it has a near duplicate appearing earlier in the list otherwise it is retained.

Inter model analyzer sub system receives the collection of labeled faces from intra model analyzer sub system and attempts to further remove incorrectly labeled entries by comparing faces annotated with different names. Inter model analyzer sub system identifies and removes faces associated with a name in the name list that have been incorrectly labeled with another name from the name list.

If the name list contains two near duplicate faces with different labels then almost certainly one or both of the labels is incorrect and the face cannot be used to reliably label incoming query faces. Inter model analyzer sub system at this stage aims to resolve near duplicate faces by considering all faces in the collection in a pairwise manner. For each pair if the faces have a distance less than a value e.g. 0.01 and the labeled celebrity names disagree then the face with the smallest near duplicate count as calculated by Intra model analyzer sub system is marked for later removal. Once all face signature pairs have been considered the faces marked for removal are discarded from the collection. However this formulation compares each face against every other face in the collection. Thus is it possible for a single face signature to lose during some comparisons or be marked for removal and win other comparisons. Face signatures are discarded by inter model analyzer from the collection if they lose during any comparison.

Spectral analyzer sub system effects the final stage of analysis and uses two components. The first component is based on intra person comparisons and the second component is based on inter person comparisons. Spectral analyzer using an intra person comparison considers the collection of images for each person individually. Spectral analyzer constructs a distance matrix to describe the pairwise relationships between all of the images of one person. The distance matrix is transformed into a graph Laplacian matrix and its spectrum is analyzed. If the second eigenvalue of the graph Laplacian is less than the Eigen gap e.g. set to 0.4 then no clustering of the collection is performed. Otherwise if the second eigenvalue is larger than the Eigen gap then the collection is partitioned into two clusters using Average Agglomerative Clustering. One of the two clusters is discarded as outliers. The cluster selection is done either by the statistics of the clusters e.g. cluster size or average in class image rank or average duplicate count computed in the previous stages or by comparing to the image collections of other people. An embodiment using a light version of such a comparison is performed with the collection of images of the person who has a higher identifier overlap with the current person. Note before the comparison of clusters is performed a dominance may be established between the current collection and the one with the highest identifier overlap. Dominance may be computed by analyzing the spectrum of the graph Laplacian of each collection. The collection having the higher second eigenvalue is considered dominant. In another embodiment using a full version the comparison is done with the collections of all persons in the name list.

Spectral analyzer using an inter person comparison can use a light embodiment and also a full version embodiment. The inter person light embodiment examines the similarity of each image in the collection to the remainder of the collection and to all of images in the collection of the person with whom most identifiers are shared. If the images similarity to one collection is less than that of another collection then the given image is considered an outlier. In the full version embodiment the same comparison is performed except that all other collections are considered recursively not just the one with highest identifier overlap.

Recognition sub system performs the final decision regarding whether a queried face is recognized or unknown. In an embodiment as previously described recognition sub system uses a recognition likelihood threshold value. If the similarity with the best matching face image does not exceed the threshold value recognition sub system declines to recognize the queried face and report the queried face as unknown. Otherwise recognition sub system presents those recognized faces with the associated corresponding names.

Aspects of the present invention shown in or any part s or function s thereof may be implemented using hardware software modules firmware tangible computer readable media having instructions stored thereon or a combination thereof and may be implemented in one or more computer systems or other processing systems.

If programmable logic is used such logic may execute on a commercially available processing platform or a special purpose device. One of ordinary skill in the art may appreciate that embodiments of the disclosed subject matter can be practiced with various computer system configurations including multi core multiprocessor systems minicomputers mainframe computers computer linked or clustered with distributed functions as well as pervasive or miniature computers that may be embedded into virtually any device.

For instance at least one processor device and a memory may be used to implement the above described embodiments. A processor device may be a single processor a plurality of processors or combinations thereof. Processor devices may have one or more processor cores. 

Various embodiments of the invention are described in terms of this example computer system . After reading this description it will become apparent to a person skilled in the relevant art how to implement the invention using other computer systems and or computer architectures. Although operations may be described as a sequential process some of the operations may in fact be performed in parallel concurrently and or in a distributed environment and with program code stored locally or remotely for access by single or multi processor machines. In addition in some embodiments the order of operations may be rearranged without departing from the spirit of the disclosed subject matter.

Processor device may be a special purpose or a general purpose processor device. As will be appreciated by persons skilled in the relevant art processor device may also be a single processor in a multi core multiprocessor system such system operating alone or in a cluster of computing devices operating in a cluster or server faun. Processor device is connected to a communication infrastructure for example a bus message queue network or multi core message passing scheme.

Computer system also includes a main memory for example random access memory RAM and may also include a secondary memory . Secondary memory may include for example a hard disk drive removable storage drive . Removable storage drive may comprise a floppy disk drive a magnetic tape drive an optical disk drive a flash memory or the like. The removable storage drive reads from and or writes to a removable storage unit in a well known manner. Removable storage unit may comprise a floppy disk magnetic tape optical disk etc. which is read by and written to by removable storage drive . As will be appreciated by persons skilled in the relevant art removable storage unit includes a computer usable storage medium having stored therein computer software and or data.

Computer system optionally includes a display interface which can include input output devices such as keyboards mice etc. that forwards graphics text and other data from communication infrastructure or from a frame buffer not shown for display on display unit .

In alternative implementations secondary memory may include other similar means for allowing computer programs or other instructions to be loaded into computer system . Such means may include for example a removable storage unit and an interface . Examples of such means may include a program cartridge and cartridge interface such as that found in video game devices a removable memory chip such as an EPROM or PROM and associated socket and other removable storage units and interfaces which allow software and data to be transferred from the removable storage unit to computer system .

Computer system may also include a communications interface . Communications interface allows software and data to be transferred between computer system and external devices. Communications interface may include a modem a network interface such as an Ethernet card a communications port a PCMCIA slot and card or the like. Software and data transferred via communications interface may be in the form of signals which may be electronic electromagnetic optical or other signals capable of being received by communications interface . These signals may be provided to communications interface via a communications path . Communications path carries signals and may be implemented using wire or cable fiber optics a phone line a cellular phone link an RF link or other communications channels.

In this document the terms computer program medium and computer usable medium are used to generally refer to media such as removable storage unit removable storage unit and a hard disk installed in hard disk drive . Computer program medium and computer usable medium may also refer to memories such as main memory and secondary memory which may be memory semiconductors e.g. DRAMs etc. .

Computer programs also called computer control logic are stored in main memory and or secondary memory . Computer programs may also be received via communications interface . Such computer programs when executed enable computer system to implement the present invention as discussed herein. In particular the computer programs when executed enable processor device to implement the processes of the present invention such as the stages in the method illustrated by flowchart of discussed above. Accordingly such computer programs represent controllers of the computer system . Where the invention is implemented using software the software may be stored in a computer program product and loaded into computer system using removable storage drive interface and hard disk drive or communications interface .

Embodiments of the invention also may be directed to computer program products comprising software stored on any computer useable medium. Such software when executed in ode or more data processing device causes a data processing device s to operate as described herein. Embodiments of the invention employ any computer useable or readable medium. Examples of computer useable mediums include but are not limited to primary storage devices e.g. any type of random access memory secondary storage devices e.g. hard drives floppy disks CD ROMS ZIP disks tapes magnetic storage devices and optical storage devices MEMS nanotechnological storage device etc. .

It is to be appreciated that the Detailed Description section and not the Summary and Abstract sections is intended to be used to interpret the claims. The Summary and Abstract sections may set forth one or more but not all exemplary embodiments of the present invention as contemplated by the inventor s and thus are not intended to limit the present invention and the appended claims in any way.

The present invention has been described above with the aid of functional building blocks illustrating the implementation of specified functions and relationships thereof. The boundaries of these functional building blocks have been arbitrarily defined herein for the convenience of the description. Alternate boundaries can be defined so long as the specified functions and relationships thereof are appropriately performed.

The foregoing description of the specific embodiments will so fully reveal the general nature of the invention that others can by applying knowledge within the skill of the art readily modify and or adapt for various applications such specific embodiments without undue experimentation without departing from the general concept of the present invention. Therefore such adaptations and modifications are intended to be within the meaning and range of equivalents of the disclosed embodiments based on the teaching and guidance presented herein. It is to be understood that the phraseology or terminology herein is for the purpose of description and not of limitation such that the terminology or phraseology of the present specification is to be interpreted by the skilled artisan in light of the teachings and guidance.

The breadth and scope of the present invention should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

