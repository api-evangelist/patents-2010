---

title: User interfaces for content categorization and retrieval
abstract: Methods, systems, and computer-readable media provide a scenario desktop for recording a current event scenario and a content desktop for presenting information about a previously recorded event scenario. When a first event scenario is detected on the mobile device, the scenario desktop is presented on the mobile device. The scenario desktop exists in parallel with a default primary desktop of the mobile device. An information bundle is created for the first event scenario, including one or more documents accessed through the scenario desktop during the first event scenario. Access to the one or more documents is automatically provided on the mobile device during a second event scenario related to the first event scenario. The access is provided through the content desktop existing in parallel with the primary desktop and the scenario desktop.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09251506&OS=09251506&RS=09251506
owner: Apple Inc.
number: 09251506
owner_city: Cupertino
owner_country: US
publication_date: 20100105
---
This subject matter is generally related to user interfaces for content categorization and retrieval on a mobile device.

Modern mobile devices such as smart phones have become an integral part of people s daily lives. Many of these mobile devices can support a variety of applications. These applications can relate to communications such as telephony email and text messaging or organizational management such as address books and calendars. Some mobile devices can even support business and personal applications such as creating presentations or spreadsheets word processing and providing access to websites and social networks. All of these functions applications can produce large volumes of information that needs to be organized and managed for subsequent retrieval.

Conventional methods for organizing and managing information include allowing the user to store information or content into directories and folders of a file system and use descriptive metadata keywords or filenames to name the directories and folders. Information can be subsequently retrieved and presented to the user in response to the user manually navigating through the directories and folders of the file system or to user entered search queries. This manual information categorization and retrieval can be laborious and time consuming.

Methods systems and computer readable media for providing a scenario desktop for recording a current event scenario occurring in association with e.g. in proximity to a mobile device and a content desktop for presenting information about a previously recorded event scenario are disclosed. An event scenario is defined by one or more participants and one or more contextual cues concurrently monitored by the mobile device and observable by a human user of the mobile device. When a first event scenario is detected on the mobile device the scenario desktop is presented on the mobile device. The scenario desktop can exist in parallel with a default primary desktop of the mobile device. An information bundle is created e.g. in real time for the first event scenario. The information bundle identifies for example one or more documents accessed through the scenario desktop during the first event scenario and retrievable based on the one or more contextual cues. Access to the one or more documents can be automatically provided on the mobile device during a second event scenario that is related to the first event scenario through the one or more common contextual cues. The access to the documents can be provided through a content desktop that exists in parallel with the primary desktop and the scenario desktop. Other scenario based content retrieval and presentation methods are also disclosed.

In various implementations the methods and systems disclosed in this specification may offer none one or more of the following advantages.

In one example an alternate desktop environment e.g. the scenario desktop can be presented in parallel with a default desktop environment e.g. the primary desktop during recording of an event scenario. The alternate desktop environment can provide all the functions available through a default system desktop e.g. the primary desktop and various controls for monitoring and annotating the contextual cues present in the event scenario. The parallel existence of the scenario desktop and the primary desktop can allow the user to confine operations e.g. document accesses relevant to the current event scenario in a dedicated desktop environment and exclude operations carried out in the primary desktop from the recording of the current event scenario.

In addition the dedicated scenario desktop can be free of the clutter and irrelevant items scattered on the default system desktop thereby reducing distraction to the user during the current event scenario. Furthermore the user can monitor and provide annotations in real time to describe the current event scenario. No subsequent categorization is needed so backlog of organization tasks can be reduced.

In one example documents associated with a past event scenario can be automatically retrieved and presented to the user during an occurrence of a related event scenario. The documents can be presented in an alternate desktop environment e.g. a content desktop in parallel with the primary desktop and the scenario desktop. The content desktop can restrict access to only those documents that are associated with a specific previously recorded event scenario. Because the primary desktop the scenario desktop and the content desktop s exist in parallel the user is less likely to get confused as to what document he or she is currently reviewing.

The details of one or more embodiments of the subject matter described in the specification are set forth in the accompanying drawings and the description below. Other features aspects and advantages of the subject matter will become apparent from the description the drawings and the claims.

In some implementations the mobile device includes a touch sensitive display . The touch sensitive display can be implemented with liquid crystal display LCD technology light emitting polymer display LPD technology or some other display technology. The touch sensitive display can be sensitive to haptic and or tactile contact with a user. In addition the device can include a touch sensitive surface e.g. a trackpad or a touchpad .

In some implementations the touch sensitive display can be multi touch sensitive display. The multi touch sensitive display can for example process multiple simultaneous touch points including processing data related to the pressure degree and or position of each touch point. Such processing facilitates gestures and interactions with multiple fingers chording and other interactions. Other touch sensitive display technologies can also be used e.g. a display in which contact is made using a stylus or other pointing device.

A user can interact with the device using various inputs. Example inputs include touch inputs and gesture inputs. A touch input is an input where a user holds his or her finger or other input tool at a particular location. A gesture input is an input where a user moves his or her finger or other input tool . An example gesture input is a swipe input where a user swipes his or her finger or other input tool across the screen of the touch sensitive display . In some implementations the device can detect inputs that are received in direct contact with the display or that are received within a particular vertical distance of the display e.g. within one or two inches of the display . Users can simultaneously provide input at multiple locations on the display . For example inputs simultaneously touching at two or more locations can be received.

In some implementations the mobile device can display one or more graphical user interfaces e.g. default system desktop on the touch sensitive display for providing the user access to various system objects and for conveying information to the user. In some implementations the default system desktop can include one or more display objects that represent system objects including various device functions applications windows files alerts events or other identifiable system objects. In this particular example the system desktop includes display object for an address book application display object for a file folder named work display object for a camera function on the device and display object for a destination for deleted files e.g. a trash can . Other display objects are possible.

In some implementations the display objects can be configured by a user e.g. a user may specify which display objects are displayed and or may download additional applications or other software that provides other functionalities and corresponding display objects. In some implementations the display objects can be dynamically generated and presented based on the current context and inferred needs of the user. In some implementations the currently presented display objects can be grouped in a container object such as task bar .

In some implementations the mobile device can implement multiple device functionalities such as a telephony device an e mail device a map device a WiFi base station device and a network video transmission and display device. As part of one or more of these functionalities the device can present graphical user interfaces on the touch sensitive display of the mobile device and also responds to input received from a user for example through the touch sensitive display . For example a user can invoke various functionalities by launching one or more programs on the device e.g. by touching one of the display objects in the task bar of the device . A user can alternatively invoke particular functionality in other ways including for example using one of the use selectable menus included in the system desktop . In some implementations particular functionalities are automatically invoked according to the current context or inferred needs of the user as determined automatically and dynamically by the mobile device for example as described in herein.

Once a program has been selected one or more windows or pages corresponding to the program can be displayed on the system desktop of the device . A user can navigate through the windows or pages by touching appropriate locations on the system desktop through the touch sensitive display . For example the window corresponds to an email application. The user can interact with the window using touch input much as the user would interact with the window using mouse or keyboard input. For example the user can navigate through various folders in the email program by touching one of the user selectable controls corresponding to the folders listed in the window As another example a user can specify that he or she wishes to reply forward or delete the current e mail by touching one of the user selectable controls present on the display.

In some implementations notifications can be generated by the operating system or applications residing on the mobile device . For example the device can include internal clock and notification window of a scheduled calendar event can be generated by a calendar application and presented on the system desktop at a predetermined time e.g. 5 minutes before the scheduled time of the calendar event.

In some implementations upon invocation of a device functionality the system desktop of the mobile device changes or is augmented with other user interface elements to facilitate user access to particular functions associated with the corresponding device functionality. In some implementations the system desktop is replaced with an alternate desktop e.g. a scenario specific desktop based on the current context and the inferred needs of the user at the moment as described herein.

In some implementations the mobile device can implement network distribution functionality. For example the functionality can enable the user to take the mobile device and provide access to its associated network while traveling. In particular the mobile device can extend Internet access e.g. WiFi to other wireless devices in the vicinity. For example the mobile device can be configured as a base station for one or more devices. As such the mobile device can grant or deny network access to other wireless devices.

In some implementations the mobile device may include circuitry and sensors for supporting a location determining capability such as that provided by the global positioning system GPS or other positioning systems e.g. systems using WiFi access points television signals cellular grids Uniform Resource Locators URLs . In some implementations a positioning system e.g. GPS receiver can be integrated into the mobile device or provided as a separate device that is coupled to the mobile device through an interface e.g. port device to provide access to location based services. In some implementations the positioning system can provide more accurate positioning within a building structure for example using sonar technologies.

In some implementations the mobile device can include one or more input output I O devices and or sensor devices. For example speaker and microphone s can be included to facilitate voice enabled functionalities such as phone and voice mail functions.

In some implementations proximity sensor can be included to facilitate the detection of the proximity or distance of the mobile device to a user of the mobile device . Other sensors can also be used. For example in some implementations ambient light sensor can be utilized to facilitate adjusting the brightness of the touch sensitive display . In some implementations accelerometer can be utilized to detect movement of the mobile device as indicated by the directional arrows.

In some implementations the port device e.g. a Universal Serial Bus USB port or a docking port or some other wired port connection can be included. The port device can for example be utilized to establish a wired connection to other computing devices such as other communication devices network access devices a personal computer a printer a display screen or other processing devices capable of receiving and or transmitting data. In some implementations the port device allows the mobile device to synchronize with a host device using one or more protocols such as for example the TCP IP HTTP UDP and any other known protocol.

The mobile device can also include one or more wireless communication subsystems such as 802.11b g communication device and or Bluetooth communication device . Other communication protocols can also be supported including other 802.x communication protocols e.g. WiMax WiFi 3G code division multiple access CDMA global system for mobile communications GSM Enhanced Data GSM Environment EDGE etc.

In some implementations the mobile device can also include camera lens and sensor . The camera lens and sensor can capture still images and or video. In some implementations the camera lens can be a bi directional lens capable of capturing objects facing either or both sides of the mobile device. In some implementations the camera lens is an omni directional lens capable of capturing objects in all directions of the mobile device.

As described with respect to the example mobile device shown in a multifunction mobile device can detect events and changes occurring within the software environment of the mobile device through various state monitoring instructions. In addition the multi functional mobile device can also utilize various built in sensory capabilities to detect the current status or changes occurring to the mobile device s own physical state and or to the physical environment immediately surrounding the mobile device. These sensory capabilities make it possible for the mobile device to detect and record an event scenario in a way that mimics how a human user of the mobile device would perceive interpret and remember the event scenario.

Because each aspect of an event scenario experienced by the human user can potentially be used by the brain as a memory cue to later retrieve other pieces of information conveyed to the user during the event scenario by recognizing and recording these event scenarios on the mobile device the mobile device can facilitate the organization and retrieval of relevant and useful information for the user. User interfaces that facilitate the recording and subsequent retrieval and presentation of the event scenarios are disclosed herein.

In some implementations the monitoring of the software environment and physical status of the mobile device and the physical environment immediate around the mobile device can be ongoing provided that enough computing resources are available to the mobile device. Alternatively some of the monitoring can start only after a record worthy event scenario has been detected.

The detection of a meaningful event scenario that warrants further processing and or a permanent record can be based on a number of indicators. For example a notification of the imminent start of a scheduled calendar event can be an indicator that a record worthy event scenario is about to occur. For another example presence of one or more of specially designated people e.g. best friends supervisors doctor accountant lawyer etc. can be used as an indicator for a record worthy event scenario. For yet another example detected presence of the mobile device in a specially designated location e.g. doctor s office the bank Omni Parker House conference room A etc. can also be used as an indicator for a record worthy event scenario. In some implementations the end of an event scenario can be detected according to the absence or expiration of all or some of the indicator s that marked the start of the event scenario. In addition to automatically triggered indicators such as those shown in the above examples manual triggers can also be used to mark the start of an event scenario. For example a software or hardware user interface element can be provided to receive user input indicating the start of an event scenario.

An event scenario can include a number of elements such as the people participating in the event scenario i.e. the participants the location at which the participants are gathered the start and end times of the event scenario the purpose or subject matter of the gathering the virtual and or physical incidents that ensued during the event scenario the information and documents accessed during the event scenario various characteristics of the environment or setting of the event scenario and so on.

In the example scenario shown in three people e.g. Scott Adler Penny Chan and James Taylor have gathered in a conference room e.g. conference room A for a scheduled group meeting. This meeting is one of a series of routine meetings. The scheduled time for the group meeting is 11 00 am every day and the meeting is scheduled to last an hour. An electronic meeting invitation had previously been sent to and accepted by each group member. The team leader e.g. Scott Adler has sent an email to each team member stating the agenda for this meeting is to discuss product quality issues. During this meeting one or more persons will generate some notes share some sales data and other product issue related information and have a discussion about the particular product quality issues raised by the participants. A proposed solution to collaborate with a quality assurance partner will be proposed and his contact information is provided to the other team members.

In this example each user present at the meeting can carry a respective mobile device e.g. devices and that implements a scenario based content categorization retrieval and presentation method described herein. The mobile device e.g. device can be a mobile device described with respect to that includes touch sensitive display and a variety of sensors and processing capabilities for gathering information about the physical environment surrounding the mobile device.

In this example as the scheduled meeting time approaches notification window can be generated and presented within a default system desktop partially shown of the mobile device . The notification window indicates that a meeting is about to start e.g. in 1 minute . Other information such as the subject the date the start and end times the recurrence frequency the location and the invitees and so on can also be included in the notification window . This event notification generated by the user s electronic calendar can be used as an indicator that a record worthy event scenario is about to occur. When the mobile device detects such an indicator it can register the start of the event scenario.

Alternatively the user of the mobile device e.g. Scott Adler can set up an automatic trigger that detects the simultaneous presence of all group members e.g. Scott Adler Penny Chan and James Taylor and use that as an indicator for the start of the event scenario. For example when the device senses the presence of the devices associated the other two meeting participants e.g. devices and through some wireless communications device can register the start of the event scenario. In some implementations the presence of devices can be sensed using Bluetooth technology or Radio Frequency Identification RFID technology.

Alternatively the user of the mobile device can set up an automatic trigger that detects the presence of the mobile device in conference room A and use that as an indicator for the start of the event scenario. For example when the positioning system on the mobile device determines that its current location is in conference room A the mobile device can register the start of the event scenario.

Alternatively the user of the mobile device can set up an automatic trigger that detects not only the simultaneous presence of all group members but also the time e.g. 11 00 am and location e.g. Conference Room A and use that combination of facts as an indicator for the start of the event scenario.

Alternatively user interface element e.g. a TAG button can be displayed on the default system desktop of the mobile device . When the user e.g. Scott Adler touches the user interface element on the system desktop the mobile device can register this user input as an indicator for the start of the event scenario.

Other methods of detecting or recognizing indicators of recordable event scenarios are possible. For example in addition to having users specify the indicators the mobile device can process the previously entered indicators and or recorded scenarios to derive new indicators for event scenarios that may be of interest to the user.

After the mobile device detects the start of an event scenario the mobile device can employ its various perception capabilities to monitor and record its own virtual and physical statuses as well as the statuses of its surrounding physical environment during the event scenario until an end of the event scenario is detected.

In some implementations it is possible to monitor and record the event scenario in the background without user intervention and all user interactions within the default system operating environment e.g. through the default system desktop can be recorded and associated with the current event scenario. However in some implementations a dedicated scenario specific operating environment e.g. a scenario desktop can be provided e.g. in parallel to the default system operating environment e.g. the default system desktop such that only user interactions that occurred within the scenario specific operating environment are associated with the current event scenario.

In addition the scenario specific operating environment can provide controls for monitoring and recording various aspects e.g. the participants and contextual cues of the current event scenario and or can allow the user to provide real time annotations e.g. functional and descriptive labels for each aspect of the current event scenario.

For example on each of the primary desktop and scenario desktop one or more user interface elements e.g. indicators and can be presented to indicate which desktop is currently displayed on the display of the mobile device . In this particular example the indicator represents the primary desktop and the indicator represents the scenario desktop . In some implementations the user can touch and flick left or right on the touch sensitive display of the mobile device to switch between the primary desktop and the scenario desktop . One of the indicators and can be highlighted to indicate which desktop is currently displayed on the mobile device .

In some implementations the scenario desktop can be a fully functional operating environment that provides all the functions available through the primary desktop . For example the scenario desktop can show a task bar that includes the same display objects as the task bar shown in the system desktop . Other functions that can be made available through the scenario desktop can include for example search within the file system of the mobile device invocation of various software applications installed on the mobile device configuration of hardware and software components of the mobile device access e.g. opening editing creating annotating downloading sharing moving deleting etc. to various documents e.g. files information items webpages folders and directories stored on the mobile device or retrievable from a remote server and system operations e.g. network configuration process management and other operating system level configurations etc. .

In some implementations the scenario desktop can also provide a cleaned operating environment characterized by a presentation of no unorganized and or extraneous information items as might be associated with the primary desktop . For example the primary desktop may show scattered files and documents that are temporarily placed on the primary desktop running software applications e.g. email program and processes windows e.g. notification and other objects. These documents windows and other objects can be collected and placed at a designated location e.g. folder named primary desktop folder on the scenario desktop such that the scattered documents and objects can be accessed through the scenario desktop if needed but do not create visual clutter or distraction to the user during the recording of the current event scenario.

In some implementations the scenario desktop can include various user interface elements for controlling the recording of various aspects of the current event scenario. These user interface elements can be placed within container object on the scenario desktop . For example the container object can include participant control audio video recording control location control annotation control and one or more other controls . In some implementations the user can configure which controls are to be presented on the scenario desktop . For example even though lighting and weather conditions can be monitored and recorded by the mobile device during the event scenario the user may decide not to manually control these aspects of the recording and hence exclude controls for these aspects from the container object on the scenario desktop .

In some implementations during the recording of the current event scenario the user can invoke the participant control to reveal participant control window on the scenario desktop . The participant control window can display the participants identified in the current event scenario by the mobile device their respective identifiers e.g. names IDs email addresses etc. functional labels e.g. job title role in the event scenario etc. and descriptive labels e.g. gender race personal characteristics etc. obtained from various sources e.g. device IDs calendar entry address book entry audio transcript facial voice recognition from video audio recordings other information servers etc. . In some implementations the participant control user interface can also display links to various data items related to the participants such as their contact information and photos. In some implementations the participant control user interface can also allow the user to enter annotations about each participant. For example the user can enter descriptive text e.g. moody concerned big boss new guy etc. for one or more of the participants. The descriptive text can be used as identifiers functional and or descriptive labels for the participants.

In some implementations during recording of the event scenario the user can invoke the audio video recording control to reveal audio video control window on the scenario . In some implementations the audio video recording control window can include separate control elements for audio and video recordings. In some implementations the audio video recording control user interface can also include a control for capturing still images. In some implementations these images audio and video recordings can be streamed in real time to a remote server for storage and processing or stored and processed locally on the mobile device. Using the control elements the user can start pause or stop the recording at any time. The user can also mark particular segments of the recording and provide real time annotations for the particular segments of the recordings. In some implementations a transcript can be generated and displayed in real time for the audio recording of the event scenario. In some implementations the user can be given opportunity to annotate or make corrections to the audio transcript within the audio video recording control window .

In some implementations during recording of the event scenario the user can invoke the location control to reveal a location control window not shown on the scenario desktop . The location control window can display the location information that has been obtained by the positioning system on the mobile device such as a set of geographical coordinates a street address and or a room number. In some implementations the location control user interface can also allow the user to enter functional and descriptive labels for the current location e.g. meeting room red walls smelly room etc. .

In some implementations the scenario desktop can also include respective controls e.g. control for other sensory functions available on the mobile device . For example an ambient light sensor can be used to determine the lighting condition. Lighting condition can potentially be used to determine the mood or ambience in the room. Some included sensors may detect characteristics of the surrounding environment such as the ambient temperature air quality humidity wind flow etc. Other sensors may detect the physical state of the mobile device such as the orientation speed movement pattern and so on.

In some implementations during the recording of the event scenario the scenario desktop can present annotation interface for the user to enter keywords and other descriptive labels for the current event scenario. For example the user can enter text a tough meeting or everyone seems excited for the event scenario as a whole.

In addition to collecting information about the physical state of the mobile device and the surrounding environment the device s location the current time and the people present nearby the mobile device can also detect and record access to any documents through the scenario desktop during the current event scenario. A document can be an individual file e.g. a text or an audio file a collection of linked files e.g. a webpage an excerpt of a file or another document e.g. a preview of a text file a thumbnail preview of an image etc. a summary of a file or another document e.g. summary of a webpage embedded in its source code a file folder and or an data record of a software application e.g. an email an address book entry a calendar entry etc. . A user of the mobile device can access a document in a variety of manners such as by opening creating downloading sharing uploading previewing editing moving annotating executing receiving or searching the document.

In the example scenario shown in if the user of mobile device performs operations through the scenario desktop such as opening a file stored locally viewing a webpage online sharing a picture with the other participants sending an email making a call from the mobile device looking up a contact creating some notes e.g. through word processing application interface creating a file folder for the notes changing the filename of an existing file and executing a demo program the file the webpage the picture the email the call log and phone number the address book entry for the contact the file folder the file with its new name and the demo program can all be recorded as documents accessed during the current event scenario. In some implementations the particular mode of access is also recorded by the mobile device. For example the MAC address of a particular access point for WiFi access could be recorded.

In this example while recording of the event scenario continues if the user switches from the scenario desktop to the primary desktop and accesses a number of documents through the primary desktop these accesses through the primary desktop need not be recorded for the current event scenario. Therefore the separation and parallel existence of the scenario desktop and the primary desktop can offer the user the option to switch to the primary desktop during an event scenario to work on something unrelated to the current event scenario but without having the unrelated information associated with the current event scenario in a recording.

A mobile device can obtain much information about an event scenario either directly through built in sensors by processing recorded data querying other data sources by user s real time annotations or by sharing information with other devices. The different pieces of information can be associated with one another to form an information unit or information bundle for the event scenario. The information bundle includes not only a simple aggregation of data items associated with the event scenario but also metadata that describe each aspect of the event scenario where the metadata can be derived from the data items either individually or as a whole.

The creation of the information bundle can be carried out locally on the mobile device remotely on a server or partly on the mobile device and partly on the remote server e.g. a server for the content organization and retrieval service shown in .

As shown in the example event scenario is defined by one or more participants present in the example event scenario locally and or remotely . The example event scenario is further defined by a plurality of contextual cues describing the example event scenario . The contextual cues include the location and the time for the event scenario and various sensory characterizations . The various sensory characterizations include characterizations for the physical environment surrounding the mobile device and characterizations for the physical states of mobile device for example. Examples of the sensory characterizations include the ambient temperature the air quality the visual landmarks the audio landmarks and the weather of the surrounding environment the speed of the mobile device and other perceivable information about the mobile device and or its external physical environment.

In addition to the participants the location the time and the various sensory characterizations the event scenario is also defined by one or more subject matter or purpose for which the event scenario has occurred or came into being. The subject matter or purpose can be determined through the calendar entry for the event scenario or emails about the event scenario keywords extracted from the conversations that occurred during the event scenario and or documents accessed during the event scenario. An event scenario may be associated with a single subject matter multiple related subject matters or multiple unrelated subject matters.

In addition the event scenario is associated with a collection of documents . The collection of documents associated with the event scenario includes documents that were accessed or referred to during the event scenario . In some event scenarios no documents may be physically accessed by the user however recordings and new data items about the event scenario are created by the mobile device. These recordings and new data items can optionally be considered documents associated with the event scenario. In some implementations the mobile device may determine that certain documents are relevant based on the participants the subject matter the recordings and new data items created for the event scenario. These relevant documents can optionally be considered documents associated with the event scenario as well.

In order to create an information bundle e.g. information bundle metadata is generated automatically by the mobile device or by a remote server that receives the information e.g. the data items associated with the event scenario . The metadata include for example names identifiers functional labels descriptive labels and or detailed descriptions of each element of the event scenario . The identifiers functional labels and descriptive labels can be extracted from the accessed documents text transcripts of the recordings image analysis facial analysis voice analysis from other information servers from information bundles of other related event scenarios and so on.

Following the example shown in the information bundle can be created for the event scenario . In some implementations the information bundle can include data items collected in real time during the event scenario . The data items can include for example files web pages video and audio recordings images data entries in application programs e.g. email messages address book entry phone numbers notes shared documents GPS locations temperature data traffic data weather data and so on. Each of these data items are standalone data items that can be stored retrieved and presented to the user independent of other data items. The data items can include data items that existed before the start of the event scenario or created or obtained by the mobile device during the event scenario . In some implementations the data items can also include data items that are generated or obtained immediately after the event scenario such as shared meeting notes summary of the meeting transcripts of the recordings etc.

For each aspect and sub aspect e.g. elements of the event scenario depicted in the information bundle such as participants subject matter associated documents and contextual cues one or more identifiers can be derived from the data items or other sources.

For example for each participant the identifiers can include a name an employee ID an alias and or an email address of the participant. These identifiers are used to uniquely identify these participants. The identifiers for the subject matter can be the subject line if unique of the calendar entry for the meeting. The identifiers for the subject matter are unique keys for identifying the subject matter of the event scenario. In some cases a unique identifier can be generated and assigned to the subject matter.

In this example three documents were accessed through the scenario desktop during the event scenario . Depending on the document type the identifiers for each of these documents can be a filename a uniform resource location URL of the document e.g. a webpage an address book entry identifier an email message identifier and so on. The identifiers for a document uniquely identify the document for retrieval.

For a location the identifier can be a street address a set of geographical coordinates a building name and or a room number. In some implementations depending on what the location is the identifier can be a store name station name an airport name a hospital name and so on. The identifiers of the location uniquely identify the location at which the event scenario has occurred.

For the time associated with the event scenario the identifier can be a date and a time of day for example. For other contextual cues the identifiers can be used to uniquely identify those contextual cues. For example for the weather element of the event scenario the identifier can be weather on 12 11 09 in B town which uniquely identifies the weather condition for the event scenario. For other contextual cues such as a visual landmark the identifier can be automatically generated e.g. L or L for uniquely identifying the landmarks in the event scenario .

In addition to identifiers each aspect and sub aspect e.g. the elements of the event scenario can also be associated with one or more functional labels . The functional labels describe one or more functions of the participants subject matters documents location time and or other contextual cues. For example a functional label of a participant can be a professional title of the participant the participant s role in the event scenario and so on. The functional label of a subject matter can be the particular purpose of the event or gathering an issue to be addressed during the event scenario and so on. The functional label for a document can be a functional characterization of the content of the document particularly in the context of the event scenario. For example a function label for a document can be a sales report a product brochure promotional material a translation and so on.

Each functional label characterizes a function or purpose of an aspect of the event scenario particularly in the context of the event scenario. A functional label does not have to be uniquely associated with any particular data item or identifier. A search using a functional label may return more than one participant locations documents etc. in the same or different event scenarios.

In addition to identifiers and functional labels a number of descriptive labels can also be associated with each aspect or sub aspect the elements of the event scenario . For example each participant can be associated with one or more descriptive labels. These descriptive labels are descriptions that an observer of the event scenario is likely to use to describe the participants e.g. in physical appearances reputation characteristics and so on. For another example the descriptive labels associated with a document can include keywords associated with the document keywords describing a feature of the document e.g. funny well written and so on.

In some implementations descriptive labels can also be associated with other contextual cues. For example in addition to the functional label of the location for the event scenario a number of descriptive labels can be associated with the location as well. For example if the conference room A is also known as the red room because it has red walls then the keyword red walls can be associated with the location as a descriptive label.

The information bundle can be stored locally at the mobile device or remotely at a central server. Alternatively the metadata for many event scenarios can be put into an index stored at the mobile device or the remote server while the data items and or associated documents are stored at their original locations in the file system either on the mobile device or the remote server .

After an information bundle has been created for an event scenario and stored either locally at the mobile device or remotely at a central server the information bundle or the documents and data items referenced in the information bundle can be automatically retrieved and presented to the user of the mobile device e.g. during a current event scenario that is related to the previously recorded event scenario . In some implementations a separate content desktop can be presented for each retrieved information bundle in parallel with the primary desktop and the scenario desktop for the current event scenario. In some implementations one desktop is presented on the display of the mobile device at a time and each of the content desktop s the scenario desk and the primary desktop can be switched in and out of the display in response to user inputs. While reference is made to presenting an information bundle at the time of a related current scenario an information bundle can be independently retrieved and presented as desired as will be discussed below in association with a query.

For example when an event notification is generated and presented on a mobile device indicating the imminent start of a scheduled calendar event the mobile device can determine whether the scheduled event relates to any previously recorded events. If the event notification refers to a previous scheduled event then the previous and the current events can be considered related events and the two event scenarios can be considered related event scenarios. Therefore at the start of the current event scenario the mobile device can automatically retrieve the information bundle associated with the previous event scenario and present information and data items e.g. documents associated with the previous event scenario on the mobile device.

In some implementations a related event scenario can be detected based on one or more common elements appearing in the current and previously recorded event scenarios. The criteria for recognizing a related event scenario based on common elements can be specified by the user of the mobile device. For example the user can specify that two event scenarios are considered related if they share the same group of participants. For another example two event scenarios can be considered related if they have the same subject matter e.g. as determined from the calendar notifications . For yet another example two event scenarios can be considered related if they have the same location e.g. two visits to the doctor s office . Other automatically detectable indicators can be specified to relate two event scenarios.

In some implementations when the mobile device determines that a current event scenario is related to a previously recorded event scenario the mobile device automatically retrieves the information bundle s associated with the previously recorded event scenario s and presents the content and information available in the retrieved information bundle s on the mobile device without explicit user request.

Following the event scenario e.g. the group meeting shown in and the creation of the information bundle shown in a follow up meeting was scheduled and is about to occur in the same conference room A. In this scenario a business contact e.g. John White that was mentioned in the previous meeting was invited to join this follow up meeting. Close to the scheduled start of the follow up meeting event notification is generated and presented e.g. on the primary desktop on the mobile device . In this event scenario the new participant John White can also carry a mobile device e.g. device .

In this example a corresponding event scenario for the follow up meeting can be detected based on the methods similar to that described with respect to the detection of the event scenario associated with the first group meeting. The scenario desktop for monitoring and recording the current event scenario e.g the follow up meeting shown in can be provided on the mobile device as shown in with controls for recording the current event scenario e.g. controls in the container object .

Upon retrieval of the information bundle of the previously recorded related event scenario the mobile device can provide access to the content in the retrieved information bundle through the content desktop . More than one content desktop can be provided in parallel if information bundles from multiple related previously recorded event scenarios have been identified.

In some implementations the content desktop can be a simplified desktop that does not provide all the functions available through the primary and or scenario desktops. Instead the content desktop can provide access only to information and content that are recorded about the previous event scenario. In some implementations the content desktop can also provide access to information and content that is retrievable based on the information recorded about the previously recorded event scenario. By limiting the content available through the content desktop the user can clearly distinguish the content that was accessed during a previously recorded event scenario from the content that is accessed during the current event scenario.

In this example indicator can be presented along with the indicators and for the primary and the scenario desktops on the display of the mobile device . The indicator indicates that content from a previously recorded event scenario has been retrieved and available for viewing. The user can switch to the content desktop by for example touch and flick to the left or right on the touch sensitive display of the mobile device .

In some implementations the content desktop can include a plurality of user interface elements for accessing information and data items associated with various aspects and sub aspects of the previously recorded event scenario. For example container object includes display object for invoking interface showing information and or data items about the participants of the previously recorded event scenario. The container object can also include display object for invoking an interface showing information and or data items about the audio and video recordings of the previously recorded event scenario. In some implementations the container object can also include display object for invoking an interface showing information and or data items about the location of the previously recorded event scenario. The container object can also include one or more other display objects e.g. display object for invoking interface s for information and or data items related to other aspects and sub aspects of the previously recorded event scenario. In some implementations the container object can also include display object for opening a folder showing documents or links to the documents that were accessed during the previously recorded event scenario.

In some implementations the documents and data items accessed through the content desktop during a subsequent event scenario can be automatically included in the information bundle of the subsequent event scenario. In some implementations the user can manually specify which of the documents and data items available in the content desktop should be added to the information bundle associated with the subsequent event scenario. In some implementations the user can drag a particular document or data item to a dedicated location e.g. the indicator on the content desktop to indicate that the particular document or data item is to be added to the information bundle associated with the subsequent event scenario.

In addition to the automatic retrieval and presentation of content from a previously recorded event scenario during a subsequent related event scenario content associated with a recorded event scenario can also be presented in response to a scenario based search query.

A scenario based search query can be a search query containing terms that describe one or more aspects of the event scenario. Scenario based search queries are helpful when the user wishes to retrieve documents that are relevant to a particular context embodied in the event scenario. For example a search query that includes a functional label doctor s visit can result in retrieval and presentation of information bundles associated with multiple recorded doctor s visits. Sometimes the user may remember nothing about the content of a document but remembers the specific context that the document was accessed. A query that specifies a suitable contextual cue can help retrieve the document even if there is no logical connection between the contextual cue and the content of the document.

In some implementations the user can invoke a search function on the mobile device e.g. on the primary desktop . In response to the user input a plurality of search fields can be presented for example on the primary desktop of the mobile device . The plurality of search fields can include one or more elements of the information bundle such as the participants the location the time the subject matter the documents and or other characterizations of an event scenario. In some implementations the plurality of fields can be automatically populated with the contextual cues that are currently present such as the participants present in proximity to the mobile device the current location the current time the subject matter being discussed at the moment and or other characterizations that are currently detected by the mobile device e.g. according to the various techniques described with respect to detection and recording of an event scenario .

In the plurality of fields shows the automatically presented and populated search fields including participant field location field time field subject field and one or more other characterization field s . Each of the fields is automatically filled with information available about the current scenario occurring in proximity to the mobile device. The user can selectively remove certain fields from the query for example by touching and swiping across the unwanted search criteria e.g. search fields and . In some implementations the user can enter new keywords functional labels and or descriptive labels for each of the search fields to complete the query.

In this example after the user has eliminated the location time subject and other characterization search fields from the query the mobile device performs the search using only the remaining search field s e.g. the current participants . If there have been a number of previously recorded event scenarios with the same group of participants information bundles for these previously recorded event scenarios can be identified. At this point the user can either request to see all the identified information bundles or further narrow the search by entering additional search criteria.

In some implementations the mobile device can process the metadata associated with the identified information bundles to identify a number of differentiating elements about these identified information bundles. These differentiating elements are identifiers and or labels that distinguish one subset of the identified information bundles with another different subset of the identified information bundles.

Once the mobile device has identified these differentiating elements these differentiating elements can be presented on the mobile device e.g. on the primary desktop . In this example a number of differentiating elements are found in the plurality of identified information bundles. These differentiating elements can be for different aspects of the recorded event scenarios. For example the differentiating elements for the identified information bundles include location identifier Pub A location identifier Conference Room A functional label Park time identifier 11 00 am time identifier 11 5 09 time identifier 10 6 09 time identifier 10 00 am functional label Barbecue functional label Product Quality functional label Team Meeting descriptive label Good Weather descriptive label Pouring Rains and descriptive label Tough Meeting. 

In some implementations each of the differentiating elements can be presented by a respective user interface element e.g. a respective icon showing the identifier and or label text on the primary desktop . In some implementations only a subset of the distinguishing elements is presented if too many distinguishing elements are identified. The subset of the distinguishing elements can be selected based on the number of information bundles that are associated with each distinguishing element.

In some implementations the user after seeing these distinguishing elements may remember additional details about the particular event scenario that he wishes to recall. At this point the user can either enter additional search criteria in the search fields and or select one or more of the displayed distinguishing elements to narrow the search. In some implementations the user can combine two distinguishing elements to narrow the search to a set of information bundles that satisfy both of the distinguishing elements. In some implementations the user can touch and drag the user interface elements for the two distinguishing elements toward each other to combine them. These selected distinguishing elements become additional search criteria for the query and the information bundles that do not satisfy both of these distinguishing elements are excluded from further consideration for the search. In some implementations the user can touch and flick a particular distinguishing element e.g. element toward the edge of the display and exclude information bundles that have the particular distinguishing element from further consideration.

After the user has selected and combined some distinguishing elements and discard some distinguishing elements the mobile device can process the remaining information bundles to find a reduced set of distinguishing elements among the remaining information bundles. For example the remaining elements in this example are the time identifier 11 5 09 the time identifier 10 6 09 the functional label Barbecue the descriptive label Tough Meeting and the functional label Team Meeting . A new combined label for the combination Park 11 00 am can be generated and presented on the mobile device . If the user further combines the combination with the descriptive label a single information bundle can be identified to satisfy all of these search criteria e.g. current participants Park 11 00 am and Tough Meeting .

Once a reasonably small set e.g. less than three of information bundles have been identified the mobile device can present information and data items from the identified information bundles in their respective content desktops e.g. the content desktop . In some implementations the search results can be presented in a designated folder on the primary desktop.

In some implementations to detect the first event scenario first user input can be received on a touch sensitive display where the first user input indicates a start of the first event scenario. In some implementations to detect the first event scenario a current location of the mobile device can be determined a current time can be determined and notification of a scheduled calendar event can be received on the mobile device where the notification indicates an imminent start of the scheduled calendar event at the current location of the mobile device. In some implementations to detect the first event scenario a current time can be determined one or more persons present in proximity to the mobile device can be identified and notification of a scheduled calendar event can be received on the mobile device where the notification indicates an imminent start of the scheduled calendar event and that the identified one or more persons are participants of the scheduled calendar event.

In some implementations the one or more contextual cues concurrently monitored by the mobile device and observable to a user of the mobile device can include one or more of a current location a current time and a sensory characterization of an environment surrounding the mobile device. In some implementations the sensory characterization of the environment surrounding the mobile device can include one or more of a temperature reading a weather report identification of a visual landmark present in the environment and identification of an audio landmark present in the environment.

In some implementations respective user interface elements for monitoring the one or more participants and the one or more contextual cues can be presented on the scenario desktop.

In some implementations to create the information bundle respective identifiers functional labels and or descriptive labels can be derived for at least one the one or more participants contextual cues or documents and the information bundle can be created and retrievable based on one or more of the derived identifiers functional labels and or descriptive labels. In some implementations the information bundle further can include content copied from the one or more documents and content recorded during the first event scenario.

In some implementations the primary desktop can be restored on the mobile device . At a second moment in time and while the restored primary desktop is presented on the mobile device a second event scenario can be detected e.g. presently occurring in proximity to the mobile device where the second event scenario is related to one or more previously recorded event scenarios by for example at least one common participant or contextual cue . In response to detecting the second event scenario and without requiring further user input respective information bundles for the one or more previously recorded event scenarios can be retrieved e.g. based on the at least one common participant or contextual cue . A respective content desktop for each of the retrieved information bundles can be provided on the mobile device where the respective content desktop provides access to documents and or data items identified in the retrieved information bundle .

In some implementations the primary desktop and each of the content desktops can be switchable in the display of the mobile device in response to user input.

In some implementations a second scenario desktop for the second event scenario is provided on the mobile device where the primary desktop the scenario desktop and the content desktop can be switchable in the display of the mobile device in response to user input.

In some implementations each of the content desktops can provide a link to the second scenario desktop for associating a document accessible in the content desktop with the second event scenario.

In some implementations the first event scenario can be associated with a first scheduled calendar event and the second event can be associated with a second scheduled calendar event related to the first calendar event.

In some implementations a query indicating at least one of the one or more of the contextual cues can be received on the mobile device. The information bundle associated with the first event scenario can be retrieved based on the contextual cues indicated in the received query. A content desktop for the retrieved information bundle can be presented on the mobile device where the respective content desktop is for accessing documents or data items associated with the retrieved information bundle.

In some implementations a query can be received on the mobile device where the query specifies identifiers and or labels for one or more participants and or contextual cues associated with an event scenario . Respective information bundles for one or more previously recorded event scenarios can be identified based on the specified identifiers or labels . A plurality of differentiating elements can be identified from the identified information bundles where each of the differentiating elements distinguishes a first subset of the identified information bundles from a second different subset of the identified information bundles . The identified differentiating elements can be simultaneously presented on the mobile device . User input combining at least two of the presented differentiating elements can be received . In response to the user input a subset of the differentiating elements can be presented on the mobile device where the subset of the differentiating elements are derived from a subset of the identified information bundles that include the combined differentiating elements .

In some implementations the user input combining the at least two of the presented differentiating elements includes simultaneously touching and dragging the differentiating elements toward one another on a touch sensitive display of the mobile device.

In some implementations one of the subset of identified information bundles can be selected based on the specified identifiers and or labels in the query and the combined differentiating elements. Access to documents or data items associated with the selected information bundle can be provided on a content desktop of the mobile device where the content desktop exists in parallel with a primary desktop of the mobile device and is switchable to the primary desktop in response to user input.

The mobile devices and can also establish communications by other means e.g. wireless communications . For example the mobile device can communicate with other mobile devices e.g. other wireless devices cell phones etc. over the wireless network . Likewise the mobile devices and can establish peer to peer communications e.g. a personal area network by use of one or more communication subsystems e.g. a Bluetooth communication device . Other communication protocols and topologies can also be implemented.

The mobile device or can for example communicate with one or more services not shown over the one or more wired and or wireless networks . For example navigation service can provide navigation information e.g. map information location information route information and other information to the mobile device or . Access to a service can be provided by invocation of an appropriate application or functionality on the mobile device. For example to invoke the navigation service a user can invoke a Maps function or application by touching the Maps object. Messaging service can for example provide e mail and or other messaging services. Media service can for example provide access to media files such as song files movie files video clips and other media data. Syncing service can for example perform syncing services e.g. sync files . Content service can for example provide access to content publishers such as news sites RSS feeds web sites blogs social networking sites developer networks etc. Data organization and retrieval service can for example provide scenario based content organization and retrieval service to mobile devices and store information bundles and other information for the event scenarios e.g. in database . Other services can also be provided including a software update service that automatically determines whether software updates exist for software on the mobile device then downloads the software updates to the mobile device where it can be manually or automatically unpacked and or installed. Other services such as location sharing services can also be provided.

Sensors devices and subsystems can be coupled to the peripherals interface to facilitate multiple functionalities. For example motion sensor light sensor and proximity sensor can be coupled to the peripherals interface to facilitate orientation lighting and proximity functions. For example in some implementations the light sensor can be utilized to facilitate adjusting the brightness of the touch screen . In some implementations the motion sensor can be utilized to detect movement of the device.

Other sensors can also be connected to the peripherals interface such as a positioning system e.g. GPS receiver a temperature sensor a biometric sensor or other sensing device to facilitate related functionalities.

For example the device can receive positioning information from positioning system . The positioning system in various implementations can be a component internal to the device or can be an external component coupled to the device e.g. using a wired connection or a wireless connection . In some implementations the positioning system can include a GPS receiver and a positioning engine operable to derive positioning information from received GPS satellite signals. In other implementations the positioning system can include a compass e.g. a magnetic compass a gyro and an accelerometer as well as a positioning engine operable to derive positioning information based on dead reckoning techniques. In still further implementations the positioning system can use wireless signals e.g. cellular signals IEEE 802.11 signals to determine location information associated with the device. Other positioning systems are possible.

Other positioning systems and technologies can be implemented on or coupled to the mobile device to allow the mobile device to self locate. In some implementations precision of location determination can be improved to include altitude information. In some implementations the precision of location determination can be improved. For example a user s exact location may be determined within building structures using sonar technologies. In such implementations building structure information may be obtained through a server of such information.

Broadcast reception functions can be facilitated through one or more radio frequency RF receiver s . An RF receiver can receive for example AM FM broadcast or satellite broadcasts e.g. XM or Sirius radio broadcast . An RF receiver can also be a TV tuner. In some implementations The RF receiver is built into the wireless communication subsystems . In other implementations the RF receiver is an independent subsystem coupled to the device e.g. using a wired connection or a wireless connection . The RF receiver can include a Radio Data System RDS processor which can process broadcast content and simulcast data e.g. RDS data . In some implementations the RF receiver can be digitally tuned to receive broadcasts at various frequencies. In addition the RF receiver can include a scanning function which tunes up or down and pauses at a next frequency where broadcast content is available.

Camera subsystem and optical sensor e.g. a charged coupled device CCD or a complementary metal oxide semiconductor CMOS optical sensor can be utilized to facilitate camera functions such as recording photographs and video clips.

Communication functions can be facilitated through one or more wireless communication subsystems which can include radio frequency receivers and transmitters and or optical e.g. infrared receivers and transmitters. Wired communication system can include a port device e.g. a Universal Serial Bus USB port or some other wired port connection that can be used to establish a wired connection to other computing devices such as other communication devices network access devices a personal computer a printer a display screen or other processing devices capable of receiving and or transmitting data. The specific design and implementation of the communication subsystem can depend on the communication network s over which the mobile device is intended to operate. For example a mobile device may include wireless communication subsystems designed to operate over a GSM network a GPRS network an EDGE network 802.x communication networks e.g. WiFi WiMax or 3G networks code division multiple access CDMA and a Bluetooth network. The wireless communication subsystems may include hosting protocols such that the device may be configured as a base station for other wireless devices. As another example the communication subsystems can allow the device to synchronize with a host device using one or more protocols such as for example the TCP IP protocol HTTP protocol UDP protocol and any other known protocol.

Audio subsystem can be coupled to speaker and one or more microphones to facilitate voice enabled functions such as voice recognition voice replication digital recording and telephony functions.

I O subsystem can include touch screen controller and or other input controller s . The touch screen controller can be coupled to touch screen . The touch screen and touch screen controller can for example detect contact and movement or break thereof using any of a plurality of touch sensitivity technologies including but not limited to capacitive resistive infrared and surface acoustic wave technologies as well as other proximity sensor arrays or other elements for determining one or more points of contact with the touch screen .

The other input controller s can be coupled to other input control devices such as one or more buttons rocker switches thumb wheel infrared port USB port and or a pointer device such as a stylus. The one or more buttons not shown can include an up down button for volume control of the speaker and or the microphone .

In one implementation a pressing of the button for a first duration may disengage a lock of the touch screen and a pressing of the button for a second duration that is longer than the first duration may turn power to the mobile device on or off. The user may be able to customize a functionality of one or more of the buttons. The touch screen can for example also be used to implement virtual or soft buttons and or a keypad or keyboard.

In some implementations the mobile device can present recorded audio and or video files such as MP3 AAC and MPEG files. In some implementations the mobile device can include the functionality of an MP3 player such as an iPod . The mobile device may therefore include a dock connector that is compatible with the iPod . Other input output and control devices can also be used.

The memory interface can be coupled to memory . The memory can include high speed random access memory and or non volatile memory such as one or more magnetic disk storage devices one or more optical storage devices and or flash memory e.g. NAND NOR . The memory can store an operating system such as Darwin RTXC LINUX UNIX OS X WINDOWS or an embedded operating system such as VxWorks. The operating system may include instructions for handling basic system services and for performing hardware dependent tasks. In some implementations the operating system can be a kernel e.g. UNIX kernel .

The memory may also store communication instructions to facilitate communicating with one or more additional devices one or more computers and or one or more servers. The communication instructions can also be used to select an operational mode or communication medium for use by the device based on a geographical location e.g. obtained by the GPS Navigation instructions of the device. The memory may include graphical user interface instructions to facilitate graphic user interface processing sensor processing instructions to facilitate sensor related processing and functions phone instructions to facilitate phone related processes and functions electronic messaging instructions to facilitate electronic messaging related processes and functions web browsing instructions to facilitate web browsing related processes and functions media processing instructions to facilitate media processing related processes and functions GPS Navigation instructions to facilitate GPS and navigation related processes and instructions camera instructions to facilitate camera related processes and functions and or other software instructions to facilitate other processes and functions e.g. security processes and functions device customization processes and functions based on predetermined user preferences and other software functions. The memory may also store other software instructions not shown such as web video instructions to facilitate web video related processes and functions and or web shopping instructions to facilitate web shopping related processes and functions. In some implementations the media processing instructions are divided into audio processing instructions and video processing instructions to facilitate audio processing related processes and functions and video processing related processes and functions respectively. An activation record and International Mobile Equipment Identity IMEI or similar hardware identifier can also be stored in memory . Scenario based instruction can also be stored in memory .

Each of the above identified instructions and applications can correspond to a set of instructions for performing one or more functions described above. These instructions need not be implemented as separate software programs procedures or modules. The memory can include additional instructions or fewer instructions. Furthermore various functions of the mobile device may be implemented in hardware and or in software including in one or more signal processing and or application specific integrated circuits.

The features described can be implemented in digital electronic circuitry or in computer hardware firmware software or in combinations of them. The features can be implemented in a computer program product tangibly embodied in an information carrier e.g. in a machine readable storage device or in a composition of matter capable of effecting a propagated signal for execution by a programmable processor and method steps can be performed by a programmable processor executing a program of instructions to perform functions of the described implementations by operating on input data and generating output.

The described features can be implemented advantageously in one or more computer programs that are executable on a programmable system including at least one programmable processor coupled to receive data and instructions from and to transmit data and instructions to a data storage system at least one input device and at least one output device. A computer program is a set of instructions that can be used directly or indirectly in a computer to perform a certain activity or bring about a certain result. A computer program can be written in any form of programming language e.g. Objective C Java including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment.

Suitable processors for the execution of a program of instructions include by way of example both general and special purpose microprocessors and the sole processor or one of multiple processors or cores of any kind of computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for executing instructions and one or more memories for storing instructions and data. Generally a computer will also include or be operatively coupled to communicate with one or more mass storage devices for storing data files such devices include magnetic disks such as internal hard disks and removable disks magneto optical disks and optical disks. Storage devices suitable for tangibly embodying computer program instructions and data include all forms of non volatile memory including by way of example semiconductor memory devices such as EPROM EEPROM and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in ASICs application specific integrated circuits .

To provide for interaction with a user the features can be implemented on a computer having a display device such as a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device such as a mouse or a trackball by which the user can provide input to the computer.

The features can be implemented in a computer system that includes a back end component such as a data server or that includes a middleware component such as an application server or an Internet server or that includes a front end component such as a client computer having a graphical user interface or an Internet browser or any combination of them. The components of the system can be connected by any form or medium of digital data communication such as a communication network. Examples of communication networks include e.g. a LAN a WAN and the computers and networks forming the Internet.

The computer system can include clients and servers. A client and server are generally remote from each other and typically interact through a network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

One or more features or steps of the disclosed embodiments can be implemented using an Application Programming Interface API . An API can define one or more parameters that are passed between a calling application and other software code e.g. an operating system library routine function that provides a service that provides data or that performs an operation or a computation.

The API can be implemented as one or more calls in program code that send or receive one or more parameters through a parameter list or other structure based on a call convention defined in an API specification document. A parameter can be a constant a key a data structure an object an object class a variable a data type a pointer an array a list or another call. API calls and parameters can be implemented in any programming language. The programming language can define the vocabulary and calling convention that a programmer will employ to access functions supporting the API.

In some implementations an API call can report to an application the capabilities of a device running the application such as input capability output capability processing capability power capability communications capability etc.

A number of implementations have been described. Nevertheless it will be understood that various modifications may be made. For example elements of one or more implementations may be combined deleted modified or supplemented to form further implementations. As yet another example the logic flows depicted in the figures do not require the particular order shown or sequential order to achieve desirable results. In addition other steps may be provided or steps may be eliminated from the described flows and other components may be added to or removed from the described systems. Accordingly other implementations are within the scope of the following claims.

