---

title: Processing data in shared memory by multiple processes
abstract: Various embodiments of systems and methods for processing data in shared memory are described herein. A number of work processes of an application server write data in corresponding areas of shared memory. At least one data unit for a first process is read from a first area of the shared memory by the first process. The first process also reads at least one unit of data for a second process from a second area of the shared memory. The first process writes information in a third area of the memory to indicate that the at least one unit of data for the first process and the at least one unit of data for the second process are read. The read data units are aggregated and saved in a storage by the first process.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08312228&OS=08312228&RS=08312228
owner: SAP AG
number: 08312228
owner_city: Walldorf
owner_country: DE
publication_date: 20100406
---
The field of the invention relates generally to data processing and digital processing systems. More specifically the invention is related to buffering and processing data in shared memory within a computer systems environment.

In general computer applications provide services to a variety of consumers. Often the separate services provided by a computer application or even some of the tasks within a single service are executed by separate work processes. This is especially true for complex computer applications with many consumers like Enterprise Resource Planning ERP systems customer relationships management CRM systems etc. The separate work processes usually run separate instances of a computer application within the same computer environment e.g. as in an application server. These separate processes run autonomously e.g. they are isolated from each other in terms of some operations. However the processes may share some of the resources of the computer system hosting the application server. For example such resources include processors volatile memory database storage etc.

The running processes of an application server generate various data related to their work. Such data may include consumers identification information about consumer requests services data lists of executed operations and tasks system parameters etc. This data is necessary for monitoring and evaluating the performance of work processes and for maintaining statistics required by audits for instance. Therefore the work processes of an application server preserve this data in permanent storages. Usually the data is saved in database tables or file logs. The operation of saving the data could be a very resource consuming task occupying a lot of processor time and storage space. The performance of a work process could be significantly decreased by these data saving operations especially when the processes compete for the same storage resource.

The data about the work of the processes of an application server is important but is not critical for the provided services. In other words if part of this data is lost for some reason the work processes will still be able to function as requested by the consumers. Hence potential data loss due to for instance unexpected shut downs could be neglected. Additionally this data is very rarely required in raw state. Once stored in a database or a file the data is aggregated and processed to a predefined condensed structure before being used. For example a service consumer provides identification information to a work process such as type of caller application e.g. Partner Application Foreign Application and Domestic Application an identification number a username etc. This information could be combined with service provider information such as name of the service the time when the service was called etc. and stored in a database. However a manager or an auditor may be interested only in the number of service calls per user in a given time interval. Therefore it may not be necessary to store all data details directly in the permanent storage.

Various embodiments of systems and methods for processing data in shared memory are described herein. A number of work processes of an application server write data in corresponding areas of shared memory. In one aspect at least one data unit for a first process is read from a first area of the shared memory by the first process. The first process also reads at least one unit of data for a second process from a second area of the shared memory. In another aspect the data units that are read are aggregated and saved in a storage by the first process. In yet another aspect the first process writes information in a third area of the memory to indicate that the at least one unit of data for the first process and the at least one unit of data for the second process are read.

These and other benefits and features of embodiments of the invention will be apparent upon consideration of the following detailed description of preferred embodiments thereof presented in connection with the following drawings.

Embodiments of techniques for processing data in shared memory are described herein. In the following description numerous specific details are set forth to provide a thorough understanding of embodiments of the invention. One skilled in the relevant art will recognize however that the invention can be practiced without one or more of the specific details or with other methods components materials etc. In other instances well known structures materials or operations are not shown or described in detail to avoid obscuring aspects of the invention.

Reference throughout this specification to one embodiment this embodiment and similar phrases means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Thus the appearances of these phrases in various places throughout this specification are not necessarily all referring to the same embodiment. Furthermore the particular features structures or characteristics may be combined in any suitable manner in one or more embodiments.

In an exemplary computer environment including application server providing services to a number of consumers through network is illustrated. Application server runs a number of work processes to parallelize and distribute the workload e.g. the processing of service requests coming from consumers . The incoming service requests are distributed by dispatcher between work process WP WP and WP N for execution. Each work process solely operates within its own memory area in local memory during execution. Further the work processes and may access same areas of shared memory . Local memory and shared memory are part of memory of application server . In one embodiment of the invention memory is volatile operative system memory such as random access memory RAM . Alternatively other types of dynamic memory could also be used.

Application server may use the set of isolated work processes and to deal with concurrent requests parallelize the execution of services and tasks and distribute the workload. Each work process generates or transmits data that is stored in permanent storage in database tables or files. The data can be statistical data e.g. the number of service calls the application server has executed. Storing such data can consume a large amount of system resources especially if the execution time of a service task is very short. When application server is loaded the data could occupy considerable space in the permanent storage. However only an aggregated and condensed extraction of this data is actually needed. To decrease resource consumption the data generated by the work processes and is buffered in shared memory and then the data is processed and transferred to storage in aggregated state.

Each isolated work process is associated with a corresponding area of local memory that cannot be accessed by the rest of the work processes and . In one embodiment of the invention shared memory can be accessed by all work processes and . Application server divides shared memory in areas and enables parallel reading of the shared memory areas by work processes and . A work process can read and manage data from an area of the shared memory by copying the data to a corresponding area in the local memory . Only one work process at a time can change a shared memory area. The writing in an area of the shared memory needs additional locking steps to ensure that only one work process can write or change the content of the area. In another embodiment of the invention parallel read and write operations can be supported by generating versions of the content of the shared memory .

According to one embodiment of the invention each of work processes WP WP and WP N is assigned to one shared memory area and is registered in a central shared memory area of shared memory as illustrated in . In some embodiments of the invention other shared memory areas could be also created and registered in parallel if the memory infrastructure provides the necessary application programming interfaces APIs . Block diagram shows the organization of shared memory in areas and the correspondence between these areas and work processes WP WP and WP N . Work processes and can read information from central area as illustrated with arrows directed from central area to WP WP and WP N . Work process has exclusive read and write access to area of shared memory as illustrated with bi directional arrow connecting WP with area . Similarly WP has exclusive read and write access to area and WP N has exclusive read and write access to area of shared memory . Work process may still have read access to areas and of shared memory . Respectively work process may have read access to areas and and work process N may have read access to areas and .

In one embodiment of the invention the data units are written in a shared memory area to form a sequence. The data units may consist of conventional data types organized efficiently to administer large amounts of data. The written data units may form an array or a queue of consecutive data units where the new data units are appended to the previously written data units. The data units may be read afterwards in the order they have been written e.g. in first in first out FIFO mode. The central shared memory area stores information indicating the processed data units in the other shared memory areas. For example the central shared memory area may keep pointers assigned to each shared memory area corresponding to a work processes. Such a pointer may show the position of a last read e.g. processed data unit in an array of data units written in a shared memory area. This could be the position number of a data unit in the queue or any other identifier that can specify data units across work process boundaries. The data in a shared memory area may be read by any of the running work processes and used for further processing or storing.

At the work process reads information from the central shared memory area to identify those data units stored in the corresponding shared memory area that were read. The data units in the shared memory can be read and processed by any of the work processes of the application server according to one embodiment of the invention. At a check is performed by the work process to verify whether there are data units in the corresponding shared memory area that were read according to the information in the central shared memory area. If there are one or more data units that are previously read and respectively transferred to a storage the work process deletes them from the corresponding shared memory area at . Thus the volume of data units that are kept in the shared memory areas could be regulated.

Central shared memory includes a list of references to every shared memory area corresponding to a work process of the application server including reference to shared memory area corresponding to work process A . In one embodiment of the invention each shared memory area corresponding to a work process is registered within list of references when the shared memory area is created and assigned to the work process. The central shared memory stores a pointer assigned to each reference in the list of references . The pointer may hold the number of read data units in the corresponding shared memory area. Thus the difference between the pointer and the counter in the corresponding shared memory area indicates the number of read units that are present in the shared memory area. In one embodiment of the invention the data units are read from shared memory area in FIFO pattern.

As illustrated in the pointer associated to the reference to shared memory area is set to number . Respectively data units were read from the shared memory area . The counter is set to e.g. as many as data units are deleted from the shared memory area . The difference between the two numbers is 3 and this means that there are three data units in shared memory area that are read but not removed. Since the data units are read in the order of writing it could be concluded that the first three data units e.g. data unit data unit and data unit are processed by some work process. Arrow points to the last read data unit e.g. to data unit in the array of data units to currently written in shared memory area . The arrow is drawn with dashed line to show that it is an optional element. The work process A as well as any other work process with read access to the shared memory areas and may read the value of the pointer in the list of references and compare it with the value of the counter to identify read data units in shared memory area .

The block diagram of shows the state of the shared memory area after the work process A has finished the operation for writing data unit X as described in . The work process A has acquired write access to shared memory area to accomplish the writing of data unit X . The work process has also removed read data units and . The labels assigned to the data units to remaining in shared memory area has been updated to reflect the new order of data units. Also the work process has increased the number of deleted data units in counter to . The number of counter equals the number of read data units held by the corresponding pointer in the list of references in central shared memory . Respectively arrow does not point to a data unit as none of data units in shared memory area is read e.g. processed by any work process.

According to one embodiment of the invention the data units that are stored in shared memory are processed e.g. read aggregated and persisted to a database or a file in a storage. The processing of the data units could be invoked by a predefined condition e.g. after a certain volume of data in the shared memory is reached after a specified time period relative to other system event etc. The predefined condition may be based on risk evaluation as the data in the shared memory could be lost for example in case of an unexpected shutdown of the application server. The data units are read and processed from the shared memory areas by one of the work processes. Thus the proposed solution reduces the number of the expensive data saving operations and eliminates the competition for storage resources between the parallel work processes at tolerable risk level. Every one of the running work processes could read the collected data units in the shared memory areas depending on a condition current work load rotation principle etc.

In one embodiment of the invention a local condition is set for a shared memory area for transferring the data corresponding to a work process to a permanent storage. The local condition could be related to events such as reaching a predefined volume of written data units a time period etc. For example if the total shared memory size is limited the local condition for a particular shared memory area could be when the size of the shared memory area reaches the total size limit of the shared memory divided by the number of running work processes. Other types of local conditions could be defined depending on a specific embodiment and the acceptable level of risk.

At a check is performed to verify whether the local condition set for the shared memory area corresponding to the reading work process is valid. If the validity of the local condition is confirmed e.g. the condition is validated the work process acquires read access to a shared memory area corresponding to another one of the running work processes at . Based on the indication in the central shared memory area the work process reads the unread units of data from the shared memory area corresponding to the other work process at . The work process repeats tasks and for every shared memory area corresponding to work processes until at it is confirmed that the data units for the remaining work processes are read. According to one embodiment of the invention the reading work process may not be able to read data units from one or more of the shared memory areas unless their corresponding work processes have written new data units into shared memory areas. Therefore the tasks and are repeated until it is confirmed that all data units available for reading are read by the reading work process.

The flowchart illustrated in shows the second part of the procedure for reading units of data from the shared memory areas assigned to the running work processes. The process continues at where the reading work process performs a check to verify the validity of a global condition. In one embodiment of the invention the check may be based on the currently read data units. If the global condition is valid the work process attempts to acquire write access to the central shared memory area at . The procedure ends if acquiring such access fails because of some reason e.g. if another work process currently has write access to the central shared memory. If the work process has successfully acquired write access to the shared memory area the procedure continues at . The work process writes information into the central shared memory area indicating the units of data read from the shared memory areas corresponding to the work processes running in the application server. The work process may simply update the information in the central shared memory area with the number of the newly read units of data per registered shared memory area.

At the reading work process aggregates the units of data it has read from the shared memory areas corresponding to the work processes of the application server. The aggregation of data units could be based on a predefined algorithm. During the aggregation the work process may use a local memory area for calculation and temporary saving of the read units of data. The aggregated information includes data for the working processes of the application server which is necessary for monitoring management auditing and other purposes. At the reading work process saves the aggregated information in a storage.

The buffering of data in the shared memory areas instead of saving it directly in the storage may significantly decrease the number of the save operations. Additionally the aggregation of the data saves resources mostly in terms of storage space. At the work process deletes the data units in the corresponding shared memory area as the data units are processed e.g. information is extracted and persisted in the storage. At the work process initializes the information in the central shared memory area about the shared memory area corresponding to the reading work process. In one embodiment of the invention the initialization may mean resetting the value stored in the central memory area showing the number of processed data units from the shared memory area corresponding to the work process.

Shared memory area contains an array of data units to . Counter informs that data units have been deleted from the shared memory area . The corresponding pointer in the list of references is set to processed data units from the shared memory area . Therefore the first four of the data units in shared memory area are read which is illustrated with arrow pointed at data unit . Arrows and are drawn with dashed lines to illustrate that they may not be included in shared memory areas and according to one embodiment of the invention.

Work process B has write access to shared memory area and to central shared memory . In addition to this work process B has read access to shared memory area . The acquired access rights are sufficient for work process B to process the available data units in shared memory areas and .

The block diagram of shows the state of shared memory areas and and central shared memory after the work process B has finished the processing of the available data units. Work process A has also finished the writing operation for data unit X in shared memory area . Therefore data unit X is drawn with solid lines. Counter was not changed as work process A has started the writing of data unit X before the reading operation performed by work process B and hence no read unit was identified by the work process A in shared memory area for deletion. Work process B has read the available data units to and has accordingly increased the number of read data units of the pointer corresponding to the shared memory area in the list of references in central shared memory . The arrow points to the last read data unit to illustrate that data units to in shared memory area are processed.

Work process B had read all data units in shared memory area . Using the exclusive write and read access the work process B has deleted the processed data units from shared memory area . In one embodiment of the invention work process B has reset the counter and the pointer corresponding to shared memory area in the list of references . The initialization of counter and the corresponding pointer in the list of references may help to avoid a potential integer overflow error. Arrow does not point to any data unit as shared memory area is empty.

Some embodiments of the invention may include the above described methods being written as one or more software components. These components and the functionality associated with each may be used by client server distributed or peer computer systems. These components may be written in a computer language corresponding to one or more programming languages such as functional declarative procedural object oriented lower level languages and the like. They may be linked to other components via various application programming interfaces and then compiled into one complete application for a server or a client. Alternatively the components maybe implemented in server and client applications. Further these components may be linked together via various distributed programming protocols. Some example embodiments of the invention may include remote procedure calls being used to implement one or more of these components across a distributed programming environment. For example a logic level may reside on a first computer system that is remotely located from a second computer system containing an interface level e.g. a graphical user interface . These first and second computer systems can be configured in a server client peer to peer or some other configuration. The clients can vary in complexity from mobile and handheld devices to thin clients and on to thick clients or even other servers.

The above illustrated software components are tangibly stored on a computer readable storage medium as instructions. The term computer readable storage medium should be taken to include a single medium or multiple media that stores one or more sets of instructions. The term computer readable storage medium should be taken to include any physical article that is capable of undergoing a set of physical changes to physically store encode or otherwise carry a set of instructions for execution by a computer system which causes the computer system to perform any of the methods or process steps described represented or illustrated herein. Examples of computer readable storage media include but are not limited to magnetic media such as hard disks floppy disks and magnetic tape optical media such as CD ROMs DVDs and holographic devices magneto optical media and hardware devices that are specially configured to store and execute such as application specific integrated circuits ASICs programmable logic devices PLDs and ROM and RAM devices. Examples of computer readable instructions include machine code such as produced by a compiler and files containing higher level code that are executed by a computer using an interpreter. For example an embodiment of the invention may be implemented using Java C or other object oriented programming language and development tools. Another embodiment of the invention may be implemented in hard wired circuitry in place of or in combination with machine readable software instructions.

A data source is an information resource. Data sources include sources of data that enable data storage and retrieval. Data sources may include databases such as relational transactional hierarchical multi dimensional e.g. OLAP object oriented databases and the like. Further data sources include tabular data e.g. spreadsheets delimited text files data tagged with a markup language e.g. XML data transactional data unstructured data e.g. text files screen scrapings hierarchical data e.g. data in a file system XML data files a plurality of reports and any other data source accessible through an established protocol such as Open DataBase Connectivity ODBC produced by an underlying software system e.g. ERP system and the like. Data sources may also include a data source where the data is not tangibly stored or otherwise ephemeral such as data streams broadcast data and the like. These data sources can include associated data foundations semantic layers management systems security systems and so on.

In the above description numerous specific details are set forth to provide a thorough understanding of embodiments of the invention. One skilled in the relevant art will recognize however that the invention can be practiced without one or more of the specific details or with other methods components techniques etc. In other instances well known operations or structures are not shown or described in details to avoid obscuring aspects of the invention.

Although the processes illustrated and described herein include series of steps it will be appreciated that the different embodiments of the present invention are not limited by the illustrated ordering of steps as some steps may occur in different orders some concurrently with other steps apart from that shown and described herein. In addition not all illustrated steps may be required to implement a methodology in accordance with the present invention. Moreover it will be appreciated that the processes may be implemented in association with the apparatus and systems illustrated and described herein as well as in association with other systems not illustrated.

The above descriptions and illustrations of embodiments of the invention including what is described in the Abstract is not intended to be exhaustive or to limit the invention to the precise forms disclosed. While specific embodiments of and examples for the invention are described herein for illustrative purposes various equivalent modifications are possible within the scope of the invention as those skilled in the relevant art will recognize. These modifications can be made to the invention in light of the above detailed description. Rather the scope of the invention is to be determined by the following claims which are to be interpreted in accordance with established doctrines of claim construction.

