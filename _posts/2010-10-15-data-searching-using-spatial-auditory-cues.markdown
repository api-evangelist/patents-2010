---

title: Data searching using spatial auditory cues
abstract: Spatial auditory cues are produced while a user searches a database for stored information. The spatial auditory cues assist the user in quickly locating stored information by producing sounds that are perceived at specific physical locations in space around the user as the search proceeds. Each location may be associated with different information. Thus, using the techniques disclosed herein, a user can more easily recall stored information by remembering the locations of sound produced by particular spatial auditory cues. The spatial auditory cues may be used in conjunction with a visual search interface. A method of producing auditory cues includes receiving a search action at a user interface included in a device, translating the search action into a spatial auditory cue corresponding to a specific location within a space, and rendering the spatial auditory cue as an audio output signal.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08417703&OS=08417703&RS=08417703
owner: QUALCOMM Incorporated
number: 08417703
owner_city: San Diego
owner_country: US
publication_date: 20101015
---
The present application for patent claims priority to Provisional Application No. 61 257 684 entitled DATA SEARCHING USING SPATIAL AUDITORY CUES filed Nov. 3 2009 and assigned to the assignee hereof.

The present disclosure pertains generally to electronic information searching and more specifically to a search interface that relies on auditory indicators.

Electronic database searches are usually performed visually. In some database interfaces the database contents are presented on a display and a user can visually search or browse an index of the information contained in the database.

Database indexes may be organized hierarchically. A hierarchical database organization allows database contents to be categorized into groups of related information such as folders genres or the like. This may permit more efficient searching. However even with categorization the number of items in each category may still be very large and thus potentially inconvenient to browse.

When a device is portable and small i.e. display space is limited a user may need to navigate through many layers of indexes menus and or folders to retrieve desired information or content from an electronic database. This may be time consuming and cumbersome in some circumstances.

To improve searching capabilities the techniques and database interfaces disclosed herein employ spatial auditory cues. Spatial auditory cues are produced while a user searches a database for stored information. The spatial auditory cues assist the user in quickly locating stored information by generating sounds that are perceived at specific physical locations in space around the user as a search proceeds. Each location may be associated with different information. Thus using the methods articles and or apparatuses disclosed herein a user can more easily recall stored information by remembering the locations of sound produced by particular spatial auditory cues. In addition in larger databases the need for layers of database indexes menus and or folders can be reduced or eliminated.

As the database content size gets larger browsing an index with many items becomes a problem especially when a device display is relatively small. Only a limited number of items can be displayed on one screen. Using spatial audio technologies browsing database items is made easier and more intuitive and the conventional process of visually searching may be enhanced.

According to an aspect a method of producing auditory cues includes receiving a search action at a user interface included in a device translating the search action into a spatial auditory cue corresponding to a location within a space and rendering the spatial auditory cue as an audio output signal.

According to another aspect a method of interfacing with a database includes visually displaying on a device at least a portion of a scrollable list of items stored in the database and mapping at least some of the items to spatial auditory cues corresponding to locations within a predefined space. Each of the spatial auditory cues corresponds to a respective distinct location within the space. The list may be scrolled. As a result of scrolling the list at least one of the spatial auditory cues is rendered as an audio output signal.

According to another aspect an apparatus includes a user interface configured to receive a search action a spatial cue generator configured to translate the search action into a spatial auditory cue corresponding to a location within a space and an audio rendering engine configured to render the spatial auditory cue as audio output.

According to a further aspect an apparatus includes means for receiving a search action means for translating the search action into a spatial auditory cue corresponding to a location within a space and means for rendering the spatial auditory cue as an audio output signal.

According to a further aspect a computer readable medium embodying a set of instructions executable by one or more processors includes code for receiving a search action at a user interface included in a device code for translating the search action into a spatial auditory cue corresponding to a location within a space and code for rendering the spatial auditory cue as audio output.

Other aspects features and advantages will be or will become apparent to one with skill in the art upon examination of the following figures and detailed description. It is intended that all such additional features aspects and advantages be included within this description and be protected by the accompanying claims.

The following detailed description which references to and incorporates the drawings describes and illustrates one or more specific embodiments. These embodiments offered not to limit but only to exemplify and teach are shown and described in sufficient detail to enable those skilled in the art to practice what is claimed. Thus for the sake of brevity the description may omit certain information known to those of skill in the art.

The word exemplary is used throughout this disclosure to mean serving as an example instance or illustration. Anything described herein as exemplary is not necessarily to be construed as preferred or advantageous over other approaches or features.

Unless expressly limited by its context the term coupled is used to indicate a direct or indirect electrical or physical connection. If the connection is indirect it is well understood by a person having ordinary skill in the art that there may be other blocks or components between the structures being coupled . The term configuration may be used in reference to a method apparatus device and or system as indicated by its particular context. Where the term comprising is used in the present description and claims it does not exclude other elements or operations. The term based on as in A is based on B is used to indicate any of its ordinary meanings including the cases i based on at least e.g. A is based on at least B and if appropriate in the particular context ii equal to e.g. A is equal to B . In the case i where A is based on B includes based on at least this may include the configuration where A is coupled to B. The term at least one is used to indicate any of its ordinary meanings including one or more .

The terms apparatus and device are used generically and interchangeably unless otherwise indicated by the particular context. Unless indicated otherwise any disclosure of an operation of an apparatus having a particular feature is also expressly intended to disclose a method having an analogous feature and vice versa and any disclosure of an operation of an apparatus according to a particular configuration is also expressly intended to disclose a method according to an analogous configuration and vice versa . The terms method process procedure and technique are used generically and interchangeably unless otherwise indicated by the particular context. The terms element and module are typically used to indicate a portion of a greater configuration.

The headset includes multiple speakers that are configured to produce sounds that may be perceived by a user at different physical locations in the space around the user . The exemplary headset includes two earpieces and at least one support such as a headband for allowing the headset to be comfortably worn by the user . In the example shown the headset is a wired headset having a conductor carrying audio signals between the device and the headset . Alternatively the headset may be a wireless headset such as a Bluetooth headset in which audio signals between the device and headset are carried over one or more wireless radio frequency RF or infrared IR channels. If implemented as a Bluetooth wireless headset the headset and device can include components and functionality as defined by the Bluetooth Specification available at www.bluetooth.com. The Bluetooth Specification provides specific guidelines for providing wireless headset functionality.

The portable device may be any device capable of producing audio output and performing the functions disclosed herein. For example the device may be a handheld device such as a wireless communication device for example a cellular phone personal digital assistant PDA or the like. The portable device may also be an MP3 player gaming device laptop computer personal stereo or the like. Although illustrated as being a portable device in the device may alternatively be implemented as a non portable device. For example the spatial auditory cueing techniques described herein may also be used with multichannel speakers in home theater systems.

The portable device includes a user interface comprising in this example a keypad having one or more buttons a display and a rocker push button . The display may be any suitable device for visually displaying information such as a liquid crystal display LCD screen or the like. As shown in the display can present among other things a scrollable list of data items stored in a database. The user interface may provide a graphical user interface for visually scrolling through a list of items stored in the database. In this example the list is a contact list of names from an address book. The database can store the names as well as information related to the names such as addresses phone numbers or the like. The user interface is only one example of possible user interfaces that may be used. For example the push button and the keypad may be integrated together or may be implemented using a touch screen rather than actual buttons.

In the address book example of the user interface can be implemented where the push button switch is a momentary contact rocker push button switch having two internal switches not shown one for scrolling the list forward and the other position for scrolling the list backwards. The user interface can be configured so that when the user momentarily rocks the switch to depress one of the internal switches the user interface provides a single step item by item accurate browse through the list and a corresponding spatial auditory cue is presented each time the internal switch is pressed. Alternatively when the user presses and holds either of the internal switches a fast scroll is initiated causing the visually displayed list items to scroll very quickly and the sounds caused by the spatial auditory cues move relatively quickly about the space . The user can continue to hold the switch until the user s hearing tells him her that the search target is near based on the location of the spatial auditory cue sounds. Other types of switches may be used for the push button .

The user may browse the list by using the push button to scroll up or down the displayed list . As the user scrolls through the displayed list the portable device generates spatial auditory cues. The spatial auditory cues assist the user in quickly locating stored information by causing sounds to be produced by the headset that are perceived at different physical locations in the space around the user as the search proceeds. A spatial auditory cue may be a signal and or information that can be rendered into audio output that produces sound at a particular physical location relative to a listener. Each location may be associated with a specific information item or record in the database. Generally as used herein the term spatial auditory cue may refer to an audible sound generated by a system so that a listener perceives the sound emanating from a particular location or alternatively to the electronic data signals necessary to generate such sound.

The system maps the relative locations of items in the database to corresponding spatial location in either two dimensions or three dimensions within the space around the user . The space may include spatial regions referred to as the audio space the auditory space the audio search space or the 3D sonic space. The space may have other names or labels it should be understood that the space encompasses spatial locations around the user . Linearly browsing database contents visually on the display can be accompanied by their mapped audio events perceived by the user in the space . Thus the user not only visually sees listed items on the display but may also listen to some sounds such as thumbnail short audio clips of the audio video content indexed in the database and also hears the sounds emanated from specific physical locations in the space . Similar to remembering where one book is located on a bookshelf with the additional spatial auditory cues database items can be searched more easily.

In the example shown the system maps the contact names to spatial locations in the space around the user . The user may also be the listener. An example of a coarse mapping is illustrated in . In the auditory space around the listener each contact is mapped to a location around the listener s head . For example a contact whose last name begins with A may be mapped to a begin location that is audibly perceived at the right rear of the user . A contact whose last name begins with a letter in the middle of the alphabet such as for example the letter M may be mapped to a middle location that is audibly perceived at in front of the user and a contact whose last name start with the letter Z may be mapped to an end location that is audibly perceived at the left rear of the user .

Whenever visually browsing to find a specific contact name in the list the currently selected name may be represented visually with a highlighted text line on the display . From the user s perspective a short sound event e.g. a click sound audio clip or the like may be generated and rendered at this item s designated spatial location which is perceived by the user in the space . When quickly scrolling through the list of items the sounds may become a relatively continuous stream moving in the space . During fast scrolling it is relatively difficult for some users to visually track scrolling text on the display but it is generally not as difficult to aurally track the moving sound in the space . By hearing noises at locations associated with the database items the user can tell whether he she is approximately near the target item being searched for. Then as the user hears the spatial auditory output approaching the items auditory cue location in the space he she may slow down and browse item by item visually on the display to visually find the target. If this function is used often the user usually can remember approximate spatial locations of certain contact names and thus reach the exact position more quickly using the combination of spatial auditory cues and visual display.

The spatial auditory cue output presented in the 3D sonic space can be rendered using different techniques some of which are known in the art. For example for the headset which includes headphones head related transfer function HRTF style filters can be used to render mono sound sources into virtual locations. For speakerphone users virtual surround sound can also be achieved through stereo speakers e.g. two speakers in front of the listener and for multichannel speaker listeners sounds can be panned and mixed so that they are physically emanated from different directions in the space around the listener .

The address book use case given above is just one example of direct mapping a database index into an auditory space. Alternative or enhanced mappings of listed items to auditory space can be implemented. For example contact names in the list maybe grouped by categories for example with a classmates category generating spatial auditory cues that cause sounds perceived by the listener at his her left rear and with a relatives category generating spatial auditory cues that cause sounds perceived by the user in the center front area of the space and so forth.

The system can be configured to scale the spatial auditory cues based on the speed of a search being performed by the user . Scaling allows the audio signal representing the spatial auditory cues to include a different amount and or type of audio information for each listed item in a database which audio information is presented at the auditory cues corresponding spatial locations. On a detailed scale or zoomed in scale when the user browses the list slowly the spatial auditory cues may present audio excerpts i.e. audio clips of each item in the list . On a macroscopic scale or zoomed out scale when the user browses the list quickly each spatial auditory cue may be represented by a more abstract sound event such as one synthesized click. The change in the listener perceived location of a stream of click sounds in the auditory space navigates the user through the database index virtually indicating where the user is while searching the database. An additional benefit is that each database item when defined properly is assigned a specific location in auditory space so that it provides a physical cue of where it is. By remembering its approximate spatial location the user may find it next time more easily. This benefit is more prominent when the user input method is limited e.g. on a hand held device where it takes relatively more time to input text strings for text searching.

An advantage of the system is that it combines the advantages of using both visual and auditory senses in searching for indexed database items. Vision is very good for detail and resolution but relatively slow in speed when scanning large data sets and also requires greater focus by an individual. Audio senses are generally not as good for detail and resolution but can be used to coarsely process relatively large amounts of information in a relatively short time. In addition most people are acutely aware of audio events occurring concurrently with visual events.

In the example illustrated by the database stores an address book of contact names. It should be understood that the techniques disclosed herein are not limited to any particular type of database or stored content. The disclosed searching techniques methods and devices may be used for other types and arrangements of stored information such as media libraries other structures of relational databases and the like.

By example while using the configuration of as the listener browses near the end of the folder i.e. the spatial auditory cue sounds emanate from right or rear right in the space relative to him her. While browsing this portion of the list of songs the listener may remember that there is a song located on his her left that he she may now want to hear. In this event the listener may press and hold the button to quickly browse in reverse. Now the spatial auditory cue for each song is scaled to become a short click and as the listener quickly reverse browses through the library the listener perceives a stream of audio clicks moving through the space from his her right side to his her left in a circular manner. When the listener perceives the audio clicks in the approximate left location of the desired song the listener may slow down the browsing by releasing the button and single clicking the button to scroll more slowly through the list listening to audio excerpts of each song again instead of the audio clicks until the desired song is found.

Alternatively database items such as media content can be assigned auditory spatial locations according to other criterion such as the type or class of information indicated by the item. illustrate exemplary auditory space configurations where the auditory space is divided according to different categories of information. For example as shown in a library of music can be arranged in the auditory space according to the mood of the songs contained in the library. As shown in songs of different moods are put in different corresponding spatial regions so that if the listener is searching for a certain mood of music the listener can search in the specific auditory space for the particular desired mood of music. In the example the system is configured to generate spatial auditory cues for sad songs which may be stored in an electronic folder labeled such in a specific region of the space that is generally perceived to the left of listener s position shown in . The system may also be configured to generate spatial auditory cues for exciting songs which may be stored in an electronic folder labeled such in a different region of the space that is generally perceived by the listener in front of listener s position shown in and the system may also be configured to generate spatial auditory cues for upbeat songs which may be stored in an electronic folder labeled such in a third region of the space that is generally perceived by the listener to the right rear of listener s position shown in .

In another exemplary configuration the system can be configured so that database items can correspond to spatial auditory cues that are arranged according to the genres of the items as shown in . In a music library can be arranged in the auditory space according to the types of songs contained in the library. As shown in songs of different genres are associated with different corresponding spatial regions so that if the listener is searching for a certain type of music the listener can search in the specific auditory space for the particular desired genre. In the example of the system generates spatial auditory cues in specific regions of the space for film soundtracks heavy metal classics and so forth. Thus in the example of if the listener is browsing for example electronica songs on the display the system may generate corresponding spatial auditory cues e.g. song excerpts that are perceived by the listener as being in front of him her.

The spatial auditory cues generated by the example configurations of may also be scaled depending on the speed of a search conducted by the listener .

The system can also be configured so that database browsing can occur about the 3 D space surrounding the listener . In this configuration the spatial auditory cues use the entire spherical space surrounding the listener to represent items. For example a vertical spatial region could be used to browse a sub category inside a category see and . In this configuration the category is located in a corresponding horizontal spatial region about the listener . In the 3 D configuration the listener may know the approximate horizontal left to right location for particular songs beginning with a certain letter e.g. S . Songs beginning with this letter may themselves be numerous and subcategorized vertically as in and in the 3 D auditory space corresponding to the horizontal spatial region for the letter S .

One way to switch from a parent category to a child category also called a sub category is to switch from a horizontal spatial region to a vertical spatial region once a tag point is played. Similarly categories may initially be located in a vertical spatial region and once a tag point is reached the listener may hear sub categories in a horizontal spatial region. A horizontal or vertical spatial region may be a plane in space. Alternatively it should also be recognized that off axis not necessarily horizontal axis or vertical axis spatial regions may also be used instead of horizontal and vertical spatial regions. For example a first off axis spatial region may contain categories and once a tag point is reached a set of sub categories may be located in a second off axis spatial region that is perpendicular to the first off axis spatial region. A tag point may be pre programmed or created by the user by specifying a search criteria. A multi modal user interface may be used to enter such criteria. is a diagram illustrating an exemplary configuration example of spatial auditory cues as tag points. The tag point may be labeled for example Favorite . The search criteria may be robust. If the item in the list being searched is a song the search criteria may be for example songs greater than five 5 minutes in duration or songs older than 1970 . A combination of search criteria may also be used to create a tag point. The user may also have control over defining the indicatory tone volume of the tag point. That is the tag point may have a different sounding auditory cue than the other items in the same spatial orientation. In Favorite is illustrated as having a high pitch tone.

It should be noted that in an alternate configuration auditory cues may be heard in a region that spans less than three hundred and sixty 360 degrees around the user . is a diagram illustrating an exemplary configuration example of a spatial region spanning less than 360 degrees. For example the user may prefer to have a narrower auditory space . Instead of perceiving auditory cues surrounding the user from zero 0 to three hundred and sixty 360 degrees the user may desire to only perceive auditory cues from zero 0 to hundred and eighty degrees 180 or negative ten 20 to two hundred degrees 200 as an example. Except for the different spatial range of degrees includes all features and functions previously described. Thus a Layer Layer or Layer may have a spatial range that is also less than 360 degrees. The same spatial range between layers is not required. Thus Layer and Layer may have a spatial range of 360 degrees while Layer has a narrower range. Similarly Layer may have a narrower range while either Layer or Layer has a broader spatial range than Layer .

Another application of System is to apply a spatial bookmark. Instead of searching items in a list a song may be played in a spatial region around the user . For example the song may begin at zero 0 degrees and finish playing at one hundred and eighty degrees 180 in a horizontal or vertical region. If the song is paused the user may be able to gauge what percentage of the song is played instead of looking at the display of the mobile device to see what percentage of the song has played. The spatial bookmark could be the fading of the song in a spatial location somewhere between 0 and 180 degrees in the spatial region. The spatial bookmark could also be silence in a location in the spatial region. The spatial region may be horizontal vertical or off axis.

The system includes the device headset and database . The headset may be the same as the headset of .

The database includes any suitable means for storing a database of information such as a memory e.g. RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that can be configured to store desired information in the form of data structures that can be accessed by the device . The information stored in the database can be any desired type of information such as media content contact information as discussed above or anything else capable of being organized and collected into a database. Although shown as a separate component in the database may be alternatively be incorporated into each of the devices shown in .

The database provides at least a database index list to the device . The index identifies items i.e. records stored in the database. For example the index list may include a number or other symbol uniquely identifying each database item in the list along with other information about the item such as a title. The index list may be hierarchically organized or it may be flat. The database may also provide database contents to the device such as stored information or media content e.g. music or the like for further processing and or output by the device .

The device may be any device capable of producing audio output and performing the functions disclosed herein. For example the device may be a handheld device configured through software programming and or hardware design to perform the functions described herein such as a wireless communication device for example a cellular phone personal digital assistant PDA or the like. The device may also be an MP3 player gaming device laptop computer PC personal stereo stereo system or the like. The device may be portable or non portable.

The exemplary device includes a user interface a spatial auditory cue SAC generator stored sound sources an audio rendering engine a multi channel digital to analog converter DAC and a left channel amplifier AMP and a right channel amplifier for driving the headset . The amplifiers can be headphone high impedance HPH amplifiers.

In the example shown the SAC generator audio rendering engine and at least a portion of the user interface may be implemented by one or more processors executing programming code. The processor can be a microprocessor such as an ARM7 digital signal processor DSP one or more application specific integrated circuits ASICs field programmable gate arrays FPGAs complex programmable logic devices CPLDs discrete logic or any suitable combination thereof.

The user interface may include the features and functions of the user interface described in connection with . The user interface receives as input user manipulations of the interface and the database index list from the database . As output the user interface visually displays the database index list to the user so that the list can be browsed scrolled or otherwise searched for example as described in connection with any of . The user interface also generates messages that indicate one or more search actions of a user. These search action messages are output to the SAC generator . A search action results from a user using the user interface to search for information stored in the database . For example the search actions can be one or more button pushes at e.g. push button switch . The button pushes may be either an item by item single step forward backward search or a push and hold fast scrolling forward backward search. Other types of user search actions may be available through the user interface .

The user interface is configured to determine the type of search action e.g. a single step search or push and hold search the direction of a user search e.g. scrolling forward or backward through a displayed database index list and the currently selected database item being displayed to the user. The user interface monitors the length of time that a user depresses the push button switches to determine the type of search action and also monitors which one of its switches the user is pressing to determine the direction of the search. The user interface can determine the currently displayed database item by monitoring the item index identifiers corresponding to the user interface display buffer defining the currently selected item on the interface display.

The search action messages are sent to the SAC generator as a result of user search actions. A search action message may be sent for each database item selected i.e. browsed by the user interface . Thus as a user scrolls through a displayed list of items a sequence of search action messages can be output from the user interface with each message being generated when a different database item is displayed as the currently selected item at the user interface .

Generally the search action messages include sufficient information from the user interface to allow the SAC generator to translate the user search actions into one or more spatial auditory cues. For example each search action message may be a digital signal that includes data fields indicating 1 the database index identifier of the currently selected database item on the user interface display 2 the type of user search action e.g. push and hold or single item searching and 3 the direction of the user search e.g. scrolling forward or backward through the database index list. Other formats may be used for the search action messages.

The SAC generator translates search actions contained in user interface messages into spatial auditory cues each of which defines specific location information for a specific auditory cue output by the system through the headset . The spatial auditory cues may optionally define the type of sound produced at the specified location. For example the type of auditory cue sound may be a short audio excerpt as described above with respect to or alternatively a synthesized clicking sound depending on the speed and type of user search being performed. If the sound type is a short audio excerpt the sound type may identify the currently selected database item so that the audio rendering engine can retrieve a corresponding audio file from the sound sources database as discussed in further detail below. The SAC generator may be configured to determined sound type based on the search action type field of the search action message. The sound type may also be based on the frequency of search action messages received by the SAC generator .

The SAC generator outputs each spatial auditory cue as for example a digital signal which is transferred to the audio rendering engine . Each spatial auditory cue may include location and optionally the sound type information as fields of the digital signal. A sequence of digital output signals representing a sequence of spatial auditory cues may be produced by the SAC generator as a result of a user search.

To determine a spatial auditory cue for a search action message the SAC generator first determines a spatial auditory cue corresponding to the currently selected database item being displayed by the user interface . This determination may be made based on the database index identifier included in the search action message. Then for example if the search action type indicated by the message is a push and hold operation the search action message is translated so that the spatial auditory cues go toward one direction in space as indicated by the direction field of the search action message and move continuously with short clicking sounds being indicated as the output auditory cues. Alternatively if for example the search action type indicated by the message is a single step the search action message is translated so that the spatial auditory cues move incrementally and relatively slowly in the direction indicated by the direction field of the search action message.

The SAC generator can be configured to perform a one to one mapping whereby each database item is mapped to a corresponding spatial auditory cue i.e. a specific location in the auditory space . Alternatively the SAC generator can be configured to perform a many to one mapping whereby a plurality of database items are mapped to each spatial auditory cue and thus a single location in the auditory space may represent more than one database item.

The audio rendering engine generates audio output signals based on the spatial auditory cue location and optional sound type information produced by the SAC generator . The audio rendering engine implements the spatial movement and localization of the audio output by applying one or more HRTF filters to input audio signals and processing them. For example a continuous movement of sound can be implemented by filtering sounds with HRTF filters and quickly interpolating different HRTF coefficients as time passes. The location information provided by the spatial auditory cues may be applied to the HRTF filters to create the perception of the audio output moving or emanating from a particular location. Thus the spatial auditory cues from the SAC generator may be rendered so that a listener perceives the audio output from the headset as moving through the predetermined space as the list of database items is scrolled using the user interface . As input the audio rending engine receives audio signals from the sound sources database and spatial auditory cues from the SAC generator . The audio rendering engine outputs PCM audio on left and right audio channels to the DAC .

The stored sound sources may be a database of audio excerpts recorded sounds synthesized sounds or the like that are provided as input audio signals to the audio rendering engine . The sound sources may be stored in different audio formats such as MIDI MP3 AAC WAV files or the like. The audio rendering engine can convert the sound sources into appropriate formats that can be played on the headset . The format of the sound sources is typically uncompressed pulse code modulated PCM data before they are processed by the audio rendering engine . Sound sources that are MIDI MP3 AAC WAV or other formats can be decoded into PCM data by the audio rendering engine . The PCM data are filtered by the audio rendering engine using for example HRTF filters. The specific location at which the output sound sources are perceived by a listener is determined by design of the spatial auditory cues.

The DAC includes a left channel DAC not shown and right channel DAC not shown . The left channel DAC converts left channel digitized audio output from the audio rendering engine into a left channel analog audio signal. The left channel analog audio signal is then amplified by the left channel audio amplifier to drive the left speaker of the headset . The right channel DAC converts right channel digitized audio output from the audio rendering engine into a right channel analog audio signal. The right channel analog audio signal is then amplified by the right channel audio amplifier to drive the right speaker of the headset .

One of ordinary skill in the art will understand that additional analog audio processing circuitry not shown beyond the audio amplifiers may be included in the device .

The left and right headset speakers are any suitable audio transducer for converting the electronic signals output from the amplifiers respectively into sound.

The system includes the device surround speaker system and database . Although shown as separate components in an alternative configuration the database and or the surround speaker system may be incorporated into the device .

The device may be any device capable of producing audio output and performing the functions disclosed herein. For example the device may be a handheld device configured through software programming and or hardware design to perform the functions described herein such as a wireless communication device for example a cellular phone personal digital assistant PDA or the like. The device may also be an MP3 player gaming device laptop computer PC personal stereo stereo system or the like. The device may be portable or non portable.

The device includes the user interface the SAC generator the sound sources an audio rendering engine and a multi channel digital to analog converter DAC and amplifiers AMPS that output audio signals to the surround sound speaker system . In the example shown the SAC generator audio rendering engine and at least a portion of the user interface may be implemented by the processor executing programming code.

The audio rendering engine performs most of the functions of the audio rending engine shown in . The primary difference between the audio rendering engines is that the audio rendering engine of produces audio output signals for the speaker array instead of a headset such as the headset . Thus the rendering engine in may include a volume panner or other speaker based algorithms for locating audio output in addition to or instead of HRTF filter algorithms. As input the audio rending engine receives audio signals from the sound sources database and spatial auditory cues from the SAC generator . The audio rendering engine outputs PCM audio on multiple audio channels to the DAC .

The DAC AMPS include DACs and audio amplifiers for each output audio channel. In the example shown there are six output audio channels one for each of the speakers . Any other suitable number of audio channels and speakers many also be used. Each channel DAC converts digitized PCM audio output from the audio rendering engine into an analog audio signal which is then provided to a corresponding channel amplifier. The audio amplifiers may be commercially available audio amplifiers. Each audio amplifier drives a corresponding speaker of the surround speaker system .

One of ordinary skill in the art will understand that additional analog audio processing circuitry not shown beyond the audio amplifiers may be included in the device and or surround speaker system .

The surround speaker system provides multiple speakers that physically surround a listener. The speakers are any suitable audio transducers for converting the electronic signals output from the amplifiers respectively into sound.

The system includes the device wireless speakers and database . Although shown as separate components in an alternative configuration the database may be incorporated into the device .

The device may be any device capable of producing audio output and performing the functions disclosed herein. For example the device may be a handheld device configured through software programming and or hardware design to perform the functions described herein such as a wireless communication device for example a cellular phone personal digital assistant PDA or the like. The device may also be an MP3 player gaming device laptop computer PC personal stereo stereo system or the like. The device may be portable or non portable.

The device includes the user interface the SAC generator the sound sources the audio rendering engine a wireless audio interface that outputs audio signals to one or more wireless speaker devices . In the example shown the SAC generator audio rendering engine at least a portion of the user interface and at least a portion of the wireless audio interface may be implemented by the processor executing programming code.

The wireless interface includes a transceiver and provides wireless communications with the wireless speaker devices . Although any suitable wireless technology can be employed with the device the wireless interface preferably includes a commercially available Bluetooth module that provides at least a Bluetooth core system consisting of an antenna a Bluetooth RF transceiver baseband processor protocol stack as well as hardware and software interfaces for connecting the module to the audio rendering engine and other components if required of the device .

The PCM audio signals can be transmitted over wireless channels to the speaker devices using for example protocols as defined by the Bluetooth Specification available at www.bluetooth.com. The Bluetooth Specification provides specific guidelines for transmitting audio signal. In particular the Bluetooth Specification provides the Advanced Audio Distribution Profile A2DP that defines protocols and procedures for wirelessly distributing high quality stereo or mono audio over a Bluetooth network. The A2DP may be used with the system .

The speaker devices may be commercially available Bluetooth speakers. Each speaker device includes a wireless interface not shown for receiving the audio signals transmitted from the device s wireless interface and a speaker . The speaker devices also each include DACs audio amplifiers not shown and other audio processing circuitry for converting the PCM audio into analog audio signals for output on the speakers . Any suitable number of speaker devices may be used.

The functions and features of devices and shown in respectively can be combined into a single device configured to have multiple and optionally selectable output interfaces for providing the spatial audio output signals to the headset surround sound speaker system and wireless speaker devices respectively rendered and formatted.

The system architecture includes one or more processors such as the processor connected by one or more digital buses to a memory user interface UI hardware a wireless interface and a multi channel DAC . The UI hardware may include the display and push button as well as other hardware for providing a user interface. The output of the multi channel DAC is provided to among other things a plurality of audio amplifiers which in turn produce spatial audio output.

As described above in connection with the processor can be a microprocessor such as an ARM7 digital signal processor DSP one or more application specific integrated circuits ASICs field programmable gate arrays FPGAs complex programmable logic devices CPLDs discrete logic or any suitable combination thereof.

The memory stores the sound sources SAC generator software code audio rendering engine software code user interface software code and database interface software code . Although not shown the memory may also store the database and in addition controller software executable by the processor for controlling overall operation of the system. The software code is executable by the processor .

The database software code when executed by the processor provides a database interface that permits access to the contents of the database and its item index list. The database software can provide the index list to the user interface for display and other uses.

The SAC generator software code when executed by the processor provides the functionality of the SAC generator .

The audio render engine software code when executed by the processor provides the functionality of any of the audio rendering engines described herein.

The user interface software code when executed by the processor in conjunction with the user interface UI hardware provides the functionality of user interface described herein.

Although shown a separate software programs in the software code may be combined together into fewer software programs.

The multi channel DAC includes a DAC for each output audio channel. Each channel DAC converts digitized PCM audio output into an analog audio signal which is then provided to a corresponding channel amplifier . The audio amplifiers may be commercially available audio amplifiers and or HPH amplifiers. Any suitable number of audio channels DACs and AMPs many be included in the architecture .

One of ordinary skill in the art will understand that additional analog audio processing circuitry not shown beyond the audio amplifiers may be included in the architecture .

The wireless interface includes a transceiver and provides wireless communications with audio output device such as the wireless speaker devices or a wireless headset. Although any suitable wireless technology can be employed for the wireless interface the wireless interface preferably includes a commercially available Bluetooth module that provides at least a Bluetooth core system consisting of an antenna a Bluetooth RF transceiver baseband processor protocol stack as well as hardware and software interfaces for connecting the module to the processor and other components if required of the architecture .

PCM audio signals can be transmitted through the wireless interface using for example protocols as defined by the Bluetooth Specification available at www.bluetooth.com. The Bluetooth Specification provides specific guidelines for transmitting audio signal. In particular the Bluetooth Specification provides the Advanced Audio Distribution Profile A2DP that defines protocols and procedures for wirelessly distributing high quality stereo or mono audio over a Bluetooth network. The A2DP may be used with the architecture .

In block one or more search actions produced as a result of the user browsing are sent from the user interface to the SAC generator . The search actions may be described in a search action message as discussed above in connection with .

In block the SAC generator translates the search actions into spatial auditory cues. Each spatial auditory cue corresponds to a particular location within the listener space . The spatial auditory cue selected for a particular search action is chosen from a plurality of spatial auditory cues corresponding to a plurality of locations within the listener space. Each of the spatial auditory cues corresponds to a respective distinct location within the listener space.

In block an audio rendering engine e.g. either of the audio rendering engines fetches sound sources corresponding to the spatial auditory cues. The particular sound source that is fetched may be determined from the sound type field of the spatial auditory cue.

In decision block the rendering engine determines the type of audio output device for which the spatial audio cues are to be rendered. In the example disclosed herein the audio output device may be a headset surround speaker system or wireless speaker system.

If the audio output device is a headset the method proceeds to block and the audio rendering engine renders the spatial auditory cues as headphone based spatial audio output signals. In block the spatial audio output signals are output to headphone speakers within a headset.

If the audio output device is a surround sound speaker system the method proceeds to block and the audio rendering engine renders the spatial auditory cues as multi channel spatial audio output signals. In block the spatial audio output signals are output to the surround sound speakers.

If the audio output device is one or more wireless audio speakers the method proceeds to block and the audio rendering engine renders the spatial auditory cues as digitized spatial audio output signals suitable for transmission over one or more wireless channels. In block the digitized spatial audio output signals are output through the wireless channels.

The functionality of the systems devices headsets and their respective components as well as the method steps and blocks described herein may be implemented in hardware one or more digital circuits executing software and or firmware or any suitable combination thereof. The software firmware may be a program having sets of instructions e.g. code segments executable by one or more digital circuits such as microprocessors DSPs embedded controllers or intellectual property IP cores. The software firmware may be stored as instructions or code on one or more computer readable media. Computer readable medium includes a computer storage medium. A storage medium may be any available medium that can be accessed by a computer. By way of example and not limitation such computer readable medium can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable medium.

Certain embodiments have been described. However various modifications to these embodiments are possible and the principles presented herein may be applied to other embodiments as well. For example the principles disclosed herein may be applied to devices other than those specifically described herein. In addition the various components and or method steps blocks may be implemented in arrangements other than those specifically disclosed without departing from the scope of the claims. Thus other embodiments and modifications will occur readily to those of ordinary skill in the art in view of these teachings. Therefore the following claims are intended to cover all such embodiments and modifications when viewed in conjunction with the above specification and accompanying drawings.

