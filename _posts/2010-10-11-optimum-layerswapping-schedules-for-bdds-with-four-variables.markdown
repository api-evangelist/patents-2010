---

title: Optimum layer-swapping schedules for BDDs with four variables
abstract: One embodiment accesses a binary decision diagram (BDD) representing a function having 4 variables, variables 1, 2, 3, and 4, wherein the BDD comprises 4 layers, layers 1, 2, 3, and 4, corresponding to the 4 variables, respectively; determines an optimum variable order of the BDD by performing at most 19 layer swaps during at most 13 iterations, wherein each of 6 iterations of the at most 13 iterations comprises: determines a first size of the layers 1 and 2 and a first size of the layers 3 and 4; swaps the layers 1 and 2 and the layers 3 and 4 concurrently; determines a second size of the layers 1 and 2 and a second size of the layers 3 and 4; and determines 1 variable order among 4 variable orders obtained during the iteration that yields a smallest size among the 4 variable orders obtained during the iteration.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08626695&OS=08626695&RS=08626695
owner: Fujitsu Limited
number: 08626695
owner_city: Kawasaki-shi
owner_country: JP
publication_date: 20101011
---
A Binary Decision Diagram BDD is a data structure that may be used to represent a Boolean function. A Reduced Ordered Binary Decision Diagram ROBDD is an optimized Binary Decision Diagram BDD that has no redundant nodes and isomorphic sub trees and that the variables appear in the same order along each path from root to a terminal node. The size of a BDD is determined by both the Boolean function it represents and the order of the variables of the function. Consequently variable ordering exposes a critical optimization problem as the size of a BDD often varies greatly as its variable order changes.

A Binary Decision Diagram BDD is a data structure that may be used to represent a Boolean function. A BDD may be graphically represented as a rooted directed and acyclic graph having one or more internal decision nodes and two terminal nodes. Each decision node represents a different variable of the Boolean function and is typically denoted as a circle in the graph. The two terminal nodes a 0 terminal node and a 1 terminal node are typically denoted as a square each in the graph. Each decision node has two edges a 0 edge typically denoted as a dash line or a dotted line in the graph and a 1 edge typically denoted as a solid line in the graph. Each edge may be connected to another decision node or to one of the terminal nodes.

Each path in the graph may by formed by one or more decision nodes and their associated edges and eventually leads to either the 0 terminal node or the 1 terminal node. The decision nodes that form a particular path each represent a different variable of the Boolean function. That is along a single path no two decision nodes represent the same variable. A path that leads to the 0 terminal node indicates that the Boolean function evaluates to FALSE for the values assigned to the variables represented by the decision nodes on the path and a path that leads to the 1 terminal node indicates that the Boolean function evaluates to TRUE for the values assigned to the variables represented by the decision nodes on the path.

BDD in fact is not the most optimized representation of the Boolean function as some of the nodes in BDD are redundant and portions of BDD are isomorphic. For example consider paths and both of which end at the 0 terminal node. By examining the decision nodes on paths and it may be determined that as long as decision node which represents variable x branches along its 1 edge the Boolean function evaluates to FALSE regardless of along which branch decision node which represents variable x proceeds. Thus decision node may be replaced by the 0 terminal node. Similarly paths and all end at the 1 terminal node. By examining the decision nodes on these four paths it may be determined that as long as decision node which represents variable x branches along its 1 edge the Boolean function evaluates to TRUE regardless of along which branches decision node which represents variable x and decision nodes and which represent variable x proceed. Thus decision nodes and may be replaced by the 1 terminal node. As another example consider decision nodes and which both represent variable x. Decision node and decision node both have their 0 edge leading to the 0 terminal node and their 1 edge leading to the 1 terminal node. Therefore they are duplicates or isomorphic of each other. Thus one of them may be removed from BDD . illustrates an example BDD representing the same Boolean function as repressed by BDD but is more optimized than BDD because it uses less number of nodes to represent the same Boolean function as a result of removing the redundant decision nodes and the isomorphic portions of BDD .

A BDD whose redundant decision nodes and isomorphic sub graphs have been removed and whose decision nodes appear in the same order from the root to the terminal nodes along all the paths in the BDD is referred to as a reduced ordered binary decision diagram ROBDD . The advantage of a ROBDD is that it is canonical for a particular function and variable order which makes it useful in various types of practical applications such as in functional equivalence checking and functional technology mapping.

A ROBDD has two important properties. First the ROBDD is ordered. That is there is a fixed order 1 . . . n x . . . x such that for any non terminal node v index low v k with k index v and index high v q with q index v hold if low v and high v are also non terminal nodes. Second the ROBDD is reduced. That is there exists no non terminal node v V with low v high v and there are no two non terminal nodes v and v such that the sub BDDs rooted by v and v are isomorphic. Note that a non terminal node is a decision node. For example in BDD has 4 layers as it represents a Boolean function having 4 variables. Since BDD is ordered each layer contains the decision nodes that correspond to a particular variable. For example layer 2 contains the decision nodes corresponding to variable xonly and does not contain any decision node corresponding to another variable e.g. xor xor x .

A Boolean function x . . . x may be partitioned into two or more Boolean functions x . . . x to x . . . x . Each of the Boolean functions to may be considered a partition of the original Boolean function . If each of the Boolean functions to is represented by a BDD then the BDD that represents the original Boolean function may be obtained by logically OR ing all the BDDs that represent the partitions of i.e. to . In particular embodiments each of the BDDs that represent the Boolean functions to may be a ROBDD and may be referred to as a partitioned reduced ordered binary decision diagram POBDD with respect to the BDD that represents the original Boolean function .

The size of a BDD is determined by both the Boolean function it represents and the chosen order of the variables of the function. The size of a BDD is the sum of the sizes of all of its individual layers. In particular embodiments the size of a BDD may be expressed in terms of the number of decision nodes in the BDD. Similarly the size of a layer of a BDD may be expressed in terms of the number of decision nodes at that layer.

Given a Boolean function x . . . x represented by a BDD depending upon the ordering of the variables x . . . x the number of nodes in the graph is linear in the best case and exponential in the worst case in terms of n. For example for Boolean function x . . . x xx xx . . . xx using the variable order x

Given a particular layer of a BDD when a first variable e.g. x is positioned at that layer the layer may have one size. When a second variable e.g. x is positioned at that same layer the layer may have another different size. In addition given a particular layer e.g. layer 3 of a BDD with a particular variable e.g. x positioned at that layer the size of the layer in connection with the variable depends on the specific variables positioned at layers above e.g. layers 1 and 2 and below e.g. layer 4 that particular layer. Thus for example if variable xis positioned at layer 3 when variables xand xare positioned at layers 1 and 2 and variable xis positioned at layer 4 layer 3 in connection with variable xmay have one size. But when variables xand xare positioned at layers 1 and 2 and variable xis positioned at layer 4 layer 3 in connection with variable xmay have another different size even though variable xremains at layer 3.

There has been some amount of research concerning BDD variable ordering. The goal of BDD variable ordering is in general to find an optimum or substantially optimal ordering of the function variables such that the number of BDD nodes needed is minimized thus reducing the size of the BDD representing the function. In general in order to find the optimum variable order of a BDD where the size of the BDD is minimum it may be necessary to test many if not all possible order permutations of the variables of the BDD so that the order permutation of the variables where the size of the BDD is the smallest may be found. This order permutation yields the optimum variable order for the BDD. Note that each specific order permutation of the variables indicates a different variable order of the BDD. In practice however finding all possible order permutations of the variables of a BDD and thus finding all possible variable orders of the BDD may be very expensive in terms of time and resources it requires since for a BDD that represents a function of n variables there are n n factorial where n 1 2 . . . n possible order permutations of the variables.

To test different order permutations of the variables of a BDD the variables of the BDD may be reordered using a suitable reordering algorithm. In their simplest form reordering algorithms transform the current order permutation of variables of a BDD to another different order permutation. The ending order permutation of the BDD may be for example specified by a person e.g. according to some design specification or performance criteria or determined based on the application in which the BDD is used. The majority of the research on BDD variable reordering algorithms or processes exploits the following property two consecutive layers of a BDD can be efficiently swapped without affecting the rest of the BDD. By swapping two layers of the BDD the order of the two corresponding variables at those two layers are also swapped thus reordering two of the variables of the BDD with each swap. Variable reordering algorithms therefore transform a given BDD by applying local swaps until some target objective is reached.

To move variable 1 to layer 4 the reordering algorithm may first swap layers 1 and 2 i.e. swap . After swap variable 2 is at layer 1 and variable 1 is at layer 2. Next layers 2 and 3 are swapped i.e. swap after which variable 3 is at layer 2 and variable 1 is at layer 3. Finally layers 3 and 4 are swapped i.e. swap . At this point variable 1 is at layer 4 its desired position and variable 4 is at layer 3. To move variable 2 to layer 3 note that due to swap variable 2 is currently at layer 1 layers 1 and 2 again are swapped i.e. swap after which variable 3 is at layer 1 and variable 2 is at layer 2. Next layers 3 and 4 are swapped i.e. swap . At this point variable 2 is at layer 3 its desired position and variable 4 is at layer 2. To move variable 3 to layer 2 note that variable 3 is currently at layer 1 layers 1 and 2 are swapped i.e. swap . At this point variable 3 is at layer 2 and variable 4 is at layer 1. The desired second variable order has been achieved for BDD and the reordering algorithm may end.

As illustrated it takes a total of 6 layer swaps to reorder the 4 variables of BDD from the first variable order to the second variable order i.e. to transform the BDD from the first variable order permutation to the second variable order permutation . Recall that two consecutive layers of a BDD can be swapped without affecting the rest of the BDD. Consequently disjoint pairs of consecutive layers may be swapped concurrently since the swapping of one pair of consecutive layers does not affect any other layers and thus any other pairs of consecutive layers. A pair of consecutive layers in a BDD is any two layers that are next to each other e.g. layers i and i 1 for 1 i n 1 . Two disjoint pairs of consecutive layers are two pairs of consecutive layers that do not share any common layer. e.g. layers i and i 1 as one pair and layers i 2 and i 3 as another pair .

In swap between layers 3 and 4 is immediately followed by swap between layers 1 and 2. Layers 3 and 4 and layers 1 and 2 are two disjoint pairs of consecutive layers as the two pairs of layers do not share any common layer. Therefore swaps and may be performed concurrently i.e. in parallel since the two swaps do not affect each other i.e. the two swaps do not depend on each other s results . On the other hand swap between layers 1 and 2 is immediately followed by swap between layers 2 and 3. Layers 1 and 2 and layers 2 and 3 are not two disjoint pairs of consecutive layers as the two pairs share a common layer layer 2. Therefore swaps and cannot be performed concurrently since swap requires the result of swap before it can be performed.

A variable order of a BDD indicates which variable of the function represented by the BDD is positioned at which layer of the BDD. An optimum variable order of a BDD is a particular ordering of the variables of the function represented by the BDD where the size of the BDD is minimum among all possible order permutations of the variables of the BDD. In general a BDD may have one or more optimum variable orders. Given a BDD that represents a function having n variables there are different algorithms or processes that may be used to find its optimum variable order or optimum variable orders.

A commonly used algorithm for determining the optimum variable order of a BDD is based on the transposition network algorithm named plain changes . This is an exact algorithm because the algorithm is able to determine the exact optimum variable order for a given BDD i.e. the variable order of the BDD that results in the BDD having the smallest size . With the Plain Changes Algorithm all possible order permutations of the variables of a BDD are obtained thereby detecting the one variable order where the BDD is of minimum size and this one variable order is considered the optimum variable order of the BDD. For a BDD representing a function of n variables the Plain Changes Algorithm requires that n 1 swaps between two consecutive layers of the BDD to be performed in order to cover all possible n order permutations of the variables. Note that a BDD always has an initial variable order therefore one order permutation of the variables is already obtained without requiring any layer swaps. Thereafter the n variables of the BDD may be reordered using a suitable reordering algorithm to achieve the optimum variable order.

A BDD has 3 layers corresponding to 3 variables i.e. n 3 . There are 6 i.e. 3 possible order permutations of the 3 variables for BDD and it takes 5 layer swaps to obtain the 6 possible order permutations of the 3 variables. To determine the optimum variable order for BDD 6 sizes of BDD corresponding to the 6 different variable orders are individually determined and recorded. The 6 sizes of are then compared and the variable order resulting in the smallest size is selected as the optimum variable order of BDD .

A BDD has 4 layers corresponding to 4 variables i.e. n 4 . There are 24 i.e. 4 possible order permutations of the 4 variables for BDD . A process similar to those described in connection with BDDs and may be applied to BDD to determine the optimum variable order for BDD . In this case there are 24 sizes of BDD corresponding to the 24 different variable orders and the variable order resulting in the smallest size is selected as the optimum variable order of BDD .

The Plain Changes Algorithm works inductively by constructing the layer swap sequence for n variables from the layer swap sequence for n 1 variables. For n variables layer swaps 1 2 2 3 . . . n 1 n and n 1 n n 2 n 1 . . . 1 2 are alternatingly added in between layer swaps from the sequence of layer swaps for n 1 variables. Thus the layer swap sequence for 3 variables is constructed from the layer swap sequence for 2 variables. Swap of BDD between layers 1 and 2 corresponds to swap of BDD . And in BDD swaps between layers 1 and 2 i.e. swap and between layers 2 and 3 i.e. swap are added before swap and swaps between layers 2 and 3 i.e. swap and between layers 1 and 2 i.e. swap are added after swap . Similarly the layer swap sequence for 4 variables is constructed from the layer swap sequence for 3 variables. Swaps and of BDD correspond to swaps and of BDD respectively. And in BDD swaps between layers 1 and 2 between layers 2 and 3 and between layers 3 and 4 and swaps between layers 3 and 4 between layers 2 and 3 and between layers 1 and 2 are alternatingly added in between swaps and .

As illustrated in since most of the layers swaps performed depend on the layer swap that immediately precedes them the Plain Changes Algorithm cannot be parallelized efficiently.

There are heuristic algorithms for determining a substantially optimal variable order of a BDD. Heuristic algorithms may not always be able to determine one optimum variable order of a BDD where the size of the BDD is at its smallest but they are able to determine a substantially optimal variable order for the BDD where the size of the BDD is sufficiently small such as below a desired threshold. A widely used heuristic algorithm is the Sifting Algorithm. It works by finding the optimum location for each variable of a BDD independently. Each variable of the BDD is moved sifted to the end layer that is closer to the initial layer where the variable is positioned. The variable is then moved to the opposite end layer of the BDD. Each time the variable is moved to a new layer the size of the layer e.g. in terms of the number of decision nodes on that layer where the variable is currently positioned is determined and recorded. Thus by moving the variable from one end layer to the other end layer of the BDD the sizes of all the layers with the variable at these layers are determined. The layer that has the smallest size is considered the optimum layer i.e. location for the variable. Thereafter the variable is moved to its optimum layer which locally minimizes with size of the BDD with respect to the variable.

The same process may be applied to each variable in turn to determine the optimum location for that variable. Each variable may be selected in turn based on the number of decision nodes that depend on it initially. For example the algorithm may begin with the variable that initially has the largest number of decision nodes depending on it determine the optimum position in the BDD i.e. the layer for this first variable using the above process and move the first variable to its optimum layer. Then the algorithm may repeat the process for another variable that initially has the second largest number of decision nodes depending on it and move this second variable to its optimum layer. And so on until all the variables have been moved to their respective optimum layers or until the total size of the BDD is smaller than a desired or predefined threshold or until further adjustment of the variable positions no longer significantly reduces the total size of the BDD e.g. the difference in sizes of the BDD between two consecutive variable position adjustments is less than a predefined threshold . The Sifting Algorithm is also not parallelizable because each layer swap required for the sifting of a given variable depends on the one that immediately precedes it.

Another heuristic algorithm is the Window Algorithm. In generally the Window Algorithm cannot detect the globally optimum variable order for BDDs but has the desirable property of fast execution times. For a BDD that represents a function having n variables a window of size k is used where 2 k

Although there are several existing variable reordering algorithms that determine the optimum or the substantially optimal variable order for a BDD and reorder the variables of the BDD according to its optimum or substantially optimal variable order none of them can be parallelized efficiently as illustrate. On the other hand reordering the variables of a BDD according to its optimum or substantially optimal variable order may be very expensive e.g. in terms of time and human or machine resources especially when the number of the variables of the BDD is sufficiently large. For example as the Plain Changes Algorithm illustrates for a BDD that represents a function having n variables it takes a total of n 1 layer swaps to determine its optimum variable order. In practical applications a BDD often has hundreds or thousands of layers.

Various embodiments of the present disclosure therefore provide several variable reordering algorithms for BDDs that significantly improve upon the existing algorithms by efficiently parallelizing the reordering process. There are two main concepts underlining the design of the parallel variable reordering algorithms described in the various embodiments. The first concept may be termed maximal parallelization . For any given BDD having n layers performing a local swap between two consecutive layers e.g. layer j and layer j 1 does not alter or affect the other layers i.e. layers 1 to j 1 and layers j 2 to n of the BDD. This property can be applied recursively. In particular embodiments all layer swaps that do not depend on each other may be executed concurrently.

For example consider that illustrates a BDD having eight layers. The eight layers may be grouped into several disjoint pairs of consecutive layers. In particular embodiments according to one type of grouping layers 1 and 2 may be paired up layers 3 and 4 may be paired up layers 5 and 6 may be paired up and layers 7 and 8 may be paired up. According to this first type of grouping the 8 layers of BDD may be grouped into 4 disjoint pairs of consecutive layers. Two pairs of consecutive layers are considered disjoint if they do not share any common layer. For example the pair with layers 1 and 2 and the pair with layers 3 and 4 do not share any common layer between them. Swapping layers 1 and 2 do not affect layers 3 to 8. Similarly swapping layers 3 and 4 do not affect layers 1 to 2 and 5 to 8. And so on. Consequently the 4 disjoint pairs of consecutive layers may be swapped concurrently as there is no interdependency among the individual pairs. Alternatively according to another type of grouping layers 2 and 3 may be paired up layers 4 and 5 may be paired up and layers 6 and 7 may be paired up. According to this second type of grouping the 8 layers of BDD may be grouped into 3 disjoint pairs of consecutive layers. Again swapping layers 2 and 3 do not affect layers 1 and 4 to 8. Swapping layers 4 and 5 do not affect layers 1 to 3 and 6 to 8. And so on. Consequently the 3 disjoint pairs of consecutive layers may be swapped concurrently as there is no interdependency among the individual pairs.

To generalize given any BDD having n layers corresponding to n variables where n may be any odd or even integer greater than or equal to 3 there are at least two ways to group the n layers into disjoint pairs of consecutive layers. For example if n 4 then the 4 layers may be grouped as 1 2 and 3 4. On the other hand if n 5 then one way to group the 5 layers may be 1 2 and 3 4 another way to group the 5 layers may be 1 2 and 4 5 and a third way to group the 5 layers may be 2 3 and 4 5. According to the first type of grouping each pair includes an odd layer j and an even layer j where j j 1 for 1 j n 1. All the pairs thus grouped may be referred to as odd grouping pairs or first grouping pairs and may be swapped concurrently. According to the second type of grouping each pair includes an even layer j and an odd layer j where j j 1 for 2 j n 1. All the pairs thus grouped may be referred to as even grouping pairs or second grouping pairs and again may be swapped concurrently. In particular embodiments all the first grouping pairs obtained according to the first type of grouping and all the second grouping pairs obtained according to the second type of grouping may be iteratively and alternatingly swapped.

For example in during the first iteration t 1 all the odd grouping pairs i.e. the first grouping pairs are swapped in parallel i.e. concurrently . During the second iteration t 2 all the even grouping pairs i.e. the second grouping pairs are swapped in parallel. During the third iteration t 2 all the odd grouping pairs are again swapped in parallel. The process may continue alternating between swapping all the odd grouping pairs and all the even grouping pairs until a desired result is achieved.

To generalize in particular embodiments the process swaps all the odd grouping pairs concurrently during each odd iteration e.g. iterations 1 3 5 . . . and swaps all the even grouping pairs concurrently during each even iteration e.g. iterations 2 4 6 . . . . Alternatively in other embodiments the process may swap all the even grouping pairs concurrently during each odd iteration and swap all the odd grouping pairs concurrently during each even iteration.

The second concept may be termed implicit enumeration of permutations . Consider that illustrates a BDD having six layers. Suppose these six layers are grouped into three disjoint pairs of consecutive layers layers 1 and 2 layers 3 and 4 and layers 5 and 6. The three disjoint pairs of consecutive layers may be swapped sequentially or concurrently. If before the three layer swaps the variable order of BDD is 1 2 3 4 5 6 i.e. variable 1 is at layer 1 variable 2 is at layer 2 variable 3 is at layer 3 and so on then after the three layer swaps the variable order of BDD becomes 2 1 4 3 6 5 i.e. variable 2 is at layer 1 variable 1 is at layer 2 variable 4 is at layer 3 variable 3 is at layer 4 variable 6 is at layer 5 and variable 5 is at layer 6 .

Particular embodiments make the following observation since the execution of each of these layer swaps does not affect the structure and thus the size of the rest of BDD the size of any permutation obtained by executing any subset of these swaps can be calculated without explicitly generating the corresponding complete variable order for the entire BDD. For example with BDD before the 3 layer swaps the sizes of the 6 layers may be individually determined with variable 1 at layer 1 variable 2 at layer 2 variable 3 at layer 3 variable 4 at layer 4 variable 5 at layer 5 and variable 6 at layer 6. After the 3 swaps the sizes of the 6 layers may be individually determined again but with variable 2 at layer 1 variable 1 at layer 2 variable 4 at layer 3 variable 3 at layer 4 variable 6 at layer 5 and variable 5 at layer 6. Thus for each disjoint pair of consecutive layers there are two sizes the size before the two layers are swapped and the size after the two layers are swapped. For the 6 layers of BDD there are 3 disjoint pairs of consecutive layers.

More specifically for layers 1 and 2 before layers 1 and 2 are swapped the size of layers 1 and 2 with variables 1 and 2 may be determined. After layers 1 and 2 are swapped the size of layers 1 and 2 with variables 2 and 1 may be determined. Similarly for layers 3 and 4 before layers 3 and 4 are swapped the size of layers 3 and 4 with variables 3 and 4 may be determined. After layers 3 and 4 are swapped the size of layers 3 and 4 with variables 4 and 3 may be determined. And for layers 5 and 6 before layers 5 and 6 are swapped the size of layers 5 and 6 with variables 5 and 6 may be determined. After layers 5 and 6 are swapped the size of layers 5 and 6 with variables 6 and 5 may be determined.

Different combinations of the sizes of the 3 disjoint pairs of consecutive layers may yield sizes of different variable orders for BDD without explicitly generating the corresponding variable orders. For example to implicitly determine the size of variable order 1 2 4 3 5 6 i.e. variable 1 is at layer 1 variable 2 is at layer 2 variable 4 is at layer 3 variable 3 is at layer 4 variable 5 is at layer 5 and variable 6 is at layer 6 particular embodiments may compute the sum of 1 the size of layers 1 and 2 with variables 1 and 2 respectively obtained before swapping layers 1 and 2 2 the size of layers 3 and 4 with variables 4 and 3 respectively obtained after swapping layers 3 and 4 and 3 the size of the layers 5 and 6 with variables 5 and 6 respectively obtained before swapping layers 5 and 6 . All three sizes have been determined either before or after the 3 layer swaps. As another example to implicitly determine the size of variable order 2 1 3 4 6 5 particular embodiments may compute the sum of 1 the size of layers 1 and 2 with variables 2 and 1 respectively obtained after swapping layers 1 and 2 2 the size of layers 3 and 4 with variables 3 and 4 respectively obtained before swapping layers 3 and 4 and 3 the size of the layers 5 and 6 with variables 6 and 5 respectively obtained after swapping layers 5 and 6 .

In the case of BDD by combining the sizes of the 3 disjoint pairs of consecutive layers obtained before and after the layer swaps the sizes of 7 additional variable orders may be computed with 3 layer swaps with respect to the 3 disjoint pairs of consecutive layers. Note that since BDD initially has variable order 1 2 3 4 5 6 the size of this variable order is already known and does not need to be computed. illustrates all eight different variable orders of BDD whose sizes may be determined by combining the different sizes of the 3 disjoint pairs of consecutive layers obtained before and after the 3 swaps. For 6 variables i.e. 3 disjoint pairs of consecutive layers there are 8 unique combinations note that one of the variable orders 1 2 3 4 5 6 is the initial order before the layer swap . To generalize given any BDD having n layers corresponding to n variables if k layer swaps are executed in parallel i.e. there are k disjoint pairs of consecutive layers then the sizes of 2 1 variable orders can be implicitly computed. Note that there is 1 because the size of the initial variable order of the BDD before the layer swaps can be obtained directly without requiring any implicit computation. In general however given k disjoint pairs of consecutive layers the sizes of 2different variable orders may be determined by swapping the k disjoint pairs of consecutive layers.

The parallel variable reordering algorithms for BDDs described in the various embodiments rely on the concepts of maximal parallelization and implicit enumeration of permutations. Existing variable reordering algorithms for BDDs are not parallelizable because most of the executed swaps are interdependent. Particular embodiments therefore attempt to structure the layer swapping process so that the interdependency between the pairs of consecutive layers that need to be swapped is minimized e.g. by forming disjoint pairs of consecutive layers thus increasing the possibility of swapping multiple pairs of consecutive layers in parallel.

Particular embodiments observe that a schedule of swaps where the depth of the swap network is minimized is desirable. Suppose a given BDD having n layers corresponding to n variables initially has a first variable order and it is desirable to reorder the n variables of the BDD according to a different second variable order. The second variable order may be obtained by any suitable means e.g. specified by a person or determined according to design specification requirements or application criteria . Particular embodiments observe that applying a given permutation i.e. variable order to the current variable permutation is equivalent to the problem of sorting if the total order imposed on the variable identifiers is defined by the desired final permutation.

In particular embodiments assume the first variable order of the BDD i.e. the variable order the BDD currently has is the identity permutation that is each variable i is at layer i for 1 i n. The desired second variable order is defined as i that is each variable i is at layer i for 1 i n. The goal is to reorder the n variables of the BDD so that the BDD eventually has the second variable order. illustrates an example of the Parallel Permutation Algorithm which reorders the n variables of a BDD initially having a first variable order according to a second variable order. illustrate the Parallel Permutation Algorithm as applied to a BDD having six layers corresponding to six variables. The steps illustrated in are described using BDD as an example.

As described above in connection with given any BDD having n layers corresponding to n variables there are two ways to group the n layers into disjoint pairs of consecutive layers. First the n layers may be grouped into odd grouping pairs also referred to as first grouping pairs where each pair includes an odd layer followed by an even layer. Second the n layers may be grouped into even grouping pairs also referred to as second grouping pairs where each pair includes an even layer followed by an odd layer. All the odd grouping pairs may be swapped concurrently as they are disjoint from each other i.e. they do not share any common layer . Similarly all the even grouping pairs may be swapped concurrently as they are also disjoint from each other. The Parallel Permutation Algorithm takes advantage of this property.

In particular embodiments the n layers of the BDD are iteratively and alternatingly grouped into odd grouping pairs and even grouping pairs and each pair of layers is swapped if the current order of the two layers during the current iteration differs from the order specified by the second variable order. More specifically using BDD having six layers corresponding to six variables in as an example. BDD initially has a first variable order which is the identity permutation 1 2 3 4 5 6 i.e. each variable i is at layer for 1 i 6 . Suppose the desired second variable order is 6 3 4 5 1 2 i.e. variable 6 at layer 1 variable 3 at layer 2 variable 4 at layer 3 and so on which means 6 

In particular embodiments during the first iteration i.e. t 1 the 6 layers of BDD is grouped into 3 odd grouping pairs layers 1 and 2 layers 3 and 4 and layers 5 and 6 as illustrated in step of . These are disjoint pairs of consecutive layers as they do not share any common layer among the pairs. Therefore the 3 odd grouping pairs may be swapped concurrently as illustrated in step of . For layers 1 and 2 variable 1 is currently at layer 1 and variable 2 is currently at layer 2. Thus the current order of the two variables at layers 1 and 2 is 1 2 which already agrees with the order specified by the second variable order for variables 1 and 2 i.e. variable 1 before variable 2 which means 1 

After each iteration the process determines whether the second variable order has been achieved as illustrated in step of . If so the process may end with success. Otherwise the process continues to the next iteration. For BDD after the first iteration the variable order becomes 1 2 3 4 6 5. Thus the desired second variable order has not been achieved and another iteration is needed.

In particular embodiments during the second iteration i.e. t 2 the 6 layers of BDD is grouped into 2 even grouping pairs layers 2 and 3 and layers 4 and 5 as illustrated in step of . Again these are disjoint pairs of consecutive layers as they do not share any common layer among the pairs. Therefore the 2 even grouping pairs may be swapped concurrently as illustrated in step of . For layers 2 and 3 variable 2 is currently at layer 2 and variable 3 is currently at layer 3. The current order of the two variables at layers 2 and 3 is 2 3 which differs from the order specified by the second variable order for variables 2 and 3 i.e. 2 3 . Therefore layers 2 and 3 are swapped during this iteration after which variable 3 is at layer 2 and variable 2 is at layer 3. Similarly for layers 4 and 5 variable 4 is currently at layer 4 and variable 6 is currently at layer 5. The current order of the two variables at layers 4 and 5 is 4 6 which differs from the order specified by the second variable order for variables 4 and 6 i.e. 4 6 . Therefore layers 4 and 5 are swapped during this iteration after which variable 6 is at layer 4 and variable 4 is at layer 5. Since two layer swaps are needed during this iteration in particular embodiments they may be performed in parallel.

Again after each iteration the process determines whether the second variable order has been achieved as illustrated in step of . If so the process may end with success. Otherwise the process continues to the next iteration. For BDD after the second iteration the variable order becomes 1 3 2 6 4 5. Thus the desired second variable order has not been achieved and another iteration is needed. The steps performed during the third and the fifth iteration is similar to those of the first iteration and the steps performed during the fourth and the sixth iteration is similar to those of the second iteration.

As illustrated in for BDD it takes a total of 6 iterations to reorder the 6 variables before the second variable ordering is achieved. During each odd iteration i.e. iterations 1 3 5 the 6 layers of BDD are grouped into odd grouping disjoint pairs of consecutive layers. During each even iteration i.e. iterations 2 4 6 the 6 layers are grouped into even grouping disjoint pairs of consecutive layers. During the third iteration i.e. t 3 layers 1 and 2 and layers 3 and 4 are swapped concurrently. During the fourth iteration i.e. t 4 layers 2 and 3 and layers 4 and 5 are swapped concurrently. During the fifth iteration i.e. t 5 layers 1 and 2 layers 3 and 4 and layers 5 and 6 are swapped concurrently. During the sixth iteration i.e. t 6 layers 4 and 5 are swapped.

However BDD is one example of the Parallel Permutation Algorithm. Alternatively during each odd iteration the 6 layers may be grouped into even grouping disjoint pairs of consecutive layers while during each even iteration the 6 layers may be grouped into odd grouping disjoint pairs of consecutive layers. The algorithm is able to achieve its goal as long as the grouping of the layers alternates between successive iterations. During each iteration the pairs of layers are either swapped or not swapped depending on whether the orders of the variables currently at the layers differ from or agree with the orders of the corresponding variables specified by the desired second variable order.

To generalize given a BDD having n layers corresponding to n variables and the BDD initially has a first variable order where each variable i is at layer i for 1 i n and given a second variable order of the BDD defined as i where each variable i is at layer i for 1 i n to reorder the n variables of the BDD according to the second variable order in particular embodiments the Parallel Permutation Algorithm performs an iterative process. During each odd iterations the n layers are grouped into a first type of disjoint pairs of consecutive layers according to a first grouping scheme. During each even iterations the n layers are grouped into a second type of disjoint pairs of consecutive layers according to a second grouping scheme. During each iteration a pair of consecutive layers is swapped only if the order of the two variables currently at the two layers differs from the order of the two variables specified by the second variable order. That is for two consecutive layers jand j during a particular iteration suppose variable iis currently at layer jand variable iis currently at layer j. Then layers jand jare swapped during this iteration only if i i . In particular embodiments all the layer swaps performed during each iteration are done in parallel i.e. concurrently .

Particular embodiments observe that for any BDD having n layers corresponding to n variables and the BDD initially has a first variable order using the Parallel Permutation Algorithm it takes at most n iterations each iteration may also be referred to as a level of layer swaps to reorder the n variables of the BDD to achieve a second variable order. In addition it takes at most

The Parallel Permutation Algorithm described above in connection with may be used for transforming permutations between different partitions of BDDs and particularly of ROBDDs. In practical applications a BDD or more commonly a ROBDD often has thousands even millions of nodes. Therefore storing such large BDDs or ROBDDs may require a great amount of storage space. To address this problem often a large BDD or ROBDD may be partitioned into two or more sub BDDs and each sub BDD is in effect a BDD by itself. The original BDD may be obtained by logically OR ing the sub BDDs. To further reduce the need for storage space the variables of each sub BDD may be reordered according to the optimum or substantially optimal variable order of that particular sub BDD. The sub BDDs are then stored thus. However since each sub BDD is in effect a BDD by itself the optimum or substantially optimal variable order of one sub BDD may differ from the optimum or substantially optimal variable order of another sub BDD.

When operations need to be performed in connection with the BDD the sub BDDs may be combined together to form the original BDD. Alternatively the operations may be performed in connection with the individual sub BDDs. In either case when performing these operations all the sub BDDs involved need to have the same variable order. If there are a total of m sub BDDs where m 2 all having different variable orders then the variables of m 1 sub BDDs may need to be reordered.

In particular embodiments suppose there are two BDDs a first BDD and a second BDD each having n layers corresponding to n variables. The first BDD currently has a first variable order. The second BDD currently has a second variable order which differs from the first variable order of the first BDD. Further suppose that the first BDD and the second BDD are two partitions i.e. two sub BDDs of a third BDD i.e. the first BDD and the second BDD together form the third BDD . When needed the n variables of the first BDD may be reordered according to the second variable order of the second BDD using the Parallel Permutation Algorithm described above in connection with . Alternatively the n variables of the second BDD may be reordered according to the first variable order of the first BDD using the Parallel Permutation Algorithm. In either case after the variable reordering the first BDD and the second BDD both have the same variable order. Thereafter they may be combined to form the third BDD or operations may be performed in connection with the first BDD and the second BDD individually. The process may be applied similarly where a BDD is partitioned into three or more sub BDDs. One sub BDD is selected as the sub BDD having the desired variable order. The variables of each of the other sub BDDs are reordered according to the variable order of the selected sub BDD using the Parallel Permutation Algorithm.

As illustrates given any BDD having n layers corresponding to variables the maximum parallelization that can be achieved is n 2 as at most n 2 layer swaps can be executed in parallel during each iteration. Therefore it is desirable to place as many as n 2 layer swaps during each iteration i.e. at each level . While this is possible for the case of the permutation algorithm it is not always possible when at the same time the process needs to respect the semantics of an exact or heuristic algorithm.

In the case of exact reordering in particular embodiments it is desirable to determine a swapping schedule that requires less than n 1 iterations to perform n 1 layer swaps e.g. as with the case of the Plain Changes Algorithm in order to go through all the possible variable permutations to determine the optimum variable order. Particular embodiments may determine the swapping schedule based on the implicit permutations concept described above.

Particular embodiments may consider a BDD having 4 layers corresponding to 4 variables and determine the optimum layer swapping schedule for such a BDD. Note that for BDDs having 2 or 3 layers corresponding to 2 or 3 variables no two swaps can be executed in parallel as for example illustrates.

For 4 variables there are a total of 24 i.e. 4 possible variable orders. To determine the optimum variable order the sizes of the 24 possible variable orders need to be determined so that the variable order with the smallest size may be selected. However based on the implicit enumeration concept the 24 possible variable orders do not need to be explicitly generated in order to determine the 24 sizes of the 24 variable orders.

Using BDD as an example suppose the initial variable order of BDD is 1 2 3 4. The size s of layers 1 and 2 with variables 1 and 2 respectively may be determined and the size s of layers 3 and 4 with variables 3 and 4 respectively may be determined. During the first iteration i.e. t 1 layers 1 and 2 and layers 3 and 4 are swapped in parallel. After the first iteration the variable order of BDD is 2 1 4 3. The size s of layers 1 and 2 with variables 2 and 1 respectively may be determined and the size s of layers 3 and 4 with variables 4 and 3 respectively may be determined. After the first iteration the sizes of 4 variable orders may be computed 1 the size of variable order 1 2 3 4 is the sum of sand s note that since 1 2 3 4 is the initial variable order of BDD the size of this variable order is in fact the initial size of BDD which is known without requiring any layer swap 2 the size of variable order 2 1 3 4 is the sum of sand s 3 the size of variable order 1 2 4 3 is the sum of sand s and 4 the size of variable order 2 1 4 3 is the sum of sand s. In practice however it may not be necessary to explicitly compute all 4 sizes of the 4 variable orders obtained in connection with the first iteration. Particular embodiments may select the smaller of sizes sand sfor layers 1 and 2 and select the smaller of sizes sand sfor layers 3 and 4 to determine the variable order that yields the smallest size for the 4 variable orders obtained in connection with the first iteration and record the variable order that yields the smallest size thus far for comparison during subsequent iterations.

During the second iteration i.e. t 2 layers 2 and 3 are swapped. After the second iteration the variable order is 2 4 1 3. The purpose of the second iteration is to position the 4 variables for another iteration where layers 1 and 2 and layers 3 and 4 may be swapped concurrently and the sizes of more variable orders may be computed based on the implicit permutations concept similar to the process described with the first iteration.

Before the third iteration the size s of layers 1 and 2 with variables 2 and 4 respectively may be determined and the size s of layers 3 and 4 with variables 1 and 3 respectively may be determined. During the third iteration i.e. t 3 layers 1 and 2 and layers 3 and 4 are swapped in parallel. After the third iteration the variable order of BDD is 4 2 3 1. The size s of layers 1 and 2 with variables 4 and 2 respectively may be determined and the size s of layers 3 and 4 with variables 3 and 1 respectively may be determined. After the third iteration the sizes of another 4 variable orders may be computed 1 the size of variable order 2 4 1 3 is the sum of sand s 2 the size of variable order 2 4 3 1 is the sum of sand s 3 the size of variable order 4 2 1 3 is the sum of sand s and 4 the size of variable order 4 2 3 1 is the sum of sand s. Again in practice it may not be necessary to explicitly compute all 4 sizes of the 4 variable orders obtained in connection with the third iteration. Particular embodiments may select the smaller of sizes sand sfor layers 1 and 2 and select the smaller of sizes sand sfor layers 3 and 4 to determine the variable order that yields the smallest size for these 4 variable orders obtained in connection with the third iteration. The smallest size for the 4 variable orders obtained in connection with the third iteration may be compared with the smallest size for the 4 variables orders obtained in connection with the first iteration. The variable order from the first or the third iteration that yields the smallest size thus far may be recorded for comparison during subsequent iterations.

During the fourth iteration i.e. t 4 layers 2 and 3 are swapped. During the fifth iteration i.e. t 5 layers 1 and 2 are swapped. After the fifth iteration the variable order is 4 3 2 1. The purpose of the fourth and the fifth iteration is to position the 4 variables for another iteration where layers 1 and 2 and layers 3 and 4 may be swapped concurrently and the sizes of more variable orders may be computed based on the implicit permutations concept similar to the process described with the first and the third iteration.

Examining BDD there are four more iterations i.e. the sixth iteration the ninth iteration the eleventh iteration and the thirteenth iteration during which layers 1 and 2 and layers 3 and 4 are swapped concurrently. During each of these iterations the sizes of four unique variable orders may be computed based on the implicit enumeration concept similar as the first and the third iteration. Examining BDD there are a total of 6 iterations i.e. the first the third the sixth the ninth the eleventh and the thirteenth iterations during which layers 1 and 2 and layers 3 and 4 are swapped concurrently. Each of these 6 iterations provide sizes of 4 variable orders based on the implicit enumeration concept. Thus these 6 iterations may be referred to as enumeration or permutation iterations. The other iterations in between these 6 enumeration iterations e.g. the second the fourth the fifth the seventh the eighth the tenth and the twelfth iteration reposition the variables for the subsequent enumeration iterations.

In particular embodiments after each enumeration iteration the variable order that yields the smallest size among the 4 variable orders obtained in connection with that enumeration iteration is selected and its size i.e. the smallest of the sizes of the 4 variable orders obtained in connection with that enumeration iteration is compared with the smallest size of the variable order obtained and recorded during the previous iterations and the variable order that yields the smaller size is recorded as the variable order that yields the smallest size thus far. Therefore at the end of the thirteenth iteration the variable order selected as the result of again comparing the smallest size of the 4 variable orders obtained in connection with the thirteenth iteration and the smallest size determined and recorded during the previous iterations is the optimum variable order for BDD as it yields the smallest size among all 24 possible variable orders.

Comparing the optimum layer swapping schedule illustrated in with for example the Plain Changes Algorithm as applied to a BDD having 4 layers corresponding to 4 variables. To obtain all possible variable permutations for the 4 variables the Plain Changes Algorithm requires 23 layer swaps packed in either 23 iterations without parallelization or 18 iterations with full parallelization where as the layer swapping schedule illustrated in only requires 13 iterations with 19 layer swaps. Obviously the layer swapping schedule illustrated in improves upon the Plain Changes Algorithm as it requires less number of iterations and layer swaps and thus less time to complete.

Note that within each group of k sets of two elements each element only appears once. For example within each of the 6 types of separation above if a number appears in the first set then it does not appear in the second set. Conversely if a number appears in the second set then it does not appear in the first set. In particular embodiments applying this concept to BDD variables an element is equivalent to a variable. Each two variable set includes two of the variables of a BDD and each group includes k ordered sets . Within each two variable set the order of the two variables is irrelevant e.g. 1 2 is considered the same as 2 1 . However for each k ordered sets of two variables the order matters. Thus 1 2 3 4 is not considered the same as 3 4 1 2 . Therefore there exists

For the case of a BDD having 6 variables i.e. n 6 and k 3 there exist 90 ways to separate the 6 variables into 3 ordered sets of two variables each i.e. 90 unique groups . The following illustrates a few example groups of the pair wise separation of the 6 variables 

In particular embodiments suppose each group of the k ordered sets of two variables is considered a particular variable order of the BDD. For example in the case of 4 variables group 1 provides variable order 1 2 3 4 i.e. variables 1 2 3 4 are at layers 1 2 3 4 respectively . Group 2 provides variable order 1 3 2 4 i.e. variables 1 3 2 4 are at layers 1 2 3 4 respectively . Group 3 provides variable order 1 4 2 3 i.e. variables 1 4 2 3 are at layers 1 2 3 4 respectively . And so on. In the case of 6 variables group 1 provides variable order 1 2 3 4 5 6 i.e. variables 1 2 3 4 5 6 are at layers 1 2 3 4 5 6 respectively . Group 3 provides variable order 2 4 1 3 5 6 i.e. variables 2 4 1 3 5 6 are at layers 1 2 3 4 5 6 respectively . Group 5 provides variable order 3 4 1 5 2 6 i.e. variables 3 4 1 5 2 6 are at layers 1 2 3 4 5 6 respectively . And so on.

Using the case of 4 variables as an example the BDD has 4 layers. Layers 1 and 2 and layers 3 and 4 form two disjoint pairs of consecutive layers. Therefore layers 1 and 2 and layers 3 and 4 may be swapped concurrently as described above in connection with . Considering group 1 of the 4 variable case 1 2 3 4 which may provide variable order 1 2 3 4. If layers 1 and 2 and layers 3 and 4 are swapped then after the layer swapping the variable order becomes 2 1 4 3. Using the concept of implicit enumeration as described above in connection with if the sizes of layers 1 and 2 are determined before and after layers 1 and 2 are swapped and the sizes of layers 3 and 4 are determined before and after layers 3 and 4 are swapped then the sizes of 4 variable orders i.e. 1 2 3 4 2 1 3 4 1 2 4 3 and 2 1 4 3 may be computed by combining of the sizes of layers 1 and 2 and the sizes of layers 3 and 4. The same process may be applied to each of the other 5 groups. For example for group 2 of the 4 variable case 1 3 2 4 before the layer swapping the variable order provided by group 2 is 1 3 2 4. After the layer swapping the variable order becomes 3 1 4 2. Again if the sizes of layers 1 and 2 are determined before and after layers 1 and 2 are swapped and the sizes of layers 3 and 4 are determined before and after layers 3 and 4 are swapped then the sizes of 4 variable orders i.e. 1 3 2 4 3 1 2 4 1 3 4 2 and 3 1 4 2 may be computed. Thus each unique group may provide the sizes of four different variable orders by swapping layers 1 and 2 and layers 3 and 4. With 6 unique groups the sizes of all 24 variable orders of a BDD having 4 variables may be computed. The variable order having the smallest size is the optimum variable order of the BDD.

Consider the case of 6 variables where the BDD has 6 layers. Layers 1 and 2 layers 3 and 4 and layers 5 and 6 form three disjoint pairs of consecutive layers. Therefore layers 1 and 2 layers 3 and 4 and layers 5 and 6 may be swapped concurrently. Each group may provide a different variable order. For example group 7 of the 6 variable case provides variable order 4 5 2 3 1 6.

If the sizes of layers 1 and 2 are determined before and after layers 1 and 2 are swapped the sizes of layers 3 and 4 are determined before and after layers 3 and 4 are swapped and the sizes of layers 5 and 6 are determined before and after layers 5 and 6 are swapped then the sizes of 8 variable orders of the BDD may be computed by combining of the sizes of layers 1 and 2 the sizes of layers 3 and 4 and the sizes of layers 5 and 6 based on the implicit enumeration concept. In fact each of the 90 unique groups may provide the sizes of 8 different variable orders by swapping layers 1 and 2 layers 3 and 4 and layers 5 and 6 thus providing the sizes of all 270 possible variable orders of a BDD having 6 variables. Again the variable order having the smallest size is the optimum variable order of the BDD.

The process may be similarly applied to a BDD having n layers corresponding to n variables where n is any integer even or odd that is greater than or equal to 3. When n is odd there may be a set in each group that has only 1 variable instead of 2 variables. For example if n 5 i.e. an odd number then some example groups of the pair wise separation of the 5 variables may be 

Because the variable sets in each group are ordered i.e. the order of the sets in each group is relevant to the variable reordering algorithms in particular embodiments when n is odd so that there is one set in each group that has only one variable the relative position of this one variable set with respect to the other two variable sets in each group is relevant and should be the same among all the groups. For example the one variable set may be the last set in all the groups or the first set in all the groups or the second set in all the groups and so on. In other words it is irrelevant which position e.g. first second third or last the one variable set is actually placed in relation to the other two variable sets in each group but it is necessary that the one variable set is placed at the same position in relation to the other two variable sets in all the groups.

Note that since within each set of two variables the order of the two variables is irrelevant 4 1 2 3 and 1 4 2 3 are considered the same group not two unique groups. Again each two sets of two variables together may provide a different variable order. The optimum layer swapping schedules described above in connection with may be used to determine the sizes of the different variable orders obtained from the 6 groups efficient. If the 4 variables are separated into the above 6 groups then the layer swapping schedule illustrated in may be used to determine the sizes of the 24 possible variable orders based on the implicit enumeration concept.

In the layer swapping schedule for the four variables is the same as that illustrated in . However only the variable orders corresponding to the above 6 groups are marked. As suggests the 6 unique groups or 2 ordered sets of 2 variables as illustrated above correspond to the 6 variable orders before the 6 iterations during which both layers 1 and 2 and layers 3 and 4 are swapped. In the more general case of n variables separated into

In particular embodiments this optimization may be performed offline once for each specific value of n. Particular embodiments may use an exhaustive approach to detect the optimum separation orderings. Nevertheless if n is large enough such that an exhaustive approach is not applicable or practical then alternatively particular embodiments may start with any separation order and subsequently independently move each separation to the left or to the right until its locally optimum position is detected. Each parallel permutation stage requires at most n iterations. Therefore each separation ordering corresponds to a layer swapping schedule that spans at most

In particular embodiments given any BDD having n where n is any integer even or odd that is greater than or equal to 3 the n variables may be separated into

Note that since the optimum variable order of a BDD having 4 variables may be determined efficiently using for example the optimum layer swapping schedules described in in practice the recursive process may continue until each set within each group has 4 variables. Then the process described above in connection with may be used to determine a locally optimum variable order for each set of 4 variables.

There are two many groups to list all in this disclosure. During the second iteration within each group each set of 4 variables are again separated into a number of unique groups where each group consists of 2 ordered sets and each set consists of 2 variables. For example after the second iterations set 1 2 3 4 may form 6 groups of 2 sets of 2 variables. Similarly set 5 6 7 8 may form another 6 groups of 2 sets of 2 variables each. Set 1 2 3 5 may form yet another 6 groups of 2 sets of 2 variables each. And so on.

After the second iteration each set within each group has 2 variables. Thus the recursion may end. If n is a number greater than 8 then more iterations are needed. After the last iteration in the sets of variables along each row form a unique group of 4 ordered sets of 2 variables and each group may provide a unique variable order for a BDD of 8 variables. The optimum variable order of the BDD may be determined using a process similar to that described in connection with . More specifically particular embodiments may determine a locally optimum variable order within each group using the implicit enumeration concept and then determine the optimum variable order for the BDD by selecting the locally optimum variable order that yields the smallest size among all the locally optimum variables corresponding to all the groups.

To summarize in particular embodiments given a set of n variables where n may be any integer odd or even that is greater than 2 the existing set may be separated into two new sets of variables with one set having

As described above the optimum variable order of a BDD having 4 variables may be determined using for example any of the algorithms illustrated in . Thus in particular embodiments the recursion to separate n variables may continue until each set in each group has 4 variables or less. Then the locally optimum variable order of each set in each group may be determined using for example any of the algorithms illustrated in . For each group its locally optimum variable order may be determined using the locally optimum variable orders of the individual sets in that group. Then for the BDD its optimum variable order may be determined using the locally optimum variable orders of the individual groups.

For the case of n 5 i.e. 5 variables based on the method of separating n variables described above in particular embodiments the 5 variables may be separated into groups of 2 ordered sets where within each group one set has 2 variables and one set has 3 variables. The optimum variable order of 5 variables may then be determined using such groups. However in particular embodiments experiments suggest that it may be more efficient to separate the 5 variables into groups of 2 ordered sets where within each group one set has 4 variables and one set has 1 variable. The locally optimum variable order of each 4 variable set in each group may be determined using for example any of the algorithms illustrated in . For each group its locally optimum variable order may be determined using the locally optimum variable order of the 4 variable set in that group. The optimum variable order for the case of 5 variables may be determined using the locally optimum variable orders of the individual groups.

In particular embodiments the recursion to separate n variables may continue until each set in each group has 5 variables or less. Then the locally optimum variable order for each 4 variable set in each group may be determined using for example any of the algorithms illustrated in . The locally optimum variable order of each 5 variable set in each group may be determined using the method described above for the 5 variable case. For each group its locally optimum variable order may be determined using the locally optimum variable orders of the individual sets in that group. Then for the BDD its optimum variable order may be determined using the locally optimum variable orders of the individual groups.

In particular embodiments the concept may be further generalized as the following. The recursion to separate n variables may continue until each set in each group has k variables or less where 1 k

In particular embodiments the separation stages are ordered and linked with parallel permutation stages in a similar fashion as described above in connection with for the four variable case. It may be shown that the required iterations are obtained by the recursion

Comparing this recursive algorithm for separating the n variables with the non recursive algorithm described above in connection with the recursive algorithm requires at most 4iterations of layer swapping to determine the optimum variable order for a BDD having n variables while the non recursive algorithm requires at most

The Window Algorithm described in connection with provides that for a BDD that represents a function having n variables a window of size k may be selected where 2 k

In particular embodiments the existing Window Algorithm may be improved with parallelization. Particular embodiments select a window size of k e.g. k 4 . A window then consists of k consecutive layers. Then within each window the locally optimum variable order for the k variables at the k consecutive layers may be determined and the k variables may be reordered according to its locally optimum variable order or locally substantial optimum variable order using any suitable BDD variable reordering algorithm. Further more multiple disjoint windows of k consecutive layers may be processed in parallel. Two windows are disjoint if they do not share a common layer.

In particular embodiments for a BDD having n layers corresponding to n variables with a window of size k e.g. k 4 during each iteration the n layers may be grouped into at most

Between different iterations the n layers may be grouped differently. In particular embodiments for example if n is divisible by 4 then during the first iteration the windows are layers 1 . . . 4 layers 5 . . . 8 . . . layers n 3 . . . n. During the second iteration the windows are layers 2 . . . 5 layers 6 . . . 9 . . . layers n 6 . . . n 3. During the third iteration the windows are layers 3 . . . 6 layers 7 . . . 10 . . . layers n 5 . . . n 2. During the fourth iteration the windows are layers 4 . . . 7 layers 8 . . . 11 layers n 4 . . . n 1. The windows of the fifth sixth seventh and eighth iterations are the same as the windows of the first second third and fourth iterations and so on. The process may continue until convergence e.g. until the total size of the BDD is smaller than a desired or predefined threshold or until further adjustment of the variable positions no longer significantly reduces the total size of the BDD .

In particular embodiments during each iteration the n layers of a BDD are separated into multiple disjoint sets of k consecutive layers. However the disjoint sets of k consecutive layers constructed during each iteration differ from the disjoint sets of k consecutive layers constructed during a previous iteration that immediately precedes the current iteration. As a result the n layers are separated and grouped differently during each iterations as illustrated in .

In practical applications windows of size 4 or less are most commonly used. However the above process illustrated in may be extended to apply to windows of any size e.g. size k . In the general case with a window size of k particular embodiments may apply the corresponding exact reordering algorithm on layers a k 1 b a 1 k b alternating between iterating on a where a 1 k b n and on b where b 0 k 1 . Swaps may again be performed until convergence.

In addition to reorder the variables within multiple windows in parallel as described above in connection with within each window the reordering of the k variables at the k consecutive layers may utilize the maximum parallelization concept as described above in connection with .

The main disadvantage of the Sifting Algorithm described above in connection with is that it is inherently sequential. The variables of a BDD are ordered according to the sizes of the layers on which they reside. To alleviate this disadvantage of the Sifting Algorithm particular embodiments concurrently sift i.e. moves k variables instead of sifting one variable at a time. However each of the k variables may be sifted in the manner similar to that described in . In particular embodiments given a BDD having n layers corresponding to n variables the n variables may be moved to their optimum layers using an iterative process. During each iteration the k variables at the k layers that currently have the largest sizes during the current iteration may be sifted to their locally optimum layers i.e. positions . For each set of k variables sifting is performed on the k variables concurrently. For example the k variables at the k largest layers are sifted concurrently first followed by the k variables at the second k largest layers and so on. After each iteration of concurrent layer swaps the size of all implicitly the generated permutations is computed. When sifting has been performed for all the variables in a set the Parallel Permutation Algorithm is utilized to return the ordering to the one that is locally minimum. The algorithm continues for all sets of variables and may be repeated until convergence.

As each variable traverses among the 9 layers when the variable is at each layer the size of that layer may be determined. Thus for variable 2 there are 9 sizes determined when variable 2 is at the 9 layers respectively. The layer that has the smallest size among the 9 sizes is the locally optimum layer for variable 2. Similarly for variable 5 there are again 9 sizes determined when variable 5 is at the 9 layers respectively. The layer that has the smallest size among the second 9 sizes is the locally optimum layer for variable 5. Thus for a given variable the layer that yields the smallest size among all the layers when the variable is position at each of the layers is the locally optimum layer for that variable during the current iteration.

If the size of the BDD is not sufficiently small then another three variables positioned at the three layers that currently have the largest sizes may be selected. The three variables may be moved to their locally optimum positions using the same process as described above with variables 2 5 and 8.

BDDs have many practical applications and the various algorithms disclosed in the present disclosure may be used with BDDs of any applications. For example in the field of integrated circuit IC design an IC may be used to implement a function which may be represented by a BDD. Sometimes a property that an IC design needs to satisfy may be represented by a BDD which may then be used in connection with formally verifying the design of the circuit. In the field of healthcare BDDs may be used to represent data collected by medical sensors. In the field of formal verification BDDs may be used to model transition relations or reachable state spaces along with their respective properties. In the context of hardware and software systems formal verification is the act of proving or disproving the correctness of intended algorithms underlying a system with respect to a certain formal specification or property using formal methods of mathematics. The verification of these hardware and software systems is done by providing a formal proof on an abstract mathematical model of a system the correspondence between the mathematical model and the nature of the system being otherwise known by construction. Examples of mathematical objects often used to model systems are finite state machines labeled transition systems Petri nets timed automata hybrid automata process algebra formal semantics of programming languages such as operational semantics denotation semantics axiomatic semantics and Hoare logic.

A BDD or more specifically the data that form the BDD may be stored in a computer readable non transitory storage medium. When the variables of the BDD are reordered using any of the algorithms described in this disclosure the data are transformed as embodied by the computer readable non transitory storage medium.

In particular embodiments any set of integers may be represented as a Boolean function and the Boolean function may be represented by a BDD. Given a set of integers particular embodiments may determine the minimum number of bits required to represent the largest integer in the set. This number of bits is the number of variables of the Boolean function. Then for each integer in the set the Boolean function evaluates to TRUE and for any integer not in the set the Boolean function evaluates to FALSE.

For example consider a set of integers 1 3 5 6. The largest integer in the set is 6 which requires 3 bits. Thus the Boolean function used to represent this set of integers requires 3 variables x x and x. The following table illustrates the values of the 3 variables and the Boolean function as they are used to represent 1 3 5 6 

Particular embodiments may be implemented on one or more computer systems. illustrates an example computer system . In particular embodiments one or more computer systems perform one or more steps of one or more methods described or illustrated herein. In particular embodiments one or more computer systems provide functionality described or illustrated herein. In particular embodiments software running on one or more computer systems performs one or more steps of one or more methods described or illustrated herein or provides functionality described or illustrated herein. Particular embodiments include one or more portions of one or more computer systems .

This disclosure contemplates any suitable number of computer systems . This disclosure contemplates computer system taking any suitable physical form. As example and not by way of limitation computer system may be an embedded computer system a system on chip SOC a single board computer system SBC such as for example a computer on module COM or system on module SOM a desktop computer system a laptop or notebook computer system an interactive kiosk a mainframe a mesh of computer systems a mobile telephone a personal digital assistant PDA a server or a combination of two or more of these. Where appropriate computer system may include one or more computer systems be unitary or distributed span multiple locations span multiple machines or reside in a cloud which may include one or more cloud components in one or more networks. Where appropriate one or more computer systems may perform without substantial spatial or temporal limitation one or more steps of one or more methods described or illustrated herein. As an example and not by way of limitation one or more computer systems may perform in real time or in batch mode one or more steps of one or more methods described or illustrated herein. One or more computer systems may perform at different times or at different locations one or more steps of one or more methods described or illustrated herein where appropriate.

In particular embodiments computer system includes a processor memory storage an input output I O interface a communication interface and a bus . Although this disclosure describes and illustrates a particular computer system having a particular number of particular components in a particular arrangement this disclosure contemplates any suitable computer system having any suitable number of any suitable components in any suitable arrangement.

In particular embodiments processor includes hardware for executing instructions such as those making up a computer program. As an example and not by way of limitation to execute instructions processor may retrieve or fetch the instructions from an internal register an internal cache memory or storage decode and execute them and then write one or more results to an internal register an internal cache memory or storage . In particular embodiments processor may include one or more internal caches for data instructions or addresses. The present disclosure contemplates processor including any suitable number of any suitable internal caches where appropriate. As an example and not by way of limitation processor may include one or more instruction caches one or more data caches and one or more translation lookaside buffers TLBs . Instructions in the instruction caches may be copies of instructions in memory or storage and the instruction caches may speed up retrieval of those instructions by processor . Data in the data caches may be copies of data in memory or storage for instructions executing at processor to operate on the results of previous instructions executed at processor for access by subsequent instructions executing at processor or for writing to memory or storage or other suitable data. The data caches may speed up read or write operations by processor . The TLBs may speed up virtual address translation for processor . In particular embodiments processor may include one or more internal registers for data instructions or addresses. The present disclosure contemplates processor including any suitable number of any suitable internal registers where appropriate. Where appropriate processor may include one or more arithmetic logic units ALUs be a multi core processor or include one or more processors . Although this disclosure describes and illustrates a particular processor this disclosure contemplates any suitable processor.

In particular embodiments memory includes main memory for storing instructions for processor to execute or data for processor to operate on. As an example and not by way of limitation computer system may load instructions from storage or another source such as for example another computer system to memory . Processor may then load the instructions from memory to an internal register or internal cache. To execute the instructions processor may retrieve the instructions from the internal register or internal cache and decode them. During or after execution of the instructions processor may write one or more results which may be intermediate or final results to the internal register or internal cache. Processor may then write one or more of those results to memory . In particular embodiments processor executes only instructions in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere and operates only on data in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere . One or more memory buses which may each include an address bus and a data bus may couple processor to memory . Bus may include one or more memory buses as described below. In particular embodiments one or more memory management units MMUs reside between processor and memory and facilitate accesses to memory requested by processor . In particular embodiments memory includes random access memory RAM . This RAM may be volatile memory where appropriate Where appropriate this RAM may be dynamic RAM DRAM or static RAM SRAM . Moreover where appropriate this RAM may be single ported or multi ported RAM. The present disclosure contemplates any suitable RAM. Memory may include one or more memories where appropriate. Although this disclosure describes and illustrates particular memory this disclosure contemplates any suitable memory.

In particular embodiments storage includes mass storage for data or instructions. As an example and not by way of limitation storage may include an HDD a floppy disk drive flash memory an optical disc a magneto optical disc magnetic tape or a Universal Serial Bus USB drive or a combination of two or more of these. Storage may include removable or non removable or fixed media where appropriate. Storage may be internal or external to computer system where appropriate. In particular embodiments storage is non volatile solid state memory. In particular embodiments storage includes read only memory ROM . Where appropriate this ROM may be mask programmed ROM programmable ROM PROM erasable PROM EPROM electrically erasable PROM EEPROM electrically alterable ROM EAROM or flash memory or a combination of two or more of these. This disclosure contemplates mass storage taking any suitable physical form. Storage may include one or more storage control units facilitating communication between processor and storage where appropriate. Where appropriate storage may include one or more storages . Although this disclosure describes and illustrates particular storage this disclosure contemplates any suitable storage.

In particular embodiments I O interface includes hardware software or both providing one or more interfaces for communication between computer system and one or more I O devices. Computer system may include one or more of these I O devices where appropriate. One or more of these I O devices may enable communication between a person and computer system . As an example and not by way of limitation an I O device may include a keyboard keypad microphone monitor mouse printer scanner speaker still camera stylus tablet touch screen trackball video camera another suitable I O device or a combination of two or more of these. An I O device may include one or more sensors. This disclosure contemplates any suitable I O devices and any suitable I O interfaces for them. Where appropriate I O interface may include one or more device or software drivers enabling processor to drive one or more of these I O devices. I O interface may include one or more I O interfaces where appropriate. Although this disclosure describes and illustrates a particular I O interface this disclosure contemplates any suitable I O interface.

In particular embodiments communication interface includes hardware software or both providing one or more interfaces for communication such as for example packet based communication between computer system and one or more other computer systems or one or more networks. As an example and not by way of limitation communication interface may include a network interface controller NIC or network adapter for communicating with an Ethernet or other wire based network or a wireless NIC WNIC or wireless adapter for communicating with a wireless network such as a WI FI network. This disclosure contemplates any suitable network and any suitable communication interface for it. As an example and not by way of limitation computer system may communicate with an ad hoc network a personal area network PAN a local area network LAN a wide area network WAN a metropolitan area network MAN or one or more portions of the Internet or a combination of two or more of these. One or more portions of one or more of these networks may be wired or wireless. As an example computer system may communicate with a wireless PAN WPAN such as for example a BLUETOOTH WPAN a WI FI network a WI MAX network a cellular telephone network such as for example a Global System for Mobile Communications GSM network or other suitable wireless network or a combination of two or more of these. Computer system may include any suitable communication interface for any of these networks where appropriate. Communication interface may include one or more communication interfaces where appropriate. Although this disclosure describes and illustrates a particular communication interface this disclosure contemplates any suitable communication interface.

In particular embodiments bus includes hardware software or both coupling components of computer system to each other. As an example and not by way of limitation bus may include an Accelerated Graphics Port AGP or other graphics bus an Enhanced Industry Standard Architecture EISA bus a front side bus FSB a HYPERTRANSPORT HT interconnect an Industry Standard Architecture ISA bus an INFINIBAND interconnect a low pin count LPC bus a memory bus a Micro Channel Architecture MCA bus a Peripheral Component Interconnect PCI bus a PCI Express PCI X bus a serial advanced technology attachment SATA bus a Video Electronics Standards Association local VLB bus or another suitable bus or a combination of two or more of these. Bus may include one or more buses where appropriate. Although this disclosure describes and illustrates a particular bus this disclosure contemplates any suitable bus or interconnect.

Herein reference to a computer readable storage medium encompasses one or more non transitory tangible computer readable storage media possessing structure. As an example and not by way of limitation a computer readable storage medium may include a semiconductor based or other integrated circuit IC such as for example a field programmable gate array FPGA or an application specific IC ASIC a hard disk an HDD a hybrid hard drive HHD an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive a floppy disk a floppy disk drive FDD magnetic tape a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive or another suitable computer readable storage medium or a combination of two or more of these where appropriate. Herein reference to a computer readable storage medium excludes any medium that is not eligible for patent protection under 35 U.S.C. 101. Herein reference to a computer readable storage medium excludes transitory forms of signal transmission such as a propagating electrical or electromagnetic signal per se to the extent that they are not eligible for patent protection under 35 U.S.C. 101. A computer readable non transitory storage medium may be volatile non volatile or a combination of volatile and non volatile where appropriate.

This disclosure contemplates one or more computer readable storage media implementing any suitable storage. In particular embodiments a computer readable storage medium implements one or more portions of processor such as for example one or more internal registers or caches one or more portions of memory one or more portions of storage or a combination of these where appropriate. In particular embodiments a computer readable storage medium implements RAM or ROM. In particular embodiments a computer readable storage medium implements volatile or persistent memory. In particular embodiments one or more computer readable storage media embody software. Herein reference to software may encompass one or more applications bytecode one or more computer programs one or more executables one or more instructions logic machine code one or more scripts or source code and vice versa where appropriate. In particular embodiments software includes one or more application programming interfaces APIs . This disclosure contemplates any suitable software written or otherwise expressed in any suitable programming language or combination of programming languages. In particular embodiments software is expressed as source code or object code. In particular embodiments software is expressed in a higher level programming language such as for example C Perl or a suitable extension thereof. In particular embodiments software is expressed in a lower level programming language such as assembly language or machine code . In particular embodiments software is expressed in JAVA. In particular embodiments software is expressed in Hyper Text Markup Language HTML Extensible Markup Language XML or other suitable markup language.

The present disclosure encompasses all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend. Similarly where appropriate the appended claims encompass all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend.

