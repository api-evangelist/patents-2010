---

title: Automatic avatar creation
abstract: A three-dimensional (“3D”) avatar can be automatically created that resembles the physical appearance of an individual captured in one or more input images or video frames. The avatar can be further customized by the individual in an editing environment and used in various applications, including but not limited to gaming, social networking and video conferencing.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08692830&OS=08692830&RS=08692830
owner: Apple Inc.
number: 08692830
owner_city: Cupertino
owner_country: US
publication_date: 20100601
---
Avatars are increasingly used in online social networking gaming and other communications typically as a surrogate for an actual photograph of the user. Avatars offer a measure of privacy while allowing the user to have control over their online identity. Although users sometimes choose an avatar that is unrelated to their physical appearance it is often desirable to have the avatar resemble the actual user.

There are several conventional tools for avatar creation and editing. These conventional tools generally allow the user to select from a palette of predefined avatar parts and in some cases to manually modify the position shape or color of these parts. Using these conventional tools to create an avatar that looks like the user can be a time consuming process that requires some degree of artistic skill.

A three dimensional 3D avatar can be automatically created that resembles the physical appearance of an individual captured in one or more input images or video frames. The avatar can be further customized by the individual in an editing environment and used in various applications including but not limited to gaming social networking and video conferencing.

In some implementations a space of avatars is searched to find an avatar that most closely approximates the appearance of the individual in the input image. A genetic process can be used to efficiently search the space and thereby estimate key parameters describing an avatar that resembles the person in the input image. During the genetic process an individual genome can be evaluated by generating an avatar according to parameter values in the individual genome. In some implementations the individual genome parameterizes a 3D avatar model which can be rendered on a device using a graphics engine. The 3D model can include an avatar head with adjustable widths at multiple elevations as well as several mesh models for hair nose eyes mouth ears glasses mustache etc. Each of these mesh models can be scaled positioned and oriented under parametric control. The 3D model can be constrained to keep the facial components attached to the head and in reasonable locations on the head. The 3D model also can include ambient and directional light sources and the ability to control the color of the lighting and of the facial components. By rendering the blank avatar head without features and then applying the facial components one at a time binary masks can be generated indicating the two dimensional extent of each facial component.

The input image s or video frame of the individual can be processed to produce binary masks and grayscale images that are specific for the facial elements. An overall fitness can be computed for each avatar in the avatar population by comparing digital representations of rendered avatar facial elements e.g. binary masks with digital representations e.g. binary masks grayscale images of facial elements of the individual genome generated from the input image s .

In some implementations a computer implemented method includes receiving one or more digital images of an individual determining in a computer digital representations of facial elements of the individual from the one or more digital images searching a population of avatars using a genetic process where the genetic process includes using the computer to evaluate the overall fitness of the avatars using a fitness function that compares the digital representations of the individual s facial elements to digital representations of corresponding avatar facial elements and selecting or receiving a selection of one or more avatars from the population of avatars based on fitness values associated with the avatars.

In some implementations a system includes one or more processors and a computer readable storage medium coupled to the one or more processors. The computer readable storage medium includes instructions. The one or more processors execute the instructions to perform the following operations receiving one or more digital images of an individual determining in a computer digital representations of facial elements of the individual from the one or more digital images searching a population of avatars using a genetic process where the genetic process includes using the computer to evaluate the overall fitness of the avatars using a fitness function that compares the digital representations of the individual s facial elements to digital representations of corresponding avatar facial elements and selecting or receiving a selection of one or more avatars from the population of avatars based on fitness values associated with the avatars.

The details of one or more implementations of automatic avatar creation are set forth in the accompanying drawings and the description below. Other features aspects and advantages of automatic avatar creation will become apparent from the description the drawings and the claims.

Genetic algorithms GAs are a class of search algorithms well suited for searching large spaces. GAs roughly mimic the biological process of evolution to find an individual or population of individuals with the highest possible fitness for a given environment. Borrowing from biological terminology the set of parameters that defines an individual solution is the genome and each parameter is a gene. Further the collection of individuals currently being evaluated is the population and each iteration in the search is referred to as a generation.

For example an avatar genome might consist of 30 genes and the genetic process might maintain a population of 10 genomes at a given time. Starting with an initial population of randomly generated individuals a GA can iterate over hundreds of generations before converging on a final population. To create a new population from an old population and so begin a new generation the old population can be sorted according to the fitness of the individuals. Next parents are selected from the population with the probability of being selected as a parent being proportional to the individual s fitness the individual s rank in the population or some other metric. The selected parents are grouped typically in pairs to produce the children that make up the new population. In some implementations some number of the best parents are added to this population and compete with their children this is called an elitist strategy and ensures that the maximal fitness value of the GA monotonically increases as a function of the generation. For example the best individual of each generation is as good or better than the best individual of the previous generation. The GA can iterate until a maximum number of generations is reached or until some termination condition is satisfied.

The fitness of individual avatars can be evaluated using fitness function which compares digital representations of an individual s facial elements with digital representations of corresponding avatar facial elements. The comparison can be performed using two different logical operations a pixel wise XOR operation and a pixel wise AND operation. The AND operation can be used for measuring the alignment of edges of facial elements and the XOR operation can be used for measuring the area of non overlap between digital representations and digital representations . Fitness function can be used to retain high fitness offspring in avatar population by replacing less fit avatars in avatar population with new avatars or offspring. Genetic operations e.g. crossover mutation can be used to generate new facial elements for the avatar population. Avatar mask generator can generate new digital representations from the new facial elements which can be evaluated by fitness function . The foregoing genetic process repeats until a termination condition is met. When the termination condition is met the avatars in avatar population can be ranked or sorted according to their overall fitness as determined by fitness function . One or more of the avatars can be selected for presentation e.g. as a grid display to a user e.g. the individual for manual selection in a computing environment e.g. in a game environment chat session avatar editor etc. 

Input image can be processed by resizing module which can downsampled input image to a lower resolution. Downsampling improves the speed of subsequent processing in second stage . Additionally in some cases downsampling can also act as a lowpass anti aliasing filter on input image .

Input image can be processed by color space conversion module which can convert input image from a first color space to a second color space. For example converting input image from Red Green Blue RGB color space to Hue Saturation Value HSV color space would allow hue to be operated by image processing modules in second stage .

Input image can be processed by ISRY module which converts input image to an intensity channel of Y UV color space followed by an operation 1 sqrt Y which has the effect of boosting lower intensity signals. The result is then inverted so that dark areas in input image are the brightest areas in a grayscale image.

Fine texture module performs several steps on input image . First homomorphic filtering is applied to remove lower spatial frequencies e.g. only variations over a few pixels are preserved . Next a standard deviation image is generated by replacing each pixel in input image by the square root of the average of the squared difference between that pixel and the other 8 pixels adjacent to that pixel. This resulting image is bright only where there is fine texture or detail.

Cartoon texture module can perform a combined downsample upsample operation. The downsample operation use a conventional downsample process and the upsample can be a spline based process. The resulting image is a cartoon effect where fine details are lost and the sharpness of large edges is maintained.

Face detection module determines an approximate center width and height of an individual s face captured in input image using a face detector process e.g. Open CV face detector .

Face mask module can use a linear discriminant analysis LDA classifier that is built from two sets of data 1 data from a rectangular region in the center of the image and 2 data from the periphery of the image. For each pixel of image an input can be vector generated that contains RGB and HSV values for that pixel. The H or hue value can be rotated to avoid a discontinuity in the red range of the color space. A second order statistics of the vectors in the two datasets can be used to determine a hyperplane which separates two classes class 1 and class 2. The image can then be classified with this hyperplane to produce a binary image where white pixels belong to class 1 and black pixels belong to class 2. The white pixels or class 1 define the face skin.

Eyebrows mask module can use the ISRY image output from ISRY module in first stage with two edge detectors one horizontal and one vertical. An output image can be prepared which can be black for pixels with a horizontal edge value below a threshold tH or vertical edge value above another threshold tV. The remaining pixels can have nonzero values given by

Eyes mask module can use a weighted average of the output image of ISRY module of first stage and output image cartoon texture module of first stage . The result can then processed as

Nose module can mask the horizontal edge detected RGB image to leave a rectangular region of nonzero pixels around the tip of the nose as determined from the output image of face detector module .

Mouth mask module can use an the output image from color space conversion module to generate a mouth mask. In some implementations an HSV image is used with the H channel modified to produce large values for colors near red. The modified H channel can be multiplied with the S channel to produce a grayscale image which can be bright in regions that contain saturated colors near red. This image can be multiplied with the horizontal edge detector result on the RGB image masked to zero out all but a rectangular area around the mouth e.g. as roughly determined by the output of face detector module and then thresholded to produce a binary image. A connected components analysis can be performed on the binary image to identify the largest contiguous collection of white pixels. A morphological closing operation can be performed on the binary image e.g. dilation followed by erosion filters to fill in gaps.

Chin Image module can mask the horizontal edge detected RGB image to leave a rectangular region of non zero pixels around the bottom of the chin e.g. as determined from the output of face detector module . The results can be masked further by a morphological closing of the skin mask leaving only edges that are within the skin regions. The final grayscale image can be amplified by a gain factor to increase contrast.

Hair mask module can use several output images from first stage . The output image from cartoon texture image module can be thresholded to produce a binary mask Mask A for the hair regions using the output of the face detector module to isolate the head. The output image from fine texture module can be thresholded to produce a binary mask Mask B of all high texture pixels.

The RGB image can be modified by converting the image to Y UV color space replacing the Y channel with 0.6 sqrt Y and then converting back to RGB colorspace. This process increases the dynamic range of dark areas and diminishes the overall intensity in the image making color more dominant. The alpha channel of this image can be replaced by an output image of cartoon texture module so that most areas are transparent except for areas with textures such as the hair and eyes. After completion of the foregoing process each pixel in the resulting image Image A now contains both color and texture information. Next the statistics of pixels in Image A over the area in Mask A and also compute the statistics for pixels in Mask B. These two sets of statistics can be combined to classify an Image A pixel as belonging to a hair class or other class.

A binary image can be produced for the hair class pixels Mask C . Mask C can then be processed by a morphological closing operation to fill in gaps Mask D . Mask D can be used to generate an LDA classification e.g. the mask denotes the in class pixels using the same LDA classifier design used for skin detection described in reference to . The LDA classification can be refined by removing pixels that are also classified as skin. A morphological opening operation can be used to remove isolated pixels and a morphological closing operation can be used to fill in the gaps Mask E .

Finally a connected components analysis can be performed on Mask E to retain a contiguous pixel group with a shortest average distance to the centroid of Mask D. Mask E can be combined via a logical OR operation with Mask D to produce the final desired mask.

Beard mask module can threshold the output image of cartoon texture module and a trapezoidal region around the chin e.g. determined by face detector module is retained.

Referring to process can begin by choosing an initial population of avatars . The initial population of avatars can be generated randomly. The avatar population size can be selected to cover a desired comparison space. In some implementations the avatar population can be seeded with avatars that are selected to provide optimal solutions.

After the initial avatar population is created the individual fitness of each avatar in the initial avatar population is evaluated . The evaluation can be accomplished using a fitness function. For example the fitness of individual avatars can be evaluated by comparing digital representations of the individual s facial elements from input image s with digital representations of facial elements of avatars in the avatar population. The comparison can be performed using two different logical operations a pixel wise XOR operation and a pixel wise AND operation. The AND operation can be used for measuring the alignment of edges of facial elements and the XOR operation can be used for measuring the area of non overlap between the digital representations. One or more pairs of best fit avatars based on an overall fitness value obtained from the fitness function can be selected for reproduction . New avatars can be created through genetic operations e.g. crossover mutation on the pair s of avatars selected for reproduction . Crossover involves randomly selecting a contiguous group of genes within the new genome and replacing those genes with the corresponding genes from one of the parents genomes. In this way a new genome can be constructed from randomly chosen sections of the genomes of both parents. Mutation of the newly created genome can be performed by randomly selecting individual genes and randomly changing the value of those genes.

The individual fitness of the new avatars offspring are evaluated . The evaluation can be accomplished using the same fitness function as used with the initial avatar population. A number of least fit avatars based on a ranking or sorting of overall fitness values in the avatar population can be replaced by the new avatars . The number of replaced avatars can be a fixed number or fixed percentage of the current avatar population. If a termination condition is met a best matching avatar or set of avatars can be selected from the current avatar population based on a ranking or sorting of overall fitness values of the avatars in the current avatar generation .

If the termination condition is not met process can return to step and repeated from step until the termination condition is met. Some examples of terminating conditions include but are not limited to i an avatar is found that satisfies some minimum criteria ii a fixed number of generations is reached iii the highest ranking avatar is reaching or has reached a plateau such that successive iterations no longer produce better results iv manual inspection or v combinations of the above.

In some implementations process can be run multiple times on the same input image and the avatar with the highest overall fitness value can be selected. Alternatively the individual can be presented with a small selection of the best avatars to choose from. For example a grid of candidate avatars can be displayed to the individual on a display of a device e.g. a personal computer mobile phone electronic pad etc. and the individual can manually select the avatar with the closest resemblance e.g. using touch input with a finger or stylus .

As described above the overall fitness of an individual genome can be computed by comparing masks produced from facial elements of avatars in the avatar population against masks and images produced from input images containing an image of an individual whose genome is being matched to an avatar. As described below this comparison can be performed separately on various facial elements to produce a fitness value e.g. a value between 0 and 1 for each facial element.

Avatar masks for face and ears can be added together and a mask for the avatar hair can be subtracted from the result. The resulting mask can be compared against the input face mask computed in second stage using a pixel wise exclusive or operation XOR to identify regions in either mask which do not overlap the other mask. The resulting XOR mask can be averaged to produce a scalar error value . The face fitness can be computed as max 0 1 g where gis a constant gain.

The XOR of the eyebrows masks from the avatar and from the input image can be averaged to produce a scalar error value . The eyebrow fitness value can be computed as max 0 1 g where gis a constant gain.

The avatar eyeglasses mask can be edge detected to produce a mask of just the frames. This mask can be added to the avatar eyes mask and the result XORed with the eyes mask from the input image. The XOR image can be averaged to produce a scalar error value . The eyes and glasses fitness value can be computed as max 0 1 g where gis a constant gain.

The avatar nose mask can be edge detected and trimmed to include only the lower portion additional trimming removes any area below the top of the avatar s mouth or above the bottom of the avatar s glasses or eyes. The trimmed nose mask can be compared with the nose image output from nose module which can be a grayscale image using a pixel wise multiplication analogous to a logical AND operation . The resulting image can be averaged over only the nonzero pixels to produce a scalar fitness value.

The XOR of the mouth masks from the avatar and from the input image can be averaged to produce a scalar error value . The mouth fitness value can be computed as max 0 1 g where gis a constant gain.

The XOR of the hair masks from the avatar and the output from hair module can be averaged to produce a scalar error value . The hair fitness value can be computed as max 0 1 g where gis a constant gain.

The XOR of the beard masks from the avatar and the output from beard module can be averaged to produce as scalar error value . The beard fitness value can be computed as max 0 1 g where gis a constant gain.

The avatar face mask can be edge detected and trimmed to retain only the chin area. As with the nose fitness this mask can be multiplied with the chin image from the input. The product image is summed over only the nonzero pixels and divided by a constant fraction of the image width to provide a normalization fitness value that does not penalize larger chins.

Once the fitness values for the facial elements are computed an overall fitness of the genome can be computed as a function of the individual facial element fitness values. Denoting the above individual facial element fitness values as f an overall fitness function can be computed as 

The term computer readable medium refers to any medium that participates in providing instructions to a processor for execution including without limitation non volatile media e.g. optical or magnetic disks and volatile media e.g. memory .

The computer readable medium further includes instructions which when executed by processor s implements an operating system e.g. Mac OS Windows Linux etc. a network communication module image processing modules genetic processing modules and one or more avatar environments . The operating system can be multi user multiprocessing multitasking multithreading real time and the like. The operating system performs basic tasks including but not limited to recognizing input from input devices sending output to display devices keeping track of files and directories on computer readable mediums e.g. memory or a storage device controlling peripheral devices e.g. disk drives printers camera interface etc. and managing traffic on the one or more buses . The network communications module includes various components for establishing and maintaining network connections e.g. software for implementing communication protocols such as TCP IP HTTP Ethernet etc. . The image processing modules enables the features and processes described in reference to . The genetic processing modules enables the features and processes described in reference to . One or more avatar environments can include an editing environment and or an application including but not limited to gaming social networking video conferencing or any other application where an avatar can be used.

Device can also establish communications by other means. For example device can communicate with other devices e.g. other wireless devices cell phones etc. over wireless network . Likewise device can establish peer to peer communications e.g. a personal area network by use of one or more communication subsystems such as a Bluetooth communication device. Other communication protocols and topologies can also be implemented.

Device can communicate with one or more services over the one or more wired and or wireless networks . For example device can communicate with avatar creation service which can provide the features and process described in reference to . Another example service can be an avatar environment service . Avatar environment service can provide various environments where an avatar can be used e.g. an avatar editing environment a game center for online gaming .

A user interface can be used to grab visual data monitor the progress of the genetic process and display a resulting 3D avatar model. In some implementations a user interface can be configured to capture live video to allow for a progressive display of genetic process results. For example a real time work flow can include grabbing video input and running the genetic process iterations at the same time. The successive video frames can be submitted to the genetic process to refine the search for the best matching avatar model.

In some implementations an automatic avatar generator application can be run on a device e.g. a personal computer mobile phone as a stand alone application or can be a service e.g. a library function accessible through an Application Programming Interface API . An automatic avatar generator can also be accessed through a network service where user interfaces are presented as web pages by a remote server computer.

In a real time workflow video preview window can be augmented with the latest best 3D avatar model found by the avatar generator. While checking the 3D avatar model rendered over video preview window with alpha transparency the user can make the head posture vary in the successive frames submitted to the genetic process. To improve the matching performed by the genetic process fitness function visual marker can be inserted into video preview window . In a sequential workflow visual marker can constrain the user posture. For example a head guide can be used during the image capture step to constrain the position of the user s head while successive images are captured during the genetic process. In a real time workflow moving marker can be included in video preview window for providing visual feedback to the user about the facial elements that are currently being evaluated by the genetic process fitness function. For example a semi transparent rectangle can be overlaid on the user s right eye to indicate that the right eye is currently being processed by the fitness function of the genetic process. When the eye processing is completed the moving marker can be overlaid on the next facial element to be processed e.g. overlaid on the user s mouth . Progress indicator e.g. a bar can visually indicate to the user the progress of the genetic process.

In a sequential workflow a progress panel not shown can replace video preview window once the avatar generation starts. If the input is a picture or a set of pictures the picture or pictures can remain visible in the progress panel until the genetic processes terminates. Intermediate avatar results can appear as semi transparent images over each picture. If the input is a video sequence the video sequence can be played in a loop mode until the genetic process terminates. During each loop the 3D avatar model obtained from a previous genetic process iteration can be rendered over the video in accordance with the estimated head view angle at each frame. The playback speed can be adjusted automatically to match the average computation time of one genetic process iteration.

In a real time workflow the successive 3D avatar models can be shown as transparent overlays over video preview window similar to the sequential workflow for a video. In the real time workflow however the user can decide to stop the evaluation manually at any time if the 3D avatar model looks satisfactory. For that purpose the real time genetic process can have a stop button and an associated keyboard shortcut.

Both sequential and real time workflows can generate candidate avatar models that are presented in results panel . Alternatively results panel can replace video preview window once the video images have been captured. Depending on the refinements of the genetic process implementation there can be one or more possible candidate avatar models that best match the user s physical appearance for a given input image or video sequence. In the case of a single best match results panel can contain the avatar as a animated 3D model. Optionally the avatar model can be refined manually using an avatar editor interface such as the interfaces described in U.S. Provisional Patent Application No. 61 321 840 for Avatar Editing Environment filed Apr. 7 2010.

If multiple candidate avatar models are produced by the genetic process the candidate avatar models e.g. thumbnails of front facing headshots can be arranged on a grid layout in results panel . The user can then choose a preferred candidate avatar model in results panel by clicking or touching on it. In some implementations panel can replace video preview window . In such an implementation a zoom animation can enlarge the selected avatar model so that it occupies a large size version of the results panel . The avatar editor can be entered automatically upon selection of the candidate Avatar from results panel or by clicking or touching button .

The disclosed and other embodiments and the functional operations described in this specification can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. The disclosed and other embodiments can be implemented as one or more computer program products e.g. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The computer readable medium can be a machine readable storage device a machine readable storage substrate a memory device a composition of matter effecting a machine readable propagated signal or a combination of one or more them. The term data processing apparatus encompasses all apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them. A propagated signal is an artificially generated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.

A computer program also known as a program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code .

The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interaction with a user the disclosed embodiments can be implemented on a computer having a display device e.g. a CRT cathode ray tube LCD liquid crystal display monitor touch sensitive device or display for displaying information to the user and a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input.

While this specification contains many specifics these should not be construed as limitations on the scope of what is being claimed or of what may be claimed but rather as descriptions of features specific to particular embodiments. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a subcombination or variation of a subcombination.

Similarly while operations are depicted in the drawings in a particular order this should not be understand as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multitasking and parallel processing may be advantageous. Moreover the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

The systems and techniques described here can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the systems and techniques described here or any combination of such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network . Examples of communication networks include a local area network LAN a wide area network WAN and the Internet.

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

Although a few implementations have been described in detail above other modifications are possible. For example the flow diagrams depicted in the figures do not require the particular order shown or sequential order to achieve desirable results. In addition other steps may be provided or steps may be eliminated from the described flow diagrams and other components may be added to or removed from the described systems. Accordingly various modifications may be made to the disclosed implementations and still be within the scope of the following claims.

