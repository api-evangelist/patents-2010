---

title: Managing automated and manual application testing
abstract: An application for which approval is requested is identified and multiple automated tests are applied to the application in groups of automated tests. Each of the groups of automated tests includes multiple ones of the multiple automated tests. If one or more automated tests in a group of automated tests returns an inconclusive result, then a manual check is initiated for the application based on the one or more automated tests that returned the inconclusive result. If one or more automated tests in a group, or a manual test applied in the manual check, returns a fail result then an indication that the application is rejected is returned, the indication that the application is rejected including an identification of why the application is rejected. If none of the multiple automated tests returns a fail result, then a manual testing phase is initiated.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08661412&OS=08661412&RS=08661412
owner: Microsoft Corporation
number: 08661412
owner_city: Redmond
owner_country: US
publication_date: 20101119
---
Applications are typically tested before they are made available to users for running on their computers. Testing applications typically identifies problems and other issues with the applications that can be fixed by the application developer resulting in an improved user experience. However testing applications is not without its problems. One such problem is the accuracy and cost of testing applications. Current testing can result in missing errors that would not be missed by a human tester and or can be time consuming and expensive.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

In accordance with one or more aspects at one or more computing devices an application for which approval is requested is identified. Multiple automated tests are applied to the application in groups of automated tests each of the groups of automated tests including multiple ones of the multiple automated tests. For each of the groups of automated tests after applying the automated tests in the group an indication that the application is rejected is caused to be returned if one or more of the automated tests in the group returns a fail result. This indication that the application is rejected includes an identification of why the application is rejected. If none of the multiple automated tests returns a fail result a manual testing phase is initiated.

In accordance with one or more aspects an application for which approval is requested is identified and multiple automated tests are applied to the application. Prior to completing all of the multiple automated tests and for one of the multiple automated tests that returns an inconclusive result a manual check is initiated for the application based on the one automated test. The inconclusive result indicates that the one automated test cannot determine whether the application is to receive a fail result or a pass result.

Managing automated and manual application testing is discussed herein. Applications are submitted to a testing system which analyzes the applications and determines whether each application is approved or rejected based on various criteria. The testing system initially applies multiple automated tests to the application in groups of automated tests. Each automated test can return a pass result indicating that the application passed the test or a fail result indicating that the application failed the test. One or more automated tests can also return an inconclusive result indicating that the automated test was unable to determine whether the application passed or failed the test. In response to an inconclusive result a manual check is initiated in which one or more people apply one or more manual tests to the application and return a pass result or a fail result. If one or more automated tests in a group or one or more manual tests returns a fail result for the application then an indication that the application is rejected is returned e.g. to the application developer . The indication that the application is rejected identifies why based on the one or more tests that returned the fail result the application is rejected. The application developer is then able to modify the application and re submit the application to the testing system.

After all the automated tests have been applied and returned a pass result then one or more manual tests of a manual testing phase are initiated. If one or more manual tests returns a fail result for the application then an indication that the application is rejected is returned e.g. to the application developer identifying why based on the one or more manual tests that returned the fail result the application is rejected. After all the manual tests have been applied and returned a pass result then an indication that the application is approved is returned e.g. to the application developer indicating that the application is approved by the testing system.

Manual tests are implemented at least in part on one or more computing devices which can be a variety of different types of computing devices such as a server computer a desktop computer a netbook or laptop computer a notepad or tablet computer a mobile station an entertainment appliance a set top box communicatively coupled to a display device a television a cellular or other wireless phone a game console an automotive computer and so forth. Manual tests are also typically based at least in part on human involvement as discussed in more detail below.

It should be noted that testing system can be distributed across a wide physical area. For example test management control module and automated tests can be implemented on computing devices in one data center and different ones of manual tests can be implemented in different locations e.g. different buildings different cities different countries etc. . By way of another example test management control module can be implemented on computing devices in one data center automated tests can be implemented on computing devices in one or more other data centers and different ones of manual tests can be implemented in different locations.

Generally an application for which approval is requested is received by testing system . Application can be received directly from the developer of application or alternatively via one or more intermediaries. In one or more embodiments the approval that is requested is an approval for the application to be made available to users through a particular store e.g. an online or electronic store or other repository although approval for other actions or rights can alternatively be requested. Testing system initially evaluates application using automated tests . Testing system can also initiate one or more manual tests at different points during the evaluation. Which automated tests and or manual tests are to be applied to analyze application as well as the timing for when those tests are to be applied is determined by test management control module as discussed in more detail below. Testing system is discussed with reference to testing a single application application . However it should be noted that testing system can test multiple applications at the same or different times.

Test management control module includes an application tracking module and an application routing module . Application tracking module manages the evaluation or testing of application keeping track of which tests and or have been applied and whether to return an indication that application is approved or rejected by testing system . Application tracking module can also maintain a record of the results returned by the tests and or that have been applied. Alternatively a record of which tests and or have been applied and the results returned by those tests can be maintained in different manners. For example a testing record can be associated with application and each test and or can update the record to reflect the result returned by that test.

Application routing module manages the routing of application to the appropriate ones of automated tests and or manual tests at the appropriate times. Application routing module can identify the appropriate test and or to which application is to be routed at a particular time based on various criteria including the results of previous tests and or various characteristics of application and so forth. This identification of the appropriate test and or to which application is to be routed at a particular time is discussed in more detail below.

Automated tests run without human intervention and are typically programs or modules or a portion of a program or module that run on one or more computing devices in response to a request from test management control module to evaluate an application. Each automated test evaluates application for compliance with one or more policies and returns a result based on the evaluation. Various different policies can be established based on for example the desires of the person or company providing or managing the particular store through which application will be available if approved by testing system . Automated tests are designed or otherwise configured to evaluate whether application complies with one or more policies.

By way of example a policy can be that in order to be approved an application is not malware e.g. is not or does not include a virus spyware or other malware does not include a link to a phishing web site etc. . Thus one or more automated tests can evaluate application to determine whether the application is malware. By way of another example a policy can be that in order to be approved an application includes appropriate content e.g. does not include pornographic or other adult themed content does not include violent subject matter does not include slang and or profanity etc. . Thus one or more automated tests can evaluate application to determine whether the application includes appropriate content.

By way of yet another example a policy can be that in order to be approved an application uses only application programming interfaces APIs that are deemed appropriate e.g. includes only APIs that are included on a particular approved list does not include APIs that are included on a particular disallowed list etc. . Thus one or more automated tests can evaluate application to determine whether the application includes only appropriate APIs. By way of still another example a policy can be that in order to be approved appropriate metadata is associated with the application e.g. the application has a title of no more than a particular number of characters the application has a summary of at least a particular number of characters etc. . Thus one or more automated tests can evaluate application to determine whether the application has the appropriate associated metadata.

As a further example a policy can be that in order to be approved an application satisfies certain performance requirements when the application is running e.g. processor usage by the application when running does not exceed a threshold amount memory usage of the application when running does not exceed a threshold amount network usage of the application when running does not exceed a threshold amount etc. . Thus one or more automated tests can evaluate application to determine whether the application satisfies those performance requirements.

Each automated test can operate in a variety of different manners based on the manner in which the automated test is implemented and the policy for which the automated test is evaluating an application. For example automated tests can search for particular strings of characters in outputs generated by application analyze the performance of application as application is run analyze the instructions or code of application for particular patterns and so forth.

In one or more embodiments automated tests are grouped together into multiple different groups each group including multiple ones of automated tests . Alternatively one or more groups can include a single automated test . Automated tests are applied to application in groups with all of the automated tests in a particular group being applied to application . The results of the automated tests in a group are evaluated and application tracking module determines a next action to be taken in evaluating application based on the results of the automated tests in the group.

Automated tests can be grouped into different groups in a variety of different manners. In one or more embodiments each automated test has an associated test type e.g. security checking content appropriateness metadata restrictions API usage application performance etc. and automated tests are grouped into groups based on the type of test. For example tests relating to security checking of application e.g. whether application is a virus spyware or other malware can be included in one group tests relating to whether application includes appropriate content e.g. whether application includes adult or pornographic content can be included in another group tests relating to the compliance with metadata restrictions e.g. whether metadata associated with application includes a title of appropriate length a summary of appropriate length etc. can be included in another group tests relating to whether application does not employ disallowed APIs e.g. whether application uses just the allowed APIs can be included in another group tests relating to whether application satisfies certain performance requirements when the application is running e.g. processor usage network usage etc. can be included in another group and so forth.

In other embodiments automated tests are grouped into groups based on other criteria. For example automated tests can be grouped into groups based on the time expected to be used in applying automated tests e.g. so that the group is expected to take a particular amount of time to complete does not take in excess of a threshold amount of time to complete etc. . By way of another example automated tests can be grouped into groups based on the frequency with which the automated tests return fail results for previously tested applications. By way of yet another example automated tests can be groups randomly so that each group includes a particular number e.g. ten automated tests based on input received from an administrator or customer of testing system and so forth.

Additionally application routing module can provide application to groups of automated tests in a particular order. Application routing module can be configured with this order e.g. being programmed into application routing module or being set by an administrator of testing system or alternatively can obtain an indication of this order from another module or device. For example tests relating to security checking of application can be the first group of automated tests that are applied to application tests relating to whether application includes appropriate content can be the second group of automated tests that are applied to application and so forth. Alternatively groups of automated tests can be applied in other manners such as by selecting groups randomly or according to some other rules or criteria.

Some automated tests return one of two different results a pass result or a fail result. Other automated tests return one of three different results a pass result a fail result or an inconclusive result. A pass result for application indicates that application satisfies whatever policy or policies or portion of a policy or policies for which the automated test is evaluating application . A fail result for application indicates that application does not satisfy whatever policy or policies or portion of a policy or policies for which the automated test is evaluating application . The fail result returned by an automated test can also include an identification of why application failed. The information identifying why application failed can vary by automated test and by implementation and can be for example a descriptive string e.g. identifying particular strings or instructions of application that did not comply with the policy an error code other descriptive information and so forth.

An inconclusive result for application indicates that the automated test cannot determine whether application satisfies whatever policy or policies or portion of a policy or policies for which the automated test is evaluating application and that automated test cannot determine whether to return a pass result or a fail result. An automated test may not be able to determine whether to return a pass result or a fail result for a variety of different reasons. For example depending on the manner in which it is used a particular word or phrase may or may not be appropriate a particular image may or may not include violent and or adult themed content and so forth.

Application routing module provides application e.g. communicates application communicates a pointer or other identifier of where application is stored etc. to a group of automated tests . Application tracking module receives the results returned by the automated tests in that group. Application routing module can provide application to one or more automated tests in the group concurrently or alternatively can provide application to one or more automated tests in the group sequentially e.g. waiting until a result from one automated test is received prior to providing application to another automated test in the group .

Application tracking module proceeds based on the results received from the automated tests in a group. If all automated tests in a group return a pass result then application tracking module determines whether there are any additional groups of automated tests that have not yet evaluated application . If there are additional groups of automated tests that have not yet evaluated application then application tracking module communicates with application routing module to provide application to one of those additional groups. Application routing module can provide application to a particular one of those additional groups based on a particular ordering of groups as discussed above. However if there are no additional groups of automated tests that have not yet evaluated application all automated tests to be applied to application have returned a pass result for application then application tracking module provides application to a manual testing phase where one or more manual tests are applied. The manual testing phase is discussed in more detail below.

If one or more automated tests in a group return a fail result then an indication that application is rejected is returned. Indication can be returned to for example the application developer an entity that submitted application another module or device and so forth. Indication can take a variety of different forms such as a message e.g. email or other message that is sent information posted at a particular location e.g. on a particular Web site page wall etc. information used by another module or device of system to drive further system processes and so forth.

Indication also includes an identification of why application is rejected. This identification allows the developer to determine what changes are to be made to application if desired so that application will be approved. This identification of why application is rejected can take a variety of different forms such as an identification of which one or more automated tests returned a fail result the identification of why application failed that was returned by the automated tests that returned the fail result and so forth. It should be noted that as automated tests are applied in groups multiple automated tests in the same group can return a fail result. The identification of why application is rejected includes information related to each of these automated tests that returned a fail result e.g. an identification of each automated test that returned a fail result the identification of why application failed that was returned by each automated test that returned a fail result etc. .

If one or more automated tests in a group return an inconclusive result then a manual check is initiated in which one or more people apply one or more manual tests to application . Manual tests run at least in part with human intervention and can involve running one or more programs or modules or a portion of one or more programs or modules to evaluate an application. Manual tests can operate in a variety of different manners based on the manner in which the manual test is implemented and the policy for which the manual test is evaluating an application. For example a manual test can involve a computing device running application and a human observing the output e.g. images audio text and so forth a human evaluating metadata associated with application and so forth.

The particular manual tests that are applied for the manual check can be determined by application routing module based at least in part on the one or more automated tests that returned an inconclusive result. For example application routing module can be configured with or otherwise obtain such as from another device or module an indication of one or more manual tests associated with each automated test. Based on this association application routing module can readily determine which one or more manual tests to initiate for each of the one or more automated tests that returned an inconclusive result. Alternatively the particular manual tests that are applied for the manual check can be determined by a computing device or person. For example application routing module can provide to a manual testing sub system e.g. one or more computing devices an indication of the one or more automated tests that returned an inconclusive result in response to which a computing device or person at the manual testing sub system can determine which one or more manual tests are to be applied for the manual check.

Each manual test returns a pass result or a fail result analogous to automated tests . A manual test that returns a fail result can also include information identifying why application failed which can vary by manual test and by implementation analogous to the discussion above regarding automated tests . Application tracking module proceeds based on the results received from both the automated tests in a group and the manual tests applied as part of the manual check. If all automated tests in a group and all manual tests performed as part of the manual check return a pass result then application tracking module proceeds to have application routing module provide application to an additional group or proceed to a manual testing phase as discussed above. If one or more automated tests in a group and or one or more manual tests applied as part of the manual check return a fail result then an indication that application is rejected is returned. Indication also includes an identification of why application is rejected which can include an identification of which one or more manual tests returned a fail result the identification of why application failed that was returned by the one or more manual tests that returned the fail result and so forth.

It should be noted that for a particular group of automated tests application tracking module can receive a pass result from one or more automated tests a fail result from one or more automated tests a pass result from one or more manual tests applied as part of the manual check a fail result from one or more manual tests applied as part of the manual check or any combination thereof. Application tracking module maintains a record of the pass results and fail results returned by automated tests in the group and if a manual check is initiated then proceeds to have application routing module provide application to an additional group initiate a manual testing phase or return an indication of failure after receiving results from the manual tests applied during the manual check.

For example assume a group includes ten automated tests and that five of those automated tests return a pass result three of those automated tests return a fail result and two of those automated tests return an inconclusive result. Application tracking module maintains a record of the five automated tests that returned a pass result and the three automated tests that returned a fail result and initiates a manual check based on the two automated tests that returned an inconclusive result. Further assume that one manual test that was applied based on the initiated manual check returns a pass result and another manual test that was applied based on the initiated manual check returns a fail result. Application tracking module returns an indication that application is rejected including an identification of why application is rejected. The identification of why application is rejected can include an identification of the three automated tests and one manual test that returned a failed result the identification of why application failed that was returned by each of the automated tests and one manual test that returned a fail result and so forth.

After all automated tests to be applied to application have returned a pass result for application a manual testing phase is initiated. If an automated test returns an inconclusive result in response to which one or more manual tests return a pass result after a manual check is initiated then that automated test can also be referred to as returning a pass result. The manual testing phase can be initiated in different manners such as application tracking module communicating with application routing module to have one or more manual tests applied to application .

In one or more embodiments all automated tests are applied to application and the manual testing phase is initiated after all of those automated tests each return a pass result. In other embodiments less than all of automated tests are applied to application in which case the manual testing phase is initiated after those automated tests that are to be applied to application each return a pass result. In embodiments in which less than all of the automated tests are to be applied to application the automated tests that are to be applied to application can be identified in different manners. For example the automated tests that are to be applied to application can be programmed into application tracking module can be determined by application tracking module can be received from another source e.g. another device another module an administrator of testing system etc. and so forth.

In the manual testing phase one or more manual tests are applied to application . As discussed above manual tests run at least in part with human intervention and can involve running one or more programs or modules or a portion of one or more programs or modules on one or more computing devices to evaluate an application. The manual tests that are applied to application can include the manual tests that were applied as part of one or more manual checks discussed above or alternatively can be other manual tests than the manual tests used in the manual checks. Manual tests can be applied in groups analogous to automated tests or alternatively can be applied individually can be applied collectively e.g. in which case all of the manual tests to be applied can be viewed as being part of a single group .

All manual tests can be applied to application or alternatively a subset of manual tests can be applied to application . The particular manual tests that are applied in the manual testing phase can be determined in different manners. For example application routing module can identify particular manual tests that are to be applied to application in the manual testing phase based on characteristics of application such as a type of application or language that application is written in either or both of which can be automatically determined by test management control module can be determined based on metadata associated with application and so forth . By way of another example application routing module can provide application to a manual testing sub system e.g. one or more computing devices and a computing device or person at the manual testing sub system can determine which one or more manual tests are to be applied for the manual testing phase.

Each manual test in the manual testing phase returns a pass result or a fail result analogous to the discussion above. If one or more manual tests in the manual testing phase returns a fail result then application tracking module returns an indication that application is rejected including an identification of why application is rejected as discussed above. However if all manual tests that are applied to application in the manual testing phase return a pass result then application tracking module returns an indication that application is approved. Application tracking module can also take other actions in light of the approval of application such as provide indication to one or more other devices or modules provide application to an online or electronic store provide indication or application to another module or device and so forth. Additionally the indication that application is approved can include a certification by test management control module that application is approved. This certification can take a variety of different forms such as test management control module generating a digital signature for application .

In one or more embodiments different manual tests can be implemented by different entities e.g. different people different testing companies or organizations and so forth . These different entities can apply different manual tests or different versions e.g. based on different languages of the same manual tests . Application routing module can determine based at least in part on characteristics of application e.g. including metadata associated with application which entity is to apply which manual tests and or which versions of manual tests to application . For example if application displays text in French then application routing module determines that an entity that is fluent in French is to apply particular ones of manual tests . By way of another example application can determine that an entity that has agreed to potentially be exposed to profanity or other adult themed content for the purposes of testing is to apply particular ones of manual tests .

However if one or more automated tests in a group of multiple automated tests returns a fail result then the group of automated tests is referred to as a bad group and the testing process enters a rejected stage . In rejected stage an indication that the application is rejected is returned e.g. to the application developer .

Furthermore if one or more automated tests in a group of multiple automated tests returns an inconclusive result then the group of automated tests is referred to as an inconclusive group and the testing process enters a manual check stage . In manual check stage one or more manual tests e.g. one or more manual tests of are applied to the application. If the one or more manual tests all return pass results then the group of automated tests is referred to as a good group and the automated test phase stage continues. However if at least one of the one or more manual tests returns a fail result then the group of automated tests is referred to as a bad group and the testing process enters rejected stage .

If all of the groups of automated tests applied to the application are good groups then the testing process enters a manual test phase stage . In manual test phase stage one or more manual tests e.g. one or more manual tests of are applied to the application in one or more groups. As each group of manual tests is applied to the application if the manual tests in that group all return pass results then the group of manual tests is referred to as a good group and the manual test phase stage continues. In one or more embodiments a manual test may return an inconclusive result. In such embodiments if a manual test returns an inconclusive result then the group of manual tests is referred to as an inconclusive group and manual testing of the application continues e.g. applying one or more different manual tests in response to the inconclusive result .

If one or more manual tests in a group of multiple manual tests returns a fail result then the group of manual tests is referred to as a bad group and the testing process enters rejected stage . However if all of the groups of manual tests applied to the application are good groups then the testing process enters an approved stage . In approved stage an indication that the application is approved is returned e.g. to the application developer .

In process an application for which approval is requested is identified act . The application can be identified in different manners such as the application being provided to the testing system e.g. emailed or uploaded an identifier of the application e.g. link to where the application can be retrieved or otherwise obtained being provided to the testing system and so forth.

Automated tests are applied to the application in groups of multiple automated tests act . The automated tests can be grouped into multiple groups in different manners as discussed above.

Process proceeds after applying a group of automated tests based on the results returned by the automated tests in that group. If one or more tests in one or more groups returns a fail result then the testing system causes a rejected indication to be returned including an identification of why the application is rejected act . The one or more tests that return a fail result can be one or more automated tests that themselves return a fail result or one or more manual tests that were applied as at least part of a manual check in response to an automated test returning an inconclusive result. The testing system can cause the rejected indication to be returned by returning the rejected indication itself or alternatively invoking one or more other systems or devices to return the rejected indication.

However if no tests in the groups return a fail result then a manual testing phase is initiated act . The tests in act refer to both the automated tests as well as manual tests that were applied as a manual check in response to an automated test returning an inconclusive result. The manual testing phase can be initiated in different manners as discussed above.

If one or more manual tests in the manual testing phase return a fail result then the testing system causes a rejected indication to be returned including an identification of why the application is rejected act . The testing system can cause the rejected indication to be returned by returning the rejected indication itself or alternatively invoking one or more other systems or devices to return the rejected indication.

However if all of the manual tests in the manual testing phase return a pass result then the testing system causes an approval indication to be returned act . If one or more manual tests in the manual testing phase return an inconclusive result followed by one or more other manual tests or a repeating of that manual test that results in a pass result then the manual test that returned the inconclusive result can also be referred to as returning a pass result. The testing system can cause the approval indication to be returned by returning the approval indication itself or alternatively invoking one or more other systems or devices to return the approval indication.

In process an application for which approval is requested is identified act . The application can be identified in different manners such as the application being provided to the testing system e.g. emailed or uploaded an identifier of the application e.g. link to where the application can be retrieved or otherwise obtained being provided to the testing system and so forth.

Multiple automated tests are applied to the application act . The automated tests can be applied in groups of multiple automated tests as discussed above or alternatively can be applied individually or can be applied collectively e.g. in which case all of the automated tests to be applied can be viewed as being part of a single group .

Process proceeds based on the results returned by the automated tests. If one or more automated tests returns a fail result then the testing system causes a rejected indication to be returned including an identification of why the application is rejected act . The testing system can cause the rejected indication to be returned by returning the rejected indication itself or alternatively invoking one or more other systems or devices to return the rejected indication.

If all automated tests return a pass result then the testing system proceeds to a next part of the testing act . The next part of the testing is for example a manual testing phase as discussed above.

If one or more automated tests returns an inconclusive result then the testing system initiates a manual check based on the one or more automated tests that returned the inconclusive result act . One or more manual tests can be determined based on the one or more automated tests that returned the inconclusive result as discussed above.

If the one or more manual tests of the manual check return a pass result then the testing system proceeds to a next part of the testing act . The next part of the testing is for example applying automated tests of one or more additional groups to the application or a manual testing phase as discussed above.

However if one or more manual tests of the manual check return a fail result then the testing system causes a rejected indication to be returned including an identification of why the application is rejected act . The testing system can cause the rejected indication to be returned by returning the rejected indication itself or alternatively invoking one or more other systems or devices to return the rejected indication.

The managing automated and manual application testing discussed herein supports various usage scenarios. The application of automated tests in groups allows application developers to get feedback regarding multiple issues they may have with their application resulting from multiple tests at the same time. For example several different security related issues may be identified by multiple different automated tests in one group and all of those security related issues can be identified to the application developer at the same time. This allows the application developer to resolve those security related issues together rather than being notified of the issues one at a time.

Furthermore applying an automated test is typically less expensive than running a manual test. Thus the techniques discussed herein provide for the initial use of less expensive automated tests but intermixed with manual tests of a manual check when appropriate in the event of an inconclusive result received from an automated test . For example if the testing system will reject all adult themed e.g. pornographic applications then an automated test for adult themed content can be applied as part of a first couple groups of automated tests that are applied to an application. If the automated test cannot determine if the application is an adult themed application then the automated application can return an inconclusive result causing a manual test to be performed before all of the automated tests have been completed. If the application has an adult theme then the manual test can return an indication that the application will not be approved due to its adult theme. The application developer thus need not spend additional time changing the application in an attempt to satisfy the other automated tests e.g. tests relating to whether the application satisfies certain performance requirements when the application is running tests relating to whether the application employs disallowed APIs etc. as the application developer knows that the application will still be rejected due to the adult theme of the application.

Computing device includes one or more processors or processing units one or more computer readable media which can include one or more memory and or storage components one or more input output I O devices and a bus that allows the various components and devices to communicate with one another. Computer readable media and or one or more I O devices can be included as part of or alternatively may be coupled to computing device . Bus represents one or more of several types of bus structures including a memory bus or memory controller a peripheral bus an accelerated graphics port a processor or local bus and so forth using a variety of different bus architectures. Bus can include wired and or wireless buses.

Memory storage component represents one or more computer storage media. Component can include volatile media such as random access memory RAM and or nonvolatile media such as read only memory ROM Flash memory optical disks magnetic disks and so forth . Component can include fixed media e.g. RAM ROM a fixed hard drive etc. as well as removable media e.g. a Flash memory drive a removable hard drive an optical disk and so forth .

The techniques discussed herein can be implemented in software with instructions being executed by one or more processing units . It is to be appreciated that different instructions can be stored in different components of computing device such as in a processing unit in various cache memories of a processing unit in other cache memories of device not shown on other computer readable media and so forth. Additionally it is to be appreciated that the location where instructions are stored in computing device can change over time.

One or more input output devices allow a user to enter commands and information to computing device and also allows information to be presented to the user and or other components or devices. Examples of input devices include a keyboard a cursor control device e.g. a mouse a microphone a scanner and so forth. Examples of output devices include a display device e.g. a monitor or projector speakers a printer a network card and so forth.

Computing devices can each be a variety of different types of devices and can each be a computing device of . For example each of computing devices can be a server computer a desktop computer a laptop or netbook computer a tablet or notepad computer a mobile station an entertainment appliance a set top box communicatively coupled to a display device a television or other display device a cellular or other wireless phone a game console an automotive computer and so forth. Different computing devices can be the same type of computing device or alternatively different types of computing devices. Each computing device can perform one or more or at least part of one or more tests such as one or more of or at least part of one or more of automated tests and or manual tests of . Although multiple computing devices are illustrated in alternatively system can include a single computing device .

Data storage device can be a dedicated storage device e.g. a database a networked hard drive etc. or other type of device e.g. any of the various types of devices discussed above with respect to computing devices and can be a computing device of . Data storage device maintains various information used by computing devices related to the testing discussed herein. For example data storage device can include instructions and or data for one or more tests such as for automated tests and or manual tests of an application for which approval is requested e.g. an application of and so forth. Although a single data storage device is illustrated in alternatively system can include multiple data storage devices .

Management console can be a variety of different types of devices e.g. any of the various types of devices discussed above with respect to computing devices and can be a computing device of . Management console allows an administrator to oversee the automated and manual application testing discussed herein providing various settings and or configuration information inputs and so forth as appropriate. Management console can also implement a test management control module such as test management control module of . Although a single management console is illustrated in alternatively system can include multiple management consoles .

Various techniques may be described herein in the general context of software or program modules. Generally software includes routines programs objects components data structures and so forth that perform particular tasks or implement particular abstract data types. An implementation of these modules and techniques may be stored on or transmitted across some form of computer readable media. Computer readable media can be any available medium or media that can be accessed by a computing device. By way of example and not limitation computer readable media may comprise computer storage media and communications media. 

 Computer storage media include volatile and non volatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media include but are not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by a computer.

 Communication media typically embody computer readable instructions data structures program modules or other data in a modulated data signal such as carrier wave or other transport mechanism. Communication media also include any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media include wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of any of the above are also included within the scope of computer readable media.

Generally any of the functions or techniques described herein can be implemented using software firmware hardware e.g. fixed logic circuitry manual processing or a combination of these implementations. The terms module and component as used herein generally represent software firmware hardware or combinations thereof. In the case of a software implementation the module or component represents program code that performs specified tasks when executed on a processor e.g. CPU or CPUs . The program code can be stored in one or more computer readable memory devices further description of which may be found with reference to . The features of the managing automated and manual application testing techniques described herein are platform independent meaning that the techniques can be implemented on a variety of commercial computing platforms having a variety of processors.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

