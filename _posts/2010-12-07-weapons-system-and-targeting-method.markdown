---

title: Weapons system and targeting method
abstract: A weapon system comprises a first, second and third sensor and a range detecting means. The weapon system further comprises a weapons platform removably mounted to a moveable vehicle. The weapons platform includes a gun. The first sensor is mechanically attached to the gun for sensing an image. The second sensor senses a position of the gun, including at least an elevation and azimuth. The third sensor detects a rate and altitude of the moveable vehicle. The range detecting means detects a range of the gun to the target. The weapon system also comprises an image processor for processing the image from the first sensor, a display for displaying the processed image and a controller. The controller calculates an expected impact point for a round of fire based upon the sensed and detected data, and superimposes the expected impact point on the processed image on the display.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08245623&OS=08245623&RS=08245623
owner: BAE Systems Controls Inc.
number: 08245623
owner_city: Johnson City
owner_country: US
publication_date: 20101207
---
Typical weapons systems are comprised of a weapon mounted onto a mount to a moving vehicle that allows the operator to slew the weapon in elevation and azimuth. These systems can be used to provide defensive suppression fire. Additionally many of these systems when employed from airborne platforms can be used to provide close air support CAS where accuracy is extremely important due to the close proximity of friendly forces to enemy combatants.

A typical system is operated by a single gunner whom identifies and locates a threat through unaided vision. At night this is accomplished usually using Night vision Goggles. However the detection is limited to the range of the gunner s eyesight. At night the problem of identifying enemy targets is even greater due to the fact that enemy combatants are aware of the limitations with Night Vision Goggles.

Once the gunner identifies a threat the gunner looking down the barrel of the weapon must compensate for the motion and speed of the moving vehicle when firing the weapon. This usually requires the gunner to fire bursts of ammunition from the weapon to walk tracers onto the target.

Accordingly disclosed is a weapon system which allows a gunner to identify a threat at greater ranges increases first round accuracy and improves lethality of the weapon.

Accordingly disclosed is a weapon system for a movable vehicle. The weapon system includes a weapons platform with a gun. The weapons platform is attached to the moveable vehicle. The weapon system comprises a first second and third sensor and a range detecting means. The first sensor is mechanically attached to the gun for sensing an image. The second sensor senses a position of the gun. The position of the gun includes at least an elevation and azimuth. The third sensor detects a rate and altitude of the moveable vehicle. The range detecting means detects a range of the gun to the target. The weapon system also comprises an image processor for processing the image from the first sensor a display for displaying the processed image and a controller. The controller calculates an expected impact point for a round of fire based upon the position sensed by the second sensor a relative distance to a target and the rate and altitude detected by the third sensor and superimposes the expected impact point on the processed image on the display.

Additionally the weapon system can comprise a global position device for determining a position of the moveable vehicle.

The moveable vehicle can be an aircraft such as a helicopter. Additionally the moveable vehicle can be a gunboat.

The weapons platform can be attached to the moveable vehicle using a pintle mount. For example the weapons platform can be pintle mounted to the door of a helicopter. The second sensor can be located in the pintle mount.

The first sensor can be a thermal sensor such as but not limited to an infrared image sensor. The infrared image sensor can include a step zoom which is used to estimate a relative distance to a target. Alternative the range detecting means actively determines the relative distance or range from the weapons platform to a target.

The third sensor detects a rate for each direction of a three directional motion of the moveable vehicle.

The controller displays the expected impact point relative to a target. The controller also determines a gun bore line based upon the sensed position of the gun and superimposes the gun bore line on the processed image. The gun bore line is displayed on the processed image using a first indicator and the expected impact point is displayed on the processed image using a second indicator. The second indicator is different than the first indicator.

Also disclosed is a method for locating a remote target using a weapons system having a manned weapon which is removably attached to a moveable vehicle. The method comprises the steps of sensing an image of a remote target using a first image sensor processing the image from the first image sensor displaying the processed image sensing a position of the manned weapon the position including elevation and azimuth detecting a rate and altitude of a moveable vehicle detecting a range of the manned weapon to the remote target and calculating an expected impact point for a round of fire based upon the sensed position a relative distance to a target and the rate and altitude and displaying the expected impact point on a display by superimposing the expected impact point on the processed image.

The method further comprises the steps of determining a gun bore line based upon the sensed position of the manned weapon and superimposing the gun bore line on the processed image.

The weapons system includes a weapons platform a controller a rate position sensor and a display . The display is responsive to signals from and controller . The weapons platform contains weapon and a vehicle mount an image sensor and a range detecting means as depicted in each of which will be described in further detail later.

The vehicle mount includes a first position sensor that senses an elevation and azimuth of the vehicle mount . The elevation and azimuth is used by the controller to calculate the elevation and azimuth of the weapon . Alternatively the controller includes a list of offsets that can be added to the elevation and azimuth to get a more accurate position for the barrel of the weapon . The list can be stored as data in a storage device within the controller . The elevation and azimuth offset can vary based upon the type of weapon and vehicle mount . The vehicle mount will be described in more detail later with respect to .

As depicted in the controller is responsive to signals received from the image sensor the first position sensor range detecting means and the rate position sensor . The rate position sensor is located within the moving vehicle.

Alternatively the controller the sensors and display are wirelessly connected to each other. The wireless connection forms the communication path for signals from the sensors and the controller . The wireless signal would be transmitted as an encrypted wireless signal using wireless transmitter. The wireless connection is a secured connection and the signals transmitted will be encrypted using known encryption techniques which will not be described herein in detail.

The storage device can be an optical magnetic or solid state memory device including but not limited to RAM ROM EEPROMS flash devices CD and DVD media HDD permanent and temporary storage device and the like. As depicted in the storage device includes a program that is executed by the processor and data . The program is executable by the processor to perform the steps of the method s disclosed herein. The sensor data received by the controller is stored in the storage device as data . The data also includes control parameters for the sensors.

The rate position sensor detects attitude position and velocity of the moving vehicle. The rate position sensor can be an inertial measurement unit such as an onboard inertial sensor gyros accelerometer . Additionally the rate position sensor can be a global position unit receiving a GPS signal from GPS satellites. The position and orientation information is relative to a fixed coordinate system e.g. yaw pitch and roll.

The weapon system detects a target and viewing area by means of an image sensor . The image sensor is an infrared sensor. The image sensor includes an infrared photodetector that senses radiation of objects in its field of view. The sensed radiation produces a voltage change in the infrared photodetector. This voltage is processed by an internal image processor. Alternatively a separate image processor can be used. A video signal is sent to the controller .

The image sensor is adapted to have a step zoom function. The step zoom function provides a control of a zoom factor. The step zoom function can be controlled by a user. A control button or switch can be included in the vehicle mount . Alternatively the control button or switch can be included on the display . The zoom can be a digital zoom factor that is applied to the video signal. The factor can be used to estimate a range to a target and be used as the range detecting means . The controller estimates the distance to the target using the zoom factor. When step zoom function is used to estimate the range to target the controller receives feedback from the image sensor on the current zoom level of the image sensor . For image sensors that use a digital zoom the zoom factor feedback from the image sensor is used. The zoom factor feedback is a digital signal received by the controller . The zoom factor feedback equates to the current field of view of the image sensor . The controller is programmed with a look up table that contains pre determined range distances that correspond to the sensor zoom factors. The controller converters the zoom factor feedback into a range to the target using the look up table. This distance is used as range constants in the algorithm that computes expected impact point.

Alternatively the range detecting means is a separate range finding device. The range finding device can be any commercial available range detector. For example an infrared laser range finder can be used. An infrared laser range finder includes a diode which emits an infrared signal towards the target. The target reflects the signal back towards the range finder. The time it takes for a roundtrip signal transmission reflection is proportional to the distance a target is to the range finding device.

The image sensor is adapted to be removably connected to the weapon . The weapon includes a second connector which mates with the first connected to form the removable connection. For example the first and second connectors can be a rail mount system where the second connector forms a channel for attaching and locking a rail on the image sensor . Alternatively the second connector can be a round aperture with a locking mechanism that forms a receptacle for a grooved extension from the image sensor where the grooved extension from the sensing unit is placed in the round aperture and locked in place. The image sensor is oriented in the same direction as the weapon .

The vehicle mount includes a first position sensor that senses the position and orientation of the vehicle mount and gun . The first position sensor can be any commercially available sensor that can detect position and orientation such as but not limited to gyros electronic compasses tilt sensors and transformers. The transformer type sensor can be either a rotary or linear variable differential sensor. The transformer would be attached to or embedded in the vehicle mount and electrically coupled to an electromechanical transducer that provides a variable alternative current output voltage that is linearly proportional to the displacement. The controller receives the voltage from the first position sensor e.g. electromechanical transducer and transformer and calculates the weapon s position based upon the voltage reading.

The display is a headset mounted in a helmet to be worn by an operator Helmet Display . Alternatively the display can be a heads up display HUD located in the moving vehicle. For example the HUD can be mounted on a wall surface of the moving vehicle.

The vehicle mount can include a user interface that controls the weapon system such as an on off switch or button. Alternatively the display can include a user interface.

The processor receives sensor data and determines the bearing of a round of ammunition relative to the line of sight to the target based upon a target range. The processor uses the sensed position information from the first position sensor to determine a pointing vector relative to a fixed coordinate system. For example a geodetic coordinate system can be used. The sensed position information includes azimuth and elevation position data. This pointing vector is a gun bore line GBL . The GBL is displayed on the display . The processor also calculates a continuous expected impact point for a round of fire or munitions CCIP . The processor uses the position information estimated measured range to target vehicle rate position information ballistics constants and environmental factors to estimate the expected impact point. The CCIP is displayed on the display .

As noted earlier the weapon is mounted to a moving vehicle using a vehicle mount . illustrates an example of a vehicle mount . The vehicle mount includes a base portion adapted to be affixed to the moving vehicle a moveable mechanical arm adapted to allow a weapon to be secured to the jaws of the arm and a lower support member adapted to support the weapon. The moveable mechanical arm can change elevation and azimuth. The first position sensor s can be located in the moveable mechanical arm or any part of the vehicle mount necessary to obtain the weapon azimuth and elevation.

Once the weapons system is on the gunner manually acquires the target by moving the weapon . Since the weapons system is on a gunner s vision is aided by the image sensor which allows a gunner to see a target at greater distance even at night. Once the target is acquired an image of the target is sensed and displayed on the display at step . A signal representing the sensed target is transmitted to the controller as a video signal. The processor which can contain a graphics processor processes and formats the video signal for display. The formatted video signal is output from the controller and transmitted to the display .

At step the position of the weapon is determined. The controller obtains the azimuth and elevation position data from the first position sensor . The controller computes a gun bore line based upon the azimuth and elevation position data at step . The controller formats the computed gun bore line for display as a pointing vector. The formatting includes superimposing the gun bore line on the displayed target image. The superimposed gun bore line and target image is displayed on the display at step . For example the gun bore line can appear as a cross hair. The computed gun bore line is also stored in storage .

At step the controller determines the range of the weapon to the target. The controller either receives a zoom factor feedback signal from the image sensor or a signal from another range detecting means to determine the range from the weapon to the target. The controller converters from received zoom factor feedback signal into a range. Additionally at step the controller obtains position rate data for the moving vehicle from the position rate sensor. Each of the sensed information or data is used by the controller to calculate the expected impact point.

At step the controller calculates a Continuously Computed Impact Point CCIP which represents the expected impact point of the round or ammunition. illustrates a flow chart for calculating the CCIP. At step the controller initializes the ballistic constants including but not limited to muzzle velocity and projectile spin. The controller can include a look up table that contains correspondence between a type of bullet and a ballistic constant used. This look up table can also include a separate ballistic contract for type of weapon as well. The controller will retrieve the ballistic constants for the type of weapon and ammunition. At step the controller converts the first position signal received from the first position sensor into a first coordinate system using a conversion matrix. For example for aircraft an aircraft coordinate system will be used. The first position signal received from the first position system is based on the sensor coordinate system. The relationship between the sensor coordinate system and the first coordinate system is apriori known. At step the controller compute an initial instantaneous trajectory vector using the converted first position signal as the direction. The magnitude of the trajectory vector i.e. speed is set to an initial value based upon the ballistic constants for the type of weapon and ammunition. At step controller converts the initial trajectory vector into a second coordinate system using a second conversion matrix. For example the second coordinate system can be an earth geodetic coordinate system. The relationship between the first and second coordinate systems is determined by vehicle attitude information heading pitch and roll from the rate position sensor .

At step the initial trajectory vector is adjusted to account for the rate and position of the moving vehicle. The controller obtains the rate position information from the rate position sensor . The speed rate and direction of the moving vehicle is added to the initial trajectory vector to adjust the vector and the adjusted initial trajectory vector is used as a starting point for a simulation of the flight of the bullet or ammunition to the target. The adjusted initial trajectory vector is continuously updated to account for aerodynamics until the position reaches the target at step . In other words the controller simulates the path of the bullet over a distance range from the weapon to the target i.e. simulated range equals the estimated or measured range from the weapon to the target. The range is detected by the range detecting means . The simulation time is the time it takes for the bullet or ammunition to travel this range. For example the simulation can be a time based numerical integration of the ammunition. For each integration a new position and speed is computed based upon the motion and path of the bullet or ammunition that accounts for aerodynamic forces acting on the projectile.

The controller also can obtain information such as atmospheric density wind vehicle airspeed gravity aerodynamic jump and propeller slipstream characteristics as applicable to accurately simulate the path or flight of the bullet or ammunition. Additionally the projectile spin of the bullet ballistic constants from above is used to account for yaw repose specific for a type of bullet or ammunition. If atmospheric density is used the density can either be estimated based upon the elevation of the moving vehicle and vehicle mount or measured directly.

The controller continuously determines if the simulated range is equal to the estimated or measured range from the weapon to the target at step . If the simulated range is less than the estimated or measured range from the weapon to the target step is repeated. If the simulated range is equal to the estimated or measured range step is stopped and the last updated trajectory vector is assigned as the impact vector at step . The impact vector represents the expected impact point in the second coordinate system. At step the impact vector is converted from the second coordinate system to the first coordinate system. At step the impact vector is converted from the first coordinate system into the sensor coordinate system for display.

At step the expected impact point converted impact vector is displayed on the display . The controller superimposes the expected impact point on the formatted video image signal and outputs the signal to the display . For example the expected impact point can appear on the video image signal using a solid circle or another variant of a cross hair symbol indicating to the user the point of impact relative to the gun bore line which is illustrated by a different indication. The controller via the processor can superimpose the symbols on the infrared image by using a graphics processing means capable of video input capture and output. The processor also contains an application programming interface such as but not limited to Open GL to draw the symbology and merge it with the captured video infrared image signal and transmit it as the new video output signal that will be viewed on the display .

As will be appreciated by one skilled in the art the present invention may be embodied as a system method or computer program product. Accordingly the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as system. 

Various aspects of the present invention may be embodied as a program software or computer instructions embodied in a computer or machine usable or readable medium which causes the computer or machine to perform the steps of the method s disclosed herein when executed on the computer processor and or machine. A program storage device readable by a machine tangibly embodying a program of instructions executable by the machine to perform various functionalities and methods described in the present disclosure is also provided.

The system and method of the present invention may be implemented and run on a general purpose computer or special purpose computer system. The computer system may be any type of known or will be known systems.

The above description provides illustrative examples and it should not be construed that the present invention is limited to these particular example. Thus various changes and modifications may be effected by one skilled in the art without departing from the spirit or scope of the invention as defined in the appended claims.

