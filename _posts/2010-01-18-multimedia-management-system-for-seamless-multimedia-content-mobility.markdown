---

title: Multimedia management system for seamless multimedia content mobility
abstract: In general, techniques are described for providing a multimedia management system to facilitate multimedia content mobility. More specifically, an apparatus may implement the techniques. The apparatus may comprise one or more wireless modems and a control unit. The one or more wireless modems receive multimedia content in a first format from a first application over a wireless communication channel. The control unit includes a Multimedia Management System (MMS) that configures the control unit to provide a multimedia bridge between the first format and a second format, where the second format is supported by a second application. The configured multimedia bridge transforms the multimedia content from the first format to the second format concurrent to the one or more wireless modems receiving a portion of the multimedia content.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08572271&OS=08572271&RS=08572271
owner: QUALCOMM Incorporated
number: 08572271
owner_city: San Diego
owner_country: US
publication_date: 20100118
---
This application claims the benefit of U.S. Provisional Application No. 61 148 152 filed Jan. 29 2009 the entire content of which is incorporated herein by reference.

This application is related to U.S. patent application filed on the same date as the present application entitled Link Management for Multimedia Content Mobility temporarily referenced by Ser. No. 12 688 992 which is assigned to the assignee of the present application and incorporated herein by reference in its entirety.

The disclosure relates to multimedia content and more particularly techniques for transferring multimedia content between devices.

A multimedia ecosystem may comprise a number of multimedia devices that communicate multimedia content between one another using a particular set of multimedia file formats. With the recent rise of wireless networks many of the multimedia file formats have evolved to facilitate communication over these wireless networks. Multimedia devices that each implement the same set of multimedia file formats for communicating multimedia content between one another over a wireless network may form what may be referred to as a wireless multimedia ecosystem. These multimedia devices of wireless multimedia ecosystems may include particular types of wireless modems to communicate via the one or more wireless networks.

A number of different types of modems exist by which to transfer multimedia content wirelessly. Example wireless modems include Wireless Personal Area Network WPAN modems e.g. Bluetooth modems cellular modems e.g. Universal Mobile Telecommunications System or UMTS modems Global Systems for Mobile communications or GSM modems High Speed Downlink Packet Access or HSDPA modems and High Speed Uplink Packet Access or HSUPA modems Wireless Wide Area Network WWAN modems e.g. Worldwide Inter operability for Microwave Access or WiMax modems and Wireless Local Area Network WLAN modems e.g. Wi Fi modems or other modems compliant with the Institute of Electrical and Electronics Engineers or IEEE 802.11 set of standards . Each of these different modems may implement different forms and levels of Forward Error Correction FEC communicate via different wireless communication channels and consume different levels of power.

In addition a number of different multimedia file formats exist for segmenting and encapsulating the multimedia content. The multimedia file formats may comprise specific transport and or application layer protocols used to encode the multimedia content or particular container or wrapper file formats. Often these different file formats may be specific to a particular application such as streaming multimedia content. For example a desktop computer may store digital video multimedia content formatted in accordance with a container format commonly referred to as MP4 defined by a Moving Pictures Expert Group MPEG 4 part 14 for these streaming applications. Other file formats for streaming multimedia content over a public network such as the Internet include an application layer protocol referred to as a Real time Transport Protocol RTP .

Given the wide variety of both types of wireless modems and file formats multimedia ecosystems are often formed for very specific multimedia applications or in some instances groups of related multimedia applications. As a result multimedia devices of one multimedia ecosystem typically only communicate with multimedia devices located in the same multimedia ecosystem. Moreover while a multimedia device may belong to one or more multimedia ecosystems inter ecosystem communication is typically limited or prohibited by multimedia content providers to prevent wide spread digital dissemination of the multimedia content for free. Consequently multimedia content may tend to become fixed within a particular multimedia ecosystem.

This disclosure relates to techniques for implementing a real time Multimedia Management System MMS that provides seamless multimedia content mobility. Rather than limit multimedia content mobility to selected multimedia ecosystems in which only one or more supported multimedia formats are supported the MMS provides a multimedia router gateway or bridge that facilitates the transfer of multimedia content between two or more multimedia devices regardless of the underlying type of modems and multimedia formats implemented by these devices.

The MMS may provide this transfer in real time by configuring hardware e.g. processors and other computing logic necessary to perform this intermediation between these multimedia devices and providing an efficient memory structure to complement transformation between the formats supported by these various devices. The MMS may provide this real time intermediation between devices while at the same time requiring little if any intervention by a user of the MMS. In this sense the MMS may enable a real time transfer of multimedia content seamlessly from a first device to a second device where the first and second devices may include different types of wireless modems and implement different file formats.

In one aspect a method comprises receiving multimedia content in a first format from a first application over a wireless communication channel established using one or more wireless modems configuring a multimedia bridge between the first format and a second format wherein the second format is supported by a second application and transforming with the configured multimedia bridge the multimedia content from the first format to the second format concurrent to receiving a portion of the multimedia content.

In another aspect an apparatus comprises one or more wireless modems that receive multimedia content in a first format from a first application over a wireless communication channel and a control unit that includes a Multimedia Management System MMS that configures the control unit to provide a multimedia bridge between the first format and a second format wherein the second format is supported by a second application. The configured multimedia bridge transforms the multimedia content from the first format to the second format concurrent to the one or more wireless modems receiving a portion of the multimedia content.

In another aspect an apparatus comprises communication means for receiving multimedia content in a first format from a first application over a wireless communication channel means for configuring a multimedia bridge between the first format and a second format wherein the second format is supported by a second application and means for transforming with the configured multimedia bridge the multimedia content from the first format to the second format concurrent to receiving a portion of the multimedia content.

In another aspect a computer readable storage medium comprising instructions that cause a processor to receive multimedia content in a first format from a first application over a wireless communication channel via one or more wireless modems configure a multimedia bridge between the first format and a second format wherein the second format is supported by a second application and transform with the configured multimedia bridge the multimedia content from the first format to the second format concurrent to receiving a portion of the multimedia content.

The details of one or more examples of the disclosure are set forth in the accompanying drawings and the description below. Other features objects and advantages of the disclosure will be apparent from the description and drawings and from the claims.

This disclosure is directed to techniques for implementing a real time Multimedia Management System MMS that provides seamless multimedia content mobility. Rather than limit multimedia content mobility to multimedia ecosystems in which only one or more supported multimedia content file formats are supported the MMS may provide a multimedia router gateway or bridge that facilitates the transfer of multimedia content between two or more multimedia devices regardless of the underlying type of wireless modems and multimedia file formats implemented by these devices. The MMS may provide this transfer in real time by configuring hardware e.g. processors necessary to perform this intermediation between these multimedia devices and providing an efficient memory structure to complement transformation or trans formatting between the file formats supported by these various devices. The MMS may provide this real time intermediation between devices while at the same time requiring little if any intervention by a user of the MMS. In this sense the MMS may enable a real time transfer of multimedia content seamlessly from a first device to a second device where the first and second devices may communicate the multimedia content via different types of wireless modems and implement different file formats by which to encode and decode the multimedia content.

In one aspect the techniques are directed to an implementation of a Link Management Protocol LMP within the MMS that controls delivery of multimedia content via the wireless modems. In another aspect the techniques are directed to an implementation of a Multimedia Exchange Protocol MEP within the MMS that controls the transformation of the multimedia content between file formats. While each of the above aspects of the techniques are generally described in this disclosure relative to one another each of these aspects may be separately implemented or otherwise performed independently of one another or in separate and distinct contexts.

The techniques directed to an implementation of the LMP may involve monitoring channel data defining a set of characteristics associated with a wireless communication channel established between the MMS and another device. For example the MMS may receive multimedia content from a first device via a first wireless communication channel. This first device may be referred to as a source device in that the first device is the source of the multimedia content. The MMS may then establish a second wireless communication channel with a second device. This second device may be referred to as a destination device in that the second device is the intended destination of the multimedia content. The MMS may implement the LMP to determine destination channel data defining a set of characteristics associated with the wireless communication channel established between the MMS and the destination device.

Based on the determined destination channel data the LMP module may then be used to configure a wireless modem used to establish the second wireless communication channel to facilitate communication of the received multimedia content to the destination device. More particularly an LMP unit may based on the determined destination channel data select an appropriate combination of parameters for configuring a logical channel a physical layer channel bandwidth allocation and Quality of Service QoS . For example the MMS may inform the LMP module of the destination multimedia application e.g. streaming multimedia content which the LMP unit may use to determine optional parameter values given the determined destination channel data. The LMP unit may then provide this configuration or combination of parameters to the wireless modem e.g. a baseband processor of the wireless modem and thereby optimally configure the wireless modem to suit a particular multimedia application. This configuration may involve selecting appropriate parameters with respect to a given multimedia application and channel characteristics to maximize so called Quality of Experience QoE of a consumer that consumes the multimedia content.

This LMP aspect of the techniques may promote content mobility by facilitating the communication of multimedia content over wireless channels for a given multimedia application. This aspect of the techniques may enable in effect a device to act as a physical data link layer bridge between two multimedia devices that reside in separate multimedia ecosystems and include different types of wireless modems. In this sense the device that implements LMP in accordance with this disclosure may dynamically adapt different types of wireless modems to create a bridge between multimedia devices of different multimedia ecosystems. Moreover as the dynamic adaption may occur with little if any required user input this LMP aspect of the techniques may occur seamlessly from a perspective of a user of the device. Accordingly LMP when implemented in accordance with the techniques of this disclosure may facilitate seamless mobility of multimedia content.

The aspect of the techniques directed to the MMS implementation of MEP may too facilitate seamless mobility of multimedia content. This aspect involves configuring a control unit to provide a multimedia bridge by which to transform content from a first format to a second format. For example the MMS may receive multimedia content in a first format from a source device over a first wireless communication channel via one of the plurality of wireless modems. In response to receiving the multimedia content the MEP may configure a control unit to provide the multimedia bridge between the first and second file formats.

In some instances the MMS may automatically identify via a discovery protocol or discovery aspect of a wireless protocol a destination device for the received multimedia content. In other instances the MMS may locate or otherwise identify a set of possible destination devices via the discovery protocol and present this set of devices via a user interface. A user may interact with the user interface to select or identify the destination device from the list. In any event the MEP unit may store data defining a plurality of multimedia device profiles for each type of multimedia device. The profiles may define parameters for configuring the multimedia bridge within the control unit. The MEP may determine a profile associated with the source device which may be referred to as a source profile and a profile associated with the destination device which may be referred to as a destination profile .

In some instances the MEP unit may analyze header information stored within the first file format to which the multimedia content is wrapped to extract header parameters. The MEP unit may for example analyze transport and or application layer headers of the file format wrapping the multimedia content to extract these header parameters such as a codec to which the multimedia content was encoded a resolution of the multimedia content a frames per second fps of the multimedia content and the like. Based on the destination profile and the extracted parameters the MEP may then determine as one set of examples whether to re encapsulate the multimedia content trans rate the multimedia content or trans code the multimedia content each of which involves a transformation or reformatting of the multimedia content in various degrees from the first file format to the second file format.

In addition the MEP unit may in some instances also base this determination on the configuration parameters determined by the LMP module in instances where the MMS implements both the LMP and MEP in accordance with the techniques described in this disclosure. In other instances the MEP unit may communicate with a resource manager to determine resource parameters. The MEP unit may further base the determination of the transformation on these resource parameters as well. In each instance the MEP unit may determine bridge configuration parameters to affect the determined transformation. The MEP unit may determine these bridge configuration parameters so as to minimize power consumption or at least reduce power consumption. This may be particularly beneficial when a mobile or other power limited device implements the techniques described in this disclosure. The MEP unit may also determine these bridge parameters to facilitate real time transfer of the multimedia content from the source device to the destination device.

The MEP unit may then configure the multimedia bridge within the control unit in accordance with the bridge configuration parameters. After configuring the multimedia bridge the control unit transforms with the configured multimedia bridge the multimedia content from the first format to the second format possibly while concurrently receiving the multimedia content. In this sense the MEP aspect of the techniques may enable a device to dynamically adapt a control unit to provide a multimedia bridge between two different multimedia devices from two different multimedia ecosystems. This multimedia bridge may comprise a transport application layer bridge that dynamically transforms multimedia content from one file format to another with little if any user input. Accordingly the aspect of the techniques directed to the MMS implementation of MEP may much like the LMP aspect of the techniques facilitate seamless mobility of multimedia content.

Notably the LMP and MEP aspects of the techniques are described below with respect to a single mobile device that includes an MMS having implementations of both the LMP and MEP. This MMS may therefore form a multimedia bridge that spans one or more of the physical and data link layers and one or more of the transport and application layers of the mobile device. Layers as used in this disclosure refer to layers of the Open Systems Interconnection OSI model. Physical data link transport and application layers may also be referred to as layers one two four and seven or L1 L2 L4 and L7 respectively where the number denotes an order of the layers within the seven layers of the OSI model. By combining both the LMP and MEP aspects of the techniques the MMS may provide a bridge that spans multiple layers and which works to build the bridge from the lower layers e.g. L1 and L2 to the upper layers e.g. L4 and L7 by passing characteristics or parameters from the LMP to the MEP such that the MEP may further optimize the bridge configuration parameters for configuring the upper layers of the multimedia bridge. Yet as noted above each of these aspects may be implemented separately from one another to form a multimedia bridge that spans for example only the lower or the upper layers of the OSI model. The techniques should therefore not be considered as limited to the particular exemplary implementations described in this disclosure.

As shown in the example of system includes a source device and a destination application both of which communicate with mobile device via a wireless communication channel and respectively. Each of devices may include a general purpose multimedia device such as a personal computer a workstation a personal digital assistant PDA a mobile phone including a so called smart phone or any other type of device comprising a general purpose processor capable of executing software and particularly multimedia software. Each of devices may alternatively comprise a dedicated multimedia device such as a video camcorder a digital video disc DVD player a television a set top box STB a compact disc CD player a digital media player e.g. a so called MP3 player or a combination MP3 MP4 player a digital video recorder DVR a global positioning system GPS device or any other device dedicated to a set of one or more multimedia applications and that typically does not enable user control over the loading and execution of multimedia software.

Regardless of whether representative of a general purpose device or a dedicated multimedia device source device generates video data in a first format for transmission to destination device . Source device includes a source application and a modem . Source application of source device may as one example include a video capture device such as a video camera a video archive containing previously captured video or a video feed from a video content provider. As a further alternative source application may as another example generate computer graphics based data as the video or a combination of live or archived video and computer generated video. In some cases if source application is a video camera source device may form a so called camera phone or video phone or any other type of camera equipped computing or communication device including mobile telephones or other devices. In other aspects source application may be coupled to or integrated with a source device . In some instances the captured pre captured and or computer generated video may be encoded by a video encoder not shown in for transmission from source device to mobile device via modem over wireless communication channel .

This video encoder may receive video data from source application . The video data received from source application may be arranged in a video sequence comprising a series of video data units such as video frames. Some or all of the frames may be divided into smaller video data units such as video slices. The video encoder may operate on blocks of pixels referred to herein as video blocks within individual video frames or slices in order to encode the video data. A frame or slice may contain multiple video blocks. The video blocks may have fixed or varying sizes and may differ in size according to a specified coding standard. A 16 16 pixel video block commonly referred to as a macroblock MB may be arranged into sub blocks.

As an example the International Telecommunication Union Standardization Sector ITU T H.264 MPEG 4 Part 10 Advanced Video Coding AVC hereinafter H.264 MPEG 4 AVC standard supports intra prediction in various block sizes such as 16 16 8 8 or 4 4 for luma components and 8 8 for chroma components as well as inter prediction in various block sizes such as 16 16 16 8 8 16 8 8 8 4 4 8 and 4 4 for luma components and corresponding scaled sizes for chroma components. In general MBs and the various sub blocks may be considered to be video blocks. Thus MBs may be considered to be video blocks and if partitioned or sub partitioned MBs can themselves be considered to define sets of video blocks. In some aspects neighboring availability check techniques may direct availability determinations based on the width of video block such as a MB or sub block.

While the techniques are described in this disclosure with respect to a variety of video data units such as video frames or video slices the techniques may be generally applicable to any encoding and decoding of video and or audio data. Moreover the techniques are described in this disclosure with respect to video data encoded and decoded according to the H.264 MPEG 4 AVC standard. However the techniques are described in reference to this standard for purposes of illustration. In various aspects such techniques may however be readily applied to any of a variety of other video coding standards such as those defined by the Moving Picture Experts Group MPEG in MPEG 1 MPEG 2 and MPEG 4 the ITU T H.263 standard the Society of Motion Picture and Television Engineers SMPTE 421M video CODEC standard commonly referred to as VC 1 the standard defined by the Audio Video Coding Standard Workgroup of China commonly referred to as AVS as well as any other video and or audio coding standard defined by a standards body or developed by an organization as a proprietary standard.

For purposes of illustration and without limitation application of various coding techniques will be described with reference to H.264 MPEG 4 AVC coding. The video encoder may encode each block e.g. a macroblock MB according to intra coding and inter coding prediction schemes e.g. as set forth in the H.264 MPEG 4 AVC standard. Following intra or inter based prediction of the video blocks the video encoder may perform a number of other operations on the video blocks. These additional operations may include transformation operations such as 4 4 or 8 8 integer transform used in H.264 MPEG 4 Part 10 AVC or a discrete cosine transformation DCT quantization operations entropy coding operations and filtering operations. The video encoder may then encode each of the blocks of the sequence of video frames and output encoded video data which may be referred to as an encoded bitstream. 

Modem of source device may manage the lower layer transmission of the multimedia content e.g. transmission over the physical and data link layers. Layers as described above may refer to various layers of the Open Systems Interconnection OSI model. Modem may for example configure and establish communication channel with mobile device for communication of the encoded video data. Modem may then transmit the encoded video data to mobile device over channel .

Likewise regardless of whether representative of a general purpose device or a dedicated multimedia device destination device receives the encoded video data via wireless communication channel from mobile device . Destination device may include a wireless modem and destination application . In some instances destination device may include a video decoder that may decode the encoded video data to obtain the original video data for playback on a display device. Destination application may comprise any application that utilizes the video data regardless of whether the video data is decoded.

Modem may like modem of source device manage the lower layer transmission of the multimedia content e.g. transmission over the physical and data link layers. Modem may for example configure and establish communication channel with mobile device for communication of the formatted video data. Modem may then receive the formatted video data via wireless communication channel . Modems and may each comprise one or more types of a wireless modem including a Wireless Personal Area Network WPAN modem e.g. a Bluetooth modem a cellular modem e.g. a Universal Mobile Telecommunications System or UMTS modem a Global Systems for Mobile communications or GSM modem a High Speed Downlink Packet Access or HSDPA modem and a High Speed Uplink Packet Access or HSUPA modem a Wireless Wide Area Network WWAN modem e.g. a Worldwide Inter operability for Microwave Access or WiMax modem and a Wireless Local Area Network WLAN modem e.g. a Wi Fi modem or other modem compliant with the Institute of Electrical and Electronics Engineers or IEEE 802.11 set of standards . Each of these different modems may implement different forms and levels of Forward Error Correction FEC communicate via different wireless communication channels and consume different levels of power.

For purposes of illustration it is assumed that source device and destination device reside within separate multimedia ecosystems. In other words it is assumed that source device includes a modem different from modem of destination device and therefore source device may not directly communicate with destination device . In addition it is assumed that source device implements a different file format than that implemented by implemented by destination device . That is source application may generate video data in a format that destination application does not support in that destination application may only support e.g. have the ability to decode or interpret video data of a different format.

As used in this disclosure formats in one aspect may refer to encodings of multimedia content that facilitate transmission of the multimedia content from a source device to a destination device. An example format may include an MP4 file format defined by a Moving Pictures Expert Group MPEG 4 part 14. The MP4 file format is a container file format that is typically used to store digital audio and digital video streams. Other container file formats comprise a simplified version of the MP4 file format referred to as 3GP an Advanced Systems Format ASF an Advanced Video Interleave AVI file format a DivX Media Format DMF an Enhanced Video Object EVO file format and a Flash video file format. Formats may in this aspect or other aspects also refer to formats used with respect to particular transport and or application layer protocols such as a Real time Transport Protocol RTP and a Stream Control Transmission Protocol SCTP . Generally format refers to any description or characteristic of multimedia content or data such as resolution in the instance of video codec used to encode the multimedia data and the like.

Source application may generally refer to hardware or both hardware and software that provides multimedia content. In some instances source application may operate within source device while in other instances source application and source device may comprise the same device. Source application is shown separate from source device in the example of to indicate those instances where source application executes within source device e.g. as a software process executing on a processor. The techniques described in this disclosure should not be limited to the example of .

Likewise destination application may generally refer to hardware or both hardware and software that is a target for or consumer of multimedia content. Destination application may in some instances operate within destination device while in other instances destination application and destination device may comprise the same device. Destination application is shown separate from destination device in the example of to indicate those instances where destination application executes within destination device e.g. as a software process executing on a processor. The techniques described in this disclosure should not be limited to the example of .

Moreover application as used herein should not be limited to either instance described above but may include dedicated devices such as a display device and or software processes executing on a processor.

In accordance with the techniques described in this disclosure mobile device includes a multimedia management system MMS that dynamically configures a multimedia bridge to transform the video data from the first format implemented by source application to the second file format implemented by destination application . Multimedia bridge is shown as a dash lined box in to reflect that multimedia bridge is a logical bridge and not statically hard coded or otherwise configured on a permanent basis. Moreover multimedia bridge is shown in to span both video encoders decoders video codecs and modems to reflect that multimedia bridge is dynamically configured across both video codec and modems of mobile device . In this respect multimedia bridge may provide a bridge between different file formats and different types of wireless modems.

Transformation as used in this disclosure generally refers to any modification of the video data. An example transformation therefore may comprise re encapsulating the video data either partially or wholly. Another example transformation may comprise trans rating the video data within the same codec by dropping frames or re quantization of the encoded video data. Yet another example transformation may comprise transcoding the video data by changing a coding format with or without scaling. Each of these various transformation are described in more detail below.

In addition to MMS mobile device includes video codecs and modems . Video codec may comprise a combination of both a video encoder and a video decoder. Often a video encoder includes an integrated video decoder for decoding content encoded by the video encoder. These video encoders with integrated video decoder are commonly referred to as a video codec or CODEC. Often a graphics processing unit GPU or other type of processing unit multimedia processor or dedicated hardware such as an Application Specific Integrated Circuit ASIC implements the video codec. Alternatively a general purpose processing unit such as a central processing unit CPU may execute software to implement the video codec. In this sense video codec may represent hardware and or a combination of hardware and software that implements a plurality of video codecs.

Modems may comprise a plurality of wireless modems each of which may include a different one of the types of wireless modems listed above with respect to modems and . Typically each of these different types of wireless modems may include a dedicated baseband processor or other processing element that manages the transmission of data over the lower level layers of the OSI model. However in some instances a single baseband processor may implement one or more types of wireless modems. Regardless modems generally represent at least one baseband processor that implements at least one type of wireless modem.

Initially MMS may discover or otherwise detect source device via a discovery protocol or some other discovery mechanism within a wireless communication protocol. Typically MMS may interact with modems to cause one or more of modems to detect any device within wireless communication range of each of these modems . Specifically MMS includes a Link Management Protocol LMP module LMP that communicates with modems to detect any devices within the wireless communication ranges of modems of mobile device . LMP may refer to a protocol described in detail in this disclosure whereby LMP module may communicate with modems to determine parameters by which to configure the lower layers of multimedia bridge .

Although not shown in MMS may include a user interface module that presents a user interface. The user interface may list the detected devices. A user or other operator of mobile device may interact with the presented user interface to select a source device e.g. source device . The user interface module may upon receiving this selection also present another user interface listing the detected devices minus the selected device. This user interface may prompt the user to select a destination device. The user may then interact with this second user interface to select a destination device from this second list e.g. destination device . In this respect MMS may identify at least one source device and at least one destination device . Alternatively MMS may automatically select the source and destination devices form the list without prompting or otherwise requesting intervention from the user.

Based on the selected either automatically or via user intervention destination device LMP module may determine which of modems should be used to communicate with destination device and establishing with this one of wireless modems wireless communication channel with destination device . This one of wireless modems may be referred to as a destination modem. LMP module may communicate with this destination modem to determine destination channel data defining a set of characteristics associated with wireless communication channel . These characteristics may comprise a Bit Error Ratio BER Packet Error Rate PER a Signal to Noise Ratio SNR a Forward Error Correction FEC strength frequency or time diversity associated with a channel coding and error distribution characteristics e.g. deep versus flat fade . LMP module may then configure this one of wireless modems based on the destination channel data so as to facilitate if not optimize transmission of multimedia content received from source device via wireless communication channel .

In some instances LMP module may interface with another one of wireless modems that manages wireless communication channel by which mobile device communicates with source device . This other one of wireless modems may be referred to as a source modem. LMP module may interface with this source modem to determine source channel data defining a similar set of characteristics as those defined by destination channel data. LMP module may then configure this source modem to facilitate if not optimize recovery of the multimedia content from the wireless signal sent via wireless communication channel . In this manner LMP module may interface with modems to construct a multimedia bridge that spans wireless modems .

Notably the source and destination modems may comprise the same one of wireless modems . In this case only the source modem involves the receive side of this same one of wireless modems while the destination modem involves the transmission side of this same one of wireless modems . Each of the receive and transmission sides may for purposes of the techniques described in this disclosure represent separate modems and each of these sides may be individually configured by LMP module to facilitate if not optimize recovery of the multimedia content from wireless signals sent over respective wireless communication channels and .

MMS may further include a Multimedia Exchange Protocol MEP module MEP that constructs the upper layers of multimedia bridge . In other words MEP module determines bridge configuration parameters by which to configure video codecs in a manner that facilitates transformation of multimedia content encoded in accordance with a first format to multimedia content encoded in accordance with a second format. In this respect MEP module configures multimedia bridge within a control unit of mobile device e.g. the collection of video codecs and any other supported processing units such that multimedia bridge spans multiple video codecs .

To configure multimedia bridge in this manner MEP module may determine a number of different types of data on which to base the configuration parameters for the upper layers of multimedia bridge . First MEP module may receive either the source or destination channel data or both the source and destination channel data from LMP module . This channel data may define a set of characteristics that MEP module may use in identifying acceptable types of file formats. LMP module may also forward the selected source device and destination device to MEP module . Based on the selected source device and destination device MEP module may select one or more of profiles . Each of profiles may represent a multimedia device and or application profile defining data that delineates file formats supported by the respective multimedia device and or application as well as characteristics of those supported file formats. MEP module may for example determine one of profiles that corresponds to source application e.g. a source profile and another one of profiles that corresponds to destination application e.g. a destination profile . MEP module may in some instances communicate with a resource manager module not shown in that manages utilization of resources within mobile device to determine resource data delineating the current utilization of resources within mobile device . MEP module may in other instances extract header data from the file format headers that wrap or encode the received multimedia content.

Based on one or more of these sets of data e.g. the channel data the device and or application data the resource data and or the header data MEP module may determine bridge configuration parameters that define a configuration for the upper layers of multimedia bridge . MEP module may in one aspect select these bridge configuration parameters to configure multimedia bridge such that it provides a real time or low latency but not necessarily instantaneous transformation of the multimedia content from the first file format to the second file format. MEP module may in another aspect select these bridge configuration parameters to configure multimedia bridge such that the transformation performed by multimedia bridge conserves power or otherwise reduces power consumption.

Various techniques may be employed to configure multimedia bridge to conserve or otherwise optimize power consumption. For example power consumption may be improved through smart transcoding. In smart transcoding multimedia content encoded in accordance with a form of entropy coding available to the H.264 MPEG 4 AVC video codecs referred to as Context Adaptive Binary Arithmetic Coding CABAC may be transcoded to a Context Adaptive Variable Length Code CAVLC . Smart transcoding may acknowledge that CABAC may introduce significant latencies and inter dependencies e.g. data dependencies that introduce serial operations incapable of being executed or performed in parallel. This serialization occurs due to context savings and multi level decoding within a macroblock slice decoding loop of codecs.

In any event the inter dependencies also increase a number of conditionals e.g. branches in coding decisions that increase usage or utilization of a processor which may be referred to as a core . This increased utilization may increase power consumption. By transcoding the multimedia content to CAVLC this power utilization may be decreased by a reduction in data dependencies. In this respect this form of transcoding may be smart in that the transcoding may adapt transcoding in order to avoid known issues. In addition smart transcoding may involve transcoding B slices to P slices to promote efficient power utilization by providing a net effect of Main profile to Baseline profile transcoding e.g. which may be useful when one mobile with MMS is serving other mobile devices in this first mobile s user group .

Also smart transcoding may involve decoding parameters from the received multimedia content and re using rather than re computing these parameters in the re encoding process. For example motion information such as motion vectors may be decoded and then re used to re encode the multimedia content before delivering that content to the destination device. This may reduce power consumption through re use or recycling of parameter information. Smart transcoding may further include determining a number of macroblock rows which allows parallelization that a given channel can support based on bandwidth data provided by an LMP module such as LMP module . This data may reduce power consumption by enabling MEP to configure video codecs so as to enable a maximum amount of parallelization which as described above may reduce power consumption. In effect smart transcoding refers to a process whereby MMS selects bridge configuration parameters so as to configure a multimedia bridge that is optimized more for latency and power and for ensuring optimum alignment between source and destination application rather than for compression efficiency.

MEP module may then interface with video codecs to configure one or more of video codecs in accordance with the determined bridge configuration parameters. MEP module may interface with video codecs via application programmer interfaces APIs provided by each of video codecs . MEP may determine which of the APIs to invoke and therefore which of video codecs to configure based on the file format to which the multimedia content received from source application is formatted and the selected one of the file formats supported by destination application as set forth in the corresponding one of profiles . In this respect each of video codecs may correspond to one or more file formats.

Notably MEP may only configure a single one of video codecs and much like in the instance above where only one of wireless modems is configured configure a receive side e.g. decoder and a transmit side e.g. encoder of this one of video codecs . In this instance the transformation may comprise a partial or whole re encapsulation of the multimedia content from a first format to the second format. Alternatively the transformation may comprise a trans rating of the multimedia content within the same codec which may involve dropping frames of the multimedia content or re quantization of the multimedia content to generate the second file format from the first file format. In this respect the file format refers to the format of the multimedia content. The first file format may therefore differ in the format of the multimedia content from the resulting second file format. When transforming involves two or more of video codecs the transformation may comprise a trans coding whereby both the type of encoding and the format of the multimedia content may change from the first file format to the second file format.

LMP module of MMS may dynamically configure multimedia bridge to receive multimedia content via a first one of wireless modems and efficiently transmit this multimedia content via a second one of wireless modems . MEP module of MMS may also dynamically configure multimedia bridge to transform the multimedia content received over the first one of wireless modems from a first file format to a second file format. The combined configuration may therefore configure multimedia bridge across various layers of the OSI model to facilitate if not optimize delivery of multimedia content from a source application of a first multimedia ecosystem to a destination application of a second different multimedia ecosystem where each of these devices include different types of wireless modems and support non overlapping and therefore different sets of multimedia file formats. Moreover the configuration may result in a multimedia bridge that promotes efficient power utilization and or seamless real time delivery and transformation of the multimedia content.

As an illustration after configuring multimedia bridge mobile device may receive via one of modems multimedia content from source device over wireless communication channel . Multimedia bridge may receive this content via a first one of wireless modems and provide error correction and other lower layer functionality to recover the multimedia content encoded in accordance with a first file format supported by source application from a wireless typically radio signal. This source modem of multimedia bridge may be configured by LMP module based on the above described source channel data to provide more robust error correction and other lower layer functionality to improve recovery and or promote efficient energy consumption.

This source modem of multimedia bridge may then forward the recovered multimedia content formatted in the first file format to one of video codecs of multimedia bridge which may be referred to as the source video codec. MEP module may configure this source video codec to promote efficient power consumption and or real time decoding of the multimedia content. The source video codec of video codecs may decode the first file format to generate unformatted multimedia content and forward this unformatted multimedia content to another one of video codecs that conforms with a file format supported by destination application of destination device which may be referred to as a destination video codec of multimedia bridge . MEP module may configure this destination video codec to promote efficient power consumption and or real time encoding of the multimedia content.

Moreover MEP module may configure both of the source and destination video codecs to optimize parallel decoding and encoding of the multimedia content from the first file format to the second file format to promote efficient power consumption and or real time transformation of the multimedia content. With respect to real time transformation of the multimedia content MMS may in some aspects configure multimedia bridge to transform the multimedia content concurrent to receiving the multimedia content from source application .

The destination video coded of video codecs may then forward the multimedia content encoded in accordance with the second file format to the destination modems multimedia bridge . Like the source modem LMP module may configure the destination modem of multimedia bridge to improve recovery of the multimedia content by destination device and or promote efficient energy consumption by mobile device . This destination modem may then transmit the formatted multimedia content to destination device over wireless communication channel .

In this manner the techniques may facilitate dynamic configuration of a multimedia bridge within a device such as mobile device to provide a bridge that enables communication between two devices such as source device and destination device . Multimedia bridge may span lower layers e.g. layers 1 and 2 or L1 and L2 of the OSI model by way of LMP module configuring one or more of wireless modems to establish wireless communication channels and . Multimedia bridge may span higher layers e.g. layers 4 and 7 of the OSI model by way of MEP module configuring one or more of video codecs to facilitate the transformation of multimedia content from one file format to another file format. Considering that multimedia bridge enables the communication of multimedia from one application to another where a first one of the applications e.g. source application resides within one multimedia ecosystem and the other application e.g. device application resides within another multimedia ecosystem multimedia bridge may be referred to as a multimedia gateway inasmuch that multimedia bridge acts as a gateway for multimedia to flow between two different multimedia ecosystems.

While described as facilitating a single direction of communication from source application to destination application the techniques may enable mobile device to provide a multimedia bridge that facilitates communication both from source application to destination application and destination application to source application . In this respect the techniques may enable mobile device to provide a duplex generic platform in that multimedia bridge provides a generic platform by which to facilitate communication between two or more applications simultaneously which is referred to as duplex communication.

As shown in the example of mobile device includes a control unit that implements the techniques described in this disclosure. Control unit may comprise one or more processors not shown in that execute software instructions such as those used to define a software or computer program stored to a computer readable storage medium again not shown in such as a storage device e.g. a disk drive or an optical drive or memory e.g. a Flash memory random access memory or RAM or any other type of volatile or non volatile memory that stores instructions e.g. in the form of a computer program or other executable to cause a programmable processor to perform the techniques described in this disclosure. Alternatively control unit may comprise dedicated hardware such as one or more integrated circuits one or more Application Specific Integrated Circuits ASICs one or more Application Specific Special Processors ASSPs one or more Field Programmable Gate Arrays FPGAs or any combination of the foregoing examples of dedicated hardware for performing the techniques described in this disclosure.

Particularly control unit implements MMS that includes LMP module and MEP module as described above. MMS may further include a user interface UI module that presents a user interface such as a Graphical User Interface GUI or a Command Line Interface CLI with which a user may interact to select one or more detected devices with which to form a bridge as described above. Although not shown in mobile device may comprise a display within which user interface module interacts to present the above described user interface.

Modems includes a plurality of different types of wireless modems A N wireless modems or modems . Each of modems includes one of Radio Frequency Front End RFFE units A N RFFE units one of baseband processors A N baseband processors one of Media Access Control MAC units A N MAC units and one of transport units A N transport units respectively. Each of RFFE units may comprise a transceiver to facilitate both transmission and receipt of wireless Radio Frequency RF signals. Typically each of RFFE units comprises various components to interface with an antenna not shown in so as to receive and transmit RF signals such as matching circuits a band pass filter a Low Noise Amplifier LNA and a mixer. RFFE units may demodulate the received RF signals to extract an original information bearing signal from a modulated carrier wave.

Baseband processors may each comprise a dedicated processor or other execution unit for performing and controlling radio communications. Baseband processors may generally decode a received information bearing signal based on channel codes embedded in the information bearing signal. Particularly baseband processors may decode the received information bearing signal based on channel codes referred to as outer codes that are embedded in this signal. Baseband processors may also embed or encode these outer codes in an information bearing signal prior to sending this signal to a respective one of RFFE units . MAC units may comprise a module or other unit that encodes and decodes the inner codes of the channel coding. Transport units may comprise a module or other unit that implements one or more transport protocols such as a Universal Datagram Protocol UDP and a Transmission Control Protocol TCP and or an application layer protocol such as the above described RTP.

Channel codes typically comprise an outer code as described above and an inner code and modems may implement channel codes to ensure accurate delivery of the information bearing signal. These codes may be used to perform error correction such as Forward Error Correction FEC . Thus when baseband processor and MAC units decode and encode the information bearing signals these processors may perform error correction generally and in various aspects FEC in particular.

The frequency with which these codes are embedded in the information bearing signal may be determined based on a Signal to Noise ratio SNR and or Bit Error Ratio BER determined for a given wireless communication channel. SNR refers to a ratio of a noise power corrupting a signal to a signal power. BER refers to a ratio of the number of bits or other information unit incorrectly received to a total number of bits or other information unit received during a specified time interval. Higher SNR or BER may typically require more frequent encoding of these codes within the information bearing signal which may decrease channel bandwidth as less of the information bearing signal is sent over a set time interval due to the increase of embedded codes . Lower SNR or BER may typically require less frequent encoding of these codes within the information bearing signal which may increase channel bandwidth as more of the information bearing signal is sent over a set time interval due to the decrease of embedded codes . Consequently error correction typically occurs at the expense of channel bandwidth.

In accordance with the techniques described in this disclosure LMP module configures the lower layers of multimedia bridge which is shown in as lower layer bridge A to facilitate if not optimize communication of multimedia content from source device to destination device . That is LMP module may configure modems used to establish the bridge so as to perform an appropriate level of error correction given an application to which the received multimedia corresponds.

For example the multimedia content may be encoded with channel codes to ensure accurate real time delivery of the multimedia content across wireless communication channel . LMP module may after interfacing with one of modems e.g. modem N to establish wireless communication channel interface with this modem N to determine destination channel data defining a set of characteristics associated with wireless communication channel . LMP module may determine the BER and FEC strength both of which are example characteristics associated with destination channel . Based on these characteristics LMP module may generally configure modem N and more particularly configure baseband processor N and MAC unit N of modem N to ensure accurate real time delivery over channel .

To configure baseband processor N and MAC unit N LMP module may determine bridge configuration parameters A bridge config parameters A based on destination channel data . These bridge configuration parameters A may define a frequency with which MAC unit N and baseband processor N encode channel codes within multimedia content or data received from transport unit N. Bridge configuration parameters A may also define a type of FEC to perform or otherwise identify options or parameters that ensure a given level of channel bandwidth with a tolerable error rate. The error rate may be tolerable in that some applications or uses of the multimedia content may tolerate more errors than others. In other words some applications may tolerate errors and lag caused by errors while others may demand strict error control to reduce lag. In any event LMP module may dynamically select bridge configuration parameters A based on real time destination channel data to suit a particular application for which the multimedia content was encoded. In the above instance to ensure accurate real time or streaming application of the multimedia content LMP module may select parameters A that provide the best bandwidth to error rate ratio.

LMP module may also interface with one of modems that established wireless communication channel e.g. modem A to determine source channel data that defines another set of characteristics associated with wireless communication channel . Source channel data may include similar if not substantially the same characteristics as those described with respect to destination channel data . LMP module may in a manner similar to that described above with respect to destination channel data determine bridge configuration parameters A based on source channel data . LMP module may configure baseband processor A and MAC unit A of modem A using these bridge configuration parameters A determined from source channel data . LMP module may configure modem A in this manner so as to facilitate if not optimize recovery of the multimedia content from a corresponding wireless RF signal sent via wireless communication channel . For example LMP may configure modem A so as to in one example optimize FEC performed by both of baseband processor A and MAC unit A.

Accordingly LMP module may dynamically configure lower layer bridge A to span multiple ones of modems e.g. modems A and N so as to facilitate if not optimize in the above described manner receipt and transmission of multimedia content via wireless communication channels and . This optimization may involve selecting bridge configuration parameters A such that baseband processors A N and MAC units A N tailor FEC to suit a particular application for which the multimedia content is being delivered such as a streaming application. While described with respect to multiple modems A and N the LMP aspect of the techniques may be implemented with respect to a single modem to facilitate if not optimize receipt and transmission by a single modem of the multimedia content.

Referring to the example of control unit of mobile device further includes a resource manager module post processing unit A post proc unit A pre processing unit B pre proc unit B editor unit and a shared storage unit . Resource manager module may represent a hardware and or software module that monitors utilization and other characteristics of various resources e.g. processors memory storage devices registers and the like within mobile device . Post processing unit A and pre processing unit B which may be referred to collectively as processing units may represent one or more processing units that may reformat the underlying data defining the multimedia content for alternate applications and or devices. A single processing unit may implement both of post processing unit A and pre processing unit B. Editor unit may represent a hardware and or software module that adds and or removes content from the multimedia content to prepare the multimedia content for different applications and or devices. Shared storage unit may represent a memory module or storage device that facilitates simultaneous or parallel writes and reads of data to and from a memory or storage device thereby enabling sharing of data stored within shared storage unit .

Video codecs are shown in the example of as a plurality of video codecs A N for purposes of illustration. Video codecs may each implement a different type or form of video codec. As mentioned above the techniques may be implemented with respect to other kinds of codecs including image codecs audio codecs combined video and audio codecs and any combination thereof. Consequently the techniques should not be limited to the example of .

As described above with respect to the example of transport units may implement a transport and or application layer protocol. Transport units may implement one or more of these protocols to reconstruct received multimedia content from a plurality of distinct data units or packets received from underlying MAC units . Transport units may also implement one or more of these protocols to segment multimedia content received from video codecs into one or more distinct data units or packets. Often transport units segment the content into distinct data units to facilitate transmission of the multimedia content over certain communication media. Transport units may also segment the content into distinct data units to facilitate certain multimedia applications such as real time streaming of multimedia content.

In any event transport units may segment the multimedia content into distinct portions and append a header to the distinct portions so as to facilitate reconstruction of the multimedia content from the distinct portions. When wrapped within a header the distinct portions of multimedia content may be referred to as a payload or payload data. To reconstruct the multimedia content transport units parse the header of each distinct data unit extract the payload data and reconstruct the multimedia content based on the header information stored to the parsed headers. Transport units may transmit the reconstructed multimedia content to control unit . This multimedia content is shown in as formatted multimedia content A formatted MM content A . Multimedia content A is formatted in that multimedia content A is formatted in accordance with a first file format.

In accordance with the techniques described in this disclosure MEP module may configure generally control unit to provide higher layer multimedia bridge B between the first format implemented by source application and a second format implemented by destination application . To configure higher layer multimedia bridge B MEP module may first collect various sets of data in order to determine bridge configuration parameters B bridge config parameters B .

In one aspect MEP module may analyze formatted multimedia content A to identify a format to which this multimedia content A is formatted and direct formatted multimedia content A to one of video codecs that support this format e.g. video codec A. Video codec A may analyze encoded multimedia codec A to identify headers associated with portions of the multimedia content. For example multimedia content may be encoded in accordance with the H.264 MPEG 4 AVC standard which may insert headers within the multimedia content to identify frames slices macroblocks and or blocks. One or more of these types of encoding headers may store parameters related to a codec type or version a resolution a Frame Per Second FPS a bit rate a number of coding layers a coded frame type distribution e.g. I frame to P frame ratios I frame to B frame ratios and or P frame to B frame ratios a Group of Pictures GOP length and or structure display parameters or multimedia application. MEP module may interface with video codec A to determine these parameters whereupon video codec A sends these parameters extracted from one or more headers of encoded multimedia codec A to MEP module as header data .

In another aspect LMP module may forward source and destination channel data as channel data to MEP module . In another aspect LMP module may in addition to forwarding channel data forward selections of source device and destination device . Again as described above UI module may present a user interface listing those devices within a range of modems and a user may interact with this user interface to select source device and destination device . UI module may receive these selections and forward the selections to LMP module which may establish lower layer bridge A in the manner described above. LMP module may then forward channel data to MEP module as well as as the selections of source device and destination device . MEP module may then based on these selections identify one or more of profiles that correspond to selected devices and based on these source and destination profiles identify device data.

In yet another aspect MEP module may interface with resource manager module to determine resource data . Resource data may identify utilization and other characteristics relating to resources of mobile device such as remaining battery power remaining operating time control unit utilization memory utilization storage device utilization current total power consumption or any other metric or characteristic related to the resources of mobile device .

In any event MEP module may receive various sets of data and as well as retrieve device data from one or more of profiles . After collecting or otherwise determining these sets of data MEP module may determine bridge configuration parameters B based on one or more of these sets of data. For example MEP module may select bridge configuration parameters B based on resource data to optimize resource consumption within control unit when resource data indicates a high current utilization of resources.

To illustrate MEP module may coordinate or otherwise communicate with resource manager module to determine resource data that indicates an optimal clock frequency by which to transform multimedia content. This clock frequency may indicate a clock frequency at which that source video codec A and destination video codec N operate to achieve a target latency for real time operation and or to minimize power e.g. run the source and destination codecs fast and then shut down thereby managing an on off duty cycle .

As another example MEP module may coordinate or otherwise communicate with resource manager module to determine a core voltage at which each hardware core in the multimedia processing system can be driven to achieve power reductions. This form of adaptive voltage update is referred to as dynamic voltage scaling. MEP module may instruct resource manager module to change the voltage at which each of these elements e.g. the one or more cores that implement the source and destination video codecs is powered. Both the clock frequency and core voltage may be dynamically adapted based on input from MMS and more particularly MEP module to resource manager module . While described above as directly configuring multimedia bridge MMS may also indirectly configure multimedia bridge by specifying bridge configuration parameters that are forwarded to resource manager module which then updates multimedia bridge .

MEP module may balance this selection of bridge configuration parameters B with header data that may for example indicate that the application to which the multimedia content corresponds is a real time streaming application. MEP module may then specify bridge configuration parameters B to provide a baseline level of real time streaming support but sacrifice quality to reduce decoding and encoding overhead thereby simultaneously limiting or reducing the amount of resource that higher layer bridge B may consume.

MEP module may also access profiles for destination device to determine formats supported by destination device . MEP module may then select one of these file formats to meet the objectives determined above e.g. one that provides real time transport and specify bridge configuration parameters B to configure the transformation of formatted MM content A from the first format to this second format which is selected by MEP module to meet the above real time and resource efficient objectives.

MEP module may further utilize channel data when specifying bridge configuration parameters B such that higher layer bridge B re encodes the MM content with sufficient resilience to accommodate certain channel characteristics such as a noisy channel. MEP module may as one example determine bridge configuration parameters B to overcome a noisy channel indicated by channel data by specifying certain encoding parameters to limit the size of dependently coded sections of the multimedia content. The smaller size may facilitate transmission over a noisy channel in that losing a portion of a dependently coded section may prohibit decoding of that portion. However as the section is purposefully set to a small size the loss of this portion may represent a negligible impact to the viewing of the decoded multimedia content.

While only a small number of examples are discussed above for purposes of illustration the techniques may be implemented such that MEP module specifies bridge configuration parameters B to meet a wide variety of objects. MEP module may specify bridge configuration parameters B to optimize power utilization or consumption suit particular device or processor capabilities accommodate real time transfer or any other multimedia application and provide seamless e.g. insomuch that little if any user interaction is required transition of multimedia data or content from a source application to a destination application.

To further illustrate MEP may also select bridge configuration parameters B so as to further optimize power consumption with respect to memories. These memory optimizations may rely on differences between on chip memory and off chip memory which is represented by shared storage device . On chip memory such as caches may consume significant amounts of power as these are usually dynamic memories that need to be updated or refreshed frequently and each refresh consumes power. Off chip memory may not consume nearly as much power due to either its lack of refresh or low refresh rates.

MEP may select bridge configuration parameters B so as to optimize motion estimation for available caches such that a deterministic amount of data traverses from external memory where reference pictures are stored to on chip caches for every macroblock or group of macroblocks. MEP may then select bridge configuration parameters B to reduce the use of the cache and thereby reduce power consumption. MEP may also select bridge configuration parameters B so that frame data in picture buffers is stored in memory banks where a fewer number of pages are opened every time data is retrieved for processing such as for motion estimation .

As another illustration MEP may also select bridge configuration parameters B to provide memory optimizations by limiting memory bus bandwidth utilization which is a major source of power consumption. Typically data traverses between processing elements e.g. CPU hardware encoder decoder display processor DSP etc. over the memory bus. MEP may select bridge configuration parameters B such that a size e.g. burst size and frequency e.g. number of bursts of packets communicated between processing elements is optimized. For example MEP may determine optimal values for these bus parameters to reduce power consumption. MEP may then select bridge configuration parameters B to configure motion estimation within the source and destination codecs such that an amount of data corresponding to each search region is aligned with the optimal bus parameters associated with the memory bus over which this data traverses. MEP may determine the bus characteristics for each bus of mobile device from resource manager module .

As yet another illustration MEP may provide overall memory optimization by selecting bridge configuration parameters B such that the video units or macroblocks decoded by the source codec are directed to cache in the destination codec in a lockstep manner. In other words MEP may select bridge configuration parameters B such that the source codec decodes the multimedia content in a time constrained manner that synchronizes decoding with the subsequent encoding performed by the destination codec. In this respect multimedia bridge may be configured to implement a transcoding pipeline of by time coupling the source codec to the destination codec.

MEP may also configure this pipeline for any transformation process and is not limited to transcoding pipelines. In this respect MEP may select bridge configuration parameters B to configure a processor pipeline that includes any number of hardware cores firmware e.g. DSPs and or computer processing units CPUs . MEP may select bridge configuration parameters B to define various interfaces and or input output operations between the various elements where the interfaces and or input output operations may be data driven register driven or interrupt driven. MEP may determine which interface to select based on the application and other requirements of a given transformation.

In any event after specifying bridge configuration parameters B MEP module may configure higher layer bridge B by interfacing with video codec A video codec N post processor unit and editor unit using one or more Application Programming Interfaces APIs . That is each of these various codecs and units may provide a respective API by which MEP module may interface with these codecs and units. MEP module may then load bridge configuration parameters B into these codecs and units to configure higher layer bridge B.

Once configured in this manner higher layer bridge B may transform formatted multimedia content A from the first format to the second format concurrent to receiving formatted multimedia content A. In the example of higher layer bridge B is shown configured to perform a highly involved transformation that requires transcoding formatted multimedia content A that corresponds to a first format into formatted multimedia content B that corresponds to a second format where the first and second formats are encoded using different video codecs. The transcoding is then followed by a reformatting of the content and an editing of the multimedia content itself. This type of transformation may facilitate viewing multimedia content on a particular device having known limitations which may be defined in a corresponding one of device profiles .

To perform this transcoding operation video codec A of higher layer bridge B may receive formatted multimedia content A from one of modems and decode the formatted multimedia content A. MEP may configure higher layer bridge B to select one of video codecs A based on header data that indicates the codec used to encode formatted multimedia content A. In any event video codec A may pass this decoded video content to post processing unit A which may reformat the decoded multimedia content for alternate application and devices.

As one example the multimedia content may originally be encoded for real time transmission over the Internet where the content may typically be viewed in a relatively small window on a personal computer. Destination device may however comprise a wireless television display rather than a computer and MEP module may specify bridge configuration parameters B such that post processing unit A resizes and otherwise performs graphic operations on the decoded multimedia content to improve playback clarity on larger screens. In this respect post processing unit A may reformat or otherwise modify decoded multimedia content e.g. by resizing the multimedia frames to larger size formats for larger display screens. Post processing unit A may then forward the modified multimedia content to editor unit .

Editor unit may further modify or edit the modified multimedia content by merging content from other applications. Typically editor unit is utilized when two or more source applications are simultaneously providing multimedia content for transformation and subsequent forwarding to one or more destination devices. Editor unit may merge this separate content into a single multimedia content such that the one or more destination devices may simultaneously present the separate content. Editor unit may then store this edited multimedia content to shared storage unit . Shared storage unit may be shared by all of the components e.g. editor unit post processor unit and video codecs within a given higher layer bridge such as higher layer bridge B. Certain benefits may be achieved by employing a shared storage unit including more efficient power consumption and faster write and read times which may improve if not enable mobile device to provide real time transformation of multimedia content form a first format to a second format.

Pre processor unit B may then retrieve this edited multimedia content from shared storage unit and perform pre processing on this edited content to again facilitate the display or otherwise adapt the edited multimedia content to suit a particular application and or destination device. Pre processor unit B forwards this content to video codec N which re encoded the multimedia content to generate formatted multimedia content B. Video codec N forwards formatted multimedia content B to the same or another one of modems which proceeds to transmit formatted multimedia content B via destination wireless communication channel to destination device .

While described above with respect to this highly involved form of transformation MEP module may configure other types of less involved forms of transformation. For example MEP module may specify bridge configuration parameters B to configure a higher layer bridge B that transforms formatted multimedia content A by re encapsulating either partially or wholly formatted multimedia content A. Re encapsulating content A may only involve updating headers appended to portions of multimedia content A without otherwise changing the format of content A. In this example MEP may configure a single one of video codecs to perform this re encapsulation.

As another example MEP module may specify bridge configuration parameters B to configure a higher layer bridge B that transforms formatted multimedia content A by trans rating formatted multimedia content A. Trans rating content A may only involve a single one of video codecs where this one of video codecs translates content A by dropping frames or re quantizing video content A without otherwise editing the format of content A.

In yet another example MEP module may specify bridge configuration parameters B to configure a higher layer bridge B that transforms formatted multimedia content A by trans coding formatted multimedia content A. Trans coding content A may involve at least two of video codecs where one of these two video codecs decodes content A coded according to one coding technique format e.g. MPEG2 and the other one of these two video codecs re encodes the decoded content in accordance with a different coding technique format e.g. H.264 . This transcoding may further involve scaling the multimedia content e.g. for different format sizes as described above.

Each of these various forms of transformation may consume different levels of resources and provide certain benefits. Re encapsulation may be the most power efficient with respect to mobile device transformation of the transformations described in this disclosure but re encapsulation may not provide a very high Quality of Experience QoE for certain applications and or devices. Trans rating may improve the QoE but also consume more power and other resources when compared to re encapsulation. Transcoding may further improve on the QoE obtained by way of trans rating but consume yet even more resources than consumed by trans rating. Transcoding with additional post and pre processing and possibly content editing as described above with respect to may provide the best QoE with respect to the transformations described herein but may further increase resource utilization. MEP module may therefore select and specify bridge configuration parameters B to perform a suitable transformation given the above sets of data and as well as the data determined from profiles .

Initially control unit of mobile device and more particularly MMS within control unit may employ UI module to present a user interface to a user of mobile device . The user interface may prompt the user to determine whether the user would like to establish a lower layer bridge between a source device application such as source device of and a destination device application such as destination device . Assuming the user enters input indicating that the user would like to establish such as bridge UI module may forward this response to LMP module of MMS . LMP module may then interface with modems to determine any devices that support the form of wireless communication supported by each of modems . In effect LMP module may discover devices within range of wireless modems .

Notably some of these devices may comprise access points to larger networks such as the Internet in which still other more remote devices reside. Often by discovering these access point devices mobile device may access and or deliver content from and or to devices that reside outside of the immediate range of wireless modems . For example one of modems may discover a Wireless Access Point WAP that provides a wired or wireless connection to a public network such as the Internet. LMP may discover additional devices such as video servers by accessing the Internet via the WAP. The techniques should not be limited therefore to those devices within range of wireless modems but may include any device that may be accessed via one or more devices within the range of one or more of wireless modems .

In any event upon discovering these devices LMP module may return a list of devices to UI module which may present via the same or another user interface the list of devices. The user may then select one of the devices from the list as a source device e.g. a provider or source of multimedia content and another one of the devices of the list as a destination device e.g. a target or destination for the multimedia content provided by the selected source device. UI module may receive these selections of the source and destination devices via the presented user interface and forward these selection to LMP module . LMP module may then select one or more of modems by which to communicate with the source device and the destination device and establish source wireless communication channel with the selected source device e.g. source device in the manner described above .

Via source communication channel the one of wireless modems may receive RF signals representative of multimedia content from source application . In the example of wireless modem A receives the RF signal representative of the multimedia content where RFFE unit A reconstructs the multimedia content from the RF signal and passes this reconstructed multimedia content to baseband processor A which decodes the channel inner codes embedded in the multimedia content as described above. Baseband processor A may then forward this partially decoded multimedia content to MAC unit A which decodes the outer codes embedded in the multimedia content and reconstructs the multimedia content from the partially decoded multimedia content.

LMP module may communicate with this wireless modem A and more specifically baseband processor A and MAC unit A to determine source channel data as described above. LMP module may in some aspects determine one or more bridge configuration parameters A to adapt wireless modem A to optimize receipt of the multimedia content in light of particular channel characteristics defined by source channel data as described above.

LMP module may meanwhile communicate with the one of wireless modems that established destination communication channel e.g. modem N in to establish destination communication channel as described above . LMP module as described above may further communicate with this modem N to determine destination channel data . Based at least on this destination channel data LMP module may determine one or more of bridge configuration parameters A to adapt wireless modem N to overcome or otherwise optimize delivery of the multimedia content in light of particular channel characteristics defined by destination channel data again as described above . LMP module may not only select bridge configuration parameters A to optimize modem N or both modem A and N to overcome certain channel characteristics but also to promote efficient power consumption or otherwise to facilitate efficient operation of mobile device .

In any event LMP module may interface with modem N or both of modems A and N to configure these one or more modems using bridge configuration parameters A as described above . After configuring one or more of modems and particularly modem N in this manner this configured modem N may forward the received multimedia content via destination communication channel to destination device . The term forwarding as used herein should not be construed as forwarding strictly the received multimedia content in the format in which this content was received buy may also involve forwarding the received multimedia content in a format different from that in which this content was received. This transformation may occur in the high level portion of the multimedia bridge as described above. Consequently forwarding the received multimedia content may comprise forwarding a transformed version of the received multimedia content as well as forwarding the received multimedia content in the same format in which this content was received.

In instances where MMS includes only LMP module to configure lower layer bridge A LMP module may configure modem A to communicate the decoded multimedia content directly to modem N through a switch or other hardware mechanism. In some instances the control unit may provide the switching mechanisms either in hardware or as a combination of hardware and software. In these instances multimedia bridge shown in may comprise lower layer bridge A and not include higher layer bridge B.

Alternatively in instances where MMS includes both LMP module and MEP module as shown in A and B LMP module may configure modem N to forward the channel decoded multimedia content to control unit for further transformation. MEP module may configure a higher layer bridge B to perform this further transformation as described above. In these instances multimedia bridge may comprise both lower layer bridge A and higher layer bridge B. Yet as MMS may include LMP module and not MEP module so may MMS include MEP module and not LMP module . In this instance multimedia bridge may only comprise higher layer bridge B as described below.

Initially control unit of mobile device and more particularly MMS within control unit may employ UI module to present a user interface to a user of mobile device . The user interface may prompt the user to determine whether the user would like to establish a higher layer bridge between a source application such as source application of and a destination application such as destination application . Assuming the user enters input signaling that the user would like to establish such as bridge UI module may forward this response to MEP module of MMS not shown in . LMP module may then interface with modems to determine any devices that support the form of wireless communication supported by each of modems . In effect LMP module may discover devices within range of wireless modems .

Again some of these devices may comprise access points to larger networks such as the Internet in which still other more remote devices reside. Often by discovering these access point devices mobile device may access and or deliver content from and or to devices that reside outside of the immediate range of wireless modems . For example one of modems may discover a Wireless Access Point WAP that provides a wired or wireless connection to a public network such as the Internet. MEP module may discover additional devices such as video servers by accessing the Internet via the WAP. The techniques should not be limited therefore to those devices within range of wireless modems but may include any device that may be accessed via one or more devices within the range of one or more of wireless modems .

In any event upon discovering these devices MEP module may return a list of devices to UI module which may present via the same or another user interface the list of devices. The user may then select one of the devices of the list as a source device e.g. a provider or source of multimedia content and another one of the devices of the list as a destination device e.g. a target or destination for the multimedia content provided by the selected source device. UI module may receive these selections of the source and destination devices via the presented user interface and forward these selection to MEP module . MEP module may then select one or more of modems by which to communicate with the source device and the destination device and cause these one or more of modems to establish source communication channel with the selected source device e.g. source device in the manner described above and destination communication channel with the selected destination device e.g. destination device .

After or while establishing these channels MEP module may determine one or more sets of data as well as data from one or more of profiles each of which concern delivery of formatted multimedia content A to destination device . That is header data may comprise data concerning multimedia content received via source communication channel that indicates for example an intended application of the multimedia content and thereby impacts delivery of this received multimedia content. Channel data may describe characteristics of destination communication channel and thereby impacts or concerns delivery of this content via destination channel . Resource data may comprise data describing resource utilization within mobile device and thereby impact or concern the ability of mobile device to deliver the received content. Data extracted from one or more of profiles may also impact or concern delivery in that this may indicate formats acceptable by destination device .

Based on these one or more sets of data and data sets extracted from one or more of profiles MEP module may determine bridge configuration parameters B to as to optimize delivery of multimedia content to destination device as described above . MEP module may next interface with one or more of video codecs post and pre processor units A B and editor unit to configure higher layer bridge B using bridge configuration parameters B as described above . Often MEP module interfaces with these components via APIs presented by each of these components.

Via source communication channel the one of wireless modems that established source communication channel e.g. source modem A may receive formatted multimedia content from source application that is encoded in accordance with a first format and forward this content to control unit as formatted multimedia content A as described above . Notably some of the sets of data e.g. header data may be extracted from this received multimedia content A and therefore the steps as shown in should not be construed as successive steps for each example of the techniques set forth in this disclosure. Rather the steps may occur in any conceivable order consistent with the various aspects described in this disclosure. The techniques therefore should not be limited to the example described with respect to .

Higher layer bridge B configured within control unit may receive formatted multimedia content A and transform formatted multimedia content A from the first format to a second different format as described above . Once transformed higher layer bridge B may output this transformed multimedia content as formatted multimedia content B to modem N which may then forward this transformed multimedia content to destination device via destination communication channel . In this manner the techniques may facilitate real time and or power efficient transfer of multimedia content encoded in accordance with a first format received from a source device or application to a destination device or application that does not support the first format but does support the second format.

While described as configuring multimedia bridge once and then performing the transformation of the multimedia content from a first format to a second format MMS may continually define and re define both new and old bridge configuration parameters . In this respect MMS may monitor the transformation in real time and adaptively adjust bridge configuration parameters so as to dynamically optimize multimedia bridge to suit a particular context e.g. application channel content encoding device resource utilization and other variables associated with providing the real time bridge. The techniques therefore should not be limited to the examples provided in this disclosure.

Media processor may implement MMS which may be substantially similar to MMS . MMS similar to MMS includes an LMP module LMP and an MEP module MEP . MEP further includes a plurality of profiles A N profiles similar to profiles . Media processor may also include multimedia controllers MM controllers application processing units and multimedia hardware MM hardware .

Multimedia controller may provide one or more interfaces e.g. APIs to MM hardware . Multimedia controller may for example include a voice encoder or vocoder unit an audio signal unit a video signal unit as well as additional units that provide an interface to various multimedia hardware . Multimedia controllers commonly include one or more Digital Signal Processors DSPs that provide high level processing of multimedia content and in interface to lower layer multimedia hardware . Application processing units may comprise one or more processing units that implement or otherwise represent a post pre processor such as post pre processor unit A of and an editor unit such as editor unit . Multimedia hardware may comprise dedicated hardware designed to provide many multimedia operations. Multimedia hardware may for example comprise audio encoder hardware audio encoder video codec hardware video codec image codec hardware image codec a graphics processing unit GPU and a display unit hardware display unit as well as any other types or form of multimedia hardware for encoding or decoding audio video images voice or other form or type of multimedia content.

In accordance with various aspects of the techniques described in this disclosure LMP may communicate with modem processor and more particularly modem controllers of modem processor . LMP may include an API or other interface not shown in FIG. by which to communicate with modem controllers to collect data concerning source and destination channels such as source channel data and destination channel data of . LMP may utilize this interface to then configure one or more of modems via modem controllers based at least on the destination channel data. By so configuring these one or more of modems LMP may configure a lower layer bridge such as lower layer bridge A as described above.

MEP may determine the above described sets of data including the set of data extracted from profiles and determine bridge configuration parameters such as bridge configuration parameters B of . Profiles and the before described profiles may comprise profiles listing characteristics of devices and or particular multimedia applications or ecosystems. As an illustration profile A may comprise a wireless display or WD profile that defines standardized and or in some instances manufacturer specific characteristics of WDs. Example manufacturer specific characteristics may include resolution scaler parameters and display parameters such as color gamut contrast ration color depth and two dimensional capabilities versus three dimensional capabilities or stereoscopic capabilities . Profile B may comprise a social network profile that defines characteristics of widely used social networks. Profile C may comprise a media capture device profile that defines standardized and or in some instances manufacturer specific characteristics of media capture devices e.g. a camcorder . Profile D may comprise a personal media player or PMP profile that defines standardized and or in some instances manufacturer specific characteristics of PMP devices e.g. an MP3 player . Profile N may comprise a gaming profile that defines standardized and or in some instances manufacturer specific characteristics of gaming devices e.g. such as handheld gaming devices .

MEP may then determine bridge configuration parameters in addition to those bridge configuration parameters determined by LMP based on one or more sets of the data described above. MEP may invoke one or more of multimedia controllers to configure MM hardware with the determine bridge configuration parameters. MEP may also load one or more of the bridge configuration parameters into MM controllers and additionally may interface with application processing units to configure application processing units and or underlying multimedia hardware using the bridge configuration parameters in the manner described above. In this manner MEP may configure a higher layer bridge within a control unit such as media processor of mobile device .

Below originating and target applications within originating device and target device respectively are video and audio decoders and encoders respectively. These decoders and encoders may process information from originating and target applications and respectively to facilitate the storing and streaming application to which each of originating and target devices are dedicated. In this respect originating and target devices and may represent dedicated multimedia devices that each provide a dedicated or fixed set of functions or operation. Originating device may for example comprise a camcorder or digital media player that stores multimedia. Target device may comprise a dedicated device for streaming multimedia such as a satellite radio device a wireless television and a Voice over IP VoIP device or telephone.

With respect to the transport layer originating device supports the above described MP4 file format while target device supports the RTP UDP and IP transports. In this example originating device supports a different set of transports that does not overlap with those supported by target device . Accordingly originating device may be considered to be a part of a different multimedia ecosystem than target device . Below the transport layer is the data link layer. While types of modems are not explicitly specified with respect to this data link layer each of originating and target devices may likewise support or otherwise include different types of modems further differentiating the two disparate multimedia ecosystems to which these devices belong.

As described above MMS may provide a multimedia bridge between these two devices that reside in disparate multimedia ecosystems. MMS may include MEP that performs the operations described above to construct a higher layer bridge that bridges in the example shown with respect to different transport layer formats. MMS may also include LMP that performs the operations described above to construct a lower layer bridge that bridges in the example shown in different data link layer protocols. The higher layer bridge is therefore higher than the lower layer bridge with respect to the layers of the OSI model. While described with respect to the transport and data link layers of the OSI model the techniques may be implemented with respect to any two or more layers of the OSI model.

Layer A comprises the lowest layer of the seven and is referred to as physical layer A. Typically operations that reside in physical layer A include modulation and channel coding in preparation for interfacing with a communication medium. Layer B is directly above layer A and is referred to as data link layer B. To comply with data link layer B operations are typically performed to handle medium access and implement FEC. Layer C is directly above layer B in the OSI model and is referred to as network layer C. To comply with network layer C typically operations are performed to enable or otherwise facilitate routing forwarding addressing internetworking error handling congestion control and packet sequencing. Above layer C is layer D which may be referred to as transport layer D.

Operations included within transport layer D comprise transparent data transfer e.g. transparent to operations above layer D and end to end error recover and flow control. Above layer D is layer E which may be referred to as session layer E. Session layer E may include operations to enable or otherwise facilitate connection coordination. Layer F is above layer E in the OSI model where layer F may be referred to a presentation or syntax layer F. Syntax layer F may include operations to enable or otherwise facilitate encryption synchronization and coding and decoding. Over layer F may reside the highest layer layer G which may be referred to as application layer G. Within application layer G may reside applications.

With respect to these layers various operations or functions are shown to the right of these layers. These functions may correspond to functions performed by a mobile device that implements an MMS in accordance with the techniques described in this disclosure such as mobile device of and or mobile device of . To illustrate within physical layer A may reside operations typically performed by various broadcast tuners Wireless Access Network WAN interfaces Wireless Local Area Network WLAN interfaces Wireless Personal Area Network WPAN interfaces and peripheral interfaces. Within data link layer B may reside functions performed by broadcast standards WAN interfaces WLAN interfaces and WPAN interfaces. Within network layer C may reside functions performed by the Internet Protocol IP portions of MPEG 2 Transport Stream TS and streaming protocols including a Real time Transfer Protocol RTP Control Protocol RTCP and a Real Time Streaming Protocol RTSP . Within layer D may reside functions performed by RTP UDP portions of the MPEG 2 TS and broadcast transport protocols including Forward Link Only FLO transport protocol which is a non MPEG 2 transport protocol . Functions within both session layer E and syntax layer F are described below with respect to functions implemented by the MMS. Within application layer G reside functions performed by a plurality of applications such as platform software web services and Internet tools content management user interfaces and Application Programmer Interfaces APIs .

Notably MMS functions are represented by a dashed box shown in as protocol bridge and cooperative QoS functions A MMS functions A . Additional MMS functions are also shown in as MMS functions B D which are also denoted by a dashed box. MMS functions A spans layers B D and F and may represent functions performed by an MMS that implements both MEP and LMP in accordance with the techniques described in this disclosure. As explained above the techniques should not be limited to this example insomuch that an MMS may implement only one of MEP and LMP.

MMS functions A includes functions that reside in data link layer B such as WPAN functions network layer C such as admission control and bandwidth reservation functions of upper layer protocols transport layer D such as transport assisted multi layer error management functions and syntax layer F such as rate control adaption error concealment and Digital Rights Management DRM functions of multimedia codecs. MMS functions B include functions typically performed by a web Internet servers. MMS functions C may include functions typically required to facilitate machine to machine communications such as encryption authorization and authentication. MMS functions D may include functions involving device management.

An MMS such as MMS of may implement these various functions to provide a protocol bridge with cooperative QoS to facilitate inter multimedia ecosystem communication. MMS may operate within these various layers to provide a cohesive bridge that spans layers in the above described manner so as to optimize delivery of multimedia content between multimedia ecosystems. This optimization may involve as described above optimization directed to achieving efficient real time transfer of multimedia content between devices of disparate multimedia ecosystems. In addition or alternatively this optimization may involve again as described above optimization directed as efficient utilization of device resources such as available power. This power efficient optimization may be particularly beneficial with respect to mobile devices that implement the MMS.

The example of represents a conceptual diagram of system in which these devices A D are shown coupling to Devices E G connectivity module sensor module and public network via interconnectivity module . This is a conceptual representation in that mobile device may provide interconnectivity module which MMS may configure in accordance with the techniques described herein to provide an optimized form of interconnectivity over conceptual interconnectivity module .

MMS may provide interconnectivity between one or more of the first set of devices A D and one or more of the second set of devices E G. Devices A G devices may comprise portable devices computing devices gaming devices an Independent Receiver Decoder IRD storage devices display devices and peripheral devices respectively. One or more of storage devices E and peripheral devices G may comprise a wireless docking module that provide a wireless interface by which to interact with these devices E G for device that are customarily accessed by way of wired interfaces. Display devices F may also comprise a wireless adapter by which to provide a wireless not wired interface by which to interface with other devices.

Connectivity module may comprise a module that provides for connectivity between two devices and therefore represents a module that provides connectivity between interconnectivity module and another device not shown in . Sensor module may represent a module that includes a sensor such as a camcorder and or a microphone as two examples. In any event MMS may provide interconnectivity module to interconnect either by way of wired interfaces or wireless interfaces any one or more of each of the first and second sets of devices in the manner described above.

For example MMS may discover each of devices connectivity module and sensor module via interconnectivity module . MMS may further be configured to detect public network and prompt a user or other operator of mobile device for an address such as a web or Internet address in the form of a Uniform Resource Locator URL or HTTP address of a multimedia server within public network . Alternatively MMS may be preconfigured to access a select multimedia server such as a video or data server within public network . In any event mobile device may present a user interface with which a user may interact to select two or more of these devices from a list.

Assuming the user selects one of computing devices B and one of display devices F MMS may establish the above described multimedia bridge between these two devices and optimize this bridge so as to facilitate a particular application e.g. real time streaming and reduce power consumption. MMS may configure the bridge seamlessly in this respect as the user need not further interact with MMS to configure the bridge. The user may however continue to interact with mobile device to select the source content and otherwise prompt the one of computing devices B to begin transmitting the multimedia content.

In some instances the multimedia content may comprise the current interfaces displayed by the selected one of the computing device B. MMS may configure the multimedia bridge to efficiently transform this interface for display on the selected one of display device F. Moreover MMS may configure the bridge to perform this transformation to improve the visual presentation of this interface on a display device such as a High Definition Television HDTV .

In this respect MMS may configure the multimedia bridge to optimize the display of an interface generated in a first multimedia ecosystem on a device of a different second multimedia ecosystem. For example MMS may select bridge configuration parameters in the manner described above to provide an optimal transformation given the type and or characteristics source and destination devices and or applications the characteristics of the wireless channel and the types of applications for which the media is intended. In this sense MMS may optimize the bridge. MMS may also configure the multimedia bridge to forward this interface e.g. a user interface in an efficient manner given the currently determined channel characteristics. In both aspects MMS may improve a quality of enjoyment by improving display of an interface on a device from a different multimedia ecosystem and optimizing delivery of the display in a manner that possibly reduces errors.

Moreover MMS may enable mobile device to provide complex bridging between three or more devices in a variety of interactive ways. A user may as described above select these three or more devices via a user interface and upon selecting three or more devices MMS may prompt the user via the user interface to specify the interaction of these devices desired by the user. Alternatively or in conjunction with the above active selection MMS may determine the interaction by way of context or indirectly given the type of content or other characteristic of the particular devices.

Extending the example above where one of computing device B provides an interface for display on one of display device F it is assumed the user also selects one of portable devices A as well. Assuming the user makes this selection MMS may prompt the user via the user interface to specify the interaction or otherwise indirectly determine the type of interaction.

For example if the one of portable devices A selected comprises an MP3 player MMS may configure the bridge to combine the audio multimedia content from the MP3 player with the interface multimedia content from the selected one of the computing devices B. In this instance MMS may not prompt the user for the type of interaction as MMS may recognize the type of interaction from the differences in source content e.g. one is audio and the other is video. MMS may encode these together in one stream or send these separately as two or more streams. This decision to encode separately or as one may in part depend on the selected target or source device and or applications e.g. the selected one of display devices F for which MMS may maintain a profile. In effect MMS may layer the audio multimedia content over the interface multimedia content.

As another example if the one of portable devices A selected however comprises a personal media player capable of playing back video and audio unlike an MP3 player that only plays back audio and the user selects video multimedia content to bridge to the selected on of display devices F MMS may prompt the user for the type of interaction. That is MMS may prompt the user for how to display both of these multimedia content on a single display device. In one aspect MMS may provide a list of display options such as Picture In Picture PIP if supported by the selected one of display devices F an either or display option that enables a user to swap between the two much like changing between currently executing programs on a conventional computer or any other display option such as horizontally or vertically split screen and overlay underlay.

In another example a user may select two or more display devices F as targets and a single one of computing devices B as a source. MMS may then prompt the user as to how to display the source multimedia content on the two or more selected ones of display devices F. MMS may for example multicast the content to the two or more selected ones of display devices F for concurrent display of the source multimedia content. MMS may alternatively display half of the source content on one display and half of the source content on another display. In this instance MMS may optimize each half for display on the different selected ones of display devices F.

While a number of examples are described above for illustrating various types and forms of connectivity the techniques should not be limited to any one of these examples. Rather the techniques may enable a mobile device such as mobile device to provide a multimedia bridge by which to transform source content received from one or more selected source multimedia devices and or applications and forward this transformed source content to one or more selected destination or target multimedia devices and or applications.

Moreover mobile device may itself comprise a display device and in some aspects as a peripheral device. For example mobile device may receive source content and transform this source content for display on mobile device concurrent to transforming and forwarding this content to a selected one of display devices F. Mobile device may then receive input from a user via a touch screen or other interface and update both the content received from the source device application with as one example a cursor or other location identifier. With respect to mobile device of editor unit may introduce this identifier to generate updated multimedia content. This updated multimedia content may then be transformed and forwarded to the destination device application which may then present the updated multimedia content. This may enable a mobile device such as mobile device to provide an accessible interface with which a user may interact with content being displayed on a device having cumbersome interfaces such as display devices F.

In addition the multimedia bridge established by MMS may provide a back channel or other communications session to a source device application to communicate with the source device application selections made by a user or provide other interactivity with the source device application to update alter or change the source content currently being delivered. This may be especially useful in instances where mobile device provides an interface for devices applications having cumbersome interfaces as MMS may provide a fully functioning interface by which a user may interact with the source content.

For example a user may access a computing device via a public network and port or otherwise forward this interface multimedia content to this type of limited interface display device via MMS of mobile device . This interface multimedia content may comprise a user interface commonly generated by an operating system. MMS may establish the multimedia bridge in the manner described above to present this interface multimedia content via a display device such as one of display devices F. MMS may incorporate within the multimedia bridge mobile device to enable mobile device as an interface by which a user may interact with the interface multimedia content presented via the display. As described above MMS may configure the bridge to update the interface multimedia content with a position or location identifier such as a cursor.

The user may also select portions of the interface such as icons on a desktop of the user interface multimedia content whereupon MMS may transmit the selection back to the source device application using the back channel communications. In response to this selection the computing device may update the source content which in this example comprises interface multimedia content to reflect the selection by the user e.g. by updating the interface multimedia content in response to executing the selected program represented by the icon. In this sense MMS may configure the bridge to facilitate transformation and transmission of the multimedia content as well as provide an interface with which to interact with this multimedia content when displayed via the target device application.

While described above with respect to a source or provider device and destination or target device the techniques may be implemented in various aspects such that a source and or destination devices each comprises another mobile or other device that implements the techniques described in this disclosure. In other words one or more devices that implement the techniques e.g. include an MMS may be chained together one to one or even one to many in a manner whereby each MMS implements a portion of a transformation.

For example a first MMS included within a first mobile device may communicate with a source device whereupon the first MMS may then communicate with a second MMS included within a second mobile device. This second MMS may then communicate with a destination device. With respect to the first MMS the second mobile device may represent a destination device insomuch that the first MMS may implement the techniques to provide a multimedia bridge between the true source device and the second mobile device. With respect to the second MMS the first MMS may represent a source device insomuch that the second MMS may implement the techniques to provide a multimedia bridge between the first mobile device and the true destination device. Consequently reference to a source and destination device above may refer not only to those devices described above as being source and destination device but also other device that implement the techniques described in this disclosure.

This form of chaining may enable a variety of benefits. In one instance referring to the example above the first and second MMSes may form a chain so as to split the transformation into two steps thereby sharing the load in terms of resource utilization. Moreover if one of these two MMSes reside within a mobile device while another MMS resides within a fixed device these MMSes may configure the multimedia bridge so as to offload power consuming portions of the transformation to the one of the MMS that is fixed.

In another instance again referring to the example above the first and second MMSes may form a chain so as to enable transformations that a single one of the MMS could not perform alone. One MMS may not include sufficient resources to provide the optimal transformation for example in real time. However by chaining these two MMS may be able to split the load and thereby achieve an optimal transformation. As another illustration the first MMS may not support a particular format but the second MMS may support this particular format while the second MMS may not be in range or capable of accessing the source device or support the format in which the source device provides the multimedia content. The first MMS may then form a chain with the second MMS so as to provide a multimedia bridge to transform the multimedia content into a format accepted by the destination device. In this respect chaining of MMSes may be beneficial to provide a transformation and often an optimal transformation.

While described herein with respect to source and destination devices throughout this disclosure the techniques may generally apply as described above to a first and second application. Applications may include source and destination devices as well as any other application implemented either in hardware or a combination of hardware and software that either provides source content or consumes multimedia content. For purposes of discussion an application that provides source content is referred to as a source application and an application that consumes source content is referred to as a destination application. These terms however should not be construed as limiting to the techniques as claimed below.

The techniques described herein may be implemented in hardware software firmware or any combination thereof. Any features described as modules units or components may be implemented together in an integrated logic device or separately as discrete but interoperable logic devices. In some cases various features may be implemented as an integrated circuit device such as an integrated circuit chip or chipset. If implemented in software the techniques may be realized at least in part by a computer readable medium comprising instructions that when executed cause a processor to perform one or more of the methods described above.

A computer readable medium may form part of a computer program product which may include packaging materials. A computer readable medium may comprise a computer data storage medium such as random access memory RAM synchronous dynamic random access memory SDRAM read only memory ROM non volatile random access memory NVRAM electrically erasable programmable read only memory EEPROM FLASH memory magnetic or optical data storage media and the like. The techniques additionally or alternatively may be realized at least in part by a computer readable communication medium that carries or communicates code in the form of instructions or data structures and that can be accessed read and or executed by a computer.

The code or instructions may be executed by one or more processors such as one or more DSPs general purpose microprocessors ASICs field programmable logic arrays FPGAs or other equivalent integrated or discrete logic circuitry. Accordingly the term processor as used herein may refer to any of the foregoing structure or any other structure suitable for implementation of the techniques described herein. In addition in some aspects the functionality described herein may be provided within dedicated software modules or hardware modules. The disclosure also contemplates any of a variety of integrated circuit devices that include circuitry to implement one or more of the techniques described in this disclosure. Such circuitry may be provided in a single integrated circuit chip or in multiple interoperable integrated circuit chips in a so called chipset. Such integrated circuit devices may be used in a variety of applications some of which may include use in wireless communication devices such as mobile telephone handsets.

Various examples of the disclosure have been described. These and other examples are within the scope of the following claims.

