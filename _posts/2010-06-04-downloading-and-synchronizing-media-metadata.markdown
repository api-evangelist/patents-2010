---

title: Downloading and synchronizing media metadata
abstract: For a first device, some embodiments provide an application for displaying several media content stored on a second device communicably connected to the first device. The application includes a graphical user interface (“GUI”). The GUI includes a media content display area for displaying the media content stored on the second device. The GUI includes a selectable item for activating a synchronization feature that automatically modifies a clock of the second device to match a clock of the first device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08549437&OS=08549437&RS=08549437
owner: Apple Inc.
number: 08549437
owner_city: Cupertino
owner_country: US
publication_date: 20100604
---
This application claims benefit to U.S. Provisional Patent Application No. 61 237 678 entitled Downloading and Synchronizing Media Metadata filed Aug. 27 2009. This application also claims benefit to U.S. Provisional Patent Application No. 61 322 287 entitled Downloading and Synchronizing Media Metadata filed Apr. 8 2010. U.S. Provisional Patent Applications No. 61 237 678 and 61 322 287 are hereby incorporated by reference.

In addition to storing an image file when taking a picture some digital cameras also store metadata for the picture. This metadata may include a thumbnail i.e. small low resolution version of the picture geolocation coordinates indicating where the picture was taken and a timestamp indicating when the picture was taken.

In order to timestamp the picture some digital cameras include internal clocks that keep track of the time and or date. The time and date at the time a picture is taken are then saved as the timestamp for that picture. However there is no guarantee that the time and date of a camera will actually be set correctly. If the time and or date is incorrect then the timestamp of a picture will be incorrect.

An incorrect time and date may be a problem if the image file is later transferred to a computer or other device. For example if images on the computer also come from a different camera with a correct time and date then the images with the incorrect time and date may be out of order.

Some embodiments of the invention provide a novel synchronization feature for a media capture application. The synchronization feature of some embodiments adjusts an internal clock of a media capture device e.g. a camera so that the time and date of the internal clock is the same as that of a clock of the device on which the image capture application operates e.g. a computer . In some embodiments media content e.g. images videos audio etc. downloaded from the media capture device is timestamped and these timestamps are modified as well in accordance with the modification to the clock.

In some embodiments the media capture application includes a graphical user interface GUI . The GUI of some embodiments includes a first display area for displaying a menu of available media capture and storage devices. The menu allows a user to select a particular device from among the devices displayed in the first display area. In some embodiments when a user selects a particular device in the first display area the GUI displays media files and or metadata about the media files e.g. the timestamps in a second display area. A third display area displays GUI items for controlling the particular device.

The GUI items include a synchronization button in some embodiments. Upon a selection of the synchronization button by a user the synchronization feature described above is initiated. That is when the user clicks or touches if using a touchscreen the synchronization button the media capture application adjusts the time and date of a selected media capture device and also adjusts the timestamps of media files downloaded from the selected device.

The preceding Summary is intended to serve as a brief introduction to some embodiments of the invention. It is not meant to be an introduction or overview of all inventive subject matter disclosed in this document. The Detailed Description that follows and the Drawings that are referred to in the Detailed Description will further describe the embodiments described in the Summary as well as other embodiments. Accordingly to understand all the embodiments described by this document a full review of the Summary Detailed Description and the Drawings is needed.

In the following detailed description of the invention numerous details examples and embodiments of the invention are set forth and described. However it will be clear and apparent to one skilled in the art that the invention is not limited to the embodiments set forth and that the invention may be practiced without some of the specific details and examples discussed. For instance many of the descriptions below refer specifically to images image capture devices and image capture applications. One of ordinary skill in the art will recognize that many of the features described are equally applicable to other media such as video or audio.

Some embodiments of the invention provide a media capture application e.g. image capture application that manages multiple different media storage devices and media capture devices often referred to herein collectively as either media storage devices or media capture devices from multiple different manufacturers. The media capture application of some embodiments detects one or more media storage devices connected to a computing device e.g. computer smartphone etc. on which the media capture application operates. In some embodiments the media capture application also detects media storage devices that are shared on a network e.g. a local area network to which the computing device is connected. The media capture application of some embodiments detects multiple types of devices including scanners cameras and memory devices that store images. Some embodiments manage multiple types of devices e.g. cameras and scanners while other embodiments manage only a single type of device e.g. cameras only .

In some embodiments the media capture application includes a graphical user interface GUI . The GUI of some embodiments includes a first display area for displaying a menu of the available media storage devices. The menu allows a user to select a particular device from among the one or more devices displayed in the first display area. In some embodiments when a user selects a particular media storage device in the first display area the GUI displays information regarding the media content stored on the particular device in a second display area. This information may be metadata about the media content in some embodiments. Metadata in some embodiments is information about data e.g. a file that is not part of the content of the file. For instance when the media content includes image files the displayed metadata may include one or more of thumbnails of the image files location data for the image files and timestamps for the image files. Different media content may have similar or different metadata. Metadata may be stored with a particular file and automatically copied with the file in some embodiments. Some embodiments may also store metadata separately from the file with which it is associated. Some devices are be unable to store metadata at all in which case metadata associated with a file may be lost if transferred to such a device.

When a user selects a particular media storage device some embodiments also display controls for the particular device in a third display area. That is the GUI of some embodiments simultaneously displays i the menu of one or more media storage devices ii media content and or metadata stored on the selected media storage device and iii controls for the selected media storage device. The controls allow the user to command the media capture application to take various actions that affect the selected media storage device and or media files e.g. image files video files audio files etc. stored on the device.

One such control activates a synchronization function for adjusting an internal clock of a media capture device e.g. a camera so that the time and date is the same as that of the clock on the device on which the media capture application operates. In some embodiments pieces of media content e.g. image files downloaded from the media capture device are timestamped and these timestamps are modified as well in accordance with the modification to the clock. That is if the synchronization function moves the internal clock of a camera forward by six hours the timestamps of any photos downloaded from the camera are also moved forward by six hours.

As shown in the GUI includes device display area image display area and control area . The device display area displays a menu of image capture devices that are available to the image capture application. In this example three image capture devices are represented in the menu by icons and . The image display area displays thumbnails and other metadata for images stored on a selected image capture device e.g. images stored on a camera . In some embodiments the image display area displays the full size images stored on the image capture device instead of or in addition to the metadata. The control area displays GUI items for controlling image capture devices and functions of the image capture application that relate to such devices. These GUI items include a synchronization button for synchronizing the internal time and date of a selected device with the clock of the device on which the image capture application operates.

The operation of the GUI will now be described by reference to the state of the GUI during the four stages . Stage illustrates the GUI after the image capture application has detected three available image capture devices and populated the menu in device display area with the detected devices. As shown the device display area displays icons and which each represent a different detected camera and icon which represents a detected scanner. These devices may be connected directly to the device on which the image capture application operates e.g. through a USB port wireless connection etc. or may be a shared device on a network to which the device running the image capture application is also connected.

At this stage none of the icons are selected and thus the image display area is empty. As shown in stage when no device is selected the GUI displays a default set of camera controls in the control area in some embodiments. Some embodiments display scanner or other device controls rather than camera controls as the default controls in control area . However in some embodiments these controls whether camera or scanner controls are inactive when no device is selected. In other embodiments when no device is selected no default controls are displayed and the control area is blank.

Stage illustrates the GUI when a first camera icon is selected. This selection is shown by the inverted colors of the icon though different embodiments use different visual indications to indicate a selection e.g. highlighting a contour of the icon etc. . As a result of the selection the image capture application retrieves metadata from the selected camera and displays the metadata in the image display area . The metadata relates to the individual image files stored on the camera. The metadata of some embodiments includes 1 thumbnail representations of the image files stored on the selected camera 2 temporal data i.e. dates and times that indicates when each picture on the camera was taken and 3 geographical location data e.g. longitude and latitude that indicates where each picture on the camera was taken.

In some embodiments the thumbnails are small low resolution representations of the images in the image files stored on the camera. The thumbnails are generated from the image by the camera in some embodiments while in other embodiments the thumbnails are generated by the device on which the image capture application operates. In some embodiments selecting the location metadata for an image opens a map that shows the area around the location at which the image was taken. The image display area also displays a checkmark which indicates that the image file represented by the marked thumbnail has been downloaded from the camera to the device on which the image capture application operates. On the other hand no checkmark is displayed for thumbnail indicating that the image represented by this thumbnail has not been downloaded.

Stage illustrates the GUI when a second camera icon is selected as indicated by its inverted colors . As a result of the selection the image capture application has retrieved metadata from the camera associated with the selected icon and displayed this metadata in image display area . This metadata also includes 1 thumbnail representations of the image files stored on the second camera 2 temporal data i.e. dates and times that indicates when each picture on the camera was taken and 3 geographical location data e.g. longitude and latitude that indicates where each picture on the camera was taken. This new metadata are the same types of metadata as displayed at stage but the content of this new metadata is different because different image files taken at different times and locations are stored on the second camera.

Stage illustrates the selection of synchronization control a GUI item for activating a synchronization function of the image capture application. When the synchronization control of some embodiments is activated it synchronizes the time and date of the selected camera s internal clock with the time and date of the clock on the device on which the image capture application operates. In some embodiments the synchronization control also causes the image capture application to adjust the timestamps e.g. temporal data of some or all of the image files downloaded from the camera and or stored on the camera in accordance with the change in the internal clock. This is illustrated by the change of the date and time in temporal data from stage to stage after the user has selected synchronization control .

The temporal data adjusted by the synchronization feature is one example of metadata about the image files stored on the image capture device. In some embodiments the image capture application can read and adjust such metadata without downloading the image files with which the metadata is associated. In fact in some embodiments different types of metadata can be retrieved independently of other types of metadata. For example some embodiments can synchronize a camera clock and timestamps of image files stored on the camera without downloading any of the image files or retrieving thumbnails of the images.

Several more detailed embodiments of the invention are described in the sections below. Section I describes the synchronization function for synchronizing computer and image capture device times. Section II then describes a download indicator that indicates whether a particular image file has been downloaded to a computer from a connected device. Section III next describes a feature that enables the image capture application to plot images on a map based on location metadata without importing the images. Section IV describes the software architecture of the image capture application of some embodiments while Section V describes a process for defining an image capture application. Finally Section VI describes an electronic system with which some embodiments of the invention are implemented.

As noted above the image capture application of some embodiments provides a synchronization feature for adjusting the time and date of an internal clock of an image capture device e.g. a camera to match the time and date of the computing device on which the image capture application operates. The synchronization feature of some such embodiments also adjusts timestamps of one or more images downloaded from and or stored on the camera in order to account for the difference between the time and date of the internal clock of the camera and the time and date of the clock of the computing device on which the image capture application operates.

The image display area displays image file names and thumbnails of images stored on the selected device. In this case the selected device is a camera as shown in device display area . Unlike in the image display area does not display other metadata regarding the image files e.g. timestamps geolocations etc. .

The device control area displays various controls for a selected device. As shown in Options are provided to share the camera on a network and delete image files on the camera after the files are imported by the image capture application. The device control area also includes a synchronization button and a clock that displays the time on the internal device clock of the selected device. As described the synchronization feature allows a user to change the device clock to match that of the computer on which the image capture application operates. In some embodiments the computer clock is also displayed in the GUI of the image capture application. In some cases the computer clock is displayed in the GUI of the operating system of the computer e.g. in the bottom right corner top right corner top center etc. .

In some embodiments different controls are displayed in the device control area when a device other than a camera is selected. For instance when an SD card is selected some embodiments do not display a synchronization function because SD cards generally do not keep an internal time. Similarly when a scanner is selected some embodiments do not display an option to delete files after import because files are generally not stored on a scanner. However other controls for managing the selected scanner might be displayed when a scanner is selected in device display area . Image capture applications of some embodiments for managing scanners and the GUIs used therein are described in U.S. patent application Ser. No. 12 479 853 filed Jun. 7 2009 which is incorporated herein by reference.

The image control area includes various controls relating to the images stored on or imported from a selected device. For example the image control area includes a drop down menu that allows a user to determine to which folder on the computer images from the selected device will be imported. In some embodiments the image control area also includes an import button for initiating the import of images from the selected device. The image control area also includes display controls such as the option to display the images in thumbnail view as shown or to switch to a list of image file names options to rotate selected images etc.

The controls area includes a synchronization button for activating the synchronization feature. The controls area also displays information regarding the current date and time according to the computing device the internal date and time of the selected camera and the temporal offset between these two. As shown the times between the two device clocks are offset by over five years.

The image display area displays thumbnails of images stored on the selected camera as well as other metadata about the image files. Specifically image display area displays timestamps for each of the image files below the respective thumbnails. As illustrated by GUIs and different embodiments provide different GUI displays. In some embodiments a user of the image capture application can customize the GUI or at least choose between multiple options for the appearance e.g. between the three options of GUIs and .

Returning to the process begins by receiving at a selection of a camera. In some embodiments a user selects a camera from the device display area e.g. area . This selection may come by the way of a user moving a cursor with a cursor controller such as a mouse tablet and stylus touchpad trackpad etc. and then providing selection input through the cursor controller e.g. clicking a mouse button tapping a touchpad etc. . In some embodiments the GUI is displayed on a touchscreen and the user touches one of the device icons in the device display area to select the icon. As shown in Camera Four has been selected by way of device icon .

As illustrated at stage of the camera which could be e.g. Camera Four stores image files timestamps and other metadata . The camera also has an internal clock set to time B. The computer includes image capture application e.g. the image capture application whose GUI is illustrated in as well as an internal clock set to time A.

The process then retrieves at any metadata for image files stored on the selected camera from the camera. In some embodiments the image capture application is able to retrieve metadata e.g. thumbnails location information timestamps etc. about image files from a camera or other device without actually retrieving the image files themselves. The process then displays at the retrieved metadata in the GUI of the image capture application. As mentioned different embodiments display different metadata. Which metadata is displayed may depend on user preferences the metadata that is available e.g. not all image files will have timestamps location information etc. and the metadata that is recognizable to the image capture application. As shown in thumbnails and timestamps are displayed in image display area of GUI .

Stage of illustrates that the timestamps and other metadata are now duplicated on the computer as timestamps and metadata . This is the result of the image capture application retrieving this data from the camera . In stage both the timestamps on the camera and the computer are based on the clock of the camera.

Next the process receives at user input selecting the synchronization feature. In some embodiments this involves selecting a UI item such as synchronization button that activates the synchronization feature. As with the selection of a device this selection may be by the way of a cursor controller e.g. mouse touchpad trackpad etc. a touchscreen or other selection mechanism e.g. a keyboard . illustrates that a cursor is placed over the synchronization button . By clicking on a mouse tapping a touchpad etc. a user can now select the synchronization button .

When the synchronization feature is selected the process determines at whether the computer running the image capture application and the selected camera have the same time and date. When the time and date are the same on the two devices there is no need to update the camera clock or modify the timestamps so the process ends.

However when the time and date are not the same the process synchronizes at the camera clock to match the computer clock. In some embodiments the image capture application sends a command to the camera to modify its clock. As illustrated in after a user has selected synchronization button the displayed camera time and date is now the same as the computer time and date and the time mismatch is zero. In the example shown the camera clock is moved forwards in time. However some embodiments can also set the camera clock backwards when the clock is set in the future e.g. if the camera clock were set to 2014 rather than 2004 .

The process also updates at the timestamps for the image files on the camera. In some embodiments the timestamps for all of the image files on the selected camera are modified by the same amount of time as the camera s clock. However in some embodiments the time stamps are only updated when doing so would not move the timestamp for an image file into the future i.e. ahead of the computer clock . Some embodiments modify both the timestamps on the camera as well as the retrieved time stamps that are stored on the computer e.g. in RAM on a hard disk etc. .

The process displays at the new timestamps e.g. in image display area . In the situation displayed in the time gap between the camera and the computer is five years one month five days four hours and two seconds. However because the timestamp is initially Jan. 28 2009 at 1 53 PM moving this timestamp forward by 5 years would move it well into the future at a time when the image could not have been taken by the camera. Accordingly as will be described in further detail below with respect to some embodiments check each timestamp for the viability of modification before updating the timestamp. As displayed in the selection of synchronization button has caused the timestamps to all be modified by the time gap between the two devices i.e. moved forward 5 years . After updating the clock and timestamps and modifying the display the process then ends.

Stage of illustrates the result of the synchronization operation. The device clock on the camera is now changed to time A that of the computer clock . Furthermore both the timestamps on the computer and the timestamps on the camera have been modified by the image capture application s synchronization operation.

As mentioned above the image capture application of some embodiments will not necessarily update all of the timestamps automatically. Specifically when moving timestamps forward some embodiments will avoid moving timestamps into the future . That is the timestamps will not be moved past the current time according to the computing device on which the image capture application operates. conceptually illustrates a process of some embodiments for updating timestamps e.g. timestamps downloaded from the camera in response to a selection of a synchronization feature. In some embodiments process is performed at operation of process . The process may also be performed as images or other timestamped media files are imported from a camera in some embodiments. That is when the images are imported the image capture application of some embodiments automatically checks for a clock discrepancy and updates the timestamps of the image files.

As shown the process begins by determining at whether the camera s internal clock before being modified by the synchronization operation is later than the computer clock. When the camera clock is later than the computer clock timestamps will be moved backwards in time rather than forward. In this case there is no need to check whether the timestamps will be moving into the future. If timestamps are set ahead of the camera clock then they will remain in the future as compared to the computer clock when modified and will likely be wrong in either case. As such the process modifies at all of the timestamps then ends. Some embodiments however leave the timestamps alone if they will still be set ahead of the computer clock after modification.

On the other hand when the camera clock is earlier than the computer clock the process will move the timestamps forward in time. The process thus selects at a timestamp. In some embodiments the timestamps are ordered by time or some other factor while in other embodiments the timestamps are selected randomly. Once a timestamp is selected the process determines at whether the selected timestamp is later than the camera clock. When the timestamp is later than the camera clock the image file to which it corresponds could not have been captured by the camera while the clock was at its current setting. As such there is a possibility that the timestamp is actually accurate. Furthermore modifying the timestamp would push the time past the current time assuming the computer time is correct . As such the process does not modify the timestamp and returns to to select the next timestamp.

When the timestamp is not later than the camera clock however the process modifies at the selected timestamp by adding to it the difference between the camera clock and the computer clock. The process then determines at whether more timestamps remain to be modified. When more timestamps remain the process returns to to select the next timestamp. Otherwise the process ends.

In the timestamps are all modified by five years one month five days four hours and two seconds because these timestamps are from times prior to the camera s internal clock. Most likely these images were taken while the camera clock was set incorrectly. However timestamp is not modified. This is because the timestamp indicates that the image was taken in 2009 well after the camera s current internal date and time. In such a situation the camera may have been set to the correct date and time when the image was taken and then later set incorrectly.

Some embodiments provide further user control over the timestamp updates. For example some embodiments provide options for applying timestamp updates to only user selected image files or options for excluding user selected files from timestamp updates. There might be user selectable checkboxes next to the thumbnails or timestamps enabling a user to select files that should be updated or excluded from an update. Some embodiments provide an upper or lower boundary for the difference between the clocks that will cause timestamp updates e.g. if the difference is less than 5 seconds the camera clock will synchronize to the computer clock but the timestamps will not be adjusted .

As described above an image capture application operating on a first computer may download image files and metadata from cameras that are i directly connected to the first computer or ii connected to a network to which the first computer is connected including through a second computer. illustrates a system of some embodiments that includes two computers and and three cameras and . Each of the three cameras is made by a different manufacturer Kodak Nikon and Canon though cameras made by any other manufacturers are possible as well . Both of the computers and camera are connected directly to a network e.g. a local area network wide area network network of networks such as the Internet etc. through which devices and folders may be shared. Camera is connected directly to computer while camera is connected directly to computer . These connections though shown in as USB connections may be any other sort of direct connection e.g. FireWire Bluetooth etc. 

The image capture application of some embodiments operates on the first computer and is able to recognize download metadata from and synchronize the times of all three of the cameras and . Thus the image capture application can read from devices that are i connected directly to the computer on which the application operates e.g. camera or ii connected to the network to which the application s computer is connected e.g. camera or . Devices in the later group may be either connected directly to the network e.g. camera or connected to a second computer that is connected to the network e.g. camera .

The image capture application of some embodiments allows a user to import image files from a camera sometimes referred to as downloading the files from the camera . Some embodiments provide a GUI with controls for selecting particular images to import. In some cases a user may wish to import different images to different folders. For instance the user may have separate folders for different groups of people photographed with the same camera e.g. one folder for family and a second folder for friends or separate folders for high quality pictures as opposed to mediocre pictures. The user may also simply desire to not import all of the pictures off of the camera in order to save hard drive space.

If the application is set to automatically delete the images from the camera after importing them then it is easy to keep track of which images have been imported because any image left on the camera has not been imported. However when the user wants to keep the images on the camera rather than deleting them after importing them it can be difficult to keep track of which images have already been imported and which images have not yet been imported.

Accordingly some embodiments provide a visible indicator that a particular image file has previously been imported from a camera. illustrates a GUI with a visual indicator for each image file that indicates whether the image file has been imported to the computer by the image capture application. This allows a user to more easily distribute a set of pictures to multiple folders on a computer without accidentally making multiple copies on the computer or accidentally omitting a copy from the computer. The GUI includes thumbnail display area control area and device display area . Thumbnail display area displays low resolution representations thumbnails of the images on the camera. The control area displays controls that allow a user to activate an import image tool and to set the folder to which the image files from the camera will be imported. The device display area displays a menu of devices for selection by a user. As can be seen the currently selected device is an SD Card. In some embodiments an SD Card attached to a camera will be treated as a separate device from the camera by the image capture application.

Thumbnail display area includes thumbnails and among several others with import indicators on thumbnails and among others and no import indicator on thumbnail . The thumbnail display area allows a user to select particular images e.g. by clicking on particular thumbnails dragging a box around a set of thumbnails touching particular thumbnails on a touchscreen etc. . A set of selected thumbnails can be imported to a computer via a selection of the import control in import control area . In some embodiments a user can use folder selector to select a destination folder for the imported images either before or after thumbnails are selected. When import control is selected the image files corresponding to the selected thumbnails are copied to the folder indicated by folder selector . In some embodiments the GUI includes an import all control . This control imports all images from the selected device to the specified folder regardless of whether the thumbnails have been selected.

After importing image files from the camera the image capture application places a checkmark next to the thumbnails of the imported images. As the image files are often imported one file at a time some embodiments place the checkmark next to each thumbnail as soon as the corresponding image file has been imported while other embodiments place all checkmarks after all chosen images have been imported. As shown in the figure the image file represented by thumbnail has not been imported as it lacks an import indicator .

The process begins when the GUI receives at a selection of one or more image files. For example in the image files represented by thumbnails and have been selected as indicated by the rectangles surrounding those thumbnails of the images. In some embodiments file names are used instead of or in addition to thumbnails. Also different embodiments may use different ways to indicate that an image has been selected e.g. highlighting the metadata displaying a contour around only the thumbnail image etc. .

The process next receives at an activation of an import control. In the activation of the import control is indicated by the inversion of the colors of import control . This activation may be by way of a user clicking the import button with a cursor as shown in tapping the import button on a touchscreen etc. In response to the activation of the import control the process imports at the image files corresponding to the selected thumbnails. In the example of the image files are imported to a folder called PictureFolder as indicated by folder selection tool . The process then generates at metadata to signify that the selected image files have been imported. The process then displays at a visual representation of the metadata that indicates that the imported image files have been imported. As shown in some embodiments visually represent this metadata as checkmarks .

Some embodiments display checkmarks on a folder by folder basis. That is when a folder is selected the image capture application compares the metadata of the images in the folder e.g. size creation date file name to the metadata of the images on the camera. The image capture application of some such embodiments displays a checkmark to indicate that a copy of a file is already stored in the folder. When a different folder is selected the image capture applications of some embodiments evaluate the new folder to determine whether images in the folder are duplicates of the images stored in the camera. In some such embodiments the metadata indicating which images are duplicates is repeatedly updated so that when an image is removed from the designated folder e.g. deleted or moved the checkmark is removed from the displayed metadata of that image. Note that in some such embodiments the metadata about the import status of an image is stored separately from the file and does not get automatically copied when the file is copied.

In the process of marking the image files as imported the image capture application of some embodiments stores metadata about the individual image files. This stored metadata relates to the status of a file as imported . The data may be stored on the computer on the camera or on both the computer and the camera. When the data is stored on the computer it can be stored for different durations. For example it could be stored until the connection between the camera and the computer is broken or it can be stored for longer periods. In some embodiments the metadata stored on the computer includes an identification of the folder to which the image has been imported.

In embodiments that store metadata of import status on the camera the metadata can be stored separately from the files or it can be stored as metadata associated with each file. The metadata stored on the camera in some embodiments is a general indication that the image file has been downloaded. In such embodiments when the camera is controlled by an instance of the image capture application on another computer the image capture application indicates that the images have been imported. In other embodiments the import metadata indicates to which specific computer the images have been imported. In some such embodiments the metadata about whether the pictures have been imported does not travel with the camera when the camera is moved to different computer.

In some embodiments the GUI displays the identity of the folder and or computer to which an image file has been imported. In some such embodiments the display of the identity of the folder is provided when a user performs a GUI operation such as hovering a cursor over or clicking on a thumbnail or import indicator. Some embodiments store data indicating multiple folders to which an image has been imported when an image has been imported to multiple folders. Some embodiments provide one type of marks when an image has been imported to one folder and a different mark when the image has been imported to more than one folder.

Some digital cameras include a built in global positioning system GPS receiver or in some other way receive and store information about the location at which a picture is taken. Such cameras store the location of the camera at the time and date that the image was taken and or other location information e.g. which direction the camera was pointing . This metadata may be retrieved by the image capture application of some embodiments. Accordingly the image capture application of some embodiments includes a map plotting feature for images taken by such cameras. Some such applications save time and hard drive space by retrieving metadata of image files stored on the camera without retrieving the image files themselves. For example some embodiments can open a map on a computer corresponding to a location indicated in the metadata of a particular image without importing the image. In some embodiments the image capture application can open such a map without even retrieving a thumbnail of the image from the camera.

Similarly some embodiments display a map showing the locations indicated by metadata of particular images on a camera or other image storage device without importing the particular images to the computer. Some embodiments also retrieve thumbnails of the image files from the camera and display the thumbnails on the map without importing the full image file. One of ordinary skill in the art will understand that many digital cameras store images on removable media such as SD cards. Accordingly some embodiments provide the same image transfer features marking map plotting when retrieving metadata and images directly from an SD card rather than through a camera. The figures in this section show the application as working with metadata from images on an SD card though one of ordinary skill in the art will realize that the described features can be applied to working with metadata from images on digital cameras or other storage devices in some embodiments.

The process receives at a selection of an image storage device e.g. a camera or an image storage medium . For example in the GUI has received a selection of SD card . The process then retrieves at metadata of the image files stored on the selected device. This metadata may include a geographic location associated with the image file thumbnails of the images timestamps for the images etc. In some embodiments no data containing an image including thumbnails is downloaded by the process before plotting representations of the image files on the map. For example some such embodiments download the geographic location data of the image file and the filename of the file but not a thumbnail. The process then displays at the metadata. displays metadata associated with image files stored on the selected camera in image listing area .

The process then receives at a selection of a geographical location. For example in a user could select coordinates or by double clicking on the coordinates by tapping the coordinates on a touchscreen etc. The process then retrieves at map data for an area about the location indicated by the selected coordinates. In some embodiments the image capture application retrieves the map data by opening a web browser to an online map website. The image capture application provides the coordinates to the website and the website then displays the relevant map.

The retrieval of the map data in other embodiments is from an internal database of the application or from some external source e.g. an Internet map site . The process then displays at a map of an area that includes the location associated with the selected image file. illustrates a map around a location in the metadata of an image file. Specifically shows a map showing the area around the coordinates .

In some embodiments the map represents an area surrounding the selected coordinates from the metadata. In other embodiments the map represents an area with the coordinates from the metadata on an edge or corner of the map. The process then ends. In some embodiments the command to view a map can come from a map activation control however some embodiments do not have a specific map activation control and activate the map in other ways such as when a user selects the coordinates. In some embodiments the displayed map includes a display of one or more thumbnails or other representations e.g. file names at the associated coordinates. In some embodiments the activation of the map view can occur before the selection of an image storage device. In other embodiments the map display may be the default view for representations of images with associated geographic coordinates.

The process receives at a selection of an image storage device e.g. a camera or an image storage medium . illustrates that the icon for an SD card has been selected. The process retrieves at metadata of the images. This metadata may include a geographic location associated with the image file or thumbnails of the images such as and as shown in or other metadata associated with the images. In some embodiments no actual image data is downloaded by the process before plotting representations of the image files on the map. For example some such embodiments download the geographic location data of the image file and the filename of the file.

The process then receives at a command to activate a map view. In some embodiments the command can come from a map activation control. In other embodiments the GUI may be the default view for representations of images with associated geographic coordinates. In some embodiments the activation of the map view can occur before the selection of an image storage device.

The process then retrieves at a map. The retrieval of the map may be from an internal database of the application or from some external source e.g. an Internet map site . The process then displays at the map with representations of image files on the location on the map corresponding to the geographic metadata of the image files. illustrates this with map . On map the GUI displays thumbnail images and at map coordinates corresponding to the geographic location metadata of the images.

Some embodiments allow a user to select the representations on the map for import. For example some embodiments allow a user to click on a thumbnail or other representation of an image plotted on a map to select that image file. Some embodiments allow a user to drag a box around multiple images e.g. all images taken in a particular geographic area to select them. Some embodiments allow a user to input a range of coordinates to select all images within that range e.g. by panning and zooming the map or by typing in sets of coordinates that form a boundary of a region . As mentioned above some embodiments include a list control button to switch the image viewer between the map and a view with a list of image files.

In some embodiments the processes described above are implemented as software running on a particular machine such as a computer or a handheld device or stored in a computer readable medium. Sub section IV.A. below describes the high level architecture of a computer system or several computer systems that performs image capture and modification tasks such as those described above. Sub section IV.B then describes in more detail the modules and application programming interfaces APIs used to carry out the image capture and modification tasks.

In some embodiments the image capture application is a stand alone application or is integrated into another application while in other embodiments the application might be implemented within an operating system. Furthermore in some embodiments the application is provided as part of a server based solution. In some such embodiments the application is provided via a thin client. That is the application runs on a server while a user interacts with the application via a separate machine remote from the server. In other such embodiments the application is provided via a thick client. That is the application is distributed from the server to the client machine and runs on the client machine.

In some embodiments the image capture application operates using multiple separate modules on a single computing device e.g. personal computer smartphone etc. . In some embodiments three separate types of modules are used i a device module e.g. a device driver that launches when an image capture device associated with that module is connected to the computer and provides an interface between the image capture device and the other modules on the computer ii a high level image capture client e.g. an application such as iPhoto Aperture etc. and iii an Image Capture Extension that runs in the background and provides connections between the device modules and the high level applications. In some embodiments the Image Capture Extension is part of an operating system of the computer or is developed to directly interface with the operating system.

The device module provides an interface between the external device connected to the computer via a port such as a USB interface FireWire interface Bluetooth interface etc. and the Image Capture Extension . The device module is a device driver for external device in some embodiments and is able to translate commands between the Image Capture Extension and the external device . Accordingly the device module launches automatically when camera is connected to computer in some embodiments.

Image Capture Extension of some embodiments provides connections between device modules in this figure device module and image capture clients in this figure image capture client . In some embodiments the Image Capture Extension runs in the background of computer without an interface visible to the end user of the image capture clients . The Image Capture Extension provides an interface between the device module and the image capture client . That is in the image capture architecture illustrated Image Capture Extension acts as an intermediary between device modules and image capture clients. This relieves the developers of image capture client from having to develop their applications to work with individual devices such as camera . As described in further detail below the Image Capture Extension translates commands between the image capture client and the device module .

The image capture client of some embodiments controls user interface and other high level image viewing and image editing functions. In some embodiments the image capture client is an application provided by the same entity e.g. the operating system provider a camera manufacturer etc. that provides the Image Capture Extension . Alternatively the image capture client could be a third party application that uses application programming interfaces APIs provided by the same entity that produces the Image Capture Extension in order to interface with the Image Capture Extension . The third party application that uses these APIs might be a word processor an image viewer an image editor a spread sheet a web browser or any other type of application. The APIs enable applications produced by third parties to work with the attached devices through the Image Capture Extension . The use of APIs of some embodiments by such third party applications is illustrated in described below.

In different embodiments the device module is developed by either the producer of the image capture device with which it interfaces or by a third party programmer. In some embodiments the developers of the Image Capture Extension provide APIs to the manufacturers of image capture devices e.g. device . These manufacturers then use the APIs to develop the device modules. The APIs enable the device modules to interface with the Image Capture Extension .

As noted above the image capture client Image Capture Extension and device module are all executed as separate processes in some embodiments. Because these modules are executed as separate processes new device modules can be dynamically added to the architecture e.g. when new image storage devices are connected . The separation of the processes also allows multiple image capture clients to use the same image storage extension. Through this tiered architecture image capture clients and similar applications may access device modules and thus external devices on remote computers as is illustrated in .

The computers and are connected through a network . The network may be a local area network wide area network telephony network wireless network network of networks such as the Internet etc. As shown in computer is executing an image viewing application in addition to the modules shown in . Like the image capture client the image viewing application controls user interface and other high level image viewing and image editing functions. In different embodiments the image viewing application might be an application provided by the same entity as the Image Capture Extension or a third party application that uses the previously mentioned APIs to interface with the Image Capture Extension . Like the image capture client the image viewing application accesses the device through the Image Capture Extension .

The modules executing on the computer include an image capture client an Image Capture Extension and device modules and . These device modules and are device modules that enable the Image Capture Extension to interface with cameras and . The Image Capture Extension is the same as Image Capture Extension in some embodiments. In other embodiments the image capture extensions are different e.g. if the two computers are running different operating systems . Similarly the image capture client may be the same as the image capture client but may also be a different application. The two image capture clients might be different versions of the same application designed for operation on the two different operating systems.

The illustrated architecture enables multiple applications to simultaneously access a single device e.g. image viewing application and image capture client both accessing device in some embodiments. However some embodiments only permit one application to actually use the device e.g. send comments to the device and receive information from the device at a time though both can access the Image Capture Extension simultaneously. Furthermore the architecture also enables one application to access multiple devices simultaneously e.g. image capture client accessing devices and .

The architecture also allows an application on a first computer e.g. image viewing application on computer to access devices connected to a second different device. As illustrated in the Image Capture Extension interfaces through network with the Image Capture Extension . Through this interface the applications and on computer can directly access the devices and on the second computer. Similarly the image capture client operating on the second computer can directly access the device that is physically connected to the first computer. In some embodiments these connections can occur simultaneously that is the image viewing application could access the device while the image capture client accesses the device .

As mentioned above in some embodiments an image capture client uses calls to APIs in order to interface with an Image Capture Extension. In some embodiments the APIs enable the image capture client to access one or more frameworks that perform image capture operations e.g. image selection image importing metadata related operations etc. . In such embodiments the frameworks are accessible to clients from a variety of parties i.e. developers and that perform a variety of different functions. For example the image capture client of such embodiments could be developed by the same programmers as the frameworks or by a third party with access to the framework APIs. The client application could be an image capture application an image viewing application an image editing application an e mail application a word processing application or any other type of application whose programmers choose to access the functionality provided through the frameworks.

In some embodiments frameworks are libraries of one or more files that contain modularized functions that are accessible through calls to one or more APIs that determine the expected inputs and outputs of the modularized functions. The frameworks and their APIs allow an application to provide a GUI and other high level functionality that takes advantage of an image capture engine supplied separately.

The APIs enable a form of black box programming. The third party application acts as a front end and provides a user interface and a certain level of functionality to a user. When the user specifies e.g. through the user interface a desired interaction with an image storage device the third party application sends commands through the APIs to an image capture engine to cause the image capture engine to perform operations that control the cameras. The APIs enable applications produced by third parties as well as additional applications from the entity that produced the APIs to work with the attached devices without a need to worry about the internal mechanics of the image capture engine.

In some embodiments the image viewing application provides a GUI such as those illustrated in the previous sections. That is the image viewing application provides the user with the functionalities to select devices synchronize times etc. As shown the image viewing application includes an image capture connection module a viewer coordinator an image editor an image converter a GUI control module and a synchronization module . One of ordinary skill will recognize that these modules are not exhaustive of all the modules that might be part of such an application.

The image capture connection module sends data to and receives data from the Image Capture Core framework and Image Kit framework . That is the image capture connection module provides the communication with the image capture engine of some embodiments for the image viewing application . The viewer coordinator manages the processes of the image viewing application in some embodiments and provides communication between the different modules. The image editor receives directives from a user to modify images e.g. to resize crop filter etc. the images and performs these actions to modify the actual image files. In some embodiments the image editor is itself made up of numerous different modules each for performing a specific image editing function. The image converter handles the conversion of image files from one format to another. The GUI control module handles the provision of the GUI including modifications due to user interaction e.g. changing a map icon to a list icon providing camera controls when a camera is selected etc. .

The synchronization module handles the synchronization of an image capture device s internal clock with the clock of the computer. The synchronization module of some embodiments performs the difference calculation to identify a time difference and issues the initial commands to modify the metadata and the device clock. As described below the modifications to the timestamps on the device and the device clock must go through the image capture engine. In some embodiments the synchronization module is part of the image editor .

The frameworks and receive commands that are formatted as calls to APIs and from the image viewing application and perform the operations dictated by those commands. In some embodiments the Image Capture Core framework handles commands that involve communication with the image capture devices and provides information about and from the image capture devices to the image viewing application . That is the frame The APIs provide an interface through which the image capture connection module can make calls to the Image Capture Core framework in order to request such information and have tasks related to such information performed. As shown in in some embodiments the Image Capture Core framework communicates with the Image Capture Extension .

In some embodiments the Image Capture Core framework also provides a communication path that allows framework to communicate with Image Capture Extension . The Image Kit framework handles commands that supply prearranged layouts i.e. predefined GUI areas for placement in the GUI of the image viewing application . In some embodiments the prearranged layouts include graphical elements and predefined interfaces to allow the placement of data from the Image Capture Core framework in the prearranged layout. For example a prearranged layout might include a GUI display area for displaying image capture devices and interfaces that place icons in the display area e.g. icons representing cameras identified through the Image Capture Core framework . These GUI areas and functions associated with them are accessed by the image capture connection module through calls to the APIs . Image storage stores image data received from cameras. In some embodiments this data is used to populate the GUI areas supplied by Image Kit framework . In some embodiments a call to an API of framework or can result in further calls from framework or to APIs in the other of the two frameworks or to Image Capture Extension .

The operations of an import data API will now be described by reference to the modules shown in . Some embodiments provide an API for metadata adjusting and image importing operations described in sections I III. When a user directs the image viewing application to import data from an image capture device e.g. by clicking on an item in the GUI provided by GUI control module a chain of commands passes through the various modules. Specifically in some embodiments a command in some embodiments using a command format unique to the image viewing application passes from 1 the GUI control module to 2 the viewer coordinator to 3 the image capture connection module . The image capture connection module then uses a call to an import API to command the Image Kit framework to import the selected image s .

The Image Kit framework using a command format of the image capture engine passes the command to import images along another chain. The command is passed to 1 the Image Capture Core framework to 2 the Image Capture Extension to 3 the device module and finally to 4 the camera . The camera then sends the image file and or metadata to 1 the device module to 2 the Image Capture Extension to 3 the Image Capture Core framework to 4 the Image Kit framework to 5 the image storage . The Image Kit framework then sends the imported image and or metadata about the imported image e.g. a thumbnail location information timestamps etc. to the image capture connection module as a return of the API call. The image capture connection module passes the data to the viewer coordinator which passes the image file on to the appropriate module of the image viewing application . For example the image file can be passed to the image converter to be saved and or converted to a specified format. Alternatively the data can be passed to an image editor so that the user can edit the imported image before saving it with the image converter . In some embodiments the Image Kit framework does not save the image to an image storage and the image is instead stored elsewhere and or by other modules.

The APIs allow the image viewing application to command the camera without having any information about any of the modules further down the chain. Similarly some embodiments supply other APIs that the image viewing application can use to command the image capture engine to perform various operations. One of ordinary skill in the art will realize that the modules are one example of a set of modules of an application that uses the APIs of some embodiments. Furthermore one of ordinary skill in the art will realize that other applications with fewer more or different modules than modules still remain within the scope of the present invention.

Some embodiments provide an API or a set of APIs that commands the Image Kit framework to supply the GUI control module with a camera control area. Some embodiments provide an API that commands the Image Kit framework to supply the GUI control module with a single window that simultaneously displays a device selection area and a camera control area. Some embodiments provide an API that commands the Image Kit framework to supply the GUI control module with a single window that simultaneously displays a device selection area a camera control area and a scan display area.

Some embodiments provide an API that commands the Image Capture Core framework to connect to cameras and retrieve information about the cameras. In some embodiments the API deals with or represents a connected image capture camera. The API allows an application to receive identifications of camera properties e.g. capability to delete images ability to synchronize clocks ability to take pictures . In some embodiments such an API also allows an application to retrieve the content of a camera. The API of some embodiments allows an application to get names of items stored on the camera. The API of some embodiments talks to the device extension and carries the names of folders and files on the camera to other modules.

As shown the process begins by defining at a first display area for displaying a menu of image capture devices such as the device display area of . Next the process defines at a second display area for displaying image capture device controls such as camera control area . The process then defines at a third display area for displaying image file metadata. An example of such a display area is image display area .

Next the process defines at rules and processes for populating the first display area with representations of detected image capture devices and defines at rules and processes for retrieving metadata associated with image files from image capture and storage devices. In some embodiments these rules and processes include calls to one or more image capture APIs such as APIs and of .

The process then defines at a synchronization tool and GUI item for activating the tool. An example of such a GUI item is item . The process then defines at GUI controls for opening a map of an area around image location metadata such as the GUI item . The process then defines at rules and processes for indicating whether an image file has been imported to a computer. The process is an example of such a process.

The process then stores at the defined image capture application i.e. the defined modules and or APIs modules GUI items etc. on a computer readable storage medium. In some embodiments the medium is one or more of a solid state device a hard disk a CD ROM or other non volatile computer readable storage medium.

One of ordinary skill in the art will recognize that the various elements defined by process are not exhaustive of the modules rules processes and GUI items that could be defined and stored on a computer readable storage medium for an image capture application incorporating some embodiments of the invention. In addition the process is a conceptual process and the actual implementations may vary. For example different embodiments may define the various elements in a different order may define several elements in one operation may decompose the definition of a single element into multiple operations etc. In addition the process may be implemented as several sub processes or combined with other operations within a macro process.

One of ordinary skill in the art will realize that although the features of various embodiments are described separately some embodiments may combine multiple features in the same embodiment. For example some embodiments provide both synchronization tools and checkmark indicators of imported images other embodiments provide synchronization tools and geographical plotting tools etc.

Many of the above described features and applications are implemented as software processes that are specified as a set of instructions recorded on a computer readable storage medium also referred to as computer readable medium . When these instructions are executed by one or more processing unit s e.g. one or more processors cores of processors or other processing units they cause the processing unit s to perform the actions indicated in the instructions. Examples of computer readable media include but are not limited to CD ROMs flash drives RAM chips hard drives EPROMs etc. The computer readable media does not include carrier waves and electronic signals passing wirelessly or over wired connections.

In this specification the term software is meant to include firmware residing in read only memory or applications stored in magnetic storage which can be read into memory for processing by a processor. Also in some embodiments multiple software inventions can be implemented as sub parts of a larger program while remaining distinct software inventions. In some embodiments multiple software inventions can also be implemented as separate programs. Finally any combination of separate programs that together implement a software invention described here is within the scope of the invention. In some embodiments the software programs when installed to operate on one or more electronic systems define one or more specific machine implementations that execute and perform the operations of the software programs.

The bus collectively represents all system peripheral and chipset buses that communicatively connect the numerous internal devices of the electronic system . For instance the bus communicatively connects the processing unit s with the read only memory the GPU the system memory and the permanent storage device .

From these various memory units the processing unit s retrieve instructions to execute and data to process in order to execute the processes of the invention. The processing unit s may be a single processor or a multi core processor in different embodiments. Some instructions are passed to and executed by the GPU . The GPU can offload various computations or complement the image processing provided by the processing unit s . In some embodiments such functionality can be provided using Corelmage s kernel shading language.

The read only memory ROM stores static data and instructions that are needed by the processing unit s and other modules of the electronic system. The permanent storage device on the other hand is a read and write memory device. This device is a non volatile memory unit that stores instructions and data even when the electronic system is off. Some embodiments of the invention use a mass storage device such as a magnetic or optical disk and its corresponding disk drive as the permanent storage device .

Other embodiments use a removable storage device such as a floppy disk flash drive or ZIP disk and its corresponding disk drive as the permanent storage device. Like the permanent storage device the system memory is a read and write memory device. However unlike storage device the system memory is a volatile read and write memory such a random access memory. The system memory stores some of the instructions and data that the processor needs at runtime. In some embodiments the invention s processes are stored in the system memory the permanent storage device and or the read only memory . For example the various memory units include instructions for processing multimedia items in accordance with some embodiments. From these various memory units the processing unit s retrieve instructions to execute and data to process in order to execute the processes of some embodiments.

The bus also connects to the input and output devices and . The input devices enable the user to communicate information and select commands to the electronic system. The input devices include alphanumeric keyboards and pointing devices also called cursor control devices . The output devices display images generated by the electronic system. The output devices include printers and display devices such as cathode ray tubes CRT or liquid crystal displays LCD . Some embodiments include devices such as a touchscreen that function as both input and output devices.

Finally as shown in bus also couples electronic system to a network through a network adapter not shown . In this manner the computer can be a part of a network of computers such as a local area network LAN a wide area network WAN or an Intranet or a network of networks such as the internet. Any or all components of electronic system may be used in conjunction with the invention.

Some embodiments include electronic components such as microprocessors storage and memory that store computer program instructions in a machine readable or computer readable medium alternatively referred to as computer readable storage media machine readable media or machine readable storage media . Some examples of such computer readable media include RAM ROM read only compact discs CD ROM recordable compact discs CD R rewritable compact discs CD RW read only digital versatile discs e.g. DVD ROM dual layer DVD ROM a variety of recordable rewritable DVDs e.g. DVD RAM DVD RW DVD RW etc. flash memory e.g. SD cards mini SD cards micro SD cards etc. magnetic and or solid state hard drives read only and recordable Blu Ray discs ultra density optical discs any other optical or magnetic media and floppy disks. The computer readable media may store a computer program that is executable by at least one processing unit and includes sets of instructions for performing various operations. Examples of computer programs or computer code include machine code such as is produced by a compiler and files including higher level code that are executed by a computer an electronic component or a microprocessor using an interpreter.

While the above discussion primarily refers to processors e.g. single processors or multi core processors that execute software some embodiments are performed by one or more integrated circuits such as application specific integrated circuits ASICs or field programmable gate arrays FPGAs . In some embodiments such integrated circuits execute instructions that are stored on the circuit itself.

As used in this specification and any claims of this application the terms computer server processor and memory all refer to electronic or other technological devices. These terms exclude people or groups of people. For the purposes of the specification the terms display or displaying means displaying on an electronic device. As used in this specification and any claims of this application the terms computer readable medium and computer readable media are entirely restricted to tangible physical objects that store information in a form that is readable by a computer. These terms exclude any wireless signals wired download signals and any other ephemeral signals.

While the invention has been described with reference to numerous specific details one of ordinary skill in the art will recognize that the invention can be embodied in other specific forms without departing from the spirit of the invention. For instance although the GUIs illustrated herein are shown with particular areas displaying particular features of the image capture application one of ordinary skill in the art will recognize that the various display areas and controls may be provided differently in different embodiments. Furthermore controls may be displayed in different locations of a display area window or screen when different devices are selected. For example some embodiments display scanner controls on the right side of a GUI when a scanner is selected but display camera controls across the bottom of the GUI when a camera is selected.

In some instances of the discussion herein displays of data are referred to as the data itself. For instance the actual timestamp of an image file is a stored set of data while the GUI displays a representation of that timestamp data as a date and time in a standard human readable format. One of ordinary skill in the art will recognize that modifying the timestamp refers in fact to both the modification of the display of the timestamp and the modification of the stored data as well.

In addition a number of the figures including and conceptually illustrate processes. The specific operations of these processes may not be performed in the exact order shown and described. The specific operations may not be performed in one continuous series of operations and different specific operations may be performed in different embodiments. Furthermore the process could be implemented using several sub processes or as part of a larger macro process.

