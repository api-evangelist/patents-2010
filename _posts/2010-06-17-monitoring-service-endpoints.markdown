---

title: Monitoring service endpoints
abstract: Today, data networks are ever increasing in size and complexity. For example, a datacenter may comprise hundreds of thousands of service endpoints configured to perform work. To reduce network wide degradation, a load balancer may send work requests to healthy service endpoints, as opposed to unhealthy and/or inoperative service endpoints. Accordingly, among other things, one or more systems and/or techniques for monitoring service endpoints, which may be scalable for large scale networks, are provided. In particular, a consistent hash function may be performed to generate a monitoring scheme comprising assignments of service endpoints to monitoring groups. In this way, multiple monitoring components may monitor a subset of endpoints to ascertain health status. Additionally, the monitoring components may communicate between one another so that a monitoring component may know heath statuses of service endpoints both assigned and not assigned to the monitoring component.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08225131&OS=08225131&RS=08225131
owner: Microsoft Corporation
number: 08225131
owner_city: Redmond
owner_country: US
publication_date: 20100617
---
Today many networks are becoming larger and more complex. For example some datacenters may comprise over a hundred thousand machines configured to accomplish work tasks under the direction of load balancers. In order to efficiently manage the large number of service endpoints monitors may be employed to monitor service endpoints for communication and system health. It may be advantageous to monitor the health of service endpoints so that a load balancer may utilize healthy service endpoints as opposed to unhealthy service endpoints. Otherwise severe network wide degradation may result when non functional service endpoints are utilized.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

Among other things one or more systems and or techniques for monitoring service endpoints are disclosed herein. In particular a consistent hash function may be performed upon identifiers of service endpoints e.g. ip address port number of a service endpoint machine to generate a monitoring scheme. It is to be appreciated that while a hash function or a consistent hash function is at times mentioned herein for generating a monitoring scheme a variety of functions and or algorithms are contemplated for generating a monitoring scheme. Accordingly a hash function e.g. as used herein may comprise any suitable mechanism technique function algorithm etc. for generating a monitoring scheme. The monitoring scheme may comprise an assignment of service endpoints to monitoring groups. In one example service endpoints may be assigned to merely a single monitoring group within the monitoring scheme e.g. assignment may be made so that there is no overlap of monitoring . Alternatively one or more service endpoints may be assigned to more than one monitoring group. It may be appreciated that a monitoring group may comprise one or more monitoring nodes. A monitoring node of a monitoring group may be configured to monitor service endpoints assigned to the monitoring group. In one example a monitoring group may comprise a monitoring node and a monitoring node . The monitoring group may be assigned to monitor service endpoint B service endpoint C and service endpoint G . The monitoring node may monitor service endpoints B C and G and monitoring node may also monitor service endpoints B C and G . The overlap in monitoring may increase monitoring reliability in the event a monitoring node fails.

A monitoring group may be configured to receive status information of monitored service endpoints from monitoring nodes within the monitoring group e.g. a health status relating to the operability and current state of a service endpoint . The status may comprise a binary measurement e.g. healthy or unhealthy and or scaled measurements e.g. 0 to 100 regarding the status of service endpoints. Scaled measurements may for example enable complex scenarios such as taking a system offline and or the implementation of complex algorithms to increase efficiency of load balancing requests amongst service endpoints. The monitoring group may maintain health status data for service endpoints e.g. status information returned by monitoring nodes regarding service endpoints assigned to the monitoring group status changes received from other monitoring groups regarding service endpoints assigned to other monitoring groups etc. . In this way a snap shot of the entire endpoint network s health may be stored by respective monitoring groups. Since in an example embodiment health status data for a set of service endpoints is stored in multiple monitoring groups when one of those monitoring groups fails health status data for the set of service endpoints stored in one or more of the other monitoring groups may be used for reassignment. That is other monitoring groups may be reassigned to monitor the set of service endpoints previously monitored by the failed monitoring group using the stored health status data.

Monitoring groups may be configured to communicate with one another regarding status changes. It may be appreciated that in an example embodiment monitoring groups may communicate status changes as opposed to unchanged status information to reduce network traffic. Thus if a status changes then a monitoring group may communicate the change to other monitoring groups otherwise few to no communications occur to reduce traffic. Additionally a monitoring group may communicate a status change of a service endpoint monitored by a different monitoring group. For example a first monitoring group may determine that a service endpoint has changed from healthy to unhealthy. The first monitoring group may send a communication to a second monitoring group about the change in status from healthy to unhealthy. The second monitoring group which doesn t monitor the service endpoint may send a communication about the status change to a third monitoring group. In this way status changes may be propagated amongst monitoring groups. Additionally monitoring groups may communicate status changes to distributed clients not within monitoring groups.

It may be appreciated that monitoring groups may fail e.g. due to a network failure a hardware failure a software failure etc. . If a failed monitoring group is determined then service endpoints assigned to the failed monitoring group within the monitoring scheme may be redistributed reassigned to one or more monitoring groups different from the failed monitoring group.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are illustrated in block diagram form in order to facilitate describing the claimed subject matter.

Today many computing networks are implemented on a large scale. For example a computing network may comprise hundreds of thousands of service endpoints configured to accomplish work tasks delegated by load balancers. It may be advantageous for such load balancers to delegate work tasks to healthy service endpoints as opposed to unhealthy service endpoints that may be unfit to perform work tasks. For example an unhealthy service endpoint may comprise a service endpoint with a hardware or software failure or a service endpoint having inadequate resources such as available memory or processor cycles to complete current tasks etc. A healthy endpoint may comprise a service endpoint with available resources sufficient to perform current and or future tasks. Monitors may be implemented to monitor communication and health status of service endpoints. Current monitoring techniques may employ a single monitoring component that monitors all service endpoints. Unfortunately a single monitoring component may not scale well for large scale computing networks. For example a single monitoring component may be unable to manage hundreds of thousands of monitoring nodes.

Accordingly among other things one or more systems and or techniques for monitoring service endpoints are provided herein. In particular multiple monitoring groups may be assigned to monitor a subset of service endpoints to ascertain store and or share service endpoint status data. A monitoring group may monitor assigned service endpoints using one or more monitoring nodes. Status changes e.g. a previous health status of 10 may change to a health status of 50 may be communicated amongst monitoring groups so that a monitoring group may comprise health status data representing not only service endpoints monitored by the monitoring group but also one or more service endpoints monitored by other monitoring groups. The assignment of service endpoints to monitoring groups may be accomplished through a consistent hashing scheme used to generate a monitoring scheme comprising assignments of service endpoints to monitoring groups.

One embodiment of monitoring service endpoints is illustrated by an exemplary method in . At the method starts. At a hash function may be performed upon identifiers of service endpoints e.g. an IP address and or port number to generate a monitoring scheme e.g. monitoring scheme of comprising assignment of service endpoints to monitoring groups. For example a consistent hash function may be used to generate the monitoring scheme. The consistent hash function may provide hash table functionality where a change in nodes e.g. service endpoints and or monitoring groups may not result in significant remapping of service endpoints to monitoring groups. Thus if a monitoring group fails then service endpoints may be reassigned with minimal reassignments as opposed to a traditional hash that may require extensive reassignment of service endpoints to monitoring groups. In one example the monitoring scheme may comprise an assignment such that respective service endpoints are assigned to merely a single monitoring group within the monitoring scheme to inhibit duplicate monitoring by different monitoring groups. A monitoring group may comprise one or more monitoring nodes. In one example a monitoring node of a monitoring group may be configured to monitor one or more service endpoints assigned to the monitoring group. In another example a monitoring node of a monitoring group may be configured to monitor all service endpoints assigned to the monitoring group. Monitoring nodes within a monitoring group may be configured to monitor the same or different service endpoints assigned to a monitoring group e.g. monitoring node and monitoring node may monitor the same service endpoints A C and D to provide redundancy and error checking or different service endpoints to conserve resources .

It may be appreciated that hundreds of thousands of service endpoints may be monitored based upon the monitoring scheme. Additionally the number of monitoring groups and or monitoring nodes comprised therein may be scaled accordingly.

In one example a first monitoring group may be assigned to monitor a first service endpoint. The first monitoring group may comprise a first monitoring node and a second monitoring node. A second monitoring group may be assigned to monitor a second service endpoint. A third monitoring group may be assigned to monitor a third service endpoint and a fourth service endpoint. A monitoring group may be configured to receive status data regarding monitored service endpoints from monitoring nodes within the monitoring groups e.g. a binary measurement of healthy or unhealthy or a scaled measurement of 1 100 etc. . Monitoring groups may send status data to distributed clients external to the monitoring groups. For example the first monitoring group may send a communication to a distributed client not within a monitoring group the communication may indicate a health status change of the first service endpoint monitored by the first monitoring group based upon the monitoring scheme.

The first monitoring group may receive a first status of the first service endpoint from the first monitoring node. The first monitoring group may receive a second status of the first service endpoint from the second monitoring node. The first status and or second status may be used to store health status data. For example the first status may indicate that the first service endpoint has a current health rating between 70 and 80 and the second status may indicate that the first service endpoint has a current health rating between 75 and 80. In one example health status data indicating the first monitoring node determined the first service endpoint has a current health rating between 70 and 80 and the second monitoring node determined the first service endpoint has a current health rating between 75 and 80 may be stored. In another example health status data indicating that the first service endpoint has a health rating around 70 to 80 may be stored. It may be appreciated that health status data may be stored in a variety of formats.

The first monitoring group may be configured to resolve inconsistencies between the first status and the second status if the first status is different from the second status. It may be appreciated that a variety of techniques may be used to resolve inconsistencies. For example the first service endpoint may be marked as unhealthy if one or more statuses indicate the first service endpoint is unhealthy.

Monitoring groups may communicate with one another regarding status changes. In one example the first monitoring group may send a communication to the second monitoring group indicative of a status change of a service endpoint monitored by the first monitoring group based upon the monitoring scheme e.g. the first service endpoint may have had a status of 80 which may have changed after the first monitoring node and or second monitoring node returned a status of 10 . In this way both the first monitoring group and the second monitoring group may know the status of the first service endpoint even though the first service endpoint may not be monitored by the second monitoring group.

In another example the first monitoring group may receive a communication from the second monitoring group the communication may be indicative of a status change of the second service endpoint monitored by the second monitoring group based upon the monitoring scheme e.g. second service endpoint may have had a status of unhealthy which may have changed after one or more monitoring nodes within the second monitoring group returned a status of healthy . Additionally the first monitoring component may send a communication to the third monitoring group indicative of the status change of the second service endpoint monitored by the second monitoring group based upon the monitoring scheme e.g. upon the first monitoring group receiving the status change communication from the second monitoring group the first monitoring group may notify the third monitoring group of the status change detected by the second monitoring group . In this way the second monitoring group the first monitoring group and the third monitoring group may know the status of the second service endpoint even though the second service endpoint may not be monitored by the first monitoring group and or the third monitoring group.

To recover from a monitoring group failure a failed monitoring group may be determined. The failed monitoring group may have been assigned within the monitoring scheme to monitor one or more service endpoints. It may be appreciated that other monitoring groups may have status data regarding the one or more service endpoints because of intercommunication of status changes between monitoring groups e.g. the failed monitoring group may have sent communications regarding status changes to other monitoring groups before failure . The status data may be utilized in redistributing the one or more service endpoints previously assigned to the failed monitoring group within the monitoring scheme to one or more monitoring groups different from the failed monitoring group e.g. see for an example of redistributing service endpoints of a failed monitoring group . In this way reassigned monitoring groups may use the status data of the redistributed service endpoints to resume monitoring. At the method ends.

In one example a first monitoring group may be assigned to monitor one or more service endpoints. The first monitoring group may comprise a first monitoring node configured to monitor the one or more service endpoints assigned to the first monitoring group within the monitoring scheme . The first monitoring group may comprise a second monitoring node configured to monitor the one or more service endpoints assigned to the first monitoring group within the monitoring scheme . The first monitoring group may be configured to receive status data from the first monitoring node and or the second monitoring node regarding the one or more service endpoints. For example the first monitoring group may receive a first status of a first service endpoint e.g. a service endpoint assigned to the first monitoring group within the monitoring scheme from the first monitoring node. The first monitoring group may receive a second status of the first service endpoint from the second monitoring node. It may be appreciated that the first monitoring group may store status data regarding the first and or second status. The first monitoring group may be configured to determine whether the first status and the second status are different. If the first status and the second status are different then the first monitoring group may resolve inconsistencies between the first status and the second status e.g. a health status for the service endpoint may be determined as an average value of the first and second status if at least one status is unhealthy then the service endpoint may be marked as unhealthy etc. .

Monitoring groups may be configured to communicate status changes with one another. For example a first monitoring group may be configured to send a communication to a second monitoring group the communication may be indicative of a status change of a first service endpoint monitored by the first monitoring group based upon the monitoring scheme . The second monitoring group may be configured to send a communication to a third monitoring group the communication may be indicative of the status change of the first service endpoint monitored by the first monitoring group based upon the monitoring scheme . In this way the first monitoring group the second monitoring group and the third monitoring group may know the status of the first service endpoint even though the first service endpoint may not be monitored by the second monitoring group and or the third monitoring group as per the monitoring scheme .

It may be appreciated that monitoring groups may fail. A failed monitoring group may have one or more service endpoints assigned to the failed monitoring group based upon the monitoring scheme . The grouping component may be configured to redistribute one or more service endpoints previously assigned to the failed monitoring group within the monitoring scheme to one or more monitoring groups different from the failed monitoring group. The redistribution may mitigate monitoring downtime caused by the failed monitoring group and may be based upon intercommunication of status changes between monitoring groups for example e.g. see for an example of redistributing service endpoints of a failed monitoring group .

The monitoring scheme may be generated by traversing the circle structure clockwise and assigning a service endpoint to a first occurring monitoring group. For example service endpoints A B and C may be assigned to monitoring group within the monitoring scheme because monitoring group at point may be the first occurring monitoring group encountered when traveling clockwise from the service endpoints A B and C respectively. Service endpoints D and E may be assigned to monitoring group within the monitoring scheme because monitoring group at point may be the first occurring monitoring group encountered when traveling clockwise from service endpoints D and E respectively. Service endpoints F and G may be assigned to monitoring group within the monitoring scheme because monitoring group at point may be the first occurring monitoring group encountered when traveling clockwise from service endpoints F and G respectively.

Service endpoint H may be assigned to monitoring group within the monitoring scheme because monitoring group at point may be the first occurring monitoring group encountered when traveling clockwise from service endpoint H. Service endpoints I and J may be assigned to monitoring group within the monitoring scheme because monitoring group at point may be the first occurring monitoring group encountered when traveling clockwise from service endpoints I and J respectively. Service endpoints K and L may be assigned to monitoring group within the monitoring scheme because monitoring group at point may be the first occurring monitoring group encountered when traveling clockwise from service endpoints K and L respectively. In this way the monitoring scheme may be generated based upon the consistent hash function.

It may be determined that monitoring group is a failed monitoring group e.g. monitoring group may have had a hardware failure . For example service endpoints A B C I and J which were previously monitored by failed monitoring group may now be unmonitored due to the failure. Thus the service endpoints A B C I and J previously assigned to the failed monitoring group may be redistributed reassigned to one or more monitoring groups different from the failed monitoring group . In this way the monitoring scheme may be updated to reflect the redistribution.

It may be appreciated that a circle structure is merely provided to illustrate how a consistent hash function may redistribute service endpoints to monitoring groups but this is not meant to be limiting. In one example a consistent hash function may be performed to redistribute service endpoints A B C I and J which were previously assigned to the failed monitoring group e.g. A B C were assigned to failed monitoring group at point and I and J were assigned to failed monitoring group at point . Because the failed monitoring group may be unable to monitor service endpoints the failed monitoring group may be removed from point and point on the circle.

The service endpoints A B C I and J previously assigned to failed monitoring group may be reassigned by traversing the circle structure clockwise and assigning respective service endpoints to first occurring monitoring groups. For example service endpoints A B and C may be assigned to monitoring group within the monitoring scheme because monitoring group at point may be the first occurring monitoring group encountered when traveling clockwise from service endpoints A B and C respectively. Service endpoints I and J may be assigned to monitoring group within the monitoring scheme because monitoring group at point may be the first occurring monitoring group encountered when traveling clockwise from service endpoints I and J respectively. In this way the monitoring scheme may be updated as illustrated in example where service endpoints F G I J K and L are assigned to monitoring group and service endpoints A B C D E and H are assigned to monitoring group . It may be appreciated that the redistribution of service endpoints assigned to failed monitoring groups may not alter assignments or mappings of service endpoints to monitoring groups that have not failed which may be accomplished based upon the use of a consistent hash algorithm for example where different results may be obtained should different algorithms be implemented.

Monitoring group may comprise monitoring node monitoring node and or monitoring node which may be configured to monitor statuses of service endpoints A B and C. The monitoring group may store status data returned from monitoring node monitoring node and or monitoring node as health status data . The monitoring group may resolve inconsistencies between statuses returned by the monitoring nodes and or . It may be appreciated that different monitoring nodes within a monitoring group may monitor the same service endpoints as illustrated to provide among other things redundancy and or may monitor different service endpoints to conserve resources. Also one or more service endpoints may merely be monitored by one monitoring group e.g. no overlap between monitoring groups or may be monitored by more than one monitoring group e.g. overlap between monitoring groups .

The monitoring groups may be configured to communicate with one another and or distributed clients. In one example monitoring group may receive status data from monitoring node that service endpoint C has gone from a healthy state to an unhealthy state. The monitoring group may store the status data within the health status data . The monitoring group may send a communication status change to monitoring group regarding the change in health status. Monitoring group may store the change in health status of service endpoint C within the health status data . In this way monitoring group and monitoring group may know the current health state of service endpoint C . It may be appreciated that similar communications may occur as a result of status changes so that respective monitoring groups e.g. and other monitoring groups not shown are aware of the status of different service endpoints being monitored potentially providing a global status awareness all service endpoints over time. Similarly this information can be propagated to distributed clients. Additionally monitoring group may send a communication status change to distributed client regarding the change in health status of service endpoint C . It may be appreciated that action may be taken based upon health status data. For example a load balancer may adjust the distribution of work requests based upon health of service endpoints.

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to implement one or more of the techniques presented herein. An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable medium e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions configured to operate according to one or more of the principles set forth herein. In one such embodiment the processor executable computer instructions may be configured to perform a method such as the exemplary method of for example. In another such embodiment the processor executable instructions may be configured to implement a system such as the exemplary system of for example. Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB firewire IEEE 1374 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via a network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

