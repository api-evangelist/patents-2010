---

title: Method and system for generating a collaboration timeline illustrating application artifacts in context
abstract: A method and apparatus for generating a collaboration timeline which illustrates application artifacts in context. A collaboration session includes a plurality of participants. Each participant collaborates via a corresponding processing device. Media streams associated with the plurality of participants are received during the collaboration session and a collaboration media stream based on the media streams is generated. A collaboration application generates an artifact during the collaboration session. A timeline entry is generated in a collaboration timeline, the timeline entry including time information identifying a time associated with the artifact, and a reference to the artifact.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08868657&OS=08868657&RS=08868657
owner: Avaya Inc.
number: 08868657
owner_city: Basking Ridge
owner_country: US
publication_date: 20101217
---
Embodiments disclosed herein relate generally to collaboration environments and in particular to generating a collaboration timeline that identifies artifacts generated during a collaboration session.

Increasingly sophisticated application programs are being developed that can greatly enhance the productivity of a collaboration session. Such application programs typically execute on a processing device such as a computer or smartphone that is involved in the collaboration session and enable program application functionality that is useful for a topic of the call.

As an example a group of executives may participate in a conference call to discuss potential future financial numbers for a business. Each of the participants may have a processing device such as a computer that is also used by the respective participant in the collaboration session. A spreadsheet collaboration application may be executed which is capable of receiving input from at least two of the participants and updating a spreadsheet in response thereto. One or more of the participants manipulates the spreadsheet which may be concurrently viewed by all of the participants by entering or modifying numbers in various what if scenarios to see potential revenue outcomes. The output such as a display of data from such collaboration applications may be referred to as an artifact. Because each of the participants views the artifacts of the spreadsheet collaboration application in real time as if all of the participants were in the same geographical location these types of collaboration applications can result in significant productivity and be the basis of important decisions.

One potential problem that arises during such collaboration sessions however is that the underlying basis of a decision made during the collaboration session may not be readily determinable at a later date. In other words referring again to the example above three months after the collaboration session an executive may recall that he agreed to a certain course of action during the collaboration session but the exact reasons that led him to agree may have been forgotten. While audio recording devices exist that enable a collaboration session to be recorded in an audio file the audio file is simply an audio track of the entire call. Trying to find the relevant three or four minutes of dialog associated with a particular portion of the collaboration session can be time consuming and frustrating. Moreover the artifacts generated by a collaboration application during a collaboration session and viewed by the participants are not captured in an audio recording. For example if during the above example a participant entered a particularly compelling scenario into the spreadsheet application which after being displayed on the participants display devices persuaded the participants to follow a particular course of action that particular artifact i.e. the particular display output that convinced the participants to follow the particular course of action may be quite important but will not exist in an audio recording of the collaboration session.

Accordingly there is a need for a collaboration timeline that identifies artifacts generated by collaboration applications during a collaboration session and facilitates subsequent identification of such artifacts and the pertinent discussions surrounding the generation of the artifacts.

Embodiments disclosed herein relate to the generation of a collaboration timeline that identifies artifacts generated by a collaboration application during a collaboration session. In one embodiment a plurality of participants participates in a collaboration session such as a conference call. Each of the participants has at least one associated processing device. The processing device can generate and continuously transmit a media stream generated by the respective participant to a source such as a media server and can receive a media stream that includes the media streams of the other participants.

During the collaboration session the media server forms a collaboration media stream based on the participants media streams. The collaboration media stream includes a media stream time index. The media server determines that a collaboration application has been initiated during the collaboration session. The collaboration application is capable of receiving input from a plurality of the participants and is capable of generating or otherwise rendering an artifact in response to participant input. The media server determines that the collaboration application has generated an artifact during the collaboration session and captures the artifact. A timeline entry including time information identifying a time associated with the artifact and a reference to the artifact is generated in a collaboration timeline.

The timeline entry may include descriptive indicia identifying the artifact such as by collaboration application name and an ordinal identifying the particular artifact of a number of artifacts generated by the respective collaboration application during the collaboration session. The media server may generate a number of timeline entries each of which corresponds to a different artifact generated during the collaboration session by one or more collaboration applications.

In one embodiment the media server determines that the collaboration application has generated the artifact via an application programming interface API that is called by the collaboration application when the collaboration application generates the artifact. The collaboration application also provides the media server with the artifact or with a reference to the artifact. The artifact may be stored in the collaboration timeline in association with the timeline entry or may be stored in a storage that is separate from the collaboration timeline and a link to the artifact may be stored in the collaboration timeline that identifies the location of the artifact.

In one embodiment where the media stream contains audio the media server generates a phonetic index of the collaboration media stream in conjunction with the collaboration media stream. The phonetic index contains phonemes of words spoken during time segments of the collaboration session. The phonetic index enables subsequent searching of the collaboration media stream based on words that may have been spoken during the collaboration session.

A collaboration timeline player may be used to subsequently obtain information from a collaboration timeline. The timeline player accesses the collaboration timeline and the collaboration media stream that corresponds to the collaboration timeline. The timeline player receives a user selection of a particular timeline entry of a plurality of timeline entries contained in the collaboration timeline. The timeline player obtains the artifact associated with the particular timeline entry and renders the artifact on a playback device. The timeline player also determines a begin location within the collaboration media stream based on the particular timeline entry. The timeline player begins rendering the media from the collaboration timeline at the begin location concurrently with the rendering of the particular artifact. A user of the timeline player is thus able to perceive the artifact while concurrently perceiving the context of the collaboration relating to the generation of the artifact.

Those skilled in the art will appreciate the scope of the present disclosure and realize additional aspects thereof after reading the following detailed description of the preferred embodiments in association with the accompanying drawing figures.

The embodiments set forth below represent the necessary information to enable those skilled in the art to practice the embodiments and illustrate the best mode of practicing the embodiments. Upon reading the following description in light of the accompanying drawing figures those skilled in the art will understand the concepts of the disclosure and will recognize applications of these concepts not particularly addressed herein. It should be understood that these concepts and applications fall within the scope of the disclosure and the accompanying claims.

Embodiments disclosed herein relate to a collaboration session in which a number of participants collaborate with one another such as a conference call. A collaboration session refers to a real time information exchange between participants wherein the real time information is exchanged without the need for separate and repeated message initiation triggering by a user such as is needed for email exchanges IM exchanges and the like. Examples of such real time information exchanges include a voice call such as a telephone conference because each piece of information is exchanged automatically as it is spoken by a participant and does not require a separate message initiation trigger such as sending an email. Another example is a video conference either with or without audio since the video information itself may comprise a real time information exchange between participants in a video call.

The participants engage in an information exchange during the collaboration session and also have associated processing devices that are communicatively coupled to one another via a network. A collaboration application refers to an application that can receive input from a plurality of the participants in the collaboration session and based on such input render an artifact to at least one of such participants. Preferably the collaboration application can receive input from all the participants in the collaboration session and renders an artifact to all participants. An artifact refers to an output of the collaboration application that is generated during the collaboration session in response to input by one or more participants. The output could be visual such as an image displayed on a display audible such as audio information played on an audio device such as a headset or both. Thus the artifact could comprise an image rendered on an output device a segment of audio or any other output perceivable by a participant in the collaboration session.

In one embodiment the communication device is a device capable of sending and receiving voice signals and is capable of executing a collaboration application as further described below. The communication device may comprise for example a computer a personal digital assistant PDA a mobile phone such as an Apple iPhone or the like.

While for purposes of illustration embodiments are described herein in the context of a single communication device that is capable of both audio processing and collaboration application functionality the embodiments are not limited to the use of a single processing device. One or more of the participants may participate in the collaboration session with multiple processing devices one of which e.g. a telephone handles and otherwise processes the audio aspects of the collaboration session and another of which e.g. a computer handles the collaboration application aspects of the collaboration session. In particular a participant may use a conventional telephone to dial into a particular conference bridge and may also direct a program on a computer such as a web browser program to a particular location such as a particular website in order to communicatively couple the computer to the collaboration session. Of course the communication device may also comprise a single processing device such as a computer with a microphone and headset or a smartphone such that both the audio aspects and the collaboration application aspects of the embodiments described herein are handled by a single processing device.

The communication devices are communicatively coupled to the media server and to one another via one or more networks . While only a single network is illustrated in it will be appreciated that communications may travel over multiple networks such as a private local area network LAN in a participant s house a public access network an enterprise network and so on between the processing devices. The communication devices A D may connect to the network via any suitable network access paths such as for example telephony technology digital subscriber line technology cable modem technology cellular technology Wi Fi Bluetooth or the like. Data such as control signals audio signals and the like are typically carried over a network access path .

An exemplary communication device such as the communication device A includes a control system which may include a processor and a random access memory RAM for controlling the overall operation of the communication device A and for executing collaboration applications as discussed in greater detail herein.

The communication device A may also include a communications interface that is adapted to communicate with the network to facilitate communications between the communication device A and external devices such as the media server . The communication device A also includes or is coupled to a display upon which video artifacts of collaboration applications may be rendered and via which with the aid of an input device such as a mouse or keyboard it is possible to interact with collaboration applications. The communication device A also preferably includes a media processor such as an audio processor which generates a media stream that includes voice signals of the participant A and sends the media stream to the media server continuously during the collaboration session or continuously for as long as the communication device A detects that the participant A is speaking. The media stream is typically although not necessarily a digitized data stream that is generated by the audio processor and represents the voice signals of the participant A. Over the course of a conference the media stream of any particular participant may be discontinuous in that the media stream may be generated only when the participant is actually speaking. As used herein the phrase incoming media stream will refer to a media stream that is sent from a communication device to the media server and the phrase outgoing media stream will refer to a media stream that is sent from the media server to a communication device .

For purposes of illustration only the embodiments herein will be discussed in the context of a telephone conference and the media stream is thus an audio stream. However the embodiments herein are not limited to media streams that contain only audio streams and are equally applicable to media streams that include video only and to media streams that include both video and audio.

The audio processor receives outgoing media streams from the media server and provides the outgoing media streams to an audio port to which an audio device such as a headset or speakers may be coupled. Alternatively if the communication device A is a smartphone for example the audio device would be integral with the communication device A.

Each of the communication devices establishes a communication session with the media server . A communication session may comprise any type of session or connection between a respective communication device and the media server that enables the transmission of a media stream from the respective communication device to the media server and the receipt of a media stream from the media server to the respective communication device irrespective of the underlying physical infrastructure used to carry the media stream or the particular protocol used to establish the communication session between the respective communication device and the media server . Suitable protocols may include for example TCP IP Session Initiation Protocol SIP conventional public switched telephone network PSTN signaling or the like. A network access path such as a wired or wireless access path typically couples a communication device to the network .

The media server includes a communications interface that is adapted to communicate with the communication network and can comprise any suitable combination of hardware and or software necessary to receive incoming media streams from the communication devices and to send outgoing media streams to the communication devices .

The media server also includes a conference processor that may establish a conference between the participants . The conference processor includes a mixer that enables the conference processor to mix or combine multiple media streams and provide a mixed outgoing media stream to one or more communication devices . During a collaboration session the conference processor operates to generate a collaboration media stream that comprises the media streams of the participants during a particular period of time during the collaboration session. The collaboration media stream includes a media stream time index which can be used to directly access a location of the collaboration media stream based on time. The collaboration media stream may comprise a mixed audio stream that includes the audio signals of all the participants during the collaboration session if the media stream is an audio stream. The collaboration media stream may comprise a plurality of video streams of all the participants if the media stream is a video stream. The collaboration media stream may comprise a combination of a combined audio stream and a plurality of video streams where the media streams include both audio and video for example.

The media server also includes a control system which may include a processor and a memory for controlling the overall operation of the media server . A voice recognition module may enable one or more of the participants to issue commands during a collaboration session such as a command issued by one of the participants indicating that an artifact generated by a collaboration application should be stored in a collaboration timeline. A collaboration timeline generator represents functionality in the media server that generates a collaboration timeline which corresponds to a particular collaboration session. The collaboration timeline will be discussed in greater detail herein. The collaboration timeline may be stored on a storage device that is local to or integral with the media server or on a network attached storage device for example. The storage device may also store one or more artifacts in an artifact storage .

Embodiments described herein may be implemented in hardware software or a combination thereof. When implemented in software the software comprises software instructions which may be executed on a processor such as the processor to cause the processing device such as the media server to implement the functionality described herein. Thus embodiments may be implemented as a computer program product such as a computer usable or computer readable medium having a computer readable program code embodied therein. The computer readable program code can include the software instructions for implementing the functionality of the embodiments described herein.

A phonetic processor may be used to generate a phonetic index that corresponds to the collaboration media stream where the media stream includes audio signals. A phonetic index enables a participant or other entity to subsequently search the collaboration media stream for the occurrence of words or phrases that may have been spoken during the collaboration session. The phonetic index can therefore be used to rapidly locate a location in the collaboration media stream where a desired topic was discussed during the collaboration session. Phonetic indexes may be generated using phonetic indexing technology which is available from for example Nexidia Inc. 3565 Piedmont Road NE Building Two Suite 400 Atlanta Ga. 30305. Additional details relating to the generation of a particular phonetic index are detailed in U.S. Patent Application Publication No. 2010 0094630 A1 which is hereby incorporated herein by reference in its entirety.

In one embodiment the media server offers a collaboration application programming interface API which enables a collaboration application to communicate with the media server . For example a collaboration application may invoke the collaboration API to automatically notify the media server that an artifact has been generated during a collaboration session. The collaboration application may also provide the generated artifact or a reference to the generated artifact to the media server via the collaboration API .

Additionally as the media server continuously receives the incoming media streams of the participants during the collaboration the media server generates a collaboration media stream that includes the voice signals of the participant s speaking during the collaboration step . The collaboration media stream includes a media stream time index which can be used to directly access a location of the collaboration media stream based on time. The collaboration media stream is typically stored in a file on a storage such as the storage device and may be encoded in any suitable public or proprietary format such as WAV MPEG or the like. If the collaboration media stream comprises video information the collaboration media stream may be stored in a suitable video format such as MPEG or the like.

At some point during the collaboration session one of the participants initiates a collaboration application. As discussed above the term collaboration application refers to an application that can receive input from a plurality of the participants in the collaboration session and based on such input render an artifact to at least one of such participants. Preferably the collaboration application can receive input from all the participants in the collaboration session and can render an artifact to each of the participants. A collaboration application may be implemented via a client server architecture where a separate client thread may execute on each of the communication devices and a master thread may execute on a central server such as the media server . A collaboration application may also be implemented via a peer to peer architecture where a separate thread executes on each of the communication devices and exchanges information with the other threads without the aid of a master thread. A collaboration application may also be a web based application implemented through a browser application executing on the communication devices .

In some collaboration applications input at one communication device may practically instantaneously be reflected on the other communication devices . An example of a collaboration application is a spreadsheet application which when initiated includes application processes or threads that execute on each of the communication devices A D. A new spreadsheet may be opened by for example the participant A and the new blank spreadsheet may be automatically displayed on each of the communication devices A D.

In one embodiment the collaboration application is capable of interfacing with the media server via for example the collaboration API. Thus the media server may determine that the collaboration application has initiated by virtue of the collaboration application invoking a particular function of the collaboration API step . In response the media server may generate a timeline entry in the collaboration timeline that identifies this event by for example the name of the collaboration application and the time of initiation of the collaboration application step .

Assume that the participant B enters several numbers that identify the costs of various components of a product into the spreadsheet. The participant B then enters a spreadsheet formula that applies an algorithm to the numbers to determine a sum of the numbers. As the participant B manipulates the spreadsheet the spreadsheets displayed on the communication devices A C and D may be substantially concurrently updated with the same information allowing the participants A C and D to view the same information as the participant B. In essence each of the participants A D view the same spreadsheet simultaneously. The output of the spreadsheet application in this example is an example of an artifact. In this example the artifact is the image that is displayed to the participants and which reflects the newly entered cost numbers and the sum of the cost numbers.

The media server determines that the artifact has been generated by the spreadsheet collaboration application step . The media server may make this determination in any of a number of different ways. In one embodiment the collaboration application may invoke the collaboration API when an artifact is generated by the collaboration application. In another embodiment one of the participants may select a Store Artifact control that is displayed by the collaboration application. In either embodiment the media server may be provided with information regarding the artifact such as the time of the generation of the artifact a copy of the artifact or a reference such as a URL to the artifact and other desired information. In response the media server generates a timeline entry in the collaboration timeline that includes the time information associated with the generation of the artifact and a reference to the artifact step . The reference to the artifact may include a copy of the artifact or a link such as a URL to the artifact. For example the collaboration application may store artifacts in an artifact storage and provide to the media server a URL identifying the location in the artifact storage of the particular artifact. The artifact typically is not separately saved in the collaboration media stream. For example where the collaboration media stream includes audio signals and the artifact comprises an audio artifact the audio artifact would not typically be stored in the collaboration media stream.

In another embodiment a participant may be able to enter a voice command such as by speaking the phrase store artifact which may be recognized during the collaboration session by the voice recognition module as a command to generate the timeline entry in the collaboration timeline . In such embodiment upon recognition of the command the media server may communicate with the collaboration application requesting suitable information such as the artifact time of generation of the artifact and the like.

This process may be repeated during the collaboration session resulting in a number of timeline entries in the collaboration timeline that identify artifacts generated by one or more collaboration applications during the collaboration session.

The collaboration timeline includes a plurality of timeline entries A J each of which identifies an event that occurred during a corresponding collaboration session. The collaboration timeline in this example covers the complete duration of the corresponding collaboration session although in other embodiments the collaboration timeline may be generated for only designated periods during the collaboration session. Moreover the collaboration timeline may be generated automatically by the media server upon some event such as the initiation of the collaboration session or upon initiation of a collaboration application or may be generated in response to a request by a participant to begin generating the collaboration timeline .

For purposes of illustration assume that the collaboration timeline relates to a collaboration session that had a duration of 16 minutes and 2 seconds and involved the use of two different collaboration applications a polling collaboration application and a product design collaboration application. The collaboration media stream contains the voice signals of the participants that were generated during the collaboration session and a media stream time index which can be used to directly access a location of the collaboration media stream based on time.

The timeline entry A reflects the initiation of the collaboration session and contains a time offset A generally time offset or time offsets or an actual time of day that identifies the time of initiation of the collaboration session. Although not illustrated the timeline entry A could also include information such as the names of the participants who participated in the collaboration session a textual identifier identifying a purpose of the collaboration session day month and year information identifying when the collaboration session took place and the like.

The timeline entry B indicates that the collaboration polling application POLL APPL in was initiated at 2 minutes and 30 seconds into the collaboration session. As discussed above the media server may have generated the timeline entry B in response to being notified by the polling application that the polling application had been initiated. The timeline entry C indicates that the polling application generated an artifact A ART in at 3 minutes and 10 seconds into the collaboration session. Also the timeline entry C includes a reference to the artifact A in the artifact storage . The timeline entry D indicates that the polling application terminated 4 minutes and 10 seconds into the collaboration session. The timeline entry E indicates that at 4 minutes and 53 seconds into the collaboration session a user label was stored in the collaboration timeline . A user label may be generated by a participant at any desired time and comprise any desired identifying indicia such as a particular textual identifier. Such user labels may be used in conjunction with a timeline player as discussed below to quickly allow the user of the timeline player to navigate the timeline player to a desired location in the collaboration timeline . The timeline entry E may be generated for example by a user who knows that the participants are about to discuss a particular topic such as product design. In order to cause the media server to generate the timeline entry E the participant may select a control provided by the collaboration application or may issue a verbal command recognized by the voice recognition module as a command to generate the timeline entry E.

The timeline entry F indicates that the collaboration product design application PROD DESIGN APPL in was initiated 5 minutes and 22 seconds into the collaboration session. The timeline entry G indicates that the product design application generated an artifact B 8 minutes and 10 seconds into the collaboration. The artifact B may comprise for example a diagram of a potential new product that is being designed by the participants during the collaboration session. The timeline entry G includes a reference to the artifact B in the artifact storage . The timeline entry H indicates that the product design application generated an artifact C 10 minutes and 10 seconds into the collaboration. The timeline entry I indicates that the product design application generated an artifact D 14 minutes and 52 seconds into the collaboration. The timeline entry J indicates that the collaboration session ended after a duration of 16 minutes and 2 seconds.

Because the collaboration timeline includes time offsets such as the time offset A which corresponds to times during the collaboration session that the timeline entries were generated the timeline entries can be correlated to locations in the collaboration media stream that contain audio of the participants at the time of the generation of the corresponding timeline entry .

In one embodiment a timeline player is capable of accessing the collaboration timeline the collaboration media stream and the artifact storage enabling efficient access to the artifacts generated during a collaboration session along with the audio streams if the information exchange included audio of the participants that were generated before during and after the generation of the artifact. Assume for example that one of the participants after the termination of the collaboration session discussed with regard to subsequently desires to re familiarize himself with the discussions surrounding a particular artifact generated during the collaboration session. For example two months after the policy discussed with respect to was implemented at the company the participant D cannot recall why the participants A D thought the policy was a good idea. The participant D initiates a timeline player application on the communication device D. is a flowchart of an exemplary process of the timeline player. The participant D may first identify to the timeline player the particular collaboration timeline that the participant D wishes to view. For example the timeline player may display a folder of all collaboration timelines arranged chronologically and enable the participant D to select the desired collaboration timeline .

The timeline player reads the collaboration timeline from the storage device step . If the collaboration media stream is not integral with the collaboration timeline the timeline player may then determine based on information in the collaboration timeline the appropriate collaboration media stream step . The timeline player may then identify the timeline entries in the collaboration timeline and display information regarding the timeline entries on the display D of the communication device D step . is a diagram of an exemplary user interface that may be displayed by the timeline player on the display D. The user interface includes a timeline slider that includes time offset identifiers that identify particularly relevant times during the corresponding collaboration session during which timeline entries were generated. The user interface may also include tags A H that include information identifying the timeline entries . For example the tag B indicates that the polling application generated the artifact A at 3 minutes and 10 seconds into the collaboration session.

Assume that the participant D selects a selector arrow and moves the selector arrow to point at the tag B to select the timeline entry C . The timeline player detects this selection of the timeline entry C step obtains the artifact A from the artifact storage and renders the artifact A in the user interface step . The timeline player also sets a begin location with respect to an audio stream slider . The audio stream slider corresponds to the collaboration media stream . The begin location may coincide with the time of the creation of the timeline entry C i.e. 3 minutes and 10 seconds or may be set to a point in time prior to such time. Setting the begin location to a point in time prior to the time of generation of the timeline entry increases the likelihood that the begin location will be positioned at a point in the collaboration media stream that coincides with the discussion relating to the generation of the artifact A. In one embodiment the begin location may comprise a predetermined amount of time prior to the generation of a timeline entry such as 2 minutes prior to the time of the generation of the timeline entry . Thus in such embodiment the begin location may be set to 1 minute and 10 seconds into the collaboration audio stream. In another embodiment the begin location may be set to coincide with the timeline entry that immediately precedes in time the selected timeline entry .

The timeline player then renders the audio stream from the collaboration media stream concurrently with the display of the artifact A in the user interface . The participant B may slide a selector arrow to a different point along the audio stream slider to select a different point in the collaboration media stream . Upon detection of a change along the audio stream slider of the location of the selector arrow the timeline player begins to render the audio from the collaboration media stream that corresponds to such location. While illustrates that the timeline slider is separate from the audio stream slider in other embodiments a single slider could be used.

The timeline player enables a user to quickly and intuitively view the artifacts that were generated in a previous collaboration session and also to listen to the discussion between the participants in the collaboration session relating to the generation of the artifact. In embodiments wherein the collaboration media stream comprises a video stream without audio the timeline player may render the collaboration media stream in a first window and render artifacts concurrently in a second window. In embodiments wherein the collaboration media stream comprises both an audio stream and a video stream the timeline player may render the video portion of the collaboration media stream in a first window render artifacts in a second window and render the audio track through an audio output device such as a headset or speakers. Where the artifact is solely an audio artifact the timeline player may render both the collaboration media stream and the audio artifact through an audio output device.

Embodiments described herein may be implemented in hardware software or a combination thereof. When implemented in software the software comprises software instructions which may be executed on a processor such as the processor to cause the processing device such as the media server to implement the functionality described herein. Thus embodiments may be implemented as a computer program product such as a computer usable or computer readable medium having a computer readable program code embodied therein. The computer readable program code can include the software instructions for implementing the functionality of the embodiments described herein.

Those skilled in the art will recognize improvements and modifications to the preferred embodiments of the present disclosure. All such improvements and modifications are considered within the scope of the concepts disclosed herein and the claims that follow.

