---

title: Computer architectures using shared storage
abstract: Shared storage architectures and methods are provided. A particular shared storage architecture is a system including shared storage including data and file system metadata separated from the data. The file system metadata includes location data specifying storage location information related to the data. Services are provided from service providers to service consumers through the shared storage.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09098562&OS=09098562&RS=09098562
owner: The Boeing Company
number: 09098562
owner_city: Chicago
owner_country: US
publication_date: 20100330
---
This patent application claims priority from U.S. Provisional Patent Application No. 61 164 717 filed Mar. 30 2009 from U.S. Provisional Patent Application No. 61 164 752 filed Mar. 30 2009 and from U.S. Provisional Patent Application No. 61 171 170 filed Apr. 21 2009 the contents of each of which are expressly incorporated herein by reference in their entirety.

The present disclosure is generally related to a computer architectures and methods using shared storage.

Exposing functions of legacy applications to enable the legacy applications to interact with other applications can lead to significant cost savings. Certain functions of the legacy applications can be re defined as modular self contained services. The capabilities of these services may be independent of context or a state of other services. Additionally these services may be designed to be invoked via a well defined interface. These services may be enabled in a Service oriented Architecture SOA through an Enterprise Service Bus ESB which connects and mediates communications and interactions between the services.

As interchange of information increases there is an increased risk that sensitive information may be unintentionally disclosed to unintended parties. SOA architectures are generally designed to transmit all user messages across one or more networks. These SOA architectures may use sessions between users to transmit data or services over a network.

Certain ESB and SOA architectures are not secure. To address this concern an ESB or SOA architecture may be secured by inspecting an entire data stream of communications using a high assurance data guard over an Internet Protocol IP network. The data guard acts as an intermediary between users of a service performing deep packet inspection to examine contents of the data stream for any sensitive data and or service. For example the data guard may receive a message via a service from a first user inspect the contents of the message and then either re transmit the message to an intended receiver or block the message when the message is not authorized e.g. blocking unauthorized distribution of sensitive information . In addition it is difficult to secure an SOA or an Enterprise service bus ESB over disparate systems.

ESBs and SOAs may be limited by low bandwidth and high latency. The low bandwidth and high latency may hinder the ability of service applications to transmit data in real time while simultaneously providing separation by security level. For example bandwidth may be limited by a number of packets that the data guard can process latency may be limited by a speed at which the data guard can inspect and process the data packets. Thus a full SOA or ESB implementation may be limited in scale by the limited capabilities of the data guard.

Data transmitted during SOA sessions is transient. Thus the data cannot be retrieved for later use or analysis. If a user is not able to receive a communication in real time the communication cannot later be retrieved unless a separate parallel process records and distributes the communication.

Large scale distributed computing environments such as those that may us a SOA or ESB often accommodate heterogeneous hardware and software components network links of varying latencies and unpredictable hardware or software failures in the network or the computers. In large storage area network SAN or network attached storage NAS environments hardware or software failures may result in abnormal termination of applications and corrupted data files. Duplicate hardware components may be deployed to address hardware and software failure concerns. The duplicate hardware may support continual copying of files file systems and or mirrored systems. Additionally complex expensive software may be used to manage local and remote file systems. Manual intervention may be used to re construct files from checkpoints.

Systems and methods to enable a robust high performance ESB over shared storage are described. In a particular embodiment infrastructure functions of the ESB are delivered by service providers to service consumers through shared storage. In this embodiment a storage layer assumes the role of the ESB to present data to and access data from users programs and infrastructure functions. A data tier may include user identifications IDs security tier and presentation tier of the ESB. A particular ESB system includes shared storage including data and file system metadata separated from the data. The file system metadata includes location data specifying storage location information related to the data. An infrastructure function of the ESB system is provided to enable messaging between providers and consumers through the shared storage. A particular method includes enabling communication between a consumer and a producer. An infrastructure function of an enterprise service bus ESB is provided through shared storage to enable messaging between the providers and the consumer.

Systems and methods to enable a Service oriented Architecture SOA over shared storage are also described. In a particular embodiment infrastructure functions of the SOA are delivered by service providers to service consumers through shared storage. Data and services may reside in a storage layer. A particular SOA system includes shared storage including data and file system metadata separated from the data. The file system metadata includes location data specifying storage location information related to the data. The shared storage provides an architecture to loosely integrate a suite of services. A particular method includes enabling communication between a consumer and a producer.

Systems and methods to enable a robust high performance service over shared storage SOSS system are also described. In a particular embodiment services are delivered by service providers to service consumers through shared storage. A particular system includes shared storage including data and file system metadata separated from the data. The file system metadata includes location data specifying storage location information related to the data. Services are provided from service providers to service consumers through the shared storage. A particular method includes hosting services on shared storage.

Additionally systems and methods to enable a federated metadata database are described. A particular system includes multiple instances of shared storage. Each of the instances of shared storage includes data and file system metadata separated from the data. The file system metadata includes location data specifying storage location information related to the data. A persistent common view is provided of local and remote files file systems and services in the shared storage. The federated metadata database may reside in the shared storage and may include user IDs security levels and locations of data files in a local or wide area network. Thus local systems may operate independently if a network link is down. Additionally file systems in a networked environment may automatically synchronize when the network link is back online. The federated metadata database may ensure that data is defined consistently that the data is re useable and shareable that the data is accurate and up to date and that the data is secure and centrally managed.

Various embodiments are disclosed that provide performance in terms of both bandwidth and latency of a dedicated system and security of a high assurance guard to protect sensitive information from inadvertent disclosure.

In a particular embodiment a metadata registry of available infrastructure functions resides in shared storage. Access to the registry may be restricted by a security level of a user a security level of an application or a security level of data. The infrastructure functions may be stored in a directory structure to enable publish and subscribe capability. The infrastructure functions may be asynchronous allowing them to be added removed or acted upon independent of time. Enabling the infrastructure functions over shared storage may reduce costs of duplicating a dedicated system for each classification of information in a multi security level environment.

The features functions and advantages that have been described can be achieved independently in various embodiments or may be combined in yet other embodiments further details of which are disclosed with reference to the following description and drawings.

Embodiments of systems and methods disclosed herein provide computer architectures and methods using shared storage. In a particular embodiment functions of an Enterprise Service Bus ESB are provided via the shared storage. For example one or more infrastructure functions of the ESB may be delivered by producers to consumers through the shared storage. To illustrate traditional ESBs may connect and mediate communications and interactions between services. Thus an ESB over shared storage as described herein may mediate communications and interactions between services via the shared storage.

In a particular embodiment ESB is a computer system that provides for communication between software applications using a universal message format that can be used to implement a service oriented architecture SOA within and or between enterprises. ESB may be implemented by including a software layer between software applications and by use of an asynchronous messaging system that carries messages between the software applications. Using the standardized universal message format a requesting application identifies information desired from a specified target application. ESB software associated with the requesting application directs the request message to the target application over the asynchronous message system. ESB software associated with the target application may translate the request message into a format that is understandable by the target application. The target application generates a response to the request message and the ESB software routes the response over the asynchronous message system to the requesting application and the ESB software translates the response into a format understandable by the requesting application.

ESB is referred to as a bus by way of analogy. A physical bus e.g. a data bus of a computer receives a message from one resource such as a hardware resource and carries the message to another resource. In this case the resources are each adapted to use a common bus protocol such that each of the resources can communicate with other resources via the bus without having to first convert requests into particular formats determined based on the other resource participating in the exchange. In this regard ESB operates like a bus. For example instead of directing a communication to another software application using the target application s application program interface API the API dictating the form of a request directed to the respective application the requesting software application issues its request in a standardized enterprise message model and the ESB software directs and translates the request as appropriate for the target application. ESB software can be distributed to multiple computers and can be packaged in containers that reside with each of the software applications to handle translation and routing of messages for each software application.

While the disclosed systems and methods may perform functions similar to ESB software such as facilitating communications between different software applications the disclosed systems and methods may perform communications more efficiently by avoiding the additional overhead of translating between each software application s particular format and a standardized universal message format.

In another particular embodiment a Service oriented architecture SOA is provided via the shared storage. A SOA is an application architecture in which functions or services are delivered by service providers over a network to service consumers. Because interfaces in a SOA may be platform independent a client program from any device using any operating system may use a service via the SOA. In an SOA over shared storage SOASS as disclosed herein data files file systems and non data aware services may reside in shared storage and effectively assume the role of an ESB. Services may be hosted on the shared storage. For example the services may be delivered by providers to consumers through the shared storage. An Application Programming Interface API to the shared storage includes standard read and write commands which many computing systems users and applications support. A services over shared storage SOSS system as disclosed herein refers to a system wherein files file systems and services reside in the shared storage.

Additionally in a particular embodiment the shared storage is federated across a plurality of shared storage systems and devices. For example a persistent common view of files file systems and services in local shared storage and in remote shared storage may be provided. The persistent common view can represent multiple file systems distributed across a computer network. Thus users may be able to view one or more separate file systems as though they were part of a single file system. The persistent common view may be maintained by storing information about the file system e.g. metadata in a specialized database e.g. a metadata database or registry . Users of the persistent common view can access the metadata database to resolve file system requests.

The shared storage may include a plurality of physical storage devices. Examples of physical storage devices may include persistent non transitory tangible storage devices and systems such as magnetic media e.g. hard disks floppy disks and magnetic tape optical media such as CD ROM disks magneto optical media e.g. floptical disks specially configured hardware devices or any combination thereof.

In a particular embodiment the shared storage includes one or more storage area networks SANS one or more network attached storage NAS systems one or more shared storage systems such as a redundant array of independent disks RAID system one or more other physical storage devices or any combination thereof. For example the shared storage may include a dedicated storage network connecting remote storage clusters to the servers . In a particular embodiment the shared storage may be persistent storage. For example data stored in the shared storage may remain stored until it is removed.

In a particular embodiment the application tier and the data tier are effectively merged in the shared storage e.g. a storage tier. For example the data stored in the shared storage and instructions to execute the services and the infrastructure functions may also be stored in the shared storage . Standard read and write commands may be used to access the shared storage . In a particular embodiment a SOA is provided by combining the data tier an external interface tier an application interface tier and a security tier in the storage layer thus simplifying the architecture relative to a traditional SOA.

In a particular embodiment the data the infrastructure functions the services or any combination thereof can be transferred without using server to server sessions. For example a user can access the data at the first security level via the first server . The first server can access the data using read commands and can modify the data and store the modified data using write commands. A second user can assess the data via fourth server that is able to access the first security level . The second user may access the data using read commands and may store the data using write commands. In a particular embodiment the first server and the fourth server may utilize read after write technology to enable near real time interaction of the first user and the second user without server to server sessions. For example the first server may write information to the data and the fourth server may read the information from the data in the shared storage immediately or nearly immediately after the information is written to the shared storage . Since server to server sessions are not used certain functions associated with ESBs are handled automatically. For example ESBs often provide protocol translation to enable two servers that use different communication protocols to interact. However since the first server writes to the shared storage using a write command and the fourth server reads from the shared storage using a read command no protocol translation is required to facilitate interaction of the servers .

Other functions associated with ESBs may also be provided via the shared storage . For example since the services and the infrastructure functions are not associated with or tied to particular servers load balancing may be unnecessary. To illustrate when the first user accesses the first service an instance of the first service may be generated at the first server at the fourth server or at a client device used by the first user. When a second user attempts to access the first service a second instance of the first service may be generated at the first server at the fourth server or at a client device used by the second user. Thus load balancing based on requests for the first service is not needed. If a need arises to provide more instances of the first service than the shared storage can accommodate e.g. due to storage access limitations the shared storage can be expanded by adding more storage capacity to accommodate the increased need. Alternately or in addition instructions to implement the first service can be redistributed to better serve the users e.g. to provide copies of the instructions to implement the first service that are more readily accessible to the users such as local cache copies . In a particular embodiment all of the infrastructure functions of the ESB system are provided through the shared storage.

In a particular embodiment capacity of the shared storage to act as an ESB may expand in direct proportion to capacity of the shared storage . In this embodiment the ESB over the shared storage can linearly scale to meet increased demands without a step function as may be required by traditional ESBs since the ESB over the shared storage is not tied to or associated with a particular server. To illustrate when the ESB over the shared storage requires an additional 10 performance 10 more capacity may be added to the shared storage . In contrast since traditional ESBs are tied to servers and transmission control protocol TCP networks and when capacity is reached a new server storage and network may be added to obtain an additional 10 of performance.

In a particular embodiment the data the services the infrastructure functions or any combination thereof may be striped across the shared storage . The shared storage may use one channel or multiple channels in parallel to provide high speed performance. To illustrate when a single channel transmits data at 100 MB sec then 10 channels may be used to transmit data in parallel at 1 GB sec.

In another example of providing functions of an ESB via the shared storage binding may be accommodated using the infrastructure functions in the shared storage . For example certain legacy applications may be designed to utilize binding to enable communications. To accommodate use of these applications the first infrastructure function may include a binding function. The binding function may generate response messages to the legacy applications to simulate binding of the legacy application to another application or server. To illustrate in response to the legacy application sending a binding message that requires an acknowledgement an instance of the first infrastructure function may be executed by the first server to generate a dummy acknowledgement message. The legacy application may accept the dummy acknowledgement message as an indication that binding has been accomplished and continue with desired processing.

Other ESB functions may also be provided via the shared storage such as quality of service control fault tolerance routing addressing service registration discovery etc. Thus by hosting the infrastructure functions on the shared storage an ESB on shared storage can be enabled. In a particular embodiment hosting a particular service on the shared storage includes enabling a client to read executable instructions to implement the particular service from the shared storage and enabling the client to read data utilized by the service from the shared storage. The executable instructions to implement the particular service and the data utilized by the service may be provided to the client without using a server to server connection a server session or an application session.

In a particular embodiment the shared storage may include one or more registries of available services infrastructure functions data or any combination thereof. The registries may be resident in the shared storage and may be accessible with standard file directory commands. In a particular embodiment the registries may be associated with the security levels . For example only users that are authorized to access particular data services and infrastructure functions may access a corresponding registry. To illustrate users authorized to access the data the services and the infrastructure functions of the first security level may be able to access the registry associated with the first security level .

In a particular embodiment the registries include metadata that is associated with the data the services the infrastructure functions or any combination thereof. The metadata may include information regarding a physical location of where the data resides encryption keys associated with encrypted data a security level of the data and structured information that describes explains locates or otherwise makes it easier to retrieve use or manage an information resource. The metadata may be stored separate from files to which the metadata pertains. Accordingly the data the services the infrastructure functions or any combination thereof can be hidden or restricted through controlled access to the registries . In a particular embodiment the registries may use standard file system protections and commands to restrict or prevent access to contents of the registries without being encrypted and without a guard. In another particular embodiment access to the registries may be controlled by a high assurance data guard. Thus by providing access controls to the registries access to the data the services the infrastructure functions or any combination thereof can be provided without processing an entire data stream to and from the shared storage .

In a particular embodiment the data the services the infrastructure functions or any combination thereof may inherit an identity a security level or both of a requestor. For example common data not shown common services not shown common infrastructure functions or any combination thereof may be provided in the shared storage . The common data common services or common infrastructure functions may be accessible via more than one security level and may inherit the identity the security level or both of the requestor. In an illustrative embodiment the infrastructure functions may include the common infrastructure function that is shared across more than one of the security levels . In this embodiment when a first user associated with the first security level accesses the common infrastructure function the common infrastructure function may inherit the identity or the security level of the first user. When a second user associated with the second security level accesses the common infrastructure function the common infrastructure function implemented by the second user e.g. a second instance of the common infrastructure function may inherit the identity or the security level of the second user. Thus if the first user is authorized to access the data associated with the first security level and the second user is not authorized to access the data associated with the first security level the common infrastructure function implemented by the first user will be able to access the data associated with the first security level but the common infrastructure function implement by the second user will not be able to access the data associated with the first security level . Rule sets and policies can be implemented to determine the security level of the data . For example output data of a particular service of the services or of a particular infrastructure function of the infrastructure functions can be analyzed based on the rule sets or policies to determine a security level of the output data. For example the security level of the output data may be determined based on a security level of data accessed by the particular service or infrastructure function the security level of the particular service or infrastructure function the security level of a user that caused the output data to be generated other factors or any combination thereof.

The registries may include a list of the data the services and the infrastructure functions that are available in a directory in the shared storage . The directory can be virtualized across one or more local and remote locations. Publishing the services and infrastructure functions in the directory may enable use of a publish subscribe interface to enable users devices or applications to publish and subscribe to the services and infrastructure functions over the shared storage .

In a particular embodiment the data the services the infrastructure functions or any combination thereof can be added removed or acted upon independent of time. For example read and write operations to the shared storage may be fully decoupled and independent. Thus a first application can write data to the shared storage without communicating with or having knowledge of a second application even when the first application and the second application access the same data service or infrastructure function. Further a service or infrastructure function can be modified while the service or infrastructure function is being used. In an illustrative embodiment the data the services the infrastructure functions or any combination thereof can be modified in real time. The data the services and the infrastructure functions are not tied to a particular server a particular CPU a particular CPU core or a particular processing thread. That is the data the services the infrastructure functions or any combination thereof may reside in the shared storage and may be available for use by any of the servers or other devices such as user client devices that have authorization to access them.

In a particular embodiment the services the infrastructure functions or both are stateless. For example the services the infrastructure functions or both may not retain or contain any knowledge of their usage current state or security level. To illustrate instructions to implement the services the infrastructure functions or both may be read from the shared storage and discarded after use leaving the services the infrastructure functions or both unchanged in the shared storage .

In a particular embodiment the shared storage the services the infrastructure functions or any combination thereof may enable in order data transport. For example information written to the data may be read from the data in the same order that the information was written. This embodiment may enable in order data transport for services such as media streaming or collaboration while eliminating fragmenting and re assembling messages. To illustrate when a Voice over Internet Protocol application is used for communications between two users via a server to server session a receiving server may receive packets in a different order than the packets were sent from a sending server. Thus the receive server or a receiving client may reorder the packets to properly assemble voice data sent from the sending server. However by providing in order reading of data from the shared storage a service utilizing the system illustrated in can avoid this time consuming packet reordering process.

In a particular embodiment the shared storage may enable logging of all requests to access the data the services the infrastructure functions or any combination thereof. For example a permanent e.g. persistent or indefinite record of all access requests may be preserved. Additionally the shared storage may be configured to be fault tolerant. For example the shared storage may be configured to monitor for errors in the data the services the infrastructure functions or any combination thereof. The shared storage may utilize automated error detection and error correction to automatically identify and correct faults and to recover faulted data. Additionally hardware failures in the shared storage may be addressed by automatically reconfiguring the shared storage . In a particular embodiment the system illustrated in may perform diagnostics against hardware of the shared storage and contents of the shared storage . The shared storage may be automatically reconfigured when a hardware failure is detected. For example a failed storage device may be bypassed or replaced using backup copies of information stored on the failed storage device. To illustrate a secondary path and a backup path for access to the shared storage and contents of the shared storage may automatically assume control. Thus an N 1 where N is a number of systems used to provide service and the plus one indicates one backup or secondary system implementation may be used to replace a 2N or 2N M where N is a number of systems used to provide service and the plus M indicates a number of backup or secondary system implementations such as may be used with ESB systems where data services or infrastructure functions are tied to particular servers.

Although illustrates the data the services the infrastructure functions and the registries as residing in and hosted on the shared storage other combinations are possible. To illustrate in an enterprise service bus over shared storage ESBOSS the infrastructure functions and optionally the registries may be hosted on the shared storage . In a service oriented architecture over shared storage SOAOSS the data the infrastructure functions and optionally the registries may be hosted on the shared storage . The SOASS may provide an architecture to loosely integrate a suite of services and the registries may include at least one registry of available services of the suite of services. In a services over shared storage SOSS the data the services and optionally the registries may be hosted on the shared storage . In other embodiments other combinations of the data the services the infrastructure functions and the registries may reside in and be hosted on the shared storage . For simplicity of the following description the term shared storage architecture is used to refer to any one or more of an ESBOSS a SOASS a SOSS or another embodiment where data services infrastructure functions or any combination thereof are hosted over shared storage.

In a particular embodiment the first server may independently access the shared storage and retrieve the service or infrastructure function at . The service or infrastructure function may be independently implemented at the first server in a second processing thread. The first server may run the service or infrastructure function in the second processing thread at and may exit the service or infrastructure function at . Additionally or in the alternative a second server may independently access the shared storage and retrieve the service or infrastructure function at . The service or infrastructure function may be independently implemented at the second server. The second server may run the service or infrastructure function at and may exit the service or infrastructure function at . Thus access to and implementation of services infrastructure functions or both in the shared storage may be performed independently by multiple servers multiple processors multiple threads or any combination thereof. Each instance of a service or infrastructure function implemented by a server a processor or a thread may be independent and may not modify the instructions to implement the service or infrastructure function in the shared storage .

In a particular embodiment the consumer credentials include a security level associated with a user. The request to access the registry may include information identifying the user. Thus the identification information may be compared to the consumer credentials to determine whether access to the registry is authorized based on the security level of the user. Additionally since services and infrastructure functions implemented or accessed by the user may inherit the user s identification or security level requests to access the registry by a service or infrastructure function implemented or accessed by the user may have the same access rights as the user.

In a particular embodiment when a request to access data a service or an infrastructure function is received from a user at a determination is made whether the user is authorized to access the data service or infrastructure function at . When the user is not authorized to access the data service or infrastructure function the request is rejected at . When the consumer is authorized to access the data service or infrastructure function access is granted at to the data service or infrastructure function from the shared storage .

By reading the data records in the order that they were written to the memory in order data transport is provided. Thus services that utilize data in a particular order can be enabled without using a reorder process to sort the data into a desired order. To illustrate when a media stream is sent to a user device via a server to server session a receiving server may receive media packets in a different order than the media packets were sent from a sending server. Thus the receive server or a receiving client may sort the media packets to properly place the media packets in a correct order for presentation of the media stream. However by providing in order reading of data from the shared storage a service utilizing the system illustrated in can avoid this time consuming sorting process.

A particular embodiment of messaging in the shared service architecture to implement the process described above is shown in . In the particular embodiment the client sends authentication data such as credentials to the security gateway . The security gateway compares the authentication data to authentication data in a database not shown that is accessible to the security gateway to determine security settings or attributes associated with the client . The security gateway send a message to the metadata controller authenticating the client . The security gateway may also sent the security settings or attributes to the metadata controller . The metadata controller sends at least a portion of a registry database to the client . The registry database may include metadata for the SAN and the portion of the registry database sent to the client may include metadata related to data services or infrastructure functions of the SAN that the client is authorized to access. In a particular embodiment the portion of the registry database sent to the client includes a directory structure. The directory structure may identify the data services and infrastructure functions that the client is authorized to access but may not include information needed to access the data services and infrastructure functions. For example the directory structure may not include storage location information or decryption keys needed to access the data services and infrastructure functions.

The client may send a request to access a service to the metadata controller . If the client is authorized to access the service the metadata controller sends storage location information for the service to the client . If the instructions to implement the service are encrypted in the SAN the metadata controller may also send decryption keys.

The client may read the storage locations of the SAN that are indicated in the storage location information and if the instructions are encoded decode the instructions using the decryption keys. The client may execute the service using the instructions.

In a particular embodiment the service may inherit access or security level attributes of the client to enable the service to access data from the SAN . For example the service may send a request for data to the metadata controller . The metadata controller may send storage location information for the requested data to the client if the service is authorized to access the data based on attributes inherited from the user. If the data is encrypted in the SAN the metadata controller may also send decryption keys for the data to the client . The service may read the data from the SAN using the storage location information and may decode the data if needed using the keys.

Some services may generate results when executed. For example a service may analyze or perform computations using the data accessed from the SAN . In another example a user may provide input to the client that generates result data via the service. For example text input by the user via the client may generate result data from the service. To illustrate the service may be a collaboration application an instant messaging application a communication application or another application that received information at the client to produce the result data. When the service generates the result data the service may send a write request to the metadata controller . The metadata controller may allocate a result storage location. The metadata controller may also update metadata associated with the SAN to indicate that the result data is stored at the result storage location and may write the result storage location to the registry. The metadata controller may send the result storage location to the client . When the result data is to be encrypted for storage the metadata controller may also send encryption keys to be used to encrypt the result data. The service may encrypt the result data using the encryption keys and write the result data to the allocated result storage locations of the SAN . The service may be terminated by the client without writing status information regarding the service to the SAN .

In a particular embodiment a second client may access the result data from the SAN . For example the second client may be authenticated and may execute a service in a manner similar to that described above with respect to the first client . The second client may implement the same service or a different service independently of the first client . The service implemented by the second client may send a request to access the result data produced by the first client to the metadata controller . If the service implemented at the second client is authorized to access the result data the metadata controller sends storage location information and keys if needed related to the result data to the second client . The service at the second client reads the result data from the SAN using the storage location information and the keys if needed .

The service at the first client and the service at the second client may be instances of the same service or may be different services. Additionally the services may be executed concurrently or sequentially. For example the service at the second client may read the result data from the SAN immediately or nearly immediately after the service at the first client writes the result data to the SAN . In another example the service at the second client may read the result data from the SAN a significant time after the service at the first client writes the result data to the SAN e.g. after the service at the first client has been terminated. Further the service at the first client and the service at the second client may read data from the SAN using standard read commands and may write data to the SAN using standard write commands. Accordingly no communication protocol translation is needed. Thus real time or delayed interaction between the first client and the second client can be provided through the SAN .

The method may also include at filtering a metadata registry to generate a filtered metadata registry. For example the metadata registry may be filtered by the security gateway or by a metadata controller such as the metadata controller of . The filtered metadata registry may identify infrastructure functions that are accessible by a user device based on a security level of the user device based on security levels associated with the infrastructure functions based on a data security level associated with data accessed by the infrastructure functions or any combination thereof. For example the metadata registry may be filtered based on the credentials associated with the user device or the security level associated with the user device.

The method may also include at sending the filtered metadata registry to the user device. The method may further include at receiving a request from the user device to implement a first infrastructure function. The first infrastructure function may be selected from the filtered metadata registry. Instructions to implement the first infrastructure function may be striped across a plurality of physical storage devices of a shared storage system. The method may include sending storage location information identifying storage locations in the shared storage system of the instructions to implement the first infrastructure function. For example the storage location information may be determined based on metadata associated with the shared storage system. In an illustrative embodiment the metadata registry includes data identifying a plurality of infrastructure functions that are hosted on the shared storage system and decryption keys associated with the infrastructure functions. In this embodiment the decryption key or keys for the first infrastructure function may be sent to in addition to the storage location information.

The user device may read the instructions from the shared storage system using the storage location information to generate a first instance of the first infrastructure function. If decryption keys are provided the user device may also decrypt the instructions using the decryption keys.

In a particular embodiment the user device may execute the first instance of the first infrastructure function. During execution of the first instance the first instance may be restricted from accessing data stored in the shared storage system based at least partially on the security level of the user device. In a particular embodiment the first instance may determine output data and the method may include at receiving a request to allocate storage space for the output data. For example the first instance of the first infrastructure function may generate or select dummy response information. To illustrate the dummy response information may be selected to satisfy a connection message expected by a second user device. Thus the first infrastructure function may simulate a binding function of an ESB.

The method may also include at allocating storage space for the output data in the shared storage system and updating the metadata registry to include storage location information identifying the allocated storage space for the output data at . The method may further include at sending the storage location information identifying the allocated storage space to the user device.

The user device may write the output data to the shared storage system using the storage location information. In a particular embodiment the user device may terminate the first instance of the infrastructure function without storing state information associated with the infrastructure function at . Additionally the output data may be read from the shared storage system by a second instance of the infrastructure function or a second infrastructure function after the first instance of the infrastructure function is terminated at .

The method may also include at filtering a metadata registry to generate a filtered metadata registry. For example the metadata registry may be filtered by the security gateway or by a metadata controller such as the metadata controller of . The metadata registry may identify services including data identifying a plurality of services that are hosted on a shared storage system. For example instructions to implement the services may be striped across a plurality of physical devices of the shared storage system. The metadata registry may also include decryption keys when the instructions are stored in an encrypted format. The filtered metadata registry may include information about services hosted on the shared storage system that are accessible by the user device based on the security level of the user device based on security levels associated with the services based on a data security level associated with data accessed by the services or any combination thereof. For example the metadata registry may be filtered based on the credentials associated with the user device or the security level associated with the user device.

The method may also include at sending the filtered metadata registry to the user device. The method may further include at receiving a request from the user device to implement a first service. The first service may be selected from the filtered metadata registry.

The method may include at sending storage location information identifying storage locations in the shared storage system of the instructions to implement the first service. For example the storage location information may be determined based on metadata associated with the shared storage system. In an illustrative embodiment the metadata registry includes data identifying a plurality of services that are hosted on the shared storage system and decryption keys associated with the services. In this embodiment the decryption key or keys for the first service may be sent in addition to the storage location information.

The user device may read the instructions from the shared storage system using the storage location information to generate a first instance of the first service. If decryption keys are provided the user device may also decrypt the instructions using the decryption keys.

In a particular embodiment the user device may execute the first instance of the first service. During execution of the first instance the first instance may be restricted from accessing data stored in the shared storage system based at least partially on the security level of the user device. In a particular embodiment the first instance may determine output data and the method may include at receiving a request to allocate storage space for the output data.

The method may also include at allocating storage space for the output data in the shared storage system and updating the metadata registry to include storage location information identifying the allocated storage space for the output data at . The method may further include at sending the storage location information identifying the allocated storage space to the user device. When the output data is to be encrypted in the shared storage system encryption keys to be used to encrypt the output data may also be send to the user device.

The user device may write the output data to the shared storage system using the storage location information and the encryption keys if provided . In a particular embodiment the user device may terminate the first instance of the infrastructure function without storing state information associated with the infrastructure function at . Additionally the output data may be read from the shared storage system by a second instance of the service or a second service after the first instance of the first service is terminated at .

In a particular embodiment a persistent common view of local and remote files file systems services infrastructure functions or any combination thereof may be provided via a single view through a virtualized layer . For example when a user has direct access to the first SAN e.g. the first SAN is local to the user and the user has remote access to the second SAN the single view through the virtualized layer may include federated metadata associated with the first SAN and with the second SAN . Thus data services and infrastructure functions available in the first SAN and data services and infrastructure functions available in the second SAN may be accessed via the persistent common view e.g. as though both the first SAN and the second SAN were local to the user . To provide the persistent common view metadata associated with the data services and infrastructure functions at the first SAN may be federated with metadata associated with the data services and infrastructure functions at the second SAN . Additionally metadata associated with the data services and infrastructure functions at the other SANs such as the third SAN may be federated with the metadata of the first SAN and the metadata of the second SAN . In a particular embodiment information to generate the persistent common view e.g. a federated metadata database or registry is stored in one or more of the instances of shared storage. In another particular embodiment information to generate the persistent common view is stored at a metadata controller associated with one or more of the instances of shared storage.

The virtual SAN may include a metadata catalog . The metadata catalog may be generated by federating metadata associated with each of the SANs of the virtual SAN . Thus the metadata catalog may include information related to data stored at the first local SAN data stored at the second local SAN data stored at the remote SAN or data stored across more than one of the SANs. In a particular embodiment the metadata catalog may be stored in one or more physical storage devices of the virtual SAN . For example the metadata catalog may be stored at one of the SANs of the virtual SAN at more than one of the SANs of the virtual SAN or across several of the SANs of the virtual SAN .

The metadata catalog may be used to provide a persistent common view of the virtual SAN . The metadata catalog may support the loss of a storage element while maintaining operation and consistency without operator intervention. For example the metadata catalog used to provide the persistent common view of the virtual SAN may be maintained at the first local SAN . When a communication link is lost to the remote SAN the metadata catalog may still be accessible and may enable operation of the virtual SAN without service interruption. While communication with the remote SAN is disrupted requests to access data services or infrastructure functions that are available on the remote SAN may be rejected may be queued for execution when the communication with the remote SAN is restored or may be serviced by another SAN that has access to the requested data services or infrastructure functions e.g. as a secondary copy . In a particular embodiment when a shared storage system is added to the virtual SAN e.g. when a new SAN is added metadata related to the new SAN may be automatically added to the metadata catalog . Accordingly SANs may be added to or removed from the virtual SAN without disrupting operation of the virtual SAN .

In a particular embodiment the metadata catalog may support governance of the virtual SAN and the SANs within the virtual SAN . For example the metadata catalog may enable managing a portfolio of services or infrastructure functions to add new services or infrastructure functions or to update existing services or infrastructure functions. In another example the metadata catalog may enable management of services and infrastructure functions lifecycles by ensuring that updates to services and infrastructure functions do not disrupt current consumers of the services or infrastructure functions. In another example the metadata catalog uses rules or policies to restrict behavior. To illustrate rules can be created that apply to selected services selected infrastructure functions all services or all infrastructure functions. In another example the metadata catalog may support governance of the virtual SAN by monitoring performance and availability of services and infrastructure functions. In a particular embodiment two or more instances of shared storage such at the first local SAN and the second local SAN may have different governance policies. For example each SAN of the virtual SAN may enforce different governance policies regarding such things as computer and data usage access outside or remote access data retention malware scanning other governance and control policies or any combination thereof.

In another particular embodiment the first user may have local access to the file and the second user may have remote access to the file . The single view through the virtualized layer may support proxying to enable non direct access clients i.e. the second user to access shared storage of the shared storage architecture.

In a particular embodiment of a shared storage architecture a consumer may request access to data at . Rules policies or both may be used to determine an access level or security level associated with the data at . A determination may be made at of whether the consumer is authorized to access the data. When the consumer is not authorized to access the data the request may be rejected at . When the consumer is authorized to access the data the consumer may be provided access to the data at via shared storage .

In a particular embodiment the single view through the virtualized layer may include federated metadata of a plurality of SANs such as a first SAN a second SAN and one or more third SANs . Each of the SANs may include one or more instances of shared storage. By restricting access to the single view through the virtualized layer access to data within each of the SANs can be restricted. For example the rules or policies may be implement by a metadata controller to restrict access to federated metadata associated with the SANs .

In a particular embodiment the single view through the virtualized layer may include metadata that includes information to reconstruct the instructions from instruction data striped across the shared storage to implement the service. Additionally the single view through the virtualized layer may include federated metadata of data services and infrastructure functions stored at multiple instances of shared storage such as a first SAN a second SAN and one or more third SANs .

In a particular embodiment the registry may be federated with registries of other SANs such as a second SAN and one or more third SANs . In this embodiment the data services and infrastructure functions in each of the SANs can be added removed and acted upon independently of one another and at any time. The single view through the virtualized layer may be provided using the federated registries. For example the single view through the virtualized layer may include federated metadata associated with the data services and infrastructure functions hosted by the shared storage of each of the SANs . Federating the metadata of the SANs does not limit independent operation of or access to the data services or infrastructure functions of the SANs .

Access to data metadata services or infrastructure functions at other SANs such as a second SAN and one or more third SANs can also be restricted or hidden. The single view through the virtualized layer may be provided using federated metadata associated with the data services or infrastructure functions hosted at each of the SANs . Data metadata services infrastructure functions or any combination thereof from each of the SANs can be hidden or restricted through controlled access to federated metadata of a federated shared storage architecture.

In a federated shared storage architecture the service or infrastructure function may also be able to access data metadata services or infrastructure functions at other SANs such as a second SAN and one or more third SANs based on the inherited characteristics. The single view through the virtualized layer may be provided using federated metadata associated with the data services or infrastructure functions at each of the SANs . Data metadata services infrastructure functions or any combination thereof from each of the SANs can be hidden or restricted from the service or infrastructure function implemented by the user based on the inherited characteristics using controlled access to federated metadata.

In a particular embodiment retrieving the stateless service or infrastructure function from the shared storage and running the stateless service or infrastructure function at a client or server may be referred to as generating an instance of the service or infrastructure function. To illustrate instructions to implement a service may be stored in the shared storage . The instructions to implement the service may be retrieved from the shared storage using metadata associated with the shared storage that includes storage location information of the instructions. When the instructions are encoded in the shared storage the metadata may also include decryption keys. Thus the metadata provides information that is used by the client to reconstruct an executable instance of the service. As described with reference to the instance of the service may inherit characteristics of the user such as security level or access level of the user. When the client is done using the instance of the service the instance of the service may be terminated and deleted. That is the instance of the service is not retained although the instructions to generate a new instance of the service remain in the shared storage and are not affected by the client generating the instance of the service.

In a federated shared storage architecture the stateless service or infrastructure function may also be accessible to users of other SANs such as a second SAN and one or more third SANs . For example the single view through the virtualized layer may be provided using federated metadata that includes information regarding the stateless service or infrastructure function .

In a particular embodiment at diagnostics may be performed of data services infrastructure functions or any combination thereof of the first SAN . A determination may be made at of whether an error has been encountered. For example an error may be detected using parity or other error detection information. When no error is detected the diagnostics may be complete at . When an error is detected the error is corrected or the data is rebuilt if possible at . For example error correction information may be used to correct the error to recover the faulted data. Alternately backup or secondary copies of the data may be used to rebuild the data to recover the faulted data.

In a federated shared storage architecture hardware elements and data elements of multiple instances of shared storage may be checked independently. For example a second SAN and one or more third SANs may perform diagnostics and status checks of hardware and data elements of the second SAN and the third SAN respectively. When faulted data or failed hardware elements are detected federated metadata of the federated shared storage architecture may be updated to reflect corrective actions taken in response to the faulted data or failed hardware element. For example the second SAN may be reconfigured as a result of a failed hardware element and the federated metadata may be updated to avoid sending requests to the failed hardware element.

In a particular embodiment maintaining the federated metadata registry includes at identifying storage locations of all user data stored at the first shared storage system and storage locations of all user data stored at the one or more remote shared storage system in the federated metadata registry. In a particular embodiment the data may be striped across multiple physical storage devices at the first shared storage system at the one or more remote shared storage system or at any combination thereof. For example the federated metadata registry may include storage location information regarding the data striped across multiple independent storage systems of one or more storage area networks. In a particular embodiment maintaining the federated metadata registry includes at synchronizing the federated metadata registry with a remote federated metadata registry associated with the one or more remote shared storage systems. To illustrate the federated metadata registry and the remote federated metadata registry may be synchronized through the shared storage systems or via a communication channel between two or more metadata controllers e.g. an internet protocol communication channel .

The method may further include at maintaining a federated service catalog. The federated service catalog may include storage location information to enable reconstruction of instructions to implement a plurality of services. For example instructions to implement a first set of the plurality of services may be stored at the first shared storage system and instructions to implement a second set of the plurality of services may be stored at the one or more remote shared storage systems. In an illustrative embodiment the federated service catalog may be a portion of the metadata catalog of .

The method may also include at maintaining a federated infrastructure function catalog. The federated infrastructure function catalog may include data descriptive of storage location information to enable reconstruction of instructions to implement a plurality of infrastructure functions. For example instructions to implement a first set of the plurality of infrastructure functions may be stored at the first shared storage system and instructions to implement a second set of the plurality of infrastructure functions may be stored at the one or more remote shared storage systems. In an illustrative embodiment the federated infrastructure function catalog may be a portion of the metadata catalog of .

The method may also include at receiving a request to access the federated metadata registry. In response to the request the method may include at filtering the federated metadata registry based on authentication information associated with a requesting device to generate a filtered federated metadata registry. The filtered federated metadata registry may not include storage location information regarding data that the requesting device is not authorized to access based on the authentication information. The method may also include at sending the filtered federated metadata registry to the requesting device.

In a particular embodiment one or more of the systems and methods disclosed herein or portions thereof may be implemented using a set of instructions executable by one or more processors. For example the servers shared storage systems including storage servers storage area networks physical storage devices and other hardware elements of the shared storage system clients security gateways metadata controllers and other elements may be implemented using one or more computer systems. A computer system refers to one or more computing devices or any collection of systems or sub systems that individually or jointly execute a set or multiple sets of instructions to perform one or more computer functions. An exemplary computer system may include at least one processor subsystem also referred to as a central processing unit or CPU . The CPU can be implemented using a single chip processor or using multiple processors or processor cores. The CPU may retrieve instructions from a memory control the reception and manipulation of input data and the generation of output data. The CPU may also interact with other components or subsystems of the exemplary computer system or with other computing systems.

The illustrations of the embodiments described herein are intended to provide a general understanding of the structure of the various embodiments. The illustrations are not intended to serve as a complete description of all of the elements and features of apparatus and systems that utilize the structures or methods described herein. Many other embodiments may be apparent to those of skill in the art upon reviewing the disclosure. Other embodiments may be utilized and derived from the disclosure such that structural and logical substitutions and changes may be made without departing from the scope of the disclosure. For example method steps may be performed in a different order than is shown in the figures or one or more method steps may be omitted. Accordingly the disclosure and the figures are to be regarded as illustrative rather than restrictive.

Moreover although specific embodiments have been illustrated and described herein it should be appreciated that any subsequent arrangement designed to achieve the same or similar results may be substituted for the specific embodiments shown. This disclosure is intended to cover any and all subsequent adaptations or variations of various embodiments. Combinations of the above embodiments and other embodiments not specifically described herein will be apparent to those of skill in the art upon reviewing the description.

The Abstract of the Disclosure is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition in the foregoing Detailed Description various features may be grouped together or described in a single embodiment for the purpose of streamlining the disclosure. This disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather as the following claims reflect the claimed subject matter may be directed to less than all of the features of any of the disclosed embodiments.

