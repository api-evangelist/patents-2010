---

title: Operating system with hardware-enabled task manager for offloading CPU task scheduling
abstract: An operating system (OS) is provided including a hardware-based task scheduler, with a method for managing OS sourced tasks to be performed by a central processing unit (CPU). An OS, partially enabled as software instructions stored in a computer-readable medium and executed by the CPU, generates CPU tasks. The CPU tasks are buffered in a computer-readable task database memory. CPU task IDs associated with the buffered CPU tasks are enqueued in a CPU queue. Subsequently, the CPU dequeues a first task ID from the CPU queue, and accessing a first CPU task from the task database associated with the first CPU task ID. The CPU delivers the first CPU task to the OS. The OS generates the CPU instructions needed to perform the first CPU task, and sends the CPU instructions to the CPU for performance.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08881161&OS=08881161&RS=08881161
owner: Applied Micro Circuits Corporation
number: 08881161
owner_city: Sunnyvale
owner_country: US
publication_date: 20100128
---
This invention generally relates to computer operating systems OSs and more particularly to an OS with the capability to offload central processing unit CPU task scheduling to a hardware device.

As noted in Wikipedia an operating system OS is an interface between hardware and user that is responsible for the management and coordination of activities and the sharing of the resources of a computer that acts as a host for computing applications run on the machine. As a host one of the purposes of an operating system is to handle the resource allocation and access protection of the hardware. This relieves application programmers from having to manage these details.

Operating systems offer a number of services to application programs and users. Applications access these services through application programming interfaces APIs or system calls. By invoking these interfaces the application can request a service from the operating system tem pass parameters and receive the results of the operation. Users may also interact with the operating system with some kind of software user interface like typing commands by using command line interface CLI or using a graphical user interface. For hand held and desktop computers the user interface is generally considered part of the operating system. On large multi user systems like Unix and Unix like systems the user interface is generally implemented as an application program that runs outside the operating system. While servers generally run Unix or some Unix like operating system embedded system markets are split amongst several operating systems although the Microsoft Windows line of operating systems has almost 90 of the client PC market.

Multitasking refers to the running of multiple independent computer programs on the same computer giving the appearance that it is performing the tasks at the same time. Since most computers can do at most one or two things at one time this is generally done via time sharing which means that each program uses a share of the computer s time to execute.

An operating system kernel contains a piece of software called a scheduler which determines how much time each program will spend executing and in which order execution control should be passed to programs. Control is passed to a process by the kernel which allows the program access to the CPU and memory. Later control is returned to the kernel through some mechanism so that another program may be allowed to use the CPU. This so called passing of control between the kernel and applications is called a context switch.

An early model which governed the allocation of time to programs was called cooperative multitasking. In this model when control is passed to a program by the kernel it may execute for as long as it wants before explicitly returning control to the kernel. This means that a malicious or malfunctioning program may not only prevent any other programs from using the CPU but it can hang the entire system if it enters an infinite loop.

The philosophy governing preemptive multitasking is that of ensuring that all programs share time on the CPU. This implies that all programs must be limited in how much time they are allowed to spend on the CPU without being interrupted. To accomplish this modern operating system kernels make use of a timed interrupt. A protected mode timer is set by the kernel which triggers a return to supervisor mode after the specified time has elapsed. On many single user operating systems cooperative multitasking is perfectly adequate as home computers generally run a small number of well tested programs.

In today s fast packet processing requirement sometimes the task scheduling becomes as computationally intensive as processing the packet creating a large overhead. This overhead makes the system very slow as CPU is busy performing the scheduling algorithms in the background. Regardless of the algorithm used and how much the software algorithm is optimized there is always going to be some overhead for software based scheduling as scheduling is a process that must be supported by the CPU.

In addition the system of does not scale well across multiple CPUs. It is difficult for the OS to provide infrastructure for task grouping task hierarchy and task distribution to multiple cores at runtime depending upon the application. Such as system cannot create pipeline processing of tasks across CPUs for task processing parallelism and it can t work with multiple operating systems running in multiprocessor or uniprocessor systems.

It would be advantageous if more CPU time could be made available by reducing the number of CPU operations needed to support OS task scheduling.

It would be advantageous if the OS could at least partially offload task scheduling to a hardware device that operates independently of the CPU.

Disclosed herein are a system and method for reducing the number of instructions that must be performed by an operating system OS in the performance of central processing unit CPU task scheduling. As a result the overall number of CPU instructions that must be executed at runtime is reduced. Further by removing scheduling algorithms from the OS the OS code size is likewise reduced. Rather the task scheduling is performed in queue management hardware using a strict protocol SP weighted round robin WRR deficit round robin DRR or some other scheduling algorithm. While hardware is performing scheduling algorithms for the OS the CPU is free to perform other tasks.

Accordingly an OS is provided including a hardware based task scheduler with a method for managing OS sourced tasks to be performed by a CPU. An OS partially enabled as software instructions stored in a computer readable medium and executed by the CPU generates CPU tasks. The CPU tasks are buffered in a computer readable task database memory. CPU task IDs associated with the buffered CPU tasks are enqueued in a CPU queue. Subsequently the CPU dequeues a first task ID from the CPU queue and accesses a first CPU task from the task database associated with the first CPU task ID. The CPU delivers the first CPU task to the OS. The OS generates the CPU instructions needed to perform the first CPU task and sends the CPU instructions to the CPU for performance.

In one aspect enqueuing the first CPU task ID includes accessing a task priority field in the first CPU task and enqueuing the first CPU task ID in a first CPU queue selected from a plurality of parallel CPU queues. The first CPU task queue is associated with the task priority field. The first CPU task ID may be dequeued from the CPU queue using an algorithm such as round robin weighted round robin deficit round robin strict priority or time slice based scheduling. In another aspect a task CPU ID field is accessed in the first CPU task and the first CPU task ID is enqueued in a CPU queue selected from a plurality of parallel CPU queues associated with a particular CPU.

Additional details of the above described method and an operating system with a hardware enabled central processing unit queue for CPU task scheduling are provided below.

As used in this application the terms component module system and the like are intended to refer to an automated computing system entity such as hardware firmware a combination of hardware and software software software stored on a computer readable medium or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a computing device and the computing device can be a component. One or more components can reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers. In addition these components can execute from various computer readable media having various data structures stored thereon. The components may communicate by way of local and or remote processes such as in accordance with a signal having one or more data packets e.g. data from one component interacting with another component in a local system distributed system and or across a network such as the Internet with other systems by way of the signal .

As used herein the term computer readable medium refers to any medium that participates in providing instructions to a processor for execution. Such a medium may take many forms including but not limited to non volatile media volatile media and transmission media. Non volatile media includes for example optical or magnetic disks. Volatile media includes dynamic memory. Common forms of computer readable media include for example a floppy disk a flexible disk hard disk magnetic tape or any other magnetic medium a CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes a RAM a PROM and EPROM a FLASH EPROM any other memory chip or cartridge a carrier wave as described hereinafter or any other medium from which a computer can read. is a schematic block diagram of an operating system

 OS with a hardware enabled central processing unit CPU queue for CPU task scheduling. The OS comprises an application programming interface API to receive service requests from a software application stored in a computer readable memory and executed by a CPU . The OS also comprises a kernel of software instructions stored in computer readable memory and executed by CPU for converting the service requests into CPU tasks and performing scheduled CPU tasks. A CPU task is very generic term that may encompass background tasks such as garbage collection background jobs submitted by users like running makefiles system monitoring software interrupts threads network programs server programs and client programs.

The OS further comprises a task scheduler cross referencing CPU tasks to CPU task IDs. The task scheduler manages a task database stored in the computer readable memory by exporting CPU tasks to the task database and enqueuing CPU tasks. Note the exporting of CPU tasks to the task database and the enqueuing of CPU tasks IDs are operations that are supported by the CPU. In one aspect the task scheduler also known as a task control block TCB adds fields to each CPU task such as a task database index field task priority field task CPU ID field or combinations of the above mentioned fields.

Although only a single application is shown for simplicity it should be understood that OS API may be in communication with a plurality of applications not shown. Also for convenience a single memory is shown. It should be understood however that the OS task database and application need not all reside in the same memory.

A system on chip SoC includes the CPU and a CPU queue for enqueuing CPU task IDs received from the task scheduler . The CPU task IDs may move from the input of the queue to the output in response to a clock signal not shown . For example the CPU dequeues a first CPU task ID from the CPU queue accesses the task database to recover a next scheduled CPU task associated with the first CPU task ID and sends the next scheduled CPU task to the kernel . Then the kernel generates a plurality of CPU instructions associated with the next scheduled CPU task as is conventional and sends them to the CPU for performance.

There are many types of OSs known in the prior art and even the same OS may be modeled differently. The OS of is not necessarily intended to describe a complete OS as there are other OS functions that have not been mentioned that are outside the scope of this disclosure. Some of these other functions may include physical and virtual memory management file system management process management hardware interaction user program execution and other miscellaneous jobs. A practitioner skilled in the art could fully enable the OS of to perform these and other unmentioned functions using conventional software modules.

CPU task ID is a unique identification number assigned to a CPU task. Task group ID is a unique identification number of the group in which the task belongs. In one aspect a task group is a set of tasks that are grouped together on the basis on a common attribute. Task context information is all the information required by system to execute the task. This information includes data such as current CPU register values and interrupt status. Task priority is the priority of task. This field is especially useful if a strict priority scheduling algorithm is used in dequeuing. Task scheduling policy is the dequeuing scheduling algorithm e.g. strict priority weighted round robin deficit round robin simple round robin etc. Task state is the current task status e.g. whether the task blocked running can run idle etc. Task resource requirements and availability are the resources the task needs to run like dynamic memory semaphores mutex spinlocks shared memory etc. Task address space is the memory space given to a task the task cannot access anything beyond this memory address space. Task stack size is typically defined in terms of bytes and is used for local variables and function calls. A task CPU mask is the task the CPU should be scheduled to perform.

In contrast to the conventional definition of an OS as purely software instructions the OS of includes the hardware component of a CPU queue and CPU . For convenience the CPU queue is shown embedded in an SoC with a CPU. However the OS also be understood as a combination of software components and just a hardware queue. Alternately the OS of may be understood to be more conventionally a collection of software module with a limited function task scheduler module.

In a different aspect SoC may be understood to be a device for managing OS sourced tasks to be performed by a CPU. In this aspect the SoC is as shown in comprising a CPU a CPU queue receiving CPU task IDs for enqueuing from an OS enabled as software instructions stored in a computer readable memory and executed by the CPU. In the example explained above the CPU dequeues a first CPU task ID from the CPU queue accesses a next scheduled CPU task from a task database stored in a computer readable memory and sends the next scheduled CPU task to the OS which in this aspect is understood to be just a combination of software modules e.g. API kernel and task scheduler . The CPU receives a plurality of CPU instructions from the OS associated with the next scheduled CPU task.

By utilizing this queue manager infrastructure task scheduling can be partially offloaded from the operating system. The operating system has all the information needed to define task priority task group hierarchical organization and the CPU runs this task from a task infrastructure database. From the perspective of the OS its CPU task scheduling is finished once the task ID is enqueue in the appropriate virtual queue. The queuing priority handling hierarchy management scheduling algorithms queue status updates to the CPU are subsequently handled by queuing device.

As noted above the operating system environment still provides a limited function task management infrastructure. The task management infrastructure includes a library to be used by an application to create tasks delete tasks assign priorities to tasks and run the tasks at initialization time as well as run time. Internally the operating system environment maintains the status of the task in a TCB task control block which is also referred to herein as a task database. The operating system interacts with the device driver of the scheduling and queuing device for queuing the tasks to get scheduled at later time. No actual task scheduling is performed by operating system.

In multiprocessor systems task affinity is provided based on classifying the computing or processing requirements and assigning the task to the queue of the device. Task affinity associates a particular task with a particular queue in this case through the choice of queue. The queue is always linked to one of the CPUs in the system and so the device always schedules the task with appropriate processor attached to the queue. Without the OS of it is very difficult to provide task affinity and process context information for task propagated across the multiple CPUs. In the multiprocessing environment the OS of provides the facility for processing the same task by multiple processing in time slicing manner per processing functional blocks or as per the resource requirements and availability. This capacity greatly helps in load balancing as well as improving overall system processing bandwidth by parallel processing or pipeline processing. This OS makes it simple to implement very complex algorithms for task scheduling queuing and in multiprocessor environment task affinity system load balancing parallel and pipeline processing.

The following is a description of task scheduling process flow using hardware device scheduling and queuing. Packet processing tasks are used as an example but the same process flow can be applied to other computing algorithms.

At OS initialization time or at runtime after getting the proper application environment the application creates the tasks required for different packet processing purposes. These tasks can include for example IP forwarder TCP terminator IPSec processing Control path exceptions etc. These tasks are given appropriate scheduling parameters along with their callback routines at create time. The OS scheduling infrastructure creates appropriate TCBs and assigns appropriate queue IDs to each block. The queue IDs represent the queue to be used for enqueuing and dequeuing. The queue ID can be selected based on various parameters given by the task creation routine. The parameters include what kind of scheduling needed by the task task priority task hierarchy task group etc.

At runtime the operating system is given the task ID from hardware to execute. The operating system blindly just receives the task ID from hardware and runs the task. However it does have a parameter index and queue ID if in case an analysis of the task is required. The actual scheduling of the tasks is done by the scheduling device. For example if a packet needs to be processed the OS classifies the packet and decides which task to make in the ready state from ideal state. If the packet needs to be forwarded then the IP forwarder needs to be made ready. If packet is sinking with a TCP connection the TCP terminator needs to get ready.

After deciding the task to be readied the OS is not expected to run the scheduling algorithms it just needs to enqueue the control message in the queue found from the TCB. It is the queuing and scheduling device that runs the scheduling algorithms between multiple queues or tasks. A number of different scheduling algorithms may be used. Once the task has an actual slot for running the scheduling device generates an interrupt to the operating system and provides task related information which may include task context and callback routines to execute the task. Note the actual packets are not queued.

A comparison to conventional packet process also helps illustrate the distinctions between the prior art of the above described OS. The job of a queue manager is to manage the enqueuing and dequeuing of the messages provided to it. These queues are conventionally used to send and receive packets. For example when the packet arrives in ingress direction Ethernet hardware in a conventional system enqueues messages to the QM and the CPU dequeues message from QM. The CPU processes the packet based on information provided in the dequeued message. The information in the message includes packet address packet length whether it is a valid packet and other packet related information.

In contrast the OS of uses these queues in a different manner. First only the CPU enqueues the message CPU task ID and only the CPU dequeues the message. Instead of sending the message which generally contains packet related information the dequeued message in the OS system of contains OS task related information. As noted in detail above the messages queued in the OS of are merely a task ID number identifying a task to be preformed they are not packets. The CPU task itself is not queued. Neither are the specific CPU instructions queued which are needed to perform the task.

The QM support 3 types of queuing functions namely Physical Queues PQs Virtual Queues VQs and Top Level Virtual Queues TLVQs . A FIFO is an example of a PQ. A TLVQ is a logical queuing point at the top level of the optional hierarchical scheduler. These queues are deemed to be virtual as messages are not physically moved into these queues. A VQ is a logical queuing point between the top and bottom levels of the hierarchical scheduler. Like TLVQs these queues are deemed to be virtual as messages are not physically moved into these queues.

In Step an OS partially enabled as software instructions stored in a computer readable medium and executed by the CPU generates CPU tasks. Step buffers the CPU tasks in a computer readable task database memory. Step enqueues CPU task IDs associated with the buffered CPU tasks in a CPU queue. In Step a CPU dequeues a first task ID from the CPU queue. In Step the CPU accesses a first CPU task from the task database associated with the first CPU task ID. In Step the CPU delivers the first CPU task to the OS. In Step the OS generates CPU instructions needed to perform the first CPU task and in Step the OS sends the CPU instructions to the CPU.

In one aspect enqueuing the CPU tasks IDs in the CPU queue in Step includes enqueuing the first CPU task ID as follows 

enqueuing the first CPU task ID in a first CPU queue selected from a plurality of parallel CPU queues where the first CPU task queue is associated with the task priority field. Alternately Step may enqueue the first CPU task ID as follows 

enqueuing the first CPU task ID in a first CPU queue selected from a plurality of parallel CPU queues associated with a first CPU.

In a different aspect dequeuing the first CPU task ID from the CPU queue in Step includes the CPU selecting the first CPU queue using an algorithm such as round robin weighted round robin deficit round robin strict priority or time slice based scheduling.

In another aspect generating CPU tasks in Step includes generating CPU tasks with fields such as task database index field task priority field task CPU ID field CPU task ID and combinations of the above mentioned fields. Step may buffer CPU tasks with fields such as CPU task ID task group ID task context information task priority task scheduling policy task state task resource requirements and availability task address space task stack size task CPU mask and combinations of the above mentioned fields.

In one aspect enqueuing the CPU task IDs in the CPU task queue Step includes enqueuing the first CPU task ID in a first CPU task queue selected from a plurality of parallel CPU task queues. Then dequeuing the first CPU task ID from the CPU task queue Step includes the CPU selecting the first CPU task queue using an algorithm such as round robin weighted round robin deficit round robin strict priority or time slice based scheduling.

An OS with a hardware enabled CPU queue for CPU task scheduling has been provided with an associated method. Examples of particular process flows hardware devices and software modules have been given to illustrate the invention. However the invention is not limited to merely these examples. Other variations and embodiments of the invention may occur to those skilled in the art in light of this disclosure.

