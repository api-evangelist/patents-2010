---

title: Method and system for handling error events
abstract: Method and system for managing error related events while a system is processing input/output (“I/O”) requests for accessing storage space is provided. Various components are involved in processing the I/O requests. Some of these components may also have sub-components. Events related to the various components are classified with respect to their severity levels. Threshold values for a frequency of these events is set and stored in a data structure at a memory location. When an event occurs, the severity level and the threshold value for the event are determined from the data structure. The actual frequency is then compared to the stored threshold value. If the threshold value is violated and there is an alternate path to route the I/O request, then the affected component is restricted and the alternate path is used to route the I/O request.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08468385&OS=08468385&RS=08468385
owner: Netapp, Inc.
number: 08468385
owner_city: Sunnyvale
owner_country: US
publication_date: 20101027
---
Various forms of storage systems are used today. These forms include network attached storage NAS systems storage area networks SANs and others. SANs typically use a network of storage devices for storing information. The storage devices appear as local storage to computing systems that operate within the SAN.

Typically a SAN uses a plurality of components for providing access to storage. For example a plurality of fabric switches a plurality of adapters and other components may be used for processing input output I O requests. An I O request is typically generated by one or more computing systems to read and write information to and from a storage device. Some of these components may fail while I O requests are being processed. Continuous efforts are being made to handle errors and failure events for efficiently processing I O requests.

In one embodiment a method and system for managing error related events while a system is processing input output I O requests for accessing storage space is provided. Various components are involved in processing an I O request. Some of these components also have sub components. Events related to the various components are classified with respect to their severity levels. Threshold values for a frequency of these events is set and stored in a data structure at a memory location.

When an event occurs the severity level and the threshold value for the event are determined from the data structure. The actual frequency is then compared to the stored threshold value. If the threshold value is violated and there is an alternate path to route the I O request then the affected component is restricted and the alternate path is used to route the I O request. Other systems for example nodes within a cluster environment that use the affected component are notified of the alternate path. If there is no alternate path then the event is logged indicating a possible component failure.

In another embodiment a system is provided. The system includes a storage system coupled to a storage device and a client computing system via a plurality of components with some of the plurality of components having sub components. The plurality of components and the sub components are used for processing input output requests for reading and writing information at the storage device.

The system also includes a processor executing instructions for establishing a classification criterion for classifying error events associated with the plurality of components and establishing a threshold value for each of the plurality of components for error events associated with the plurality of components. If an event frequency for an error event associated with a component violates an associated threshold value then the usage of the component and the sub component is automatically restricted.

In yet another embodiment a machine implemented method is provided. The method includes receiving notification of an event associated with a component used in a network for processing an input output I O request for reading and writing information to a storage device determining if the component includes any sub components and determining a classification of the event to ascertain a severity level.

The method further includes determining if an event frequency for the determined classification violates a threshold value that is set for restricting a usage of the component and the sub component and restricting the usage of the component and the sub component if the set threshold value for the classified event is violated.

In another embodiment a machine implemented method is provided. The method includes identifying a plurality of components within a network used for processing input output I O requests for reading and writing information at a storage device and identifying which of the plurality of components include sub components.

The method further includes establishing a classification criteria for classifying error events associated with the plurality of components establishing a threshold value for the plurality of components for error events associated with the plurality of components and restricting usage of a component based on an error event that violates the threshold value for the component.

This brief summary has been provided so that the nature of this disclosure may be understood quickly. A more complete understanding of the disclosure can be obtained by reference to the following detailed description of the various embodiments thereof in connection with the attached drawings.

In one embodiment a method and system for managing error related events while a system is processing input output I O requests for accessing storage space is provided. Various components are involved in processing an I O request. Some of these components also have sub components. Events related to the various components are classified with respect to their severity levels. Threshold values for a frequency of these events is set and stored in a data structure at a memory location.

When an event occurs the severity level and the threshold value for the event are determined from the data structure. The actual frequency is then compared to the stored threshold value. If the threshold value is violated and there is an alternate path to route the I O request then the affected component is restricted and the alternate path is used to route the I O request. Other systems for example a node within a cluster environment that uses the affected component is notified of the alternate path. If there is no alternate path then the event is logged indicating a possible component failure.

As a preliminary note the terms component module system and the like as used in this disclosure are intended to refer to a computer related entity either software executing general purpose processor hardware firmware and a combination thereof. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer.

By way of illustration both an application running on a server and the server can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers. Also these components can execute from various computer readable media having various data structures stored thereon. The components may communicate via local and or remote processes such as in accordance with a signal having one or more data packets e.g. data from one component interacting with another component in a local system distributed system and or across a network such as the Internet with other systems via the signal .

Computer executable components can be stored for example on computer readable media including but not limited to an ASIC application specific integrated circuit CD compact disc DVD digital video disk ROM read only memory floppy disk hard disk EEPROM electrically erasable programmable read only memory memory stick flash memory device or any other non volatile memory device or any other storage device in accordance with the claimed subject matter.

Switch includes various ports A E to operationally couple different modules of system . For example port A is operationally coupled to adapter A of storage system A via a link port B is operationally coupled to adapter B of storage system B via a link . Port C is operationally coupled to an adapter port A of an adapter via a link . Port D is operationally coupled to an adapter port A of adapter via a link . Port E is used to communicate with switch .

Ports A E include logic and circuitry to handle information for example frames and packets complying with certain standard protocols for example Fibre Channel Fibre Channel over Ethernet and others. Links and are used to carry information between the various components mentioned above Switch is similar to switch and may provide alternate connection paths for processing I O requests.

Switch may also include a plurality of ports A E. Port A is operationally coupled to storage system A via link A while port B is operationally coupled to storage system B via link A. Port C is operationally coupled to storage subsystem A via link A and port D is operationally coupled to storage subsystem B via link A. Port E is operationally coupled to port E of switch .

Ports A E may also include logic and circuitry to handle information for example frames and packets complying with certain standard protocols for example Fibre Channel Fibre Channel over Ethernet and others. Similar to links and links A A A and A are used to carry information between the various components mentioned above.

Switch and provide storage systems A and B with various routing paths to access storage sub systems A and B. The routing paths may be stored in routing tables at each storage system and may also be maintained by management application .

Adapters and are used by the storage subsystems A and B to respond to I O requests from storage systems A B. Adapter ports A and A include logic and circuitry for sending and receiving information in compliance with certain standard protocols for example Fibre Channel Fibre Channel over Ethernet and others.

Storage subsystems A and B include a plurality of mass storage devices A N. The I O requests from storage system A B are typically used to read or write information to the plurality of mass storage devices A N. The mass storage devices A N in each storage subsystem may be for example conventional magnetic disks optical disks such as CD ROM or DVD based storage magneto optical MO storage flash memory storage device or any other type of non volatile storage devices suitable for storing data. The examples disclosed herein may reference a storage device as a disk but the adaptive embodiments disclosed herein are not limited to disks or any particular type of storage media device.

The storage systems A and B may be operationally coupled to a plurality of clients through a network . Each storage system receives and responds to various read and write requests from clients directed to data stored in or to be stored in a corresponding storage subsystem via switch or switch and adapters and .

Each client may be for example a conventional personal computer PC workstation or the like. The network may be for example a local area network LAN a wide area network WAN a storage area network SAN or any other type of network or a combination of networks.

Also connected to the network is a management console that may store and execute a management application may also be referred to as a storage management application . The management console may be for example a conventional PC a workstation or the like. The management application may be used by a storage network administrator to manage a pool of storage devices and various components of system for example switch switch adapters and and others as described below in more detail.

Management application is configured to collect various parameters and data from the operating systems of the storage systems and different components of system . To obtain such information communication between the management application clients and storage systems may be accomplished using any of the various conventional communication protocols and or application programming interfaces APIs the details of which are not germane to the technique being introduced here. This communication can be done through the network or it can be via a direct link not shown between the management console and the storage systems A and B.

Management Application illustrates the management application in greater detail for implementing the various processes described below according to one embodiment. In the illustrated embodiment the management application includes a graphical user interface GUI module to generate a GUI e.g. for use by an administrator a monitoring module for configuring and monitoring various components of system one or more other management modules to perform various other storage management related functions and a communication module . In another embodiment the management application may provide a command line interface CLI for use by an administrator for managing and configuring various components of system . The communication module implements one or more conventional communication protocols and or APIs to enable the management application to communicate with the storage systems clients switch switch and storage subsystems A and B.

Monitoring module maintains a monitoring data structure may also be referred to as data structure for storing information regarding various components of system . For example data structure may include a listing A of all the components of system that are used for processing I O requests for all routing paths. For example a listing of storage devices A and N switches and adapters and and links A A A and A. The routing paths itself may be included in segment A or may be include in a routing table separate from data structure . The routing table may maintained by each storage system.

Data structure includes segment B for storing information regarding components of segment A that may have sub components. For example switch or switch may be categorized as a component with ports A E as sub components in listing B. A cable or SFP Small Form Pluggable Transceiver for a port for receiving and sending frames not shown may be designated as component without any sub components and hence may only reside in listing A.

Monitoring module may also store certain threshold values in segment C or data structure C for various components and sub components. Segment C may also be used to store different event categories. The event categories classify events related to components and sub components as being minor major and critical. The classification is based on the impact of different events. The threshold values for different event categories are used to determine whether a particular component and or sub component should be restricted and an alternate path if available be used for servicing an I O request. For example if a component has N sub components and there is an error Efor M sub components. Then monitoring module may set a threshold value where if Eis greater than or equal to of N subcomponents then the component is restricted for use and an alternate path is sought. In this example if Eis greater than or equal to of N violates the set threshold value.

Monitoring module may also set up threshold values for sub components for example a number of errors reported in an hour E and a number of errors reported by a sub component in a day E . Monitoring module may set Eto a certain value for example 5 and if the number of errors within an hour is equal to or greater than 5 then the associated sub component is restricted because the set threshold value is violated. Monitoring module may configure Ein a way that if errors are seen only at a particular time during the day then the restriction is selectively applied only during that duration.

Monitoring module may also set a certain value for example 5 for Esuch that if there are 5 errors from a sub component within a day then the sub component is restricted for use because the set threshold value is violated.

It is noteworthy that the examples given above are shown only to illustrate the use of the threshold values and not limit the threshold values to any particular value. These values are programmable and can be set based on the overall operating conditions of system .

Monitoring data structure also maintains an event log D. The event log D is used to store information regarding different events and how often the events occur i.e. the frequency of the events. The use of the frequency and event information from event log D and threshold values C is described below in more detail.

In one embodiment although data structure is shown to have multiple component segments for example A D they may be included in an integrated single data structure. In a distributed architecture different components of data structure may be stored in different memory locations and may be accessible to management application via network .

Data structure may be maintained by management application at a memory location that is accessible to management application . For example the memory location may be local to the management console that executes management application or may be remote to management console .

It is noteworthy that although monitoring module and data structure have been described above with respect to management application the adaptive embodiments described herein are not limited to management application . As described below in more detail monitoring module and data structure may be executed and maintained by one or more storage systems A and or B.

The management application may also maintain policies a list of all volumes in a storage pool as well as a data structure shown as free space with information regarding all free storage space in a storage pool. Free space may include details regarding storage space that may be available for a user at any given time. In one embodiment management application may use policies volume list and free space for allocating and managing storage space in system .

The process starts in block S when an administrator sets up system . In another embodiment the configuration or re configuration may take place when system is already operational. In block S the various components in system are determined. In one embodiment this information may be ascertained by management application that communicates with various components in system . The manner in which this information is gathered depends on the protocol type. For example in a Fibre Channel SAN management application can query all the components that are connected at any given time using Fibre Channel commands.

In block S various components and their sub components of system are identified. This information is used to build segment A and B of . In one embodiment all components are first identified and then a list of components having sub components is created B . As an example switch and may be a categorized as components with sub components for example ports while a cable or SFP Small Form Pluggable Transceiver for a port not shown used by switches and may be designated as components without any sub components.

In block S in one embodiment management application may be used to set up threshold values for different components and or sub components and categorizes different events that are related to the components and sub components. The threshold values and event categories are used to determine when a component and or a sub component should be restricted such that the component and or sub component do not hinder processing of an I O request.

Event categories or classification separate events into different categories for example minor major and critical. The event categories depend on the type and functionality of the components sub components. As an example a switch may report different types of error events. The events may include congestion due to lack of credit at switch memory buffers a port being down due to a sub component failure communication failure due to a link being down and others. These events can be categorized as being minor major and critical. The threshold values are then associated with each category of events to restrict the usage of components and sub components. The following provides an example of setting the threshold values.

Assume that a component C includes n sub components and component C is represented by S where S S SS . . . S Equation 1 .

If E greater than or equal to S and if the error events are critical then a component that generates those events is restricted and an alternate path is sought to process an I O request. It is noteworthy that this restriction is applied to all storage systems nodes that use the restricted component.

If a single sub component for example a cable or a SFP reports failure events then the following threshold values may be set to restrict the sub component 

An administrator may set a value for both Eand Eto restrict the usage of the sub component. For example if Eexceeds a threshold value of 5 then the sub component is restricted when the events are critical. The value may be 10 if the events are major or 15 if the events are minor. In another example if Eoccurs during a particular time of day then the restricting principle is applied only for that duration.

In yet another example if Eexceeds a threshold of for example 5 for critical events then the sub component is restricted. The value may be 10 if the events are major or 15 if the events are minor.

It is noteworthy that the embodiments disclosed herein are not limited to any particular threshold value or event category. Different threshold values and event categories may be set based on system and user needs. The threshold values and event categories may be changed by a user using management application .

In block S management application determines if the event is related to a component with sub components. Management application uses segment B to ascertain this information. If the event is not related to a component with sub components then the process moves to block S that is described below. If the event is related to a component with sub components then the process moves to block S.

In block S management application determines whether the parent component is reporting an error of certain severity for example a major or critical error. Segment D is used to ascertain the nature of the event. If the reported event is major or critical then data regarding all the sub components is collected in block S and the process moves to block S. If the event is not a major or critical event then the process simply moves to block S.

In block S the frequency and nature of the event is compared to programmed threshold values for the event. The frequency of the event may be determined by monitoring module or monitoring module by examining the event log D. The threshold values may be set as described above with respect to equations I II. If the threshold values are violated by the event frequency and severity then in block S management application determines if there are any alternate paths for servicing the I O request. The programmed threshold values are violated if the actual error frequency for a certain severity level is equal to or exceeds the programmed threshold values.

If alternate paths are available then the affected component and or sub component are restricted for use in block S and an alternate path from available alternate paths is selected for processing the I O. The different routing paths including the alternate paths that may be used by storage system A and B to access storage sub systems A and B may be stored in a routing table as described above.

In block S the restriction is communicated to other storage systems such that alternate paths may be selected for all storage systems that use the affected components. For example with respect to if both storage systems A and B use switch to access storage and switch is the affected component then the use of switch is restricted for both storage systems A and B. In this example switch may be used as an alternate path by both storage systems A and B.

In a cluster environment described below with respect to a plurality of nodes may use a same path with the restricted component. All the nodes are notified of the restricted component in block S. This allows the nodes to seek alternate paths without the restricted component.

If there are no alternate paths then a warning message is generated in block S and the process moves back to block S for processing the next event.

In one embodiment events are categorized and thresholds are established for different event types as described above with respect to . When an error event occurs the processes described above isolate components and sub components and when available use alternate paths. This allows one to process I O requests and isolate error generating components and sub components.

The embodiments disclosed herein are especially useful in a cluster environment where various nodes are interconnected. A brief description of a cluster environment is provided below.

The process flow of described above are applicable to cluster . For example cluster uses a plurality of nodes with various components and sub components. When a component is restricted for one node then the other nodes are notified of the restriction such that the restricted component does not impair the ability of other nodes to process I O requests. Because of the notification other nodes may also be able to find alternate paths if available and hence avoid the restricted component.

Nodes comprise various functional components that cooperate to provide distributed storage system architecture of cluster . Each node is generally organized as a network element N module and a disk element D module . N module includes functionality that enables node to connect to clients over a computer network and to management application while each D module connects to one or more storage devices may generically be referred to as disks or storage array via an adapter having at least one port A. Adapter may be categorized as a parent component with sub components.

Each N module and D module may also include their own adapters logic for interfacing with each other and storage devices. described below provide examples of such adapters logic.

It should be noted that while there is shown an equal number of N and D modules in the illustrative cluster there may be differing numbers of N and or D modules in accordance with various embodiments of the present invention. For example there may be a plurality of N modules and or D modules interconnected in a cluster configuration that does not reflect a one to one correspondence between the N and D modules. As such the description of a node comprising one N module and one D module should be taken as illustrative only.

Nodes may be interconnected by a cluster switching fabric with ports A D which in the illustrative embodiment may be embodied as a Gigabit Ethernet switch. Switch may be categorized as a parent component with sub components similar to switch of .

Switch with ports A D may be used for an alternate path if a communication path via switch is restricted based on the process flow of described above in detail.

Clients similar to clients may be configured to interact with a node in accordance with a client server model of information delivery. That is each client may request the services of the node and the node may return the results for the services requested by the client by exchanging packets over the network .

For a SAN based configuration client may issue I O requests using application complying with block based access protocols such as the Small Computer Systems Interface SCSI protocol encapsulated over TCP iSCSI and SCSI encapsulated over FCP. Alternatively client may issue packets using application including file based access protocols such as the CIFS protocol or the NFS protocol over TCP IP when accessing information in the form of certain data containers. Data container means a block a file a logical unit of data or any other information. CIFS means the Common Internet File System Protocol an access protocol that client systems use to request file access services from storage systems over a network. NFS means Network File System a protocol that allows a user to access storage over a network.

Cluster also uses management application that communicates with the plurality of nodes for generating and maintaining the data structure described above with respect to . The use of data structure has been described above with respect to

The cluster access adapter comprises a plurality of ports adapted to couple node to other nodes of cluster . Cluster adapter may be categorized as a component that is monitored and managed using the process flow diagrams described above with respect to .

In the illustrative embodiment Ethernet may be used as the clustering protocol and interconnect media although it will be apparent to those skilled in the art that other types of protocols and interconnects may be utilized within the cluster architecture described herein. In alternate embodiments where the N modules and D modules are implemented on separate storage systems or computers the cluster access adapter is utilized by the N D module for communicating with other N D modules in the cluster .

Each node is illustratively embodied as a dual processor storage system executing a storage operating system that preferably implements a high level module such as a file system to logically organize the information as a hierarchical structure of named directories files and special types of files called virtual disks hereinafter generally blocks on storage devices . However it will be apparent to those of ordinary skill in the art that the node may alternatively comprise a single or more than two processor systems. Illustratively one processor A executes the functions of the N module on the node while the other processor B executes the functions of the O module .

The memory illustratively comprises storage locations that are addressable by the processors and adapters for storing programmable instructions and data structures. The processor and adapters may in turn comprise processing elements and or logic circuitry configured to execute the programmable instructions and manipulate the data structures. It will be apparent to those skilled in the art that other processing and memory means including various computer readable media may be used for storing and executing program instructions pertaining to the invention described herein.

The storage operating system portions of which is typically resident in memory and executed by the processing elements functionally organizes the node by inter alia invoking storage operations in support of the storage service implemented by the node. An example of operating system is the DATA ONTAP Registered trademark of NetApp Inc. operating system available from NetApp Inc. However it is expressly contemplated that any appropriate storage operating system may be enhanced for use in accordance with the inventive principles described herein. As such where the term ONTAP is employed it should be taken broadly to refer to any storage operating system that is otherwise adaptable to the teachings of this invention.

The network adapter comprises a plurality of ports adapted to couple the node to one or more clients over point to point links wide area networks virtual private networks implemented over a public network Internet or a shared local area network. The network adapter thus may comprise the mechanical electrical and signaling circuitry needed to connect the node to the network. Network adapter may be categorized as a component that is monitored and managed using the process flow diagrams described above with respect to . Illustratively the computer network may be embodied as an Ethernet network or a FC network. Each client may communicate with the node over network by exchanging discrete frames or packets of data according to pre defined protocols such as TCP IP.

The storage adapter cooperates with the storage operating system executing on the node to access information requested by the clients and management application . The information may be stored on any type of attached array of writable storage device media such as video tape optical DVD magnetic tape bubble memory electronic random access memory flash memory devices micro electro mechanical and any other similar media adapted to store information including data and parity information. However as illustratively described herein the information is preferably stored on the disks of storage array . The storage adapter comprises a plurality of ports having input output I O interface circuitry that couples to the disks over an I O interconnect arrangement such as a conventional high performance FC link topology. Storage adapter may also be categorized as a component that is monitored and managed using the process flow diagrams described above with respect to .

In one example operating system may include several modules or layers executed by one or both of N Module and D Module . These layers include a file system manager that keeps track of a directory structure hierarchy of the data stored in storage devices and manages read write operations i.e. executes read write operations on disks in response to client requests.

Operating system may also include a protocol layer and an associated network access layer to allow node to communicate over a network with other systems such as clients and management application . Protocol layer may implement one or more of various higher level network protocols such as NFS CIFS Hypertext Transfer Protocol HTTP TCP IP and others as described below.

Network access layer may include one or more drivers which implement one or more lower level protocols to communicate over the network such as Ethernet. Interactions between clients and mass storage devices are illustrated schematically as a path which illustrates the flow of data through operating system .

The operating system may also include a storage access layer and an associated storage driver layer to allow D module to communicate with a storage device. The storage access layer may implement a higher level disk storage protocol such as RAID redundant array of inexpensive disks while the storage driver layer may implement a lower level storage device access protocol such as FC or SCSI.

It should be noted that the software path through the operating system layers described above needed to perform data storage access for a client request received at node may alternatively be implemented in hardware. That is in an alternate embodiment of the disclosure the storage access request data path may be implemented as logic circuitry embodied within a field programmable gate array FPGA or an ASIC.

As used herein the term storage operating system generally refers to the computer executable code operable on a computer to perform a storage function that manages data access and may in the case of a node implement data access semantics of a general purpose operating system. The storage operating system can also be implemented as a microkernel an application program operating over a general purpose operating system such as UNIX or Windows XP or as a general purpose operating system with configurable functionality which is configured for storage applications as described herein.

In addition it will be understood to those skilled in the art that the invention described herein may apply to any type of special purpose e.g. file server filer or storage serving appliance or general purpose computer including a standalone computer or portion thereof embodied as or including a storage system. Moreover the teachings of this disclosure can be adapted to a variety of storage system architectures including but not limited to a network attached storage environment a storage area network and a disk assembly directly attached to a client or host computer. The term storage system should therefore be taken broadly to include such arrangements in addition to any subsystems configured to perform a storage function and associated with other equipment or systems. It should be noted that while this description is written in terms of a write any where file system the teachings of the present invention may be utilized with any suitable file system including a write in place file system.

The processing system includes one or more processors and memory coupled to a bus system . The bus system shown in is an abstraction that represents any one or more separate physical buses and or point to point connections connected by appropriate bridges adapters and or controllers. The bus system therefore may include for example a system bus a Peripheral Component Interconnect PCI bus a HyperTransport or industry standard architecture ISA bus a small computer system interface SCSI bus a universal serial bus USB or an Institute of Electrical and Electronics Engineers IEEE standard 1394 bus sometimes referred to as Firewire .

The processors are the central processing units CPUs of the processing system and thus control its overall operation. In certain embodiments the processors accomplish this by executing programmable instructions stored in memory . A processor may be or may include one or more programmable general purpose or special purpose microprocessors digital signal processors DSPs programmable controllers application specific integrated circuits ASICs programmable logic devices PLDs or the like or a combination of such devices.

Memory represents any form of random access memory RAM read only memory ROM flash memory or the like or a combination of such devices. Memory includes the main memory of the processing system . Instructions which implements the migration techniques introduced above e.g. the management application in may reside in and may be executed by processors from memory .

Also connected to the processors through the bus system are one or more internal mass storage devices and a network adapter . Internal mass storage devices may be or may include any conventional medium for storing large volumes of data in a non volatile manner such as one or more magnetic or optical based disks. The network adapter provides the processing system with the ability to communicate with remote devices e.g. storage servers over a network and may be for example an Ethernet adapter a FC adapter or the like. The processing system also includes one or more input output I O devices coupled to the bus system . The I O devices may include for example a display device a keyboard a mouse etc.

Cloud Computing The system and techniques described above are applicable and useful in the upcoming cloud computing environment. Cloud computing means computing capability that provides an abstraction between the computing resource and its underlying technical architecture e.g. servers storage networks enabling convenient on demand network access to a shared pool of configurable computing resources that can be rapidly provisioned and released with minimal management effort or service provider interaction. The term cloud is intended to refer to the Internet and cloud computing allows shared resources for example software and information to be available on demand like a public utility.

Typical cloud computing providers deliver common business applications online which are accessed from another web service or software like a web browser while the software and data are stored remotely on servers. The cloud computing architecture uses a layered approach for providing application services. A first layer is an application layer that is executed at client computers. In this example the application allows a client to access storage via a cloud.

After the application layer is a cloud platform and cloud infrastructure followed by a server layer that includes hardware and computer software designed for cloud specific services. Details regarding these layers are not germane to the inventive embodiments.

The storage systems described above can be a part of the server layer for providing storage services. Monitoring module may be executed at any system that is coupled to the cloud. Data structure may stored at a storage device coupled to the cloud. The process steps of may be executed using monitoring module and other programming instructions that may be adapted for the cloud computing environment.

Thus a method and apparatus for managing errors in a system for accessing storage have been described. Note that references throughout this specification to one embodiment or an embodiment mean that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the present invention. Therefore it is emphasized and should be appreciated that two or more references to an embodiment or one embodiment or an alternative embodiment in various portions of this specification are not necessarily all referring to the same embodiment. Furthermore the particular features structures or characteristics being referred to may be combined as suitable in one or more embodiments of the invention as will be recognized by those of ordinary skill in the art.

While the present disclosure is described above with respect to what is currently considered its preferred embodiments it is to be understood that the disclosure is not limited to that described above. To the contrary the disclosure is intended to cover various modifications and equivalent arrangements within the spirit and scope of the appended claims.

