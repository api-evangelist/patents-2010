---

title: In-memory database system
abstract: A computer system includes a memory and a processor coupled to the memory. The processor is configured to execute instructions that cause execution of an in-memory database system that includes one or more database tables. Each database table includes a plurality of rows, where data representing each row is stored in the memory. The in-memory database system also includes a plurality of indexes associated with the one or more database tables, where each index is implemented by a lock-free data structure. Update logic at the in-memory database system is configured to update a first version of a particular row to create a second version of the particular row. The in-memory database system includes a non-blocking garbage collector configured to identify data representing outdated versions of rows.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09251214&OS=09251214&RS=09251214
owner: Microsoft Technology Licensing, LLC
number: 09251214
owner_city: Redmond
owner_country: US
publication_date: 20100408
---
Many database systems include storage engines that were designed based on the assumption that data is stored on a disk and paged in and out of main memory when required for processing. As a result of the growth in main memory capacity it may be possible to store many databases entirely in memory. Furthermore there is a trend toward more processors i.e. central processing unit CPU cores in computer systems.

Existing in memory storage engines are unlikely to achieve maximal performance on current and future servers e.g. multi core machines . Existing in memory storage engines use one or more frequently accessed data structures and protect shared data by locks and latches. This may limit the level of concurrency and the total throughput of the system e.g. the locks and latches may become bottlenecks .

Many database systems have storage engines that were designed assuming that data would be stored on disk and frequently paged in and out of memory. Main memories are becoming large enough that many databases can be stored entirely in memory. Furthermore there is a trend toward more processors CPU cores in modern computer systems which may increase the need to efficiently scale across a large number of processors.

The present disclosure describes an in memory database system e.g. a database stored entirely in a main memory of a computer system designed for modern multi processor computer systems. The in memory database system is designed to improve efficiency to allow a high degree of concurrency and to provide full transaction support for modern multi processor computer systems. For example the in memory database system may avoid bottlenecks associated with commonly accessed data structures such as locks and latches. Full transaction support may include atomicity consistency isolation and durability e.g. ACID support.

The in memory database system disclosed herein may utilize a combination of lock free data structures versioning of database table rows a non blocking multi version concurrency control scheme and a non blocking cooperative technique for garbage collection and may execute transactions without blocking and thread switching.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

In a particular embodiment a computer system is disclosed that includes a memory and a processor coupled to the memory. The processor is configured to execute instructions that cause execution of an in memory database system that includes one or more database tables. Each database table includes a plurality of rows where data representing each row of the plurality of rows is stored in the memory. The in memory database system also includes a plurality of indexes associated with the one or more database tables. Each index of the plurality of indexes is implemented by a lock free data structure. The in memory database system further includes update logic configured to update a first version of a particular row to create a second version of the particular row. The in memory database system also includes a non blocking garbage collector configured to identify and deallocate data representing outdated versions of rows. These features enable the database system to execute a transaction without blocking thereby avoiding the overhead of thread switching.

In another particular embodiment a method includes receiving a request to execute a transaction at an in memory database system where the transaction is configured to update one or more rows of the in memory database system. The method includes determining a start timestamp for the transaction and identifying a first version of the one or more rows to be updated. The method further includes updating the first version of the one or more rows to create a second version of the one or more rows at the memory. The method includes determining an end timestamp for the transaction and committing the transaction. The second version of the one or more rows is added to one or more indexes of the in memory database system and the first version of the one or more rows is deallocated by a non blocking garbage collector of the in memory database system when the first version is no longer required by any transaction.

In another particular embodiment a computer readable storage medium includes processor executable instructions. When executed by a processor the instructions cause the processor to execute a non blocking garbage collector GC . The GC is configured to determine an oldest active transaction at an in memory database system by finding an active transaction having an earliest start timestamp. The GC is also configured to identify one or more terminated transactions having end timestamps earlier than the start timestamp of the oldest active transaction. The GC is further configured to for each of the identified one or more terminated transactions determine whether the terminated transaction is committed or aborted. When the terminated transaction is committed the GC marks old versions of rows updated by the terminated transaction as garbage. When the terminated transaction is aborted the GC marks new versions of rows created by the terminated transaction as garbage. An execution thread that encounters a version marked as garbage may disconnect the version from one or more indexes and deallocate the version when it is no longer connected to any index. The GC is configured to track versions of rows marked as garbage that have not been deallocated from a memory. The GC is also configured to dispatch one or more sweeper threads of the in memory database system to deallocate tracked versions of rows marked as garbage that have not been deallocated by execution threads of the in memory database system.

Main memories for servers typically grow at a rate that exceeds the rate of growth in typical OLTP database sizes. This suggests that at some point in the future many OLTP databases may either fit entirely in main memory or a significant percentage of their working set may fit in main memory especially if a cluster of machines is considered. At present a 1 terabyte TB OLTP database may be considered large while operating systems may support 2 TB of installed physical memory with no major impediment to extending that limit even further.

There are several consequences that may be derived from the principles enunciated above. A first consequence is that a system that has abundant main memory may have little use for a paging system. The reason for paging or for a buffer pool is to offer the illusion of infinite or very large memory. If the memory is large enough use of buffer pool pages may not be necessary.

A second consequence is that without a policy that uses buffer pool pages there may be no reason to store undo records in a database log. Moreover log records can be purely logical and can be grouped and written together at transaction commit time. In other words each commit may incur a single input output I O operation that contains the redo records associated with that transaction alone. A global commit order may be sufficient to recover from the transaction log streams. It may be possible to harden these transaction log streams to different devices. Recovery may involve a merge sort of the streams from each log device. Such logical logging may simplify many areas of the system e.g. mirroring replication and backup .

A third consequence is that without a buffer pool there may not be a reason to keep rows clustered in memory in the same page format used on disk. Rows stored on pages may cause a number of difficulties. For example they may involve latching of full pages for access split merge page logic page re arrangement code to accommodate insertion and deletion of rows in the middle of the page and a B Tree or heap layout for search traversal. For in memory lookup B Trees may not be the most efficient data structure available so there may be a performance penalty associated with this layout. Moreover page re arrangement splits and merges may lead to rows being moved around such that rows can no longer be identified and de referenced by virtual address. As such another level of indirection and additional cost may be added to reach any row. To avoid this rows may be stored in their own memory unrelated to any clustering unit such as the page .

Data representing each row of the plurality of rows is stored in the memory . In one embodiment the data representing each row includes a fixed size portion of the memory and the fixed size portion of the memory includes a fixed size data structure in accordance with a row schema. In another embodiment the data representing each row also includes a variable size portion of the memory and the fixed size portion includes a link to the variable size portion. The variable size portion of the memory may be located at a heap storage area of the memory see heap of below . In one embodiment one data portion can point to another data portion e.g. when the row data is large .

The execution threads may execute transactions performing retrieval insertions updates and deletions at the in memory database system in accordance with a row versioning and concurrency control scheme. Each row of the database table may be associated with one or more particular versions where each particular version has a valid time. When a transaction updates a particular row a new version of the particular row may be created. In a particular embodiment transactions may be classified as active transactions or terminated transactions. Terminated transactions may include committed transactions and aborted transactions. Transactions may be aborted due to errors commit dependencies or another reason. For example a transaction Tx may read data written by another transaction Tx. The transaction Tx may have a commit dependency on Tx. If Tx fails or aborts for any reason Tx is also required to abort. On the other hand if Tx terminates before Tx the execution thread processing Tx may move on to a new transaction and the execution thread processing Tx may complete processing of Tx. In this way execution threads do not need to block but continue executing as long as there is work to be done. Non blocking transaction execution may reduce context switches at the in memory database system thereby conserving resources e.g. processor cycles .

The transaction map stored in the memory may be configured to track active transactions at the in memory database system. In one embodiment the transaction map contains pointers to transaction objects similar to a transaction object . The transaction object may include two timestamps defining the transaction s lifetime e.g. a start timestamp and an end timestamp and a transaction log including a sequence of operations plus a pointer to record versions affected by the operation. An operation may be a delete of a version e.g. an old version or an insert of a version e.g. a new version . In the embodiment illustrated in the transaction log of transaction object contains an insert operation of a version e.g. including a link to data representing version . The transaction log also contains a delete operation of a version e.g. including a link to data representing version . Additional operations may also be performed. For example the transaction log of transaction object may include a third database operation with respect to one of the plurality of versions that includes a link to the affected version. Similarly the transaction log of transaction object may include a fourth database operation with respect to one of the plurality of versions that includes a link to that version.

The in memory database system may operate in accordance with a concurrency control scheme. For example versions of rows having valid times that overlap with the transaction lifetime of a particular active transaction may be visible to the particular active transaction but versions of rows having valid times that do not overlap with the transaction lifetime of the particular active transaction may not be visible to the particular active transaction. Thus multiple versions of a particular row may be operated upon by the execution threads at any given time. Updating a particular row may include creating a new updated version of the particular row. Reading from a particular row may include identifying an appropriate version e.g. based on an as of read time specified by a particular transaction or a latest version visible to a particular transaction of the particular row.

Transaction isolation i.e. logical stability may be implemented at an in memory database system via versioning. In one embodiment all versions of a row are stored on the same lock free data structure. Higher level isolation modes e.g. repeatable read serializable may be based on plain versioning. This approach may provide the benefit of an implementation that does not penalize most users for the cost of higher isolation modes.

In a particular embodiment cursors are used to access tables of the in memory database system. A cursor may be a software class that abstracts database operations on the table. The cursor may implement two classes of operations i.e. interfaces . A first class of operations may be a database search operation that includes a point lookup followed by subsequent iteration. A second class of operation may be a database modify operation e.g. a database insert operation a database update operation and a database delete operation that is position agnostic.

The garbage collector GC may identify data representing outdated versions of rows at the in memory database system. In a particular embodiment a GC thread identifies outdated versions of rows by determining an oldest active transaction at the in memory database system by finding an active transaction having an earliest start timestamp. Scanning the transaction map may be sufficient for obtaining the oldest active transaction in the system. Instead of a single GC thread it is also possible to run multiple GC threads in parallel.

Once the oldest active transaction is determined the GC thread may identify one or more terminated transactions having end timestamps that are earlier than the start timestamp of the identified oldest active transaction. In a particular embodiment the in memory database system divides transactions into generations and the GC thread identifies generations of terminated transactions that are older than the identified oldest active transaction. For each of the identified terminated transactions the GC thread determines whether the terminated transaction is committed or aborted. When the terminated transaction is committed the GC thread marks old versions of rows tracked in the terminated transaction s log as garbage. When the terminated transaction is aborted e.g. due to an error the GC thread marks new versions of rows tracked in the terminated transaction s log as garbage.

Garbage collection at the in memory database system may be a cooperative process. The execution threads may deposit completed transactions in per CPU communication queues that may be periodically consumed by the GC thread . When the execution threads encounter a version of a row that has been marked as garbage the execution threads may deallocate the version of the row. Besides marking versions of rows as garbage the GC thread may also maintain a garbage table to track versions of rows that have been marked as garbage but that have not been deallocated by the execution threads . Periodically the GC may dispatch one or more sweeper threads to deallocate versions of rows identified by the garbage table . Thus the garbage table may enable deallocation of garbage that is not encountered by the execution threads thereby preventing unnecessary storage of versions no longer needed.

Referring to a computer system configured to execute instructions that cause execution of an in memory database system is illustrated at . Many of the elements of correspond to the elements of . illustrates further aspects of the runtime model of the present disclosure.

In a sample row format of a record associated with a particular row e.g. row is illustrated. The sample row format of the record includes a fixed portion and a variable portion stored in a memory heap . The sample row format of the record contains links and and a non interpreted image of an end user row schema e.g. an integer Id field and a floating point Price field .

The log manager may assemble multiple pages belonging to multiple transactions in a single log arena e.g. log buffer . Each log arena may be the subject of a single asynchronous I O to the log device submitted via a WriteFileGather application programming interface API . The log arena size i.e. the number of pages in the arena may be determined dynamically based on the computed throughput for the log device. The log stream may keep a history of the number of recently submitted pages. The log stream may also record the number of committed transactions that have exited the current log stream in a fixed time interval e.g. three seconds . If the throughput of the system increases relative to the recorded history the log stream may continue to push the arena size target in the same direction as the previous change. In other words if the arena target size was previously growing the log stream may continue to grow it while if the arena target size was shrinking the log stream may continue to shrink it. In one embodiment the amount of the adjustment to the log arena size is random.

If on the other hand the throughput of the current log stream decreases the log stream may change the direction of the target adjustment. For example the log stream starts growing the target if it was previously shrinking and starts shrinking the target if it was previously growing. A local target arena size that efficiently utilizes the log device may thus be determined. Since an arena contains the log records from one or more transactions this approach may also result in implementation of a throughput directed group commit.

A log stream may contain two lists of buffers one list of submitted I Os and another list of overflow I Os. The submitted list may be protected via locks. If a thread completing validation cannot acquire a lock to the submitted I O list the thread may append its buffers to the overflow list. On the other hand threads that run under the protection of the submitted list lock may be responsible for picking up items from the overflow list and adding them to the submitted list. This approach may allow the execution threads to proceed without blocking. For example one of the execution threads that can acquire the submitted I O lock cooperatively can pick up and complete the work of other execution threads that could not obtain the submitted I O lock. Execution threads unable to obtain the I O lock may have returned to transaction processing on behalf of another user.

The method includes receiving a request to execute a transaction at an in memory database system at . The transaction is configured to update one or more rows of the in memory database system. For example in one of the execution threads may receive a request to execute the transaction .

The method also includes determining a start timestamp for the transaction at . For example in the start timestamp may be determined. The method further includes identifying a first version of the one or more rows that are to be updated at .

The method includes updating the first version of the one or more rows to create a second version of the one or more rows at . The second version of the one or more rows is added to one or more indexes of the in memory database system. For example in a second version of the one or more rows may be created at the memory and the second version of the one or more rows may be added to the indexes .

The method includes determining an end timestamp for the transaction at and committing the transaction at . The first version of the one or more rows is later deallocated by a non blocking garbage collector of the in memory database system when the first version becomes outdated. For example in the end timestamp may be determined the transaction may be committed and the GC may deallocate the first version of the one or more rows when the first version becomes outdated.

It will be appreciated that the method of may enable transaction execution at a database system in accordance with a row versioning scheme and a concurrency control scheme. It will thus be appreciated that the method of may be utilized to execute multiple concurrent transactions at a database system stored entirely in memory e.g. RAM .

The method includes at a non blocking garbage collector of an in memory database system determining an oldest active transaction having an earliest timestamp at . Determining the oldest active transaction includes scanning a transaction map for a first earliest timestamp associated with a first active transaction at . For example in the GC thread may scan the transaction map . Determining the oldest active transaction may also include scanning one or more thread local storage TLS locations for a second earliest start timestamp that is associated with a second active transaction at . For example in the GC thread may scan TLS locations associated with one or more of the execution threads . The oldest active transaction may be determined as the earlier of the first transaction and the second transaction at .

The method also includes identifying one or more terminated transactions having end timestamps earlier than the start timestamp of the oldest active transaction at . The method further includes for each of the identified one or more terminated transactions marking tracked versions of rows as garbage at . At a determination may be made as to whether each of the terminated transactions was committed or aborted. When the terminated transaction was committed old versions of rows tracked by the terminated transaction may be marked as garbage at . When the terminated transaction was aborted new versions of rows tracked by the terminated transaction may be marked as garbage at .

The method includes tracking versions of rows marked as garbage that have not been deallocated from a memory at . For example in the garbage table may be maintained to track versions of rows marked as garbage that have not been deallocated from the memory . The method also includes dispatching one or more sweeper threads to deallocate the tracked versions of rows marked as garbage that are not deallocated by execution threads at . For example in the sweeper threads may be dispatched.

It will be appreciated that the method of may enable cooperative non blocking garbage collection at a database system. It will thus be appreciated that the method of may help prevent memory leaks at a database system stored entirely in main memory.

The computing device includes at least one processor and a system memory . For example the system memory may include the memory of . Depending on the configuration and type of computing device the system memory may be volatile such as random access memory or RAM non volatile such as read only memory or ROM flash memory and similar memory devices that maintain stored data even when power is not provided or some combination of the two. The system memory typically includes an operating system one or more application platforms one or more applications and other program instructions. For example the system memory includes one or more database tables . The one or more database tables may include the database table of and .

The system memory may also include garbage collection instructions deallocation instructions and timestamp scanner instructions . For example the garbage collection instructions and the timestamp scanner instructions may be associated with execution of the GC thread of and e.g. to determine an oldest active transaction . As another example the deallocation instructions may be associated with execution of the one or more sweeper threads of and FIG. . The system memory may further include update and read logic . The update and read logic may be configured to update a first version of a particular row to create a second version of the particular row and to read data from a particular row by identifying an appropriate version of the particular row.

The computing device may also have additional features or functionality. For example the computing device may also include removable and or non removable additional data storage devices such as magnetic disks optical disks tape and standard sized or flash memory cards. Such additional storage is illustrated in by removable storage and non removable storage . Computer storage media may include volatile and or non volatile storage and removable and or non removable media implemented in any technology for storage of information such as computer readable instructions data structures program components or other data. The system memory the removable storage and the non removable storage are all examples of computer storage media. The computer storage media includes but is not limited to RAM ROM electrically erasable programmable read only memory EEPROM flash memory or other memory technology compact disks CD digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium that can be used to store information and that can be accessed by the computing device . Any such computer storage media may be part of the computing device .

The computing device may also have input device s such as a keyboard mouse pen voice input device touch input device etc. Output device s such as a display speakers printer etc. may also be included. The computing device also contains one or more communication connections that allow the computing device to communicate with other computing devices over a wired or a wireless network.

It will be appreciated that not all of the components or devices illustrated in or otherwise described in the previous paragraphs are necessary to support embodiments as herein described. For example the removable storage may be optional.

The illustrations of the embodiments described herein are intended to provide a general understanding of the structure of the various embodiments. The illustrations are not intended to serve as a complete description of all of the elements and features of apparatus and systems that utilize the structures or methods described herein. Many other embodiments may be apparent to those of skill in the art upon reviewing the disclosure. Other embodiments may be utilized and derived from the disclosure such that structural and logical substitutions and changes may be made without departing from the scope of the disclosure. Accordingly the disclosure and the figures are to be regarded as illustrative rather than restrictive.

Those of skill would further appreciate that the various illustrative logical blocks configurations modules and process steps or instructions described in connection with the embodiments disclosed herein may be implemented as electronic hardware or computer software. Various illustrative components blocks configurations modules or steps have been described generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. Skilled artisans may implement the described functionality in varying ways for each particular application but such implementation decisions should not be interpreted as causing a departure from the scope of the present disclosure.

The steps of a method described in connection with the embodiments disclosed herein may be embodied directly in hardware in a software module executed by a processor or in a combination of the two. A software module may reside in computer readable media such as random access memory RAM flash memory read only memory ROM registers a hard disk a removable disk a CD ROM or any other form of storage medium known in the art. An exemplary storage medium is coupled to a processor such that the processor can read information from and write information to the storage medium. In the alternative the storage medium may be integral to the processor or the processor and the storage medium may reside as discrete components in a computing device or computer system.

Although specific embodiments have been illustrated and described herein it should be appreciated that any subsequent arrangement designed to achieve the same or similar purpose may be substituted for the specific embodiments shown. This disclosure is intended to cover any and all subsequent adaptations or variations of various embodiments.

The Abstract of the Disclosure is provided with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition in the foregoing Detailed Description various features may be grouped together or described in a single embodiment for the purpose of streamlining the disclosure. This disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather as the following claims reflect inventive subject matter may be directed to less than all of the features of any of the disclosed embodiments.

The previous description of the embodiments is provided to enable a person skilled in the art to make or use the embodiments. Various modifications to these embodiments will be readily apparent to those skilled in the art and the generic principles defined herein may be applied to other embodiments without departing from the scope of the disclosure. Thus the present disclosure is not intended to be limited to the embodiments shown herein but is to be accorded the widest scope possible consistent with the principles and novel features as defined by the following claims.

