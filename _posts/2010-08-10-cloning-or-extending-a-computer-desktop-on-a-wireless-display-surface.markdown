---

title: Cloning or extending a computer desktop on a wireless display surface
abstract: Techniques are provided for cloning a computer desktop to a wireless display surface. A source computer and a display in communication with a destination computer establish a wireless connection. A user console session of the source computer has a virtual display driver that corresponds to the wireless display. An application of the console session instructs the virtual display driver to render graphics to a display surface. The source computer takes this graphical information that, when executed on a processor generate an image, text, sound or inputâ€”encodes it with a remote presentation protocol. Through encoding and decoding image data, text, sound, and input of the user console session transmitted to a wireless display with a remote presentation protocol, fidelity and interactivity are improved.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08839112&OS=08839112&RS=08839112
owner: Microsoft Corporation
number: 08839112
owner_city: Redmond
owner_country: US
publication_date: 20100810
---
It has been common to share a computer desktop and applications with a remote client using remote presentation protocol RPP technologies such as Remote Desktop Protocol RDP and Independent Computing Architecture ICA . Such shared computing systems typically are established through instantiating a user session for the RPP session on the server of the session. Where the server s screen is to be shared with a client of the session the RPP session obtains that information from a console session that is local to the server. During the RPP session the client transmits the keyboard presses and mouse clicks or selections to the server and the server sends screen updates back in the other direction to the client over a network connection e.g. the INTERNET . As such the user of the client has the experience as if his or her computer is executing the applications locally when in reality the client computer is only sent screenshots of the applications as they appear on the server side.

It has also been common for a computer to display images on a display device such as a television or a monitor via a cable such as a composite RCA cable or a High Definition Multimedia Interface HDMI cable. There also exists technology that enables a computer to display images on a display device wirelessly. There are many issues with displaying images on wireless devices some of which are well known.

The present invention provides improved techniques to display screen data and enable the computer desktop experience on wireless displays. As used herein screen data may comprise images to be displayed on a monitor such as a computer desktop audio to be played through one or more speakers and input to a computer such as movement of a cursor manipulation of a multi touch track pad or keyboard presses . Screen data that is sent to a destination computer and output thereon will be referred to with terms such as being displayed output or presented and this may include the output of audio through one or more speakers. Prior art techniques suffer from constraints in bandwidth and buffering which negatively impact both fidelity the quality of the displayed screen data and interactivity the rate at which a change to the screen data is displayed on the wireless display . It would therefore be an improvement over the prior techniques to provide techniques for wireless displays that offer a high level of fidelity and interactivity. In doing so a wireless display configuration may provide as a computer desktop experience to a user that is nearly identical to what the user experiences when using a monitor connected to a source computer directly through a cable.

As used herein the term wireless display is not intended to convey that the display has no wires but rather that there is not a continuous wire between the wireless display and the source computer that the source computer uses to transmit images to the wireless display. In an embodiment a source computer and a destination computer that is in communication with a wireless display establish a wireless connection and the source computer has a virtual display driver that corresponds to the wireless display similar to how a conventional graphics display driver corresponds to a wired display of the source computer . A user who is directly using the source computer has a user console session on that source computer. In that user console session the user executes applications. Those applications execute to produce graphics such as an application window on a computer desktop and to produce those graphics for the wireless display an application instructs the virtual display driver to render graphics to a memory area or a display surface of the source computer. The source computer takes this graphical information be it an image or computer executable instructions that when executed on a processor generate an image encodes it with a remote presentation protocol RPP and sends it to the wireless display from the user console session.

Other techniques for using a RPP to transmit data require more than one user session to do so. For instance versions of the terminal server RPP require a client computer to connect to the source computer with a second user session. Then to share the user console session s computer desktop with the client computer the second user session intercepts screen data from the user console session and sends it to the client and injects user input e.g. cursor movements from the client computer into the user console session.

In using the present techniques the paradigm is changed from a conventional RPP session. A conventional RPP session comprises a user at a client computer sending input to the server and receiving images back. In contrast under the present techniques the user is logged into the console of the source computer where he or she makes input into the server and then the screen data generated from that local input is transmitted to the destination computer for display.

As a result of transmitting RPP data with a single user session on the source computer the process of the source computer encoding screen data with a remote presentation protocol RPP and the display computer decoding the screen data with the remote RPP occurs outside of a conventional remote presentation session. That is in a remote presentation session a server may authorize a client s credentials and create a separate user session on the server in which the remote presentation session occurs. In contrast in the present invention while screen data is encoded according to a remote presentation protocol other operations commonly associated with a remote presentation session like creating a separate operating system session may not occur.

There exist operating systems that include sessions in addition to conventional user sessions. For instance versions of the MICROSOFT WINDOWS operating system contain a session 0 in which system services are executed but no user processes are executed. These session 0 system services may include a RPP service that encodes and transmits screen data. The discussion of this invention that discusses the use of a single user session should not be read to exclude embodiments of the invention that include non user sessions such as session 0.

Through encoding and decoding image data transmitted to a wireless display with a remote presentation protocol fidelity and interactivity are improved. These operations may reduce the amount of bandwidth and buffering necessary to transmit the screen data across a wireless communications network. In using less bandwidth to transmit screen data bandwidth is then available to transmit screen data in higher fidelity. Likewise in using less bandwidth to transmit screen data that screen data be transmitted to a wireless display in a nearer amount of time to when it is generated improving interactivity. Similarly by reducing the amount of buffering needed to encode the screen data such as by using lower latency codecs interactivity is improved.

The virtual device driver may be both extended and duplicated cloned to the wireless display surface. To the source computer the virtual display driver may be treated as equivalent to the graphics device driver of any monitor physically coupled to the source computer. Graphics commands from the virtual display driver are taken encoded and transmitted to the wireless display computer where they are decoded. The wireless display computer may comprise a lightweight decoding component that is configured to decode and render graphics. This wireless display computer may further comprise an integrated circuit that is part of the wireless display.

While the primary embodiment discussed herein involves transmitting screen data to a wireless display it may be appreciated that these techniques may be applied across other communications channels where fidelity and interactivity are constrained. For instance these techniques may be applied where a source computer communicates with a monitor over a Universal Serial Bus 2.0 USB 2.0 connection.

It can be appreciated by one of skill in the art that one or more various aspects of the invention may include but are not limited to circuitry and or programming for effecting the herein referenced aspects of the present invention the circuitry and or programming can be virtually any combination of hardware software and or firmware configured to effect the herein referenced aspects depending upon the design choices of the system designer.

The foregoing is a summary and thus contains by necessity simplifications generalizations and omissions of detail. Those skilled in the art will appreciate that the summary is illustrative only and is not intended to be in any way limiting.

Embodiments may execute on one or more computer systems. and the following discussion are intended to provide a brief general description of a suitable computing environment in which the disclosed subject matter may be implemented.

The term circuitry used throughout the description can include hardware components such as hardware interrupt controllers hard drives network adaptors graphics processors hardware based video audio codecs and the firmware used to operate such hardware. The term circuitry can also include microprocessors application specific integrated circuits and or one or more logical processors e.g. one or more cores of a multi core general processing unit configured by instructions read from firmware and or software. Logical processor s can be configured by instructions embodying logic operable to perform function s that are loaded from memory e.g. RAM ROM firmware and or mass storage. In an example embodiment where circuitry includes a combination of hardware and software an implementer may write source code embodying logic that is subsequently compiled into machine readable code that can be executed by a logical processor. Since one skilled in the art can appreciate that the state of the art has evolved to a point where there is little difference between hardware implemented functions or software implemented functions the selection of hardware versus software to effectuate herein described functions is merely a design choice. Put another way since one of skill in the art can appreciate that a software process can be transformed into an equivalent hardware structure and a hardware structure can itself be transformed into an equivalent software process the selection of a hardware implementation versus a software implementation is left to an implementer.

Referring now to an exemplary general purpose computing system is depicted. The general purpose computing system can include a conventional computer or the like including at least one processor or processing unit a system memory and a system bus that communicative couples various system components including the system memory to the processing unit when the system is in an operational state. The system bus may be any of several types of bus structures including a memory bus or memory controller a peripheral bus and a local bus using any of a variety of bus architectures. The system memory can include read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within the computer such as during start up is stored in ROM . The computer may further include a hard disk drive for reading from and writing to a hard disk not shown a magnetic disk drive for reading from or writing to a removable magnetic disk and an optical disk drive for reading from or writing to a removable optical disk such as a CD ROM or other optical media. The hard disk drive magnetic disk drive and optical disk drive are shown as connected to the system bus by a hard disk drive interface a magnetic disk drive interface and an optical drive interface respectively. The drives and their associated computer readable media provide non volatile storage of computer readable instructions data structures program modules and other data for the computer . Although the exemplary environment described herein employs a hard disk a removable magnetic disk and a removable optical disk it should be appreciated by those skilled in the art that other types of computer readable media which can store data that is accessible by a computer such as flash memory cards digital video disks random access memories RAMs read only memories ROMs and the like may also be used in the exemplary operating environment. Generally such computer readable storage media can be used in some embodiments to store processor executable instructions embodying aspects of the present disclosure.

A number of program modules comprising computer readable instructions may be stored on computer readable media such as the hard disk magnetic disk optical disk ROM or RAM including an operating system one or more application programs other program modules and program data . Upon execution by the processing unit the computer readable instructions cause the actions described in more detail below to be carried out or cause the various program modules to be instantiated. A user may enter commands and information into the computer through input devices such as a keyboard and pointing device . Other input devices not shown may include a microphone joystick game pad satellite disk scanner or the like. These and other input devices are often connected to the processing unit through a serial port interface that is coupled to the system bus but may be connected by other interfaces such as a parallel port game port or universal serial bus USB . A display or other type of display device can also be connected to the system bus via an interface such as a video adapter . In addition to the display computers typically include other peripheral output devices not shown such as speakers and printers. The exemplary system of also includes a host adapter Small Computer System Interface SCSI bus and an external storage device connected to the SCSI bus .

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be another computer a server a router a network PC a peer device or other common network node and typically can include many or all of the elements described above relative to the computer although only a memory storage device has been illustrated in . The logical connections depicted in can include a local area network LAN and a wide area network WAN . Such networking environments are commonplace in offices enterprise wide computer networks intranets and the Internet.

When used in a LAN networking environment the computer can be connected to the LAN through a network interface or adapter . When used in a WAN networking environment the computer can typically include a modem or other means for establishing communications over the wide area network such as the Internet. The modem which may be internal or external can be connected to the system bus via the serial port interface . In a networked environment program modules depicted relative to the computer or portions thereof may be stored in the remote memory storage device. It will be appreciated that the network connections shown are exemplary and other means of establishing a communications link between the computers may be used. Moreover while it is envisioned that numerous embodiments of the present disclosure are particularly well suited for computerized systems nothing in this document is intended to limit the disclosure to such embodiments.

A user s session including application executes in user mode a mode where processes cannot access the memory of other processes save for through application programming interface API functions or commands. Processes in user mode also cannot interfere with interrupts or context switching. When application draws to a display surface application sends a graphics API command to graphics subsystem . Graphics subsystem comprises window manager which controls the placement and appearance of windows within an operating system s desktop and graphics device interface GDI which is responsible for representing graphical objects and transmitting to an output device such as a computer monitor. Graphics subsystem executes in kernel mode sometimes referred to as system mode a mode in which any process may execute any instruction and reference any memory address.

Draw commands can be received from applications including a subcomponent of an operating system that is responsible for creating the desktop and be processed by graphics device interface . Graphics device interface in general can include a process that can generate graphical object draw commands. Graphics device interface in this example embodiment can be configured to pass its output to the display driver that is attached to the session.

When graphics subsystem has processed the graphics API command received from application to produce a result such as a bitmap stored in a memory address graphics subsystem sends the result to graphics device driver . Graphics device driver is a process that communicates with the output device through a communications subsystem. When graphics subsystem invokes a routine in graphics device driver graphics device driver issues commands to the output device and an image is produced on that output device.

Application user mode graphics subsystem window manager graphics device interface and kernel mode may be similar to application user mode graphics subsystem window manager graphics device interface and kernel mode as depicted in respectively. While depicts that several operations are performed by software processes it may be appreciated that they may be performed by hardware or a combination of hardware and software. For instance similar operations may be performed by an application specific integrated circuit ASIC that decodes graphics data prior to it being displayed on a wireless display .

Virtual device driver is a device driver configured to issue commands to a wireless display surface in a manner similar to how graphics device driver is configured to issue commands to output device . Virtual device driver may communicate with wireless display surface via a wireless connection such as a Wireless Display connection depicted as communication path . An example wireless display connection protocol enables devices to create ad hoc networks to communicate with each other without prior setup or the use of separate wireless access points. In a common scenario a source computer and a wireless display surface discover each other with source computer taking the role of a soft access point AP . The wireless display surface may participate in this operation of discovery through the use of a destination computer that is connected to the wireless display surface through a cable such as a HDMI cable or through a destination computer that is built into the wireless display surface . After discovery confirmation of creating a wireless display connection may be established through user input at source computer such as pressing a particular button on a keyboard or the input of a short alphanumeric code displayed on the wireless display surface .

Virtual device driver audio driver which receives audio data from application and input driver which receives user input from an input device communicate with remote presentation protocol RPP encoder . Graphics data from application passes along communication channel between the application and the graphics subsystem and then communication channel between the graphics subsystem and the virtual display driver . Audio commands generated from application are passed from application to audio driver along communication channel . RPP encoder is configured to compress screen data including images sound and input according to a RPP. While RPP encoder is depicted here as receiving graphics data from graphics device interface it may be appreciated that RPP encoder may receive graphics data from a variety of areas within computer such as a media file stored on a disk a graphics command like a DIRECTX command a composition image from a graphics subsystem or an animation image or command from an animation subsystem. A RPP used by RPP encoder may to classify the screen data to compress it with different encoding techniques applicable to the specifics of particular screen data thereby improving the fidelity and or interactivity of the screen data being presented.

Bandwidth may be conserved when encoding screen data with a RPP in a variety of ways. For instance an image may be subdivided into tiles and only those tiles that change between images dirty tiles may be sent. When tiles are received by a client the client may cache the tiles then the server may instruct the client to re use cached tiles instead of the server sending identical tiles. Where windows are moved or scrolled that information may be determined and the server may instruct the client to re use the identical information corresponding to that window move or scroll between a previously received image frame and a new image frame. Another way to conserve bandwidth is rather than sending the graphical result of rendering a graphics command such as a resultant bitmap image the server may send the graphics commands themselves which are then rendered by the client. Where graphics rather than graphics commands are sent these graphics may be compressed such as via a H.264 encoder and a single desktop frame may be compressed with multiple codecs. For instance the text on a computer desktop may be compressed with a first codec whereas the images on that same computer desktop may be compressed with a second codec. These are some techniques that may be used by a remote presentation protocol but the techniques described herein do not make up an exhaustive list of such techniques.

Upon being encoded with remote presentation encoder the encoded screen data is transmitted to destination computer in adherence with the communication protocol with which source computer and wireless destination computer communicate such as a IEEE 802.11n protocol . The encoded screen data transmitted across this communication channel appears on the channel to be RPP data. That is where the data is transmitted as a plurality of packets each packet appears to be a RPP packet.

Destination computer may comprise logic and or circuitry configured to decode RPP data received from source computer . As depicted destination computer comprises lightweight RPP decoder . Lightweight RPP decoder may comprise a software process executed on a general purpose CPU that is receives RPP packets from a network interface of destination computer . Lightweight RPP decoder is configured to decode received RPP data and display it on wireless display . Lightweight RPP decoder may offload some of this decoding to hardware decoders such as depicted HW decoders A and B. A hardware decoder may comprise for example specialized hardware configured to decode RemoteFX encoded data or H.264 encoded data. Lightweight RPP decoder may be considered lightweight because does not contain logic to process aspects of a conventional RPP session. For instance Lightweight RPP decoder may not contain logic to initiate or terminate a RPP session to store and or transmit user credentials to a RPP server to validate a RPP session to encode screen data or receive screen data including images sounds that is input locally at destination computer .

Interactivity may be further improved by assigning a priority to portions of a desktop that correspond to user input. This is because someone viewing a desktop may be drawn to those portions of the desktop that correspond to user input so the rate at which these portions are updated may impact that person s impression of interactivity more than the rate at which other portions of the desktop are updated. This priority may be assigned in a variety of ways. For instance where a frame of a desktop is subdivided into tiles the tile or tiles that contain s all or part of a user s cursor may be given an assigned priority. Also for instance where user input results in a change in the size shape or position of a window on the desktop such as by the user using the cursor to drag a corner of a window the tile or tiles that contain all or part of this changing window may be assigned a higher priority. A high priority may give screen data preference in how it is processed in a queue of the source computer or destination computer such as being placed in a queue ahead of lower priority screen data. These queues may include a quote of screen data to be encoded decoded or transmitted.

Source computer may be able to encode images according to a variety of techniques and do this based on attributes of destination computer such as destination computer s presence or lack thereof of hardware dedicated to decode a particular codec the overall processing power of destination computer destination computer s amount of RAM whether and if so what type of GPU destination computer possesses as well as the communications network via which source computer and destination computer communicate. In a common scenario source computer may be a general purpose computer that in addition to transmitting data to be displayed on wireless display along communication channel may be used for other purposes concurrently such as to execute a web browser or an e mail client. In contrast in this common scenario destination computer may be dedicated to decoding image data received from source computer and displaying that decoded image on wireless display . Given that in this scenario processing resources of source computer may be used for things other than encoding and transmitting data to destination computer whereas destination computer may be used exclusively or nearly exclusively for receiving decoding and presenting data received from source computer it may be preferable for as much processing to be done as is possible on destination computer . Thus the amount of encoding performed by source computer may be determined based on a maximum decoding capability of destination computer . This may be accomplished for instance by when source computer and destination computer establish communication destination computer indicates to source computer its capabilities to receive decode and display image data.

This indication from destination computer may comprise for instance one or more codecs that destination computer may decode as well as an indication of preference among those one or more codecs. For instance the indication may state that destination computer is capable of decoding both RemoteFX and H.264 codecs but prefers H.264 because it has specialized hardware to decode H.264 while it must decode RemoteFX with a general purpose CPU. Where a codec format allows for a variable amount of compression or quality where a low amount of compression may be decoded more quickly but requires more bandwidth to transmit and a high amount of compression may not be decoded as quickly but requires less bandwidth to transmit this indication from destination computer may also include the degree of compression that destination computer is capable of decoding.

This indication from destination computer may also comprise other information about the ability of the destination computer to decode data encoded with a remote presentation protocol. For instance where the remote presentation protocol may subdivide a desktop frame into tiles and instruct destination computer to cache and re use tiles destination computer may indicate to source computer that it has a limited amount of memory with which to cache tiles.

Source computer may receive this indication from destination computer and from the indication and information about source computer determine how to encode information with remote presentation encoder . For instance while destination computer may indicate a preference to use a particular format because it has hardware dedicated to decoding that format that may be a particularly tough format for source computer to encode based on the particulars of the source computer architecture. Given this information source computer may select a way to encode computer desktops with remote presentation encoder and use this selected way to encode when encoding computer desktops to be sent to destination computer .

In another common scenario while destination computer is dedicated to decoding and presenting screen data received from source computer destination computer has limited processing resources because it is a low cost embedded device. In this scenario source computer may attempt to overcome the limitations of destination computer by performing a great deal of processing locally such as classifying different parts of a computer desktop and encoding the different parts differently to make decoding less resource intensive . However because source computer may also be executing user applications such as those applications that make up the screen data that is being transmitted to destination computer a favored situation may involve source computer devoting as much processing resources to encoding screen data without denying the user applications any processing resources e.g. only using otherwise available processing resources .

In another common scenario the screen data may comprise a video with sound and source computer may be in communication with destination computer for the purpose of presenting that screen data on a home theater that includes wireless monitor . In such a scenario as well as other scenarios it may be important that the sound and video are played synchronously. In such a scenario remote presentation encoder may receive sound or audio data from an audio driver of source computer encode this sound data and send it to destination computer along with the image data of the video. Source computer may further mark the sound and image data such as with a time code to signify what sound data synchronizes with what image data. Destination computer may use this time code information so that it instructs wireless display and an audio output means communicatively connected to destination computer to both respectively play the sound and image synchronously.

Remote user session is the user session that communicates with client computer in the RPP but it is the local screen that s to be shared or mirrored or duplicated with client computer and that local screen is associated with a different user session user console session . To share the local screen with client computer remote user session receives input from client computer and transmits that user input to user console session where it is processed. Likewise the screen data that user console session creates is received by remote user session . Remote user session takes that screen data and sends it to session 0 for it to be encoded with a RPP and transmitted to client computer for display. In the depicted embodiment user console session does not interact with session 0 for the purpose of encoding screen data with a RPP and transmitting it to client computer . That process is handed by remote user session .

The operational procedures begin with operation . Operation depicts establishing a wireless communication channel between a user console session of a source computer and a destination computer the destination computer being configured to display screen data on a wireless display. This wireless communication channel may comprise for instance a Wireless USB or Wireless HD communication channel. The communication channel may be established between a source computer such as source computer of and a destination computer such as destination computer of . The destination computer may comprise a ASIC embedded within a wireless display or a computer physically coupled to a wireless display such as an embedded system set top box. The destination computer may comprise specialized circuitry apart from a general purpose processor that is configured to decode remote presentation data and render graphics on the wireless display.

Operation depicts determining first screen data of the user console session to be displayed on the wireless display. This screen data may comprise a computer desktop or other image audio and indications of user input. This determination may occur as a result of a graphics subsystem of the source computer rendering a computer desktop to a memory area of the source computer. Where the wireless display is used to extend a display of the source computer rather than mirror a display of the source computer this screen data may not be displayed by a display of the source computer but only by the wireless display.

Operation depicts encoding the screen data with a remote presentation protocol RPP . This process of encoding the screen data may occur outside of a remote presentation session in that a remote presentation session may not be established at the beginning of the operational procedures there may be no validation of user credentials and or a remote presentation session may not be terminated at the end of the operational procedures. The encoded first screen data may comprise for instance an image encoded with a H.264 format or an indication of cached screen data for the wireless device computer to use.

Operation may include encoding a first portion of the first screen data with a first codec and encoding a second portion of the first screen data with a second codec the second codec differing from the first codec. For instance the first portion may comprise a representation of text such as an image that represents text and that text may be extracted from and the second portion may comprise a near photographic quality image. Or the first portion may comprise a black and white image and the second portion a color image. Though these two portions may be part of the same frame in the screen data it may be that they are better encoded using different codecs and this may be done.

Operation depicts sending the encoded first screen data to the destination computer from the user console session without the encoded first screen data being transmitted a second user session such that the destination computer will decode the encoded first screen data and display the decoded first screen data on the wireless display. The source computer and destination computer communicate over the established wireless communication channel. When the source computer sends the encoded first screen data to the destination computer it does so using this communication channel but it does not first establish a remote presentation session across this communication channel before doing so. In response to receiving the encoded first screen data the destination computer decodes the data and assembles it on the wireless display. While the decoded first screen data corresponds to the first screen data it may not exactly match the first screen data. For instance if the first screen data is encoded and then decoded with a lossy codec some of the image will be lost and the decoded first screen data will be different from than first screen data.

Operation depicts encoding second screen data of the console session with the remote presentation protocol sending the encoded second screen data to the destination computer from the user console session without the encoded second screen data being transmitted a second user session and sending a priority of the second screen data to the destination computer such that the display computer will display decoded second screen data on the wireless display before displaying the decoded first screen data on the wireless display.

Screen data sent between the source computer and the destination computer may be assigned a priority. Screen data or portions of screen data that have a great affect on a user s impression of the interactivity of the display may be assigned a high priority so that they are displayed more quickly than other images. For instance when a user moves a cursor on a computer desktop or re sizes an application window types of input to a source computer he or she may be focused on seeing that change occur on the wireless display as opposed to for instance a clock in corner of the display update its time. So this kind of screen data that the user bases his impression of interactivity on may be given a high priority by the source computer. Then high priority screen data may be processed preferably. Where the source computer has queues to process screen data such as a queue for encoding or a queue for transmitting this high priority data may be placed in a queue ahead of non high priority screen data. High priority screen data may be similarly be given preferential treatment in a queue of the destination computer such as in a decode queue or a display queue or when high priority data is ready to display screen data may be flushed to the screen immediately.

Operation depicts determining a sound of the user console session to be played contemporaneously with displaying the decoded first screen data encoding the sound with the RPP and sending the encoded sound to the destination computer from the user console session without the encoded sound being transmitted a second user session such that the destination computer will play the sound contemporaneously with the wireless display displaying the decoded first screen data.

This operation may be effectuated by encoding the first screen data with a time stamp the time stamp indicating a time at which the screen data is to be displayed and encoding the sound with a second time stamp the second time stamp indicating a second time at which the sound is to be played the time stamp and the second time stamp indicating to play the sound contemporaneously with the wireless display displaying the decoded first screen data. The time stamps may denote contemporaneous play that is the time stamps may not be identical but may differ by a small amount such that the sound is played while the screen data is displayed. In assigning time stamps to screen data and sounds and then the destination computer playing that screen data and sounds according to the time stamps synchronization between the screen data and sounds may be maintained.

In addition to the source computer transmitting screen data to be displayed on the wireless display the source computer may also transmit sound data to be played on a speaker for instance speakers built into the wireless display . The sound may be captured from an audio driver of the source computer similarly to how screen data is captured from a display driver of the source computer as well as encoded transmitted decoded and played in a similar manner.

Operation depicts determining an indication of user input of the user console to be delivered contemporaneously with displaying the decoded first screen data encoding the indication of user input with the RPP and sending the encoded indication of user input to the destination computer from the user console session without the encoded user input being transmitted a second user session such that the destination computer will display the indication of user input contemporaneously with the wireless display displaying the decoded first screen data. This user input may comprise for instance text entered by a user on a keyboard or a cursor movement made by a user using an input device like a mouse or track pad. This indication of user input may be encoded and transmitted in a similar manner as screen data is encoded and transmitted.

Operation depicts determining a maximum decoding capability of the destination computer and wherein encoding the first screen data with a remote presentation protocol comprises encoding the first image based on the maximum decoding capability. In some scenarios the destination computer is dedicated to receiving and displaying screen data and audio from the source computer so it may devote all of its processing resources to this task without negatively impacting another process that it is to carry out. In contrast the source computer may be a general purpose computer where a user attempts to multi task while this communication with the destination computer takes place. So in such a scenario it may be that the source computer receives from the destination computer an indication of its processing ability. This indication may be a measure of its raw processing power such as FLOPS or floating point operations per second as well as what codecs it is configured to decode and whether it has special ability to decode any particular codecs such as specialized circuitry for decoding H.264. Based on this indication received from the destination computer the source computer may determine how much of the work of the communication session the destination computer may perform and also the parameters of the communication for instance the codec to be used and the settings for the codec that reduce or minimize the amount of processing resources that the source computer devotes to the communication session.

Operation depicts 9 determining an amount of available processing resources of the source computer not used by a user application and wherein encoding the first screen data with a remote presentation protocol comprises encoding the first screen using no more than the amount of available processing resources. A user of the source computer may not just be conducting this communication with the destination computer and wireless display he or she may be executing applications that create graphics to be displayed on the wireless display such as a video player application. In such a scenario it may be decided that the encoding will not affect any of the user s executing applications and will use only those processing resources that are free or not otherwise used by another application. For instance where 80 of the source computer s CPU cycles are in use by other user applications the encoding may be throttled so as to not attempt to use more than 20 of the source computer s CPU cycles.

While the present disclosure has been described in connection with the preferred aspects as illustrated in the various figures it is understood that other similar aspects may be used or modifications and additions may be made to the described aspects for performing the same function of the present disclosure without deviating there from. Therefore the present disclosure should not be limited to any single aspect but rather construed in breadth and scope in accordance with the appended claims. For example the various procedures described herein may be implemented with hardware or software or a combination of both. Thus the methods and apparatus of the disclosed embodiments or certain aspects or portions thereof may take the form of program code i.e. instructions embodied in tangible media such as floppy diskettes CD ROMs hard drives or any other machine readable storage medium. When the program code is loaded into and executed by a machine such as a computer the machine becomes an apparatus configured for practicing the disclosed embodiments. In addition to the specific implementations explicitly set forth herein other aspects and implementations will be apparent to those skilled in the art from consideration of the specification disclosed herein. It is intended that the specification and illustrated implementations be considered as examples only.

