---

title: Method of compositing variable alpha fills supporting group opacity
abstract: A method of compositing a plurality of graphic objects with a compositing buffer, is disclosed. The plurality of graphic objects forming a group is attenuated by group opacity and is composited from a top object to a bottom object. Based on a first mask and the group opacity, a second mask is generated. The first mask stores a remaining possible contribution for further graphic objects below and including the plurality of graphic objects. The plurality of graphic objects in a top down order is processed. In particular, for each graphic object of the plurality of graphic objects: (a) a contribution value for the graphic object using the second mask is determined, the contribution value representing a contribution of the graphic object to the compositing buffer; (b) a colour value of the graphic object is composited with the compositing buffer using the contribution value; and (c) the second mask is updated using the contribution value. The first mask is then updated using the second mask and the group opacity. The updated first mask is configured for further compositing of objects below the plurality of graphic objects.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08350868&OS=08350868&RS=08350868
owner: Canon Kabushiki Kaisha
number: 08350868
owner_city: Tokyo
owner_country: JP
publication_date: 20101005
---
This application claims the benefit under 35 U.S.C. 119 of the filing date of Australian Patent Application No. 2009225336 filed 13 Oct. 2009 hereby incorporated by reference in its entirety as if fully set forth herein.

The current invention relates to the field of computer graphics and compositing of two dimensional 2D graphic objects and in particular to the application of group opacity to one or more graphic objects in a rendering system. The current invention is particularly advantageous for use with those rendering systems in which processing resources are limited. The current invention also relates to a method and apparatus for compositing a graphic object with a compositing buffer and to a computer program product including a computer readable medium having recorded thereon a computer program for a graphic object with a compositing buffer.

The problem of compositing graphic objects using limited processing resources is known within the field of computer graphics. Performing complex compositing operations on an embedded device such as a mobile phone portable media player or digital camera requires expensive central processing unit CPU and memory hardware resources. Equipping embedded devices with such hardware increases overall device cost. Furthermore performing complex compositing operations reduces battery life in portable devices. In the past these difficulties have prohibited the use of complex compositing operations on embedded devices. Consequently embedded device graphical user interfaces tend to be unappealing in nature and generally lacking complex compositing. By contrast performing complex compositing operations on computer devices with comparatively unlimited resources eg. notebook and desktop computers is commonplace.

As embedded devices become more feature rich there is a clear need for higher quality graphical user interfaces. Improving aesthetic quality and responsiveness of a graphical user interface improves the overall usability and user experience that such a device offers.

Applying a single opacity to a group of graphic objects is a compositing feature that user interface UI designers desire for use in an embedded device user interface. This feature has long been possible in desktop personal computer PC user interfaces. However when using existing methods providing this feature in embedded devices is cost prohibitive.

One conventional method of applying group opacity involves recursively compositing grouped graphic objects. Such a method composites each group of graphic objects into a separate compositing buffer. Essentially this method flattens grouped graphic objects so that each group can be processed as if the group were a single graphic object. The disadvantage of this method is that an extra compositing buffer is required for each group of graphic objects. Furthermore using this method requires extra processing because the result of each flattened group must be composited with other graphic objects.

Another conventional method of applying group opacity involves determining intersection regions of overlapping graphic objects and decomposing the graphic objects into fragment graphic objects such that an opacity value can be applied to each fragment graphic object to produce a correct result. This method requires much pre processing of graphic object data to determine intersection regions. Furthermore this method does not support graphic objects having a variable opacity.

Still another conventional method of applying group opacity relies on removal of background graphic objects from a partial compositing result. After background objects have been removed group opacity may be applied. Following application of the group opacity the result is re combined with background graphic objects. Such a method requires allocation of additional buffers and much copying between buffers.

It is an object of the present invention to substantially overcome or at least ameliorate one or more disadvantages of existing arrangements.

According to one aspect of the present invention there is provided a method of compositing a plurality of graphic objects with a compositing buffer said plurality of graphic objects forming a group being attenuated by group opacity and being composited from a top object to a bottom object the method comprising the steps of 

generating based on a first mask and the group opacity a second mask the first mask storing a remaining possible contribution for further graphic objects below and including said plurality of graphic objects 

processing said plurality of graphic objects in a top down order the processing comprising the sub steps of for each graphic object of the plurality of graphic objects 

updating the first mask using said second mask and the group opacity wherein said updated first mask is configured for further compositing of objects below said plurality of graphic objects.

According to another aspect of the present invention there is provided an apparatus for compositing a plurality of graphic objects with a compositing buffer said plurality of graphic objects forming a group being attenuated by group opacity and being composited from a top object to a bottom object the apparatus comprising 

means for generating based on a first mask and the group opacity a second mask the first mask storing a remaining possible contribution for further graphic objects below and including said plurality of graphic objects 

means for processing said plurality of graphic objects in a top down order the processing comprising the steps of for each graphic object of the plurality of graphic objects 

means for updating the first mask using said second mask and the group opacity wherein said updated first mask is configured for further compositing of objects below said plurality of graphic objects.

According to still another aspect of the present invention there is provided a system for compositing a plurality of graphic objects with a compositing buffer said plurality of graphic objects forming a group being attenuated by group opacity and being composited from a top object to a bottom object the system comprising 

a processor coupled to said memory for executing said computer program said computer program comprising instructions for 

According to still another aspect of the present invention there is provided a computer readable medium having recorded thereon a computer program for compositing a plurality of graphic objects with a compositing buffer said plurality of graphic objects forming a group being attenuated by group opacity and being composited from a top object to a bottom object the program comprising 

code for generating based on a first mask and the group opacity a second mask the first mask storing a remaining possible contribution for further graphic objects below and including said plurality of graphic objects 

code for processing said plurality of graphic objects in a top down order the processing comprising the steps of for each graphic object of the plurality of graphic objects 

code for updating the first mask using said second mask and the group opacity wherein said updated first mask is configured for further compositing of objects below said plurality of graphic objects.

A method of compositing filled graphic objects including graphic objects filled using a variable opacity fill will be described below with reference to . The method may be referred to as a compositing process . One or more of the graphic objects are attenuated by group opacity. As described below the contribution of a graphic object is determined by multiplying RGB red green blue values of the graphic object s fill by corresponding alpha values and by a mask i.e. a set of values including one value for each pixel . The mask incorporates the remaining possible contribution for graphic objects below and the effect of any group opacity including the group opacity that is nested. The remaining contribution represents a contribution of red green blue and alpha channels when used in an RGB colour space. The mask is updated as graphic objects are processed down a list of active graphic objects.

The electronic device comprises a display controller which is connected to a video display such as a liquid crystal display LCD panel or the like. The display controller is configured for displaying graphical images on the video display in accordance with instructions received from the processor .

The electronic device also comprises user input devices which are typically formed by keys a keypad or like controls. In some implementations the user input devices may include a touch sensitive panel physically associated with the display to collectively form a touch screen. Such a touch screen may thus operate as one form of graphical user interface GUI as opposed to a prompt or menu driven GUI typically used with keypad display combinations. Other forms of user input devices may also be used such as a microphone not illustrated for voice commands or a joystick thumb wheel not illustrated for ease of navigation about menus.

As seen in the electronic device also comprises a portable memory interface which is coupled to the processor via a connection . The portable memory interface allows a complementary portable memory device to be coupled to the electronic device to act as a source or destination of data or to supplement the internal storage module . Examples of such interfaces permit coupling with portable memory devices such as Universal Serial Bus USB memory devices Secure Digital SD cards Personal Computer Memory Card International Association PCMIA cards optical disks and magnetic disks.

The electronic device also comprises a communications interface to permit coupling of the device to a computer or communications network via a connection . The connection may be wired or wireless. For example the connection may be radio frequency or optical. An example of a wired connection includes Ethernet. Further an example of wireless connection includes Bluetooth type local interconnection Wi Fi including protocols based on the standards of the IEEE 802.11 family Infrared Data Association IrDa and the like.

Typically the electronic device is configured to perform some special function. The embedded controller possibly in conjunction with further special function components is provided to perform that special function. For example where the device is a digital camera the components may represent a lens focus control and image sensor of the camera. As another example the device may be a mobile telephone handset. In this instance the components may represent those components required for communications in a cellular telephone environment. Where the device is a portable device the special function components may represent a number of encoders and decoders of a type including Joint Photographic Experts Group JPEG Moving Picture Experts Group MPEG MPEG 1 Audio Layer 3 MP3 and the like.

The methods described below may be implemented using the embedded controller wherein the processes of to be described may be implemented as one or more software application programs executable within the embedded controller . The electronic device is an effective and advantageous apparatus for implementing the described methods. In particular with reference to the steps of the described methods are effected by instructions in the software that are carried out within the controller . The software instructions may be formed as one or more code modules each for performing one or more particular tasks. The software may also be divided into two separate parts in which a first part and the corresponding code modules performs the described methods and a second part and the corresponding code modules manage a user interface between the first part and the user.

The software is generally loaded into the controller from a computer readable medium and is then typically stored in the ROM of the internal storage module as illustrated in after which the software can be executed by the processor . In some instances the processor may execute software instructions that are located in RAM . Software instructions may be located in RAM by the processor initiating a copy of one or more code modules from ROM into RAM . Alternatively the software instructions of one or more code modules may be pre installed in a non volatile region of RAM by a manufacturer. After one or more code modules have been located in RAM the processor may execute software instructions of the one or more code modules.

As described herein the application program is typically pre installed and stored in the ROM by a manufacturer prior to distribution of the electronic device . However in some instances the application programs may be supplied to the user encoded on one or more CD ROM not shown and read via the portable memory interface prior to storage in the internal storage module or in the portable memory . In another alternative the software application program may be read by the processor from the network or loaded into the controller or the portable storage medium from other computer readable media. Computer readable storage media refers to any storage medium that participates in providing instructions and or data to the controller for execution and or processing. Examples of such storage media include floppy disks magnetic tape CD ROM a hard disk drive a ROM or integrated circuit USB memory a magneto optical disk flash memory or a computer readable card such as a PCMCIA card and the like whether or not such devices are internal or external of the device . Examples of computer readable transmission media that may also participate in the provision of software application programs instructions and or data to the device include radio or infra red transmission channels as well as a network connection to another computer or networked device and the Internet or Intranets including e mail transmissions and information recorded on Websites and the like. A computer readable medium having such software or computer program recorded on it is a computer program product.

The second part of the application programs and the corresponding code modules mentioned above may be executed to implement one or more graphical user interfaces GUIs to be rendered or otherwise represented upon the display . Through manipulation of the user input device e.g. the keypad a user of the device and the application programs may manipulate the interface in a functionally adaptable manner to provide controlling commands and or input to the applications associated with the GUI s . Other forms of functionally adaptable user interfaces may also be implemented such as an audio interface utilizing speech prompts output via loudspeakers not illustrated and user voice commands input via the microphone not illustrated .

The processor typically includes a number of functional modules including a control unit CU an arithmetic logic unit ALU and a local or internal memory comprising a set of registers which typically contain atomic data elements along with internal buffer or cache memory . One or more internal buses interconnect these functional modules. The processor typically also has one or more interfaces for communicating with external devices via system bus using a connection .

The application program includes a sequence of instructions though that may include conditional branch and loop instructions. The program may also include data which is used in execution of the program . This data may be stored as part of the instruction or in a separate location within the ROM or RAM .

In general the processor is given a set of instructions which are executed therein. This set of instructions may be organised into blocks which perform specific tasks or handle specific events that occur in the electronic device . Typically the application program will wait for events and subsequently execute the block of code associated with that event. Events may be triggered in response to input from a user via the user input devices as detected by the processor . Events may also be triggered in response to other sensors and interfaces in the electronic device .

The execution of a set of the instructions may require numeric variables to be read and modified. Such numeric variables are stored in the RAM . The disclosed method uses input variables that are stored in known locations in the memory . The input variables are processed to produce output variables that are stored in known locations in the memory . Intermediate variables may be stored in additional memory locations in locations of the memory . Alternatively some intermediate variables may only exist in the registers of the processor .

The execution of a sequence of instructions is achieved in the processor by repeated application of a fetch execute cycle. The control unit of the processor maintains a register called the program counter which contains the address in ROM or RAM of the next instruction to be executed. At the start of the fetch execute cycle the contents of the memory address indexed by the program counter is loaded into the control unit . The instruction thus loaded controls the subsequent operation of the processor causing for example data to be loaded from ROM memory into processor registers the contents of a register to be arithmetically combined with the contents of another register the contents of a register to be written to the location stored in another register and so on. At the end of the fetch execute cycle the program counter is updated to point to the next instruction in the system program code. Depending on the instruction just executed this may involve incrementing the address contained in the program counter or loading the program counter with a new address in order to achieve a branch operation.

Each step or sub process in the processes of the methods described below is associated with one or more segments of the application program and is performed by repeated execution of a fetch execute cycle in the processor or similar programmatic operation of other independent processor blocks in the electronic device .

In a graphics rendering system rendering of graphic objects produces pixel values in a frame buffer suitable for display on a display device such as a liquid crystal display LCD screen. In a simple rendering system each graphic object is rasterised in order from bottom most graphic object to top most graphic object. The bottom most graphic object may be obscured by any of the graphic objects above the bottom most graphic object. Such a rendering system is known as a painter s algorithm renderer. Rendering in such a way is efficient in terms of memory usage and processing even in the presence of opacity being applied to individual graphic objects. In rendering systems colour and opacity can be represented in various ways.

The red green blue RGB pixel format is the most common format to encode colour information. The colour is expressed as an RGB triplet r g b each colour component of which can vary from zero to a defined maximum value. The value of the r colour component represents intensity of red the value of the g colour component represents the intensity of green and the value of the b colour component represents the intensity of blue. If all three colour components are zero the result is black. If all three colour components are at maximum the result is a brightest representable white.

The red green blue alpha RGBA pixel format is a variant of the RGB pixel format which includes a component for opacity. The opacity component is commonly known as the alpha channel so the format is named RGBA. RGBA is a representation that integrates opacity information along with colour information. An RGBA pixel value may be expressed in the form r g b a . The alpha channel allows for alpha blending of one image over another. If the alpha value is zero the result is fully transparent if the alpha value is at maximum the result is fully opaque.

 i as fractional values between 0.0 and 1.0 inclusive. This representation is used in systems that use floating point representations 

 iii as integer numbers in the range zero 0 to two hundred and fifty five 255 the range that a single 8 bit byte can offer by encoding 256 distinct values or

 iv as integer numbers in the range zero 0 to sixty five thousand five hundred and thirty five 65535 the range that sixteen 16 bits can offer as is common in high end digital imaging equipment.

Another pixel format referred to as the RGBA8888 pixel format consists of four 4 component values of eight 8 bits each. This means that the RGBA8888 pixel format consumes a total of thirty two 32 bits per pixel BITS PER PIXEL which is equivalent to four 4 bytes per pixel BYTES PER PIXEL .

When determining the pixel values of the frame buffer each graphic object intersecting some point on the display screen is considered. Moreover for a given point on the display screen corresponding to a display pixel any graphic object intersecting the point may have some colour value contributing to the display pixel value. The process of determining a resulting display pixel value based on intersecting graphic objects is known as compositing.

When compositing graphic objects that are completely opaque i.e. each graphic object s opacity is 100 a top most intersecting graphic object will have a 100 contribution to a resulting display pixel value. That is the resulting display pixel value will be equal to the colour value of the top most intersecting graphic object. Moreover any intersecting graphic object below the top most graphic object will have no contribution i.e. each graphic object below the top most will have 0 contribution to the resulting display pixel value.

When compositing graphic objects that may have an opacity between 0 and 100 the colours of graphic objects need to be blended using compositing operations. Such a blending process is referred to as alpha compositing.

Consider a painter s algorithm renderer that composites graphic objects into a compositing buffer B. Before any graphic objects are composited into the compositing buffer the compositing buffer colour component B.colour is initialised to 0 . Now consider a graphic object O with colour component O.colour and opacity O.opacity. The graphic object O can be alpha composited into i.e. on top of the compositing buffer using the Equation 1 as follows B.colour O.colour O.opacity 100 O.opacity B.colour 1 

Equation 1 is known as the OVER compositing operator. If the compositing buffer needs to be alpha composited over other graphic objects then a compositing buffer opacity component B.opacity for each pixel may be stored in the compositing buffer. Before any graphic objects are composited into the compositing buffer the compositing buffer opacity component B.opacity is initialised to 0 . When a graphic object O is alpha composited into the compositing buffer the compositing buffer opacity component B.opacity is determined using the Equation 2 as follows B.opacity O.opacity 100 O.opacity B.opacity 2 

After applying the OVER compositing operator i.e. Equations 1 and 2 the effect of the opacity component B.opacity has already been applied to the resulting colour component B.colour . Such a colour value is described as B.colour having been pre multiplied by B.opacity.

A graphic object P that has been pre multiplied by an associated alpha channel can be alpha composited into i.e. on top of an initialised compositing buffer B using Equation 3 as follows B.colour P.colour 100 P.opacity B.colour 3 

The effect of using pre multiplied graphic objects does not affect alpha channel calculations. That is the opacity component B.opacity is determined using the OVER compositing operator for alpha channel calculations i.e. Equation 2 .

A subset of graphic objects may be composited as a group and then an additional opacity may be applied to the result of compositing the group. Such an additional opacity is referred to as a group opacity. An additional render buffer which will be referred to as the group buffer GB may be used for applying the group opacity. The additional render buffer method renders the subset of graphic objects into the group buffer in isolation from the final display buffer. Once the subset of graphic objects has been rendered into the group buffer GB the group opacity associated with the group is en applied to the group buffer. The following expressions may be used determine a result GBof applying group opacity GO to a group buffer GB in accordance with Equations 4 and 5 below GB.colour GO GB.colour 4 GB.opacity GO GB.opacity 5 

The group buffer is then used in place of the subset of graphic objects producing what may be referred to as the group graphic object. The group graphic object has been pre multiplied by a corresponding alpha channel. The group graphic object is then composited with the remaining graphic objects into the final display buffer. Such a method uses additional memory and introduces additional calculations associated with compositing the group graphic object with remaining graphic objects. The methods described below replicate the effect of applying group opacity using the method described above while minimising resource costs normally associated with applying such an effect.

The application of group opacity to a graphic object may be used to hide part or all of a graphic object. This may be achieved by using a zero 0 group opacity value which will result in grouped graphic objects being invisible. Such an effect which results in graphic objects being invisible may be described as a clipping effect.

When rendering graphic objects some graphics rendering systems composite graphic objects in a top down order. Such a graphics rendering system is sometimes described as a reverse painter s algorithm renderer.

The described methods composite a number of bitmap image graphic objects. Bitmap image graphic objects may be composited using the OVER compositing operator as described above. Additionally a subset of bitmap image graphic objects may be grouped so as to apply group opacity. The described methods permit nested grouping such that the graphic objects in one group are a subset of the graphic objects of a parent group.

In accordance with the described methods a number of bitmap image graphic objects may be provided to the processor for compositing and rendering to a frame buffer configured within RAM . Bitmap image graphic objects may have various pixel formats. Two such formats are RGB and RGBA as described above.

A bitmap image may have a varying opacity across the image. Such an image is described as having variable alpha. A bitmap image may have the same opacity for all pixels. Such an image is described as having constant alpha. A bitmap image may have the same colour for all pixels. Such an image is described as having a constant colour. A bitmap image may have all pixels fully opaque. Such an image is described as being fully opaque. As described herein flags may be used to distinguish the different types of images i.e. variable alpha constant alpha constant colour and fully opaque described above. The flags may be used during the compositing process to perform various optimisations such as using simple compositing for constant colour bitmap or for a quick determination of fully opaque resulting image etc.

While the described methods accept bitmap image graphic objects it will be appreciated that other types of graphic objects may be used. For example the described methods may be applied to vector graphic objects run length encoded graphic objects linear blended graphic objects etc.

The described methods render graphic objects by creating a rasterised representation of the graphic objects referred to as a frame. Rendering of a frame is broken into two processes firstly a frame setup process followed by a frame render process.

The frame setup process involves receiving a description of graphic objects that are to be rendered. Additionally the frame setup process involves receiving a description of graphic objects to be grouped so as to allow the application of group opacity. During the frame setup process the combined description of all graphic objects and groups of graphic objects is referred to as the frame description. The frame description is constructed by calls to an Application Programming Interface API .

When setting up a frame iterative calls to an API specify bitmap images to be placed in the frame to be rendered. Each time a bitmap is placed using the API a bitmap data structure may be added to a list of all bitmap data structures for the frame configured within the RAM . This list of bitmaps may be referred to as the bitmaps list. The bitmaps list is part of the frame description and is initialised to be an empty list before the user adds any bitmap images to the frame description.

In addition to bitmap images iterative calls to an API are used to specify groups of graphic objects which allow group opacity to be applied. Each time a group is defined using the API a group data structure may be added to a list of all group data structures for the frame. This list of groups is referred to as the groups list. The groups list is part of the frame description and is initialised to be an empty list before the user adds groups to the frame description.

After bitmaps and groups have been added to the frame description the frame may be rendered using a call to the API.

The method begins at step where an API function is called by the processor to select a first bitmap image as the current image. Then in step an API function is called by the processor to add the current bitmap image graphic object to a frame description configured within the RAM . A method of adding the bitmap image to the frame description will be described in detail below with reference to . In step if the processor determines that there are additional bitmap images to be added then the method proceeds to step where the next bitmap image is selected by the processor to be the current image. Then in step the image selected in step is added to the frame description configured within the RAM . Steps and repeat until all bitmap images have been added to the frame description.

The method of adding a bitmap image to the frame description as executed at step will now be further described with reference to . The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

Referring to the method begins at step where the position of the bitmap image is determined by the processor using x y screen pixel co ordinates. Step will be described in further detail below. At step the processor determines a priority value for the bitmap image. This priority value affects the compositing order of graphic objects. Step will be described in further detail below.

In step the processor creates a bitmap data structure in the RAM for the bitmap image being added to the frame description. In step the bitmap data structure is passed to a clipping operation by the processor which either discards the bitmap data structure or clips the bitmap data structure so that the data structure lies completely within bounds of a screen displayed on the display device . A method of discarding and clipping an image as executed at step will be described below with reference to .

In step the processor updates the bitmap data structure and sorts the bitmap data structure into a list of all bitmap data structures in the order required by the compositing process

At step the position of the bitmap image is determined by specifying the screen pixel column and row for positioning the top left corner of the bitmap image. The screen pixel column and row are specified using an x y screen pixel co ordinate system. A value of 0 0 indicates a position at the top left corner of the screen displayed on the display device . A value of SCR WIDTH SCR HEIGHT indicates a position at the bottom right of the screen where the values SCR WIDTH and SCR HEIGHT represent the actual values of the screen width and screen height in pixels respectively. A bitmap image may be positioned within the bounds of the screen displayed on the display device overlapping the screen bounds or completely outside the screen bounds.

As described above at step the processor determines a priority value for the bitmap image. The priority value associated with the bitmap image of a graphic object provides information indicating the compositing order of the graphic object relative to all other graphic objects placed into the frame description for rendering. shows the relationship between rendering order and priority. As seen in graphic objects and are associated with priority values one 1 two 2 and three 3 respectively. The object has a priority value of one 1 in the frame description and is rendered closest to a background. As shown in graphic object is obscured by graphic objects and since the graphic object has the lowest priority value i.e. one 1 of the three graphic objects and in the frame. The graphic object has a priority value of three 3 which is the highest priority value in the frame description and therefore is rendered the furthest from the background. As seen in graphic object obscures all other graphic objects because graphic object has the highest priority value of the three graphic objects in the frame. When the graphic objects are processed using a top down renderer graphic objects with a higher priority value are processed before graphic objects with lower priority value.

As described above in step a bitmap data structure is created. shows fields in an exemplary bitmap data structure. The bitmap data structure includes the following fields 

Each of the fields is initialised at step of the method . In addition to the above listed fields the bitmap data structure contains fields which are used and modified by the processor . The additional fields include SORT X SORT Y the IS ACTIVATING flag and the BMP NEXT pointer . The usage of the fields is described in more detail below.

As described above in step the bitmap image is either discarded or clipped to the screen bounds. Step optimises the frame description whereby an image displayed outside of the screen bounds is discarded. If the image is not discarded then the image either lies entirely inside the screen bounds or partially within the screen bounds. If the image lies partially within the screen bounds then the image is clipped so that the image lies entirely within the screen bounds. The rendering of the frame is performed by the processor based on the assumption that all graphic objects are defined within the screen bounds. As such image discarding and clipping operations are performed.

The method of discarding and clipping an image as executed at step will described with reference to . The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

The method begins at where if the processor determines that the bitmap image is placed above the top edge of the screen displayed on the display device then the method proceeds to step . Otherwise the method proceeds to step . The determination is made by the processor at step by checking if the bottom edge of the bitmap image is above or coincides with the top edge of the screen i.e. BMP Y BMP HEIGHT

At step the processor determines whether the bitmap image is placed below the bottom edge of the screen of the display device by checking if the top edge of the bitmap image is below or coincides with the bottom edge of the screen or bottom screen edge displayed on the display device i.e. BMP Y SCR HEIGHT . If the bitmap image is placed below the bottom screen edge then the method proceeds to step . Otherwise the method proceeds to step . At step the bitmap data structure for the bitmap image is deleted.

At step the processor determines whether the bitmap image is placed to the left of the left screen edge i.e. the left edge of the screen being displayed on the display device by checking if the right edge of the bitmap image is to the left of or is coincident with the left screen edge i.e. BMP X BMP WIDTH 

At step the processor determines whether the bitmap image is placed to the right of the right screen edge i.e. the right edge of the screen being displayed on the display device by checking if the left edge of the bitmap image is to the right of or is coincident with the right screen edge i.e. BMP X SCR WIDTH . If the bitmap is placed to the right of the right screen edge then the method proceeds to step . Otherwise the method proceeds to step . At step the bitmap data structure for the bitmap image is deleted.

At step the bitmap image is clipped so that the bitmap image is entirely within the bounds of the screen displayed on the display device . A method of clipping the bitmap image as executed at step will now be described with reference to . The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

Any image that reaches the bitmap clipping stage intersects with some region of the screen. The method begins at step where a check is performed by the processor to determine whether the bitmap image overlaps the top edge of the screen being displayed on the display device . If the bitmap image does overlap the top edge of the screen i.e. BMP Y

At step a check is performed by the processor to determine whether the bitmap image overlaps the bottom edge of the screen. If the bitmap image does overlap the bottom edge of the screen i.e. BMP Y BMP HEIGHT SCR HEIGHT then the method continues to step where the bitmap image is clipped so that the bitmap image is aligned with the bottom edge of the screen. Following this clipping step the method continues to step . If at step the processor determines that the bitmap image does not overlap the bottom edge of the screen then the processor continues directly to step .

At step a check is performed by the processor to determine whether the bitmap image overlaps the left edge of the screen. If the bitmap image does overlap the left edge of the screen i.e. BMP X

At step a check is performed by the processor to determine whether the bitmap image overlaps the right edge of the screen. If the bitmap image does overlap the right edge of the screen then the method continues to step where the bitmap image is clipped so that the bitmap image is aligned with the right edge of the screen. Following this clipping step the clipping process has completed. If at step the processor determines that the bitmap image does not overlap the right edge of the screen then the method has completed.

In step the bitmap image is clipped to align with the top edge of the screen by updating the bitmap data structure fields BMP PIXEL DATA BMP HEIGHT and BMP Y as follows BMP PIXEL DATA BMP PIXEL DATA BMP STRIDE BMP BMP HEIGHT BMP HEIGHT BMP BMP Y 0

In particular at step the bitmap pixel data is updated to reference the first scanline of bitmap pixel data that is required to be rendered. This is achieved by offsetting the bitmap data address by exactly BMP STRIDE BMP Y bytes. The BMP Y field is negative whenever this clipping step is performed.

In step the bitmap image is clipped to align with the bottom edge of the screen by updating the bitmap data structure field BMP HEIGHT as follows BMP HEIGHT SCR HEIGHT BMP

Accordingly only the BMP HEIGHT field is updated at step . The values of other fields and are not changed.

In step the bitmap image is clipped to align with the left edge of the screen by updating the bitmap data structure fields BMP PIXEL DATA BMP WIDTH and BMP  701 as follows BMP PIXEL DATA BMP PIXEL DATA BYTES PER PIXEL BMP BMP WIDTH BMP WIDTH BMP BMP X 0

In particular at step the processor updates the bitmap pixel data to reference the first column of bitmap pixel data that is required to be rendered. This is achieved by offsetting the bitmap data reference by exactly BYTES PER PIXEL BMP X bytes where BYTES PER PIXEL defines the number of bytes that one pixel of bitmap image data occupies. The BMP X field is negative whenever this clipping step is performed.

In step the bitmap image is clipped to align with the right edge of the screen by updating the bitmap data structure field BMP WIDTH as follows BMP WIDTH SCR WIDTH BMP

Referring to in step the processor updates the bitmap data structure and sorts the bitmap data structure into a scan ordered list of bitmap data structures. The method of updating and sorting a bitmap data structure will now be described in detail with reference to . The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

The method begins at step where runtime field SORT Y is initialised to the BMP Y field representing the starting column of the bitmap image.

At the next step the runtime field SORT  710 is initialised to the BMP X field representing the starting column of the image. Then at step the runtime field IS ACTIVATING is initialised to TRUE.

After step the method continues to step . In step the bitmap data structure is insertion sorted into the bitmaps list configured within the RAM . The bitmaps list is sorted in scan order. That is the bitmaps list is sorted lowest to highest first by the SORT Y field and then by the SORT X field for items which have equal SORT Y values. After step the method of updating and sorting a bitmap data structure is complete and the frame description including the bitmaps list is in a state where rendering can be performed.

In one embodiment after bitmap images have been specified groups of graphic objects and their corresponding group opacity values may be specified. For each such group of graphic objects an API function is called to define parameters for the group of objects and a group data structure is added to the groups list. Referring to the fields of a group data structure include the following 

In one embodiment the group opacity field G ALPHA may be specified for each pixel of the screen. In such an embodiment a group opacity buffer configured within RAM may be used to store a group opacity value for each pixel of the screen. Such a group opacity may be denoted G ALPHA.

In another embodiment the group opacity G ALPHA may be specified for each scanline of the screen. In such an embodiment a group opacity buffer configured within RAM may be used to store a group opacity value for each scanline of the screen. Such a group opacity may be denoted G ALPHA.

In yet another embodiment the group opacity G ALPHA may be defined by some function of x and y. Accordingly the group opacity may be a function of screen position.

When a definition for a group of objects is added to the frame description a new group data structure is allocated and added into the groups list configured within RAM . As described above the groups list contains all group data structures to be applied during the rendering of the frame. In one embodiment the groups list is stored in a RAM as a singly linked list. Before any groups are added into the frame description the groups list is initialised to be empty. To initialise the groups list a head pointer of the list is set to be NULL. The groups list is sorted highest to lowest by the group top most priority field G TOP . Group data structures that have equal values for the G TOP field are further sorted lowest to highest by group bottom most priority according to the G BOT field . As described below the groups list is sorted in this way for efficient processing during the compositing process .

Each group of objects is defined by calls to an API function. For each group of objects a group data structure is initialised and added to the groups list configured within RAM . A method of adding a new group data structure to the groups list will now be described with reference to . The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

The method begins at where a previous pointer prey is initialised to NULL and a current pointer cur is initialised to point to the head of the groups list configured within RAM . After this the method continues to step . At step the current pointer cur is compared with the NULL value. If the current pointer cur is NULL then the method continues to step . At step the new group is appended to the end of the existing groups list configured within the RAM .

At step if the processor determines that the existing groups list is empty then the head pointer is set to point to the new group data structure and the next pointer of the new group data structure is set to be NULL. Still at step if the processor determines that the existing groups list is not empty then the next pointer of the previous group data structure is set to point to the new group data structure and the next pointer of the new group data structure is set to be NULL. After step the insertion of the new group data structure has been completed.

If at step the current pointer is found to be not NULL by the processor then the method continues to step . At step the processor determines if the top most priority as represented by the G TOP field of the new group data structure is greater than the top most priority as represented by the G TOP field of the current group data structure. At if the result of the determination is TRUE then the method continues to step . At step the processor inserts the new group data structure into the groups list configured within RAM between the previous and current group data structures.

At step if the processor determines that the previous pointer i.e. prey is NULL then the head pointer is set to point to the new group data structure and the next pointer G NEXT of the new group data structure is set to point to the current group data structure. After step has been performed the insertion of the new group data structure into the groups list is complete.

At step if the processor determine that the result of the comparison is FALSE then the method continues to step . At step the processor determines if the top most priority G TOP of the new group data structure is equal to the top most priority G TOP of the current group data structure. Then at step if the result of the comparison is TRUE then the method continues to step . At step the processor compares whether the bottom most priority G BOT of the new group data structure is greater than the bottom most priority G BOT of the current group data structure. At step if the result of the comparison is TRUE then the method continues to step where the new group data structure is inserted into the groups list configured within RAM between the previous group and current group data structures.

At step if the result of the comparison is FALSE then the method continues to step which involves advancing to the next group data structure. At step the previous pointer i.e. prey is set to point to the current group data structure and the current pointer i.e. cur is set to point to the next group data structure in the groups list or NULL if at end of list. Following step processing continues at step .

After the frame has been set up an API function may be called by the processor in order to commence the rendering of the frame. Upon the rendering commencing a frame description comprising scan ordered list of bitmap data structures and priority ordered list of group data structures is rendered to a frame buffer configured within the RAM . The frame buffer is an area of memory where result pixel data is stored. After rendering is complete the pixel data of the frame buffer is in a format ready for display on the display device . Typically the frame buffer contains scan ordered pixel data. That is typically pixel data in the frame buffer is ordered scanline by scanline from the top of display to the bottom of display where pixels within a scanline appear in left to right order. In one embodiment the processor outputs composited pixels to a scan ordered frame buffer.

The pixel data within the frame buffer is of a particular pixel format. A common frame buffer pixel format is RGB888 which consists of eight 8 bits of red channel data followed by eight 8 bits of green channel data and eight 8 bits of blue channel data giving a total of twenty four 24 bits per pixel. Many other pixel formats exist which use a different number of bits per channel or use a different ordering of colour channels or use an entirely different colour space to represent pixel data.

For certain applications the frame buffer may contain alpha opacity information. A frame buffer using the RGBA8888 pixel format allows an eight 8 bit opacity value to be stored for each pixel in addition to red green and blue channel data. This opacity information is referred to as an alpha channel. The presence of an alpha channel in the frame buffer allows the frame buffer itself to be alpha composited with other images at a later stage. In one embodiment the processor writes composited pixels to a frame buffer using the RGBA8888 pixel format.

The size of the frame buffer depends on the frame buffer pixel format and the width and height of the display in pixels. The minimum size of the frame buffer in bits is provided by Equation 6 below frame buffer size BITS PER PIXEL SCR WIDTH SCR HEIGHT 6 

In some instances a memory offset may be introduced between scanlines of pixel data in the frame buffer. This for example allows the start of each scanline to be aligned to a thirty two 32 bit boundary in the memory address space. Introducing a memory offset between scanlines of pixel data may also allow a subregion of a larger buffer to be used as the frame buffer. To facilitate such a memory offset between scanlines a stride value is associated with the frame buffer. The stride value is equal to the number of bytes between the start of one scanline and the start of the following scanline. If there is no memory offset between scanlines then the stride value in bytes is given by the Equation 7 as follows stride BITS PER PIXEL SCR WIDTH 8 7 

If the memory offset between scanlines is scanline offset bytes then the stride value in bytes is given by the Equation 8 as follows stride BITS PER PIXEL SCR WIDTH 8 scanline offset 8 

As described herein the processor processes bitmap images to identify scan ordered runs of pixels. For each run of pixels compositing is performed to display the run of pixels on the display device . The required compositing for a run of pixels is performed in accordance with a method of compositing variable opacity objects which will be described in detail below with reference to . Each time the method is performed a corresponding run of pixels is written to the frame buffer configured within the RAM .

In one embodiment each scan line of the display is rendered in scan order. is a flow diagram showing a method of rendering each scan line. The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

The method begins at step where a list of active bitmaps is initialised to be empty by the processor . This list may be configured within the RAM and is referred to as the active bitmaps list. The active bitmaps list is initially empty and is used to store pointers to bitmap data structures. The active bitmaps list is sorted highest to lowest by bitmap priority value BMP PRIORITY . The active bitmaps list is later used during the compositing process in accordance with the method to specify the bitmaps to be composited for a particular run of pixels. In addition to the active bitmaps list a value used to track the current scan line CUR Y is initialised to a value of zero 0 to indicate the first scan line to render. In one embodiment the first i.e. top most scan line in the screen displayed on the display device will have a CUR Y value of zero 0 and the final i.e. bottom most scan line has a CUR Y value one 1 less than the height of the screen in pixels i.e. SCR HEIGHT 1 .

An additional value to be tracked is the current column CUR X within the current scanline. At step the CUR X value is set to zero 0 by the processor .

After step the method continues to step where the processor determines whether there is a next bitmap available for processing. This is determined by comparing the head pointer of the bitmaps list with NULL. If no next bitmap exists then the method continues to step where the current scanline is rendered from the current column within the scanline CUR X to the right screen edge. A method of rendering to the right screen edge as executed at step is shown in and will be described in more detail below.

At step if a next bitmap does exist then the method continues to step where the next bitmap data structure from the bitmaps list is retrieved by the processor . The step of retrieval at step does not remove the bitmap data structure from the bitmaps list but accesses the fields contained within the bitmap data structure.

After step the method continues to step where a test is performed by the processor to determine whether the retrieved bitmap intersects with the current scanline CUR Y . To determine this the SORT Y field of the bitmap data structure is compared with the CUR Y value. If the processor determines that the currently retrieved bitmap intersects with the current scanline then the method continues to step where the bitmap data structure retrieved is processed. A method of processing a current bitmap data structure as executed at step will be described in detail below with reference to . After step the method continues to step to retrieve the next bitmap if one exists.

At step if the processor determines that the retrieved bitmap does not intersect with the current scan line being processed then there are no more images that need to be rendered for the current scan line and the method continues to step . At step the current scanline is rendered from the current column within the scanline CUR X to the right screen edge in accordance with the method .

At step after a scanline has been rendered to the screen edge the current scanline CUR Y is incremented. After step the method flows to where the processor performs a test to check whether the last scanline on the screen has been rendered. If the last scanline on the screen has not been reached then the processor continues to step to render the next scanline.

The method of rendering to the right edge of the screen will now be described. The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

The method begins at step where the processor determines a composite width value. The composite width value is the number of pixels to be composited and rendered in accordance with the method i.e. the compositing process . The composite width is stored in a variable named COMP WIDTH configured within the RAM . To render the remaining pixels in the current scanline the COMP WIDTH value is calculated by deducting the current column position CUR X from the total number of pixels in a scanline SCR WIDTH . After step the method continues to step where the compositing process is performed by the processor in accordance with the method . The method i.e. the compositing process involves processing the graphic objects in the active bitmap list and will be described in more detail later. After step the method continues to step where the current scanline variable CUR Y is incremented to indicate rendering is advancing to the next scanline. After step the method of rendering to the right edge of the screen is complete.

The method of processing a current bitmap data structure as executed at step will now be described with reference to . The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

The method begins at step where a check is performed by the processor to determine if the current bitmap starts in the current column in the current scanline being processed. If the bitmap image does not start at the current column then the method continues to step where the processor determines the number of pixels COMP WIDTH between the current column and the starting column of the current bitmap SORT X . Following step at step using the current row CUR Y the current column CUR X the number of pixels to be composited COMP WIDTH and the active bitmaps list a compositing process is performed by the processor in accordance with the method .

Following step the method continues to step where the current column variable CUR X is incremented by the number of composited pixels COMP WIDTH . After step the method flows to step .

At if it is determined that the current bitmap starts in the current column then the method flows to step .

At step the current bitmap data structure is examined by the processor to determine if the current bitmap data structure is associated with the activating left or deactivating right side of a bitmap image. A bitmap data structure with IS ACTIVATE flag set to TRUE marks the activating left side of a bitmap. Such a bitmap data structure may be referred to as an activating bitmap data structure.

If at step an activating bitmap data structure is encountered by the processor then the method moves to step where the bitmap data structure fields are updated so that the bitmap data structure fields mark the ending column for the current bitmap. In particular at step the processor adds the bitmap width BMP WIDTH to the SORT X field and sets the IS ACTIVATE flag to FALSE. Once these fields have been adjusted the method moves to step where a pointer to the bitmap data structure is added into the active bitmaps list configured within the RAM such that the bitmap data structure of the active bitmaps list are sorted from highest to lower by the bitmap priority value BMP PRIORITY . After step the method continues to step where the processor re sorts the bitmaps list configured within RAM to ensure that the bitmap data structure is in the correct position within the bitmaps list according to the updated field values. The re sorting step results in the bitmap data structures of the bitmaps list being sorted in scan order. That is the bitmaps list is sorted lowest to highest first by the SORT Y field and then by the SORT X field for items which have equal SORT Y values.

If at step a deactivating bitmap data structure is encountered by the processor then the method moves to step where the bitmap data structure is removed from the active bitmaps list. Following step the method continues to step where the SORT Y field of the bitmap data structure is incremented to indicate the next scanline of the bitmap which will need rendering.

Following step the method continues to step where the processor determines if the last scanline of the bitmap image has been reached. In particular at step the processor compares whether the SORT Y value is equal to BMP Y BMP HEIGHT. If this test returns FALSE then the method flows to step . At step the SORT X field of the bitmap data structure is set to be equal to the left column value of the bitmap BMP X and the IS ACTIVATE flag is set to a value of TRUE. Following step at the next step the bitmaps list is re sorted by the processor . After step the processing of a current bitmap data structure is complete.

If the processor determines at step that the last scanline of the bitmap has been reached then the method continues to step . At step the processor removes the bitmap data structure from the bitmaps list so that the bitmap data structure is not processed on subsequent scanlines. After step the processing of a current bitmap data structure is complete.

The compositing process composites a number of graphic objects using a top down compositing order. The method compositing process accepts a number of RGBA8888 pixel format bitmap image graphic objects to be composited. Alternatively pixel formats other than RGBA8888 may also be used. The following parameters are determined before the method compositing process is invoked by the processor 

In accordance with the method compositing process group opacity is applied to the graphic objects of the active bitmaps list configured within RAM . The application of group opacity is performed in accordance with the group data structure definitions of the groups list. The method compositing process composites the graphic objects of the active bitmaps list and renders a run of pixels to the frame buffer configured within RAM . The number of pixels in the run of pixels to be rendered is equal to the composite width COMP WIDTH . In one embodiment the maximum composite width is equal to the screen width in pixels SCR WIDTH .

In another embodiment the maximum composite width is limited to a value less than the screen width in pixels SCR WIDTH . Such a limitation reduces RAM requirements at the cost of some additional processing overhead.

During compositing as graphic objects are processed top to bottom in a top down compositing fashion a mask stored in a mask buffer configured within RAM is used to store remaining opacity which can be applied to those graphic objects yet to be processed. In one embodiment each value of the mask is a one 1 byte quantity holding a value between zero 0 and two hundred and fifty five 255 inclusive. For each nested group that is entered the mask is saved into a temporary mask stored in a temporary mask buffer configured within RAM for later use. Each mask buffer is large enough to hold mask values for each pixel in the run of pixels to be rendered. The maximum mask buffer size is defined by the maximum composite width required during compositing.

As compositing takes place result pixel colour and opacity values accumulate in a compositing buffer configured within the RAM . The compositing buffer is large enough to hold pixel values for the run of pixels to be rendered. The compositing buffer has a maximum size defined by the maximum composite width required during compositing.

A particular colour or opacity channel r g b a corresponding to a particular pixel in the compositing buffer may be denoted as composite buffer.

After compositing of all pixels in a run has completed the result pixel values are read from the compositing buffer converted to the required frame buffer pixel format and written to the frame buffer configured within RAM . The pixel data in the frame buffer is in a format suitable for display on the display .

The method of compositing graphic objects including variable opacity graphic objects will now be described with reference to . One or more of the graphic objects are attenuated by group opacity. As described above the method may be referred to as the compositing process. The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

The method begins at step where a number of initialisations are performed by the processor . In particular a primary mask is initialised within RAM such that all mask values have value two hundred and fifty five 255 . Accordingly the processor performs that step of initialising the primary mask. The initialised primary mask may be referred to as a first mask. Further the compositing buffer is initialised so that red green blue and alpha components are zero and a NEXT GROUP variable is set to point to the first rendering group in the groups list. Finally also at step a MASK ALL ZERO flag is initialised to FALSE. The NEXT GROUP variable indicates the next new group in the groups list that needs to be processed during the execution of the method compositing process .

Following step the method compositing process continues to step where the current graphic object is set to be the first graphic object in the active bitmap list configured within RAM . After step processing continues to step where the processor performs a test to determine whether the current graphic object is the start graphic object of a group. Step is achieved by comparing the priority BMP PRIORITY of the current graphic object with the start priority G TOP of the NEXT GROUP in the groups list. If the current graphic object does correspond to the start graphic object of a group then the method proceeds to step . Otherwise the method proceeds to step to process the current graphic object. The current graphic object is processed at step in accordance with a method of processing a current graphic object which will described in detail below with reference to . At step the following variables and buffers may be updated 

At step the group of graphic objects is processed in accordance with a method of processing grouped graphic objects which will be described in detail below with reference to . The method may be referred to as a process group method. The processing of a group may update the primary mask values current graphic object NEXT GROUP and MASK ALL ZERO flag accordingly. The current graphic object will have been set to refer to the last i.e. bottom most graphic object of the group as the group will have been processed. After step the method proceeds to step .

At step the processor tests the MASK ALL ZERO flag. If the MASK ALL ZERO flag is set to TRUE then the remaining graphic objects in the active bitmaps list do not need to be processed and the method compositing process is complete. Otherwise at step if the MASK ALL ZERO flag is set to FALSE then the method continues to step .

At step the processor checks whether the current graphic object is the bottom most graphic object to be processed i.e. the last bitmap data structure in the active bitmaps list . If the current graphic object is not the bottom most graphic object then the method continues to step where the graphic object below the current graphic object BMP NEXT is set as the new current graphic object. After step the method loops back to step to process the new current graphic object. If at step the current graphic object is the bottom most graphic object to be processed then the method compositing process is complete as there are no more graphic objects to be processed.

The method of processing grouped graphic objects will now be described with reference to . As described above the method may be referred to as the process group method. The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

The input of the method includes a mask which will be referred to as the primary mask in method . The primary mask contains the mask values for each pixel in the run of pixels to be rendered. The input to the method also includes the current row CUR Y being rendered the start column CUR X of the run of pixels to be rendered and the number of pixels in the run to be rendered COMP WIDTH . The input to the method also includes a current graphic object bitmap in the active bitmap list a current group in the priority ordered groups list and a frame buffer FRAME BUF .

The method starts at step where the processor performs initialisation by setting the MASK ALL ZERO flag to FALSE and the NEXT GROUP variable to reference the next group of the current group.

Following step at step the group opacity G ALPHA of the current group is tested. If the group opacity is zero 0 then the method advances to step . Otherwise if the group opacity is not zero 0 then the method continues to step .

At step the primary mask is stored for later use. This stored mask will be referred to as the stored mask. A new mask is allocated or generated within RAM and this new mask becomes the second primary mask. The new mask is allocated with the same size as the stored mask as follows stored mask primary mask allocate new mask 2primary mask new mask

The above expressions involve assignments of references and no copying of buffer content is performed.

Then at step the second primary mask i.e. the newly allocated mask or second mask is initialised according to the opacity of the current group G ALPHA and the stored mask. Accordingly at step the processor performs the step of generating the second primary mask. For each second primary mask value the initialisation is carried out in accordance with Equation 9 as follows 2primary mask stored mask G ALPHA 255 9 

In one embodiment if the current group opacity is a variable opacity then the second primary mask is initialised according to Equation 10 as follows 2primary mask stored mask G ALPHA 255 10 

In another embodiment if the current group opacity is a variable opacity in the vertical direction only then the second primary mask is initialised according to Equation 11 as follows 2primary mask stored mask G ALPHA 255 11 

Accordingly the group opacity G ALPHA may be a function of screen position. In yet another embodiment the group opacity G ALPHA value may be determined by evaluating some function of screen row and column position.

At step the current graphic object is tested by the processor to determine whether the current graphic object corresponds to the start graphic object of a new rendering group. The processor makes the determination at step by examining the start priority G TOP of the NEXT GROUP in the groups list. If the current graphic object is the start of a new group the method continues to step and the new group is processed by recursively calling the process group method itself. The processing of the new rendering group may update the values of the second primary mask the MASK ALL ZERO flag the current graphic object pointer and the NEXT GROUP accordingly. After processing the new group at step the current graphic object will have been set to the end graphic object of the new group as the new group will have been processed at step . Otherwise at step if the current graphic object is not the start of a new rendering group then the method proceeds to step . At step the current graphic object is processed in accordance with the method of processing the current graphic object described below using the second primary mask.

After step the method continues to step where the MASK ALL ZERO flag is tested. If the MASK ALL ZERO flag is FALSE then the method continues to step where the current graphic object is tested to determine whether the current graphic object corresponds to the end graphic object of the current rendering group. Step is performed by testing if there is a next graphic object BMP NEXT with priority BMP PRIORITY greater than or equal to the bottom most priority G BOT of the current group. If the current graphic object is not the end graphic object of the current group then at the next step the graphic object below the current graphic object BMP NEXT is set to be the new current graphic object. After step the method loops back to step to process the new current graphic object. At step if the current graphic object is the end graphic object of the current rendering group the method continues to step where the stored mask is adjusted before the processing of the group finishes.

If the group opacity is zero at step or the MASK ALL ZERO flag is set to TRUE at step then the method continues to step .

At step all graphic objects contained within the current group are skipped. A graphic object O is considered to be contained within a group G if the graphic object O satisfies the following condition G.G BOT

Step is performed by setting the current graphic object to be the end bottom most graphic object within the current group. Following step the method advances to step .

At step all groups contained within the current group are skipped. A group CHILD is considered to be contained within another group PARENT if the top priority of the group CHILD is smaller or equal to the top priority of the group PARENT and the bottom priority of the group CHILD is greater or equal to the bottom priority of the group PARENT. Step is performed by scanning the group list from the current group until a group is found that is not contained within the current group. The NEXT GROUP variable is updated to point to the first group not contained within the current group or NULL if no such group is found. Following step the method advances to step .

At step the stored mask may be adjusted by the processor . If the group opacity G ALPHA is zero then the stored mask adjustment is not performed. In this case there is no adjustment needed. If the group opacity is not zero then the mask adjustment is carried out in accordance with Equation 12 as follows stored mask 2primary mask 255 G ALPHA 255 stored mask 12 

Following the stored mask adjustment the stored mask is returned to the primary mask for subsequent processing. The MASK ALL ZERO flag is also updated according to the values in the primary mask by setting the MASK ALL ZERO flag to true if the primary mask is all zero. The stored mask restored as the primary mask is updated using the second primary mask and the group opacity. The primary mask can then be used for compositing graphic objects located below the current object. After step the method is complete.

The method of processing a current graphic object will now be described in with reference to . The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor . The method operates on a primary mask. The primary mask is usually the equivalent of the second primary mask used in the method of or the primary mask of the method . Alternatively the primary mask is the primary mask of a method which will be described below with reference to .

The method starts at step where the processor performs the step of determining the contribution value OBJ CONTRIB of each pixel of the current graphic object based on the opacity of the graphic object OBJ ALPHA and the values of the primary mask. The contribution value OBJ CONTRIB of each pixel of the current graphic object may be determined in accordance with Equation 14 and represents a contribution of the graphic object to the compositing buffer. The contribution value can be calculated as follows OBJ CONTRIB OBJ ALPHA primary mask 255 14 

At step if the graphic object is a fully opaque image i.e. the opacity of the graphic object OBJ ALPHA is equal to two hundred and fifty five 255 then the calculation of the contribution OBJ CONTRIB of each pixel of the current graphic object can be optimised in accordance with Equation 15 as follows OBJ CONTRIB primary mask 15 

The contribution value OBJ CONTRIB is later used to update the values of the primary mask. In addition to setting the contribution of the current graphic object at step if the graphic object is fully opaque then the MASK ALL ZERO flag is set to TRUE.

Then at step the processor performs the step of determining an output colour value OBLOUT COL of each pixel of the graphic object. The output colour value OBLOUT COL is based on the colour OBJ COL of the graphic object and the corresponding value of the primary mask. The red green and blue colour channels of the output colour value OBLOUT COL are determined in accordance with Equation 16 as follows OBJ OUT COL OBJ COL OBJ CONTRIB 255 16 

The opacity channel of the output colour value OBJ OUT COL is equal to the contribution value of the graphic object in accordance with Equation 16b as follows OBJ OUT COL OBJ CONTRIB 16b 

The determination of the opacity channel of the colour value OBJ OUT COL is a function of the contribution value OBJ CONTRIB of the graphic object in accordance with Equation 16 . Furthermore the contribution value OBJ CONTRIB of the graphic object is a function of the primary mask value in accordance with the Equation 14 . Furthermore the primary mask value is a function of group opacity G ALPHA in accordance with Equation 9 . Accordingly the colour value OBJ OUT COL is determined at step using the group opacity G ALPHA . The contribution value OBJ CONTRIB is also used in updating the mask. Further the determined colour value OBJ OUT COL includes an opacity value in accordance with Equation 16b .

After the output colour value OBJ OUT COL for each channel has been determined at step the processor performs the step of compositing the output colour with a compositing buffer. In particular at step each output channel red green blue and alpha is added to the compositing buffer configured within RAM in accordance with Equation 17 as follows composite buffer composite buffer OBJ OUT COL 17 

After step the method continues to step where the processor performs the step of updating the primary mask values. Corresponding to each pixel the primary mask values are updated in accordance with Equation 19 as follows primary mask primary mask OBJ CONTRIB 19 

The updated primary mask values are a function of the contribution value OBJ CONTRIB of the graphic object in accordance with Equation 19 . Furthermore the contribution value OBJ CONTRIB of the graphic object is a function of the opacity of the graphic object OBLALPHA in accordance with the Equation 14 . Additionally the existing primary mask values are a function of group opacity G ALPHA in accordance with Equation 9 . Accordingly at step the primary mask values are updated using the group opacity G ALPHA and the opacity OBJ ALPHA corresponding to the graphic object. Following step the method is complete.

In an alternative embodiment graphic objects may be composited without using a recursive technique. Instead of using recursion information associated with a group may be stored in a stack data structure configured within the RAM . A method of compositing variable opacity graphic objects will now be described with reference to . One or more of the graphic objects are attenuated by group opacity. The method may be referred to as an alternative compositing process . The method avoids recursion and may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

The method starts at where a number of initialisations are performed by the processor . In particular at step a primary mask or first mask is initialised within RAM such that all values of the primary mask have a value of two hundred and fifty five 255 the compositing buffer is initialised so that red green blue and alpha components are zero 0 and a current group CUR GROUP is set to NULL. Accordingly at step the processor performs the step of initialising the primary mask. Additionally at step a next group NEXT GROUP is set to the first rendering group in the groups list the parent group of the next group is set to NULL a MASK ALL ZERO flag is initialised to FALSE and the current graphic object CUR OBJECT is set to be the first graphic object in the active bitmap list.

The current group CUR GROUP indicates the innermost group currently attenuating the current graphic object CUR OBJECT . The next group NEXT GROUP indicates the next group in the groups list after the current group CUR GROUP that needs to be processed during the compositing process .

Following step the method continues to step where a test is performed by the processor to determine whether the next group NEXT GROUP starts at or above the current graphic object CUR OBJECT where above is determined by Z order. If the next group does start at or above the current graphic object then the method advances to step . Otherwise the method advances to step . At step a reference to the primary mask is pushed on a stack for later use. The primary mask will be referred to as the stored mask.

Following step the method continues to step where a new mask is initialised according to the opacity of the next group. The new mask becomes the primary mask. The new mask will be a second mask when the step is executed a first time and a third mask when executed a second time and so on. The operations of initialising a new mask at step are summarised below allocate new mask new mask stored mask NEXT GROUP.G ALPHA 255 primary mask new mask

Still at step the current group CUR GROUP is set to be the next group NEXT GROUP . Following step the next group NEXT GROUP is set to be the group following the current group CUR GROUP.G NEXT in the groups list configured within RAM . Still at step if the NEXT GROUP is not NULL then the NEXT GROUP.G PARENT field is set to be the current group CUR GROUP . At steps and an optimisation may be performed to ignore groups that end above the current graphic object. Additionally at steps and groups that have 100 group opacity may be ignored. Following step the method flows back to step .

At step the current graphic object CUR OBJECT is processed in accordance with the method described above with reference to . In particular the current graphic object CUR OBJECT is processed at step using the primary mask which could be the first second or any other mask that is currently in use by the method .

Following step the method flows to step where the current graphic object CUR OBJECT is tested to determine whether the current graphic object CUR OBJECT is the bottom most graphic object. If the current graphic object CUR OBJECT is the bottom most graphic object then the method is complete. If the current graphic CUR OBJECT object is not the bottom most graphic object then the method continues to step .

At step the processor sets the current graphic object CUR OBJECT to be the next graphic object CUR OBJECT.G NEXT in the active bitmap list configured within RAM . Following step the method continues to step .

At step test is performed by the processor to determine if the current group CUR GROUP ends above in terms of Z order the current graphic object CUR OBJECT . If the current group CUR GROUP does end above the current graphic object CUR OBJECT then method continues to step . Otherwise the method loops back to step .

At step the stored mask reference is popped from the stack. Still at step the stored mask referenced by the popped reference is adjusted in a similar manner to step as described above. After adjustment the primary mask is removed from RAM and the adjusted stored mask is restored as the primary mask. These operations performed at step are summarised below stored mask primary mask 255 CUR GROUP.G ALPHA 255 stored mask free primary mask primary mask stored mask 

Still at step the current group CUR GROUP is set to be the parent group of the current group CUR GROUP.G PARENT . Continuing at the step the MASK ALL ZERO flag is updated according to the values of the primary mask. Following step the method flows to step .

The methods described above will now be described by way of example with reference to B C D E F G and H. In the example three graphic objects a rectangle a triangle and a circle are composited in accordance with the method as shown in . As seen in the rectangle is the top most graphic object. The triangle is below the rectangle . The circle is the bottom most graphic object. The top two graphic objects i.e. the rectangle and triangle are grouped together and a group opacity of 0.4 is applied to the grouped graphic objects. The grouped graphic objects comprising the rectangle and triangle will be referred to below as the group .

As shown in the mask may be used as a second primary mask to determine contribution values of the rectangle graphic object as at step of the method . The contribution values of the rectangle graphic object are determined by multiplying the opacity of the rectangle graphic object which is one 1 i.e. 100 with the values of the mask comprising values of 0.4. The contribution values may then be used for compositing as at steps and of method to determine a rectangle area having a final colour value. In the present example the rectangle area is stored in composite buffer configured within RAM . The final output colour value of the rectangle area in the composite buffer is 40 of the original colour of the rectangle graphic object .

As shown in the updated mask may be used to determine contribution values of the triangle graphic object as at step of the method . The contribution values of the triangle are determined by multiplying the opacity of the triangle graphic object of value one 1 representing 100 opacity with the values of the updated mask . As shown in area in the updated mask buffer has values of zero 0 and part of the triangle graphic object intersects with the area . The contribution of the part of the triangle graphic object that intersects with the area is zero 0 and the contribution of a remaining part of triangle graphic object is 0.4. In the example of the contribution values are used to perform compositing as at steps and of method to determine an area having a final output colour value. The area is stored in composite buffer configured within RAM . The final output colour value of the area in the composite buffer is 40 of the original colour of the triangle . The composite buffer contains the rectangle area that corresponds to the rectangle graphic object and the area that corresponds to part of the triangle graphic object . The two areas and have a colour value that is 40 of the original colour value of the rectangle graphic object and the triangle graphic object respectively.

As shown in the restored primary mask may be used to determine contribution values and of the circle graphic object as at step of method . The contribution values and of the circle graphic object may be determined by multiplying opacity of the circle graphic object i.e. the value one 1 representing 100 opacity with the values of the mask . As shown in area in the mask buffer has the value 0.6 and part of the circle intersects the area . The contribution values of the part of the circle that intersects the area are 0.6 and the contribution values of the remaining part of circle are one 1 . The contribution values and may be used for compositing as described previously in steps and of method . A final output colour value in the composite buffer is 100 of the original colour of the circle . The composite buffer contains an area that corresponds to part of the rectangle graphic object and an area that corresponds to part of the triangle graphic object . Both of the two areas and comprise colour values that are 40 of the original colour value of corresponding graphic objects. An area in composite buffer has a mixed colour from both rectangle graphic object and the circle graphic object . In the area the colour value is a mix of 40 of the original colour value from rectangle graphic object and 60 of the original colour value from the circle graphic object . An area in composite buffer has a mixed colour from both triangle graphic object and circle graphic object . In the area the colour value is a mix of 40 of the original colour value from triangle graphic object and 60 of the original colour value from the circle graphic object .

In one embodiment an optimisation may be used to improve the efficiency of compositing constant alpha graphic objects. In such an embodiment graphic objects above the top most variable alpha graphic object may be processed using just a single mask value representing the entire run of pixels to be rendered. Such an optimisation may be used to process graphic objects that are above i.e. of higher priority than the top most variable alpha graphic object. Instead of initialising the mask buffer at the size of the number of pixels involved in compositing COMP WIDTH only a single mask value is initialised. When a graphic object with variable alpha is encountered a mask buffer with size equal to the run length COMP WIDTH may be initialised so that all mask values are equal to the single mask value. Following the initialisation of the mask buffer the methods described above may be used to composite variable opacity objects with group opacity applied.

Following the steps of the method compositing process or the method alternative compositing process the result pixels for the run are read from the compositing buffer converted into the frame buffer pixel format and written to the frame buffer configured within RAM .

As described above there are numerous pixel formats that can be used for representing a bitmap image. In one embodiment the frame buffer contains pixels of the RGBA8888 pixel format which can be assembled from individual 8 bit red green blue and opacity channels. In this instance the opacity information is stored as part of each frame buffer pixel. The opacity information is only necessary in some applications. If opacity information is not required in the frame buffer then the opacity information may be omitted from the frame buffer as an optimisation.

In one embodiment the compositing buffer may be used as the frame buffer and no separate frame buffer is required. In such an embodiment no conversion of pixel format takes place since the pixels of the compositing buffer are in a pixel format that is suitable for display on display device .

A dithering operation may be applied to each frame buffer pixel. Display devices using a low number of bits per colour channel can exhibit unintended patterns that degrade the visual quality of the rendered output image. Such unintended patterns are a result of the low dynamic range of phosphor intensities to which such displays are limited. Dithering is used to minimise such unwanted effects.

In one embodiment the rendering system outputs eight 8 bits per channel data. In this instance dithering is not performed since eight 8 bits per channel data provides sufficient dynamic range of phosphor intensities.

After all pixel runs in the frame have been composited and written to the frame buffer the frame buffer will be in a state suitable for display on the display device .

In one embodiment the processor executes a method of creating a linear gradient filled bitmap image. After creating a linear gradient filled bitmap image the bitmap image may be used as input to for compositing with other bitmap images.

A method of filling a bitmap image with a linear gradient will now be described with reference to . The method may be implemented as one or more code modules of the application program resident in ROM and being controlled in its execution by the processor .

The method begins at step where the processor determines parameters of the linear gradient. The linear gradient parameters are as follows 

The linear gradient to fill the bitmap image consists of nine 9 ordered RGBA colour values. Each of these nine 9 colours are specified in a colour ramp parameter RAMP . The colour ramp is an array of unsigned thirty two 32 bit values where each unsigned thirty two 32 bit value represents one RGBA8888 colour value.

A linear gradient may be defined to exist in a two dimensional 2D gradient space. In the gradient space the linear gradient blends colours of the colour ramp across a range from x 0 to x 65536. The gradient space range x65536 will be filled using a last colour ramp value RAMP 8 .

A transformation TXFM parameter may be specified for mapping the linear gradient from gradient space into the bitmap image space. The transformation supplied is an affine transformation as is commonly used in the field of two dimensional 2D computer graphics. The transformation parameter TXFM may be determined in accordance with Equation 20 below 

The TXFM parameter may be used to scale rotate and translate the linear gradient by transforming the gradient space into the bitmap image space. If an identity transform i.e. one that does not scale rotate or translate is supplied as the TXFM parameter then the linear gradient will be rendered so that the 9 colours of the colour ramp RAMP are blended between the range x 0 to x 65536.

Following step the method continues to step where the processor determines a determinant value of the transformation parameter TXFM . The determinant value is calculated in accordance with Equation 21 as follows Determinant 10 21 

After step the method continues to step wherein a horizontal step value is calculated in accordance with Equation 22 as follows Horizontal Step Value Determinant 22 

After step the method continues to step where the processor determines whether the horizontal step value is less than zero. If the horizontal step value is less than zero 0 then the method continues to step . Otherwise the method continues to step .

At step the processor updates TXFM to include a one hundred and eighty 180 degree rotation about the centre of the linear gradient and the horizontal step value is set to the negative of the horizontal step value.

The rotation of the linear gradient at step is achieved using a matrix multiplication in accordance with Equation 23 as follows 

Following step the method continues to step which involves reversing the colours of the colour ramp RAMP . The colour ramp is reversed by swapping the colour value RAMP 0 with the colour value RAMP 8 the colour value RAMP 1 with the colour value RAMP 7 the colour value RAMP 2 with the colour value RAMP 6 and the colour value RAMP 3 with the colour value RAMP 5 .

Following step the method continues to step . At step a vertical step value may be determined by the processor in accordance with Equation 24 as follows Vertical Step Value 1 Determinant 24 

After step the method continues to step where the gradient space position corresponding to the bitmap image origin is determined by the processor . The gradient space position is the start point when rendering the linear gradient to the bitmap image. The gradient space bitmap image origin value may be determined in accordance with Equation 25 as follows Gradient Space Bitmap Origin 1 Determinant 25 

After step the method continues to step where linear gradient pixels are rendered by the processor to a bitmap image buffer B BUF configured within RAM . The linear gradient pixel rendering is performed one scan line at a time until all scan lines for the bitmap image are finished. For each pixel in each scan line of the bitmap image a gradient space position gx is determined from the bitmap image space pixel position x y according to the following equation Gradient Space Bitmap Origin Vertical Step Value Horizontal Step Value 26 

Following determination of the gradient space position gx a final pixel colour value is determined as follows 

The methods described above perform alpha compositing of graphic objects attenuated by group opacity very efficiently. The described methods need less memory than conventional compositing methods since no additional RGBA image buffer is needed. In accordance with the methods described above a single mask is used for each nested group. The mask is 25 of the size of such a RGBA image buffer.

The compositing methods described above support nested groups and only visible graphic objects are rendered. For example if graphic object A is obstructed then the graphic object A will not be rendered. Accordingly there is no need to access obstructed graphic objects below a current graphic object in accordance with the described methods.

In accordance with the methods described above there is no per graphic object overhead to support group opacity. Further the scan ordered frame buffer only needs to be written once for each graphic object.

It is apparent from the above that the arrangements described are applicable to the computer and data processing industries.

The foregoing describes only some embodiments of the present invention and modifications and or changes can be made thereto without departing from the scope and spirit of the invention the embodiments being illustrative and not restrictive.

In the context of this specification the word comprising means including principally but not necessarily solely or having or including and not consisting only of . Variations of the word comprising such as comprise and comprises have correspondingly varied meanings.

