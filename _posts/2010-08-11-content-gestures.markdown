---

title: Content gestures
abstract: Content gestures are described. In implementations, one or more controls are output to control output of content and for display in a user interface by a computing device. An input is recognized, by the computing device, which was detected using a camera as a gesture to interact with a particular one of the controls to control the output of the content.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09009594&OS=09009594&RS=09009594
owner: Microsoft Technology Licensing, LLC
number: 09009594
owner_city: Redmond
owner_country: US
publication_date: 20100811
---
The application claims priority to U.S. Provisional Patent Application No. 61 353 626 filed on Jun. 10 2010 and titled Motion Based Media Controls the disclosure of which is hereby incorporated by reference in its entirety.

User may have access to a variety of different devices to interact with media. For example a user may utilize a cursor control device to interact with media output by a desktop computer a remote control device to interact with media on a television and so on. Consequently each one of these different devices may have a different layout of buttons that support different features which may be confusing to the user.

Further some of the devices may be misplaced and difficult to relocate. For instance a user may misplace a remote control device for a television. Additionally the remote control device may be configured as a primary input device for the television such that some functions are available exclusively through use of the remote control device. Accordingly the user may spend a significant amount of time in trying to find the device which may lead to user frustration and a diminished user experience.

Content gestures are described. In implementations one or more controls are output to control output of content and for display in a user interface by a computing device. An input is recognized by the computing device which was detected using a camera as a gesture to interact with a particular one of the controls to control the output of the content.

In implementations an input is recognized by a computing device which was detected using a camera as a gesture to select a marker in a seekbar the marker describing a position in an output of content described by the seekbar. Responsive to the recognizing a display of the seekbar is zoomed by the computing device to display an amount of time in the playback of the media in greater detail.

In implementations one or more computer readable media comprise instructions that responsive to execution on a computing device cause the computing device to perform operations comprising outputting a seekbar to control playback of media by the computing device and recognizing an input that was detected using a camera as a gesture to select a particular point in the playback of the media through interaction with the seekbar.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

Remote control devices were developed to aid users to navigate through output of content. However the devices may be frequently misplaced or located far away from the user when the user desires to control output of the content such as to playback particular television show. This may be inefficient for the user as the user may have a difficult time locating the remote control and a difficult time navigating to a desired position within the content.

In implementations a computing device provides users with the ability to control content output using gestures. For example the user may use a hand gesture to engage a seekbar system a second hand gesture to drag a handle on the seekbar to change a position at which the content is to be output and then use a third hand gesture to start playback of the content. This allows the user to control content output without directly interacting with a remote control device e.g. pressing physical buttons or other device.

In addition the seekbar may provide zoom functionality to permit increased control for user selections. For example a user may select a marker in a seekbar that indicates a current position within a playback of media to be output. Responsive to this selection the seekbar may show at least a portion of the seekbar in greater detail. In this way the user can refine their selection on the seekbar automatically.

Further the seekbar may also include thumbnail previews of the media at different positions along the seekbar. For example the user may move the marker along the seekbar. In response the computing device may provide an output of thumbnails that correspond to the locations in the playback of the media through which the marker is moved. This gives the user a quick view of media content without forcing the user to abandon the current media being viewed which may be displayed as a background. A variety of other functionality is contemplated further discussion of which may be found in relation to the following sections.

In the following discussion an example environment is first described that is operable to employ the media playback control techniques described herein. Example illustrations of the techniques and procedures are then described which may be employed in the example environment as well as in other environments. Accordingly the example environment is not limited to performing the example techniques and procedures. Likewise the example techniques and procedures are not limited to implementation in the example environment.

The computing device is illustrated as including an input output module . The input output module is representative of functionality relating to recognition of inputs and or provision of outputs by the computing device . For example the input output module may be configured to receive inputs from a keyboard mouse to identify gestures and cause operations to be performed that correspond to the gestures and so on. The inputs may be detected by the input output module in a variety of different ways.

The input output module may be configured to receive one or more inputs via touch interaction with a hardware device such as a controller as illustrated. Touch interaction may involve pressing a button moving a joystick movement across a track pad use of a touch screen of the display device e.g. detection of a finger of a user s hand or a stylus and so on. Recognition of the touch inputs may be leveraged by the input output module to interact with a user interface output by the computing device such as to interact with a game an application browse the internet change one or more settings of the computing device and so forth. A variety of other hardware devices are also contemplated that involve touch interaction with the device. Examples of such hardware devices include a cursor control device e.g. a mouse a remote control e.g. a television remote control a tablet computer a mobile communication device e.g. a wireless phone configured to control one or more operations of the computing device and other devices that involve touch on the part of a user or object.

The input output module may also be configured to provide a natural user interface NUI that may recognize interactions that do not involve touch. For example the computing device may include a NUI input device . The NUI input device may be configured in a variety of ways to detect inputs without having a user touch a particular device such as to recognize audio inputs through use of a microphone. For instance the input output module may be configured to perform voice recognition to recognize particular utterances e.g. a spoken command as well as to recognize a particular user that provided the utterances.

In another example the NUI input device that may be configured to recognize gestures presented objects images and so on through use of a camera. The camera for instance may be configured to include multiple lenses so that different perspectives may be captured. The different perspectives may then be used to determine a relative distance from the NUI input device and thus a change in the relative distance. The different perspectives may be leveraged by the computing device as depth perception. The images may also be leveraged by the input output module to provide a variety of other functionality such as techniques to identify particular users e.g. through facial recognition objects and so on.

The input output module may leverage the NUI input device to perform skeletal mapping along with feature extraction of particular points of a human body e.g. skeletal points to track one or more users e.g. four users simultaneously to perform motion analysis. For instance the NUI input device may capture images that are analyzed by the input output module to recognize one or more motions and or positioning of body parts or other objects made by a user including what body part is used to make the motion as well as which user made the motion. An example is illustrated through recognition of positioning and movement of one or more fingers of a user s hand and or movement or positioning of the user s hand as a whole. The motions and or positioning may be identified as gestures by the input output module to initiate a corresponding operation.

A variety of different types of gestures may be recognized such a gestures that are recognized from a single type of input as well as gestures involving multiple types of inputs e.g. a hand gesture and voice recognition. Thus the input output module may support a variety of different gesture techniques by recognizing and leveraging a division between inputs. It should be noted that by differentiating between inputs in the natural user interface NUI the number of gestures that are made possible by each of these inputs alone is also increased. For example although the movements may be the same different gestures or different parameters to analogous commands may be indicated using different types of inputs. Thus the input output module may provide a natural user interface the NUI that supports a variety of user interactions that do not involve touch.

Accordingly although the following discussion may describe specific examples of inputs in instances different types of inputs may also be used without departing from the spirit and scope thereof. Further although in instances in the following discussion the gestures are illustrated as being input using a NUI the gestures may be input using a variety of different techniques by a variety of different devices such as to employ touchscreen functionality of a tablet computer or mobile communications device e.g. a wireless phone.

The computing device is further illustrated as including a media playback control module that is representative of functionality relating to control of media playback. For example the media playback control module may be configured to accept inputs from a controller and or NUI input device to control output of media by the computing device such as the media that is currently being displayed in this example. As illustrated on the display device for instance the media playback control module may display one or more controls that are selectable to control playback of media such as a seekbar and other controls examples of which include a display of a pause button and a stop button .

By interacting with these controls a user is able to control output of content by the computing device and in implementations may do so indirectly e.g. without physically handling another device via one or more gestures that are recognized by the media playback control module . Thus the media playback control module may be used to support natural interaction with the computing device to control output of the media further discussion of which may be found in relation to the implementation examples below.

Again although media is described in this example in relation to the techniques described herein these techniques may be leveraged for a variety of other purposes to control output of content. For example the seekbar may be used to scrub pages in a document e.g. thumbnails may represent chapter header pages as further described below a set of pictures position on a map and so on. Accordingly units displayed by the seekbar may be configured in a variety of ways such as discrete number e.g. page numbers in a document distance e.g. distance from start in a street view navigation application logarithmic zoom scale non numeric scales e.g. categories such as movie genre and so on.

In the example system multiple devices are interconnected through a central computing device. The central computing device may be local to the multiple devices or may be located remotely from the multiple devices. In one embodiment the central computing device may be a cloud of one or more server computers that are connected to the multiple devices through a network the Internet or other data communication link. In one embodiment this interconnection architecture enables functionality to be delivered across multiple devices to provide a common and seamless experience to a user of the multiple devices. Each of the multiple devices may have different physical requirements and capabilities and the central computing device uses a platform to enable the delivery of an experience to the device that is both tailored to the device and yet common to all devices. In one embodiment a class of target devices is created and experiences are tailored to the generic class of devices. A class of devices may be defined by physical features types of usage or other common characteristics of the devices.

In various implementations the client device may assume a variety of different configurations such as for computer mobile and television uses. Each of these configurations includes devices that may have generally different constructs and capabilities and thus the computing device may be configured according to one or more of the different device classes. For instance the computing device may be implemented as the computer class of a device that includes a personal computer desktop computer a multi screen computer laptop computer netbook and so on.

The computing device may also be implemented as the mobile class of device that includes mobile devices such as a mobile phone portable music player portable gaming device a tablet computer a multi screen computer and so on. The computing device may also be implemented as the television class of device that includes devices having or connected to generally larger screens in casual viewing environments. These devices include televisions set top boxes gaming consoles and so on. The media playback control techniques described herein may be supported by these various configurations of the client device and are not limited to the specific examples of media playback control techniques described herein.

The cloud includes and or is representative of a platform for content services . The platform abstracts underlying functionality of hardware e.g. servers and software resources of the cloud . The content services may include applications and or data that can be utilized while computer processing is executed on servers that are remote from the client device . Content services can be provided as a service over the Internet and or through a subscriber network such as a cellular or Wi Fi network.

The platform may abstract resources and functions to connect the computing device with other computing devices. The platform may also serve to abstract scaling of resources to provide a corresponding level of scale to encountered demand for the content services that are implemented via the platform . Accordingly in an interconnected device embodiment implementation of functionality of the media playback control module may be distributed throughout the system . For example the media playback control module may be implemented in part on the computing device as well as via the platform that abstracts the functionality of the cloud .

Generally any of the functions described herein can be implemented using software firmware hardware e.g. fixed logic circuitry or a combination of these implementations. The terms module functionality and logic as used herein generally represent software firmware hardware or a combination thereof. In the case of a software implementation the module functionality or logic represents program code that performs specified tasks when executed on a processor e.g. CPU or CPUs . The program code can be stored in one or more computer readable memory devices. The features of the media playback control techniques described below are platform independent meaning that the techniques may be implemented on a variety of commercial computing platforms having a variety of processors.

The seekbar in this example describes a total duration of playback of an item of media which is a one hour television show in this example but other media items are also contemplated such as music video stored locally or streamed over a network games and so on. Other examples are also contemplated such as to display an amount of time in playback of an item of media that is less than a total duration taken to output the media such as elapsed time for streaming a video playing a game and so forth.

The seekbar also includes a marker that indicates a current position in an output of the media and thus may also be referenced in the following discussion as a current position marker . This allows the user to see how much media has been viewed and the amount of content that is currently playable such as for progressive downloads live playback or other embodiments. Accordingly the amount of media that is currently playable may change with time. The quality of the media playback may also be displayed in the seekbar.

To initiate interaction with the seekbar a user may make a gesture that indicates that the user desires to interact with the media control functionality of the media playback control module . In this way the media playback control module may help to limit recognition of inadvertent gestures made by the user. As described above a gesture may be defined as movement and or be a position of a hand or other bodily part of the user. Thus a variety of different gestures may be supported by the media playback control module to enter a media playback control mode.

In this example an indication is also displayed in the user interface to indicate a position of the display device that corresponds to the user s hand as recognized by the media playback control module . In this way the media playback control module may provide feedback to a user to assist the user in navigating through the user interface. In this example system a user has made a gesture to initiate a mode to interact with one or more media controls. Example interaction with the one or more media controls is further described in relation to the following figure.

In addition the seekbar may provide for greater control for user selections by providing zooming functionality. After the current position marker is selected for instance the seekbar may zoom in to show a section e.g. of the amount of time of the overall media in greater detail. As shown in for example the seekbar is illustrated as representing an amount of time from zero to sixty minutes whereas the amount of time represented by the seekbar in is from ten to thirty minutes and thus allows for a finer granularity in selecting a particular time using the seekbar .

The amount of time represented by the seekbar when zooming may be configured in a variety of ways such as a percentage of the overall duration of the media playback a set interval and so on. Additionally if the configured amount of time is less than the time for the overall media a zoom may not be performed.

In an implementation the configured amount of time may be consistent such that the area from left to right represents the same amount of time. Additionally the seekbar may expand across the display device such as expand to fill the width of the display device to provide even greater detail. Thus the zooming functionality may provide the user with a more refined selection on the seekbar through selection of particular positions in the playback of the media in greater detail. Thus in this example system a user has selected the marker of the seekbar which may then be moved to select a position in the seekbar for output of corresponding media as further described in the next figure.

Scrubbing may include a variety of other techniques. In an example if the user scrubs to the edge of the seekbar on the display device the seekbar may automatically scroll to bring in another section of the timeline. Furthermore if the user scrubs until the end of the timeline the scrolling may stop. In another embodiment a user s hand motion may be leveraged by the media playback control module to determine scrolling speed. For example if the user s hand motion is far to the left the scrolling speed to the left may be faster. Scrolling speed and other characteristics of scrolling may also be configured by the user.

The media playback control module is also illustrated as providing a thumbnail preview of the media at different positions along the seekbar that corresponds to positions of the marker when moved. For example the thumbnail of includes an image taken from the media at a point 12 04 in the playback of the media. This gives the user a quick visual of media at positions along the seekbar without forcing the user to abandon the current media being viewed.

A thumbnail is again displayed proximally to the marker and includes an image taken from the media at that point in time during the playback. In this instance the current position of the marker is desired for viewing by the user. The thumbnail is also illustrated as including an un zoomed representation of the seekbar such that a user may keep track of their place in the overall playback of the media. Accordingly as shown in the system of the user may perform a gesture to disengage from the seekbar opening of the grasping motion of the user s hand and start media playback from the frame in the thumbnail . The thumbnail of is zoomed into full screen and media playback may continue from the thumbnail frame.

In an implementation a user may perform a scrub gesture faster than the thumbnails can be fetched and rendered by the computing device . In such an implementation the thumbnails may be output as a blur animation of images. In another implementation the thumbnail preview might be hidden and as such the current position is shown solely. Additionally the user may configure the system to disable thumbnail preview without departing from the spirit and scope thereof.

The seekbar as illustrated may also contain indicators of particular points in time in the output of the media e.g. chapter marks that appear on the seekbar as tick marks in the illustrated example but may assume a variety of other characteristics. The indicators may be located at commonly referenced points in playback of the media e.g. after a commercial after a certain number of pictures at a configurable time increment and so on.

Additionally the indicators may utilize a certain gravity or stickiness by the media playback control module to promote selection of the indicators . For example the media playback control module may be configured to position the marker at the indicator which the marker is released within a predefined range of the indicator. Thus when a user drags the marker of the seekbar across indicators within the media the media playback control module may pull the selection towards the indicators. This allows the user to select an indicator with ease. In implementations the indicators may be configured by the user to increase or decrease pull on the marker of the seekbar .

The media playback control module may provide feedback to the user in a message field located in the user interface. For example if the computing device changes state the message field may inform the user and if the user tries to perform an action that is not supported the message field may display action not supported message. Some example state changes include play pause fast forward e.g. 2 4 8 16 32 rewind e.g. 2 4 8 16 32 and so on. Additionally the message field may display symbols to communicate information to the user.

The media playback control module may support a variety of other functionality in relation to the seekbar . For example a user may detach from the seekbar and return to displayed media . In an example a user may perform a motion to start playback at a current handle. In another example a user may perform a motion to leave the marker at a current position without playback. Additionally if the user does not interact with the computing device for a duration of time the device may automatically timeout and remove the controls from display on the display device .

In another implementation a user may make a motion to select other controls on the display device . A variety of different controls and corresponding gesture may be supported such as stop skip forward skip backward pause or play. Skip forward and backward may involve a specified duration of time chapter skipping content skipping and so forth. Additionally the media playback control module may be configured to permit user specification of controls. Further controls may be enabled when the media is in a certain state e.g. skip controls are enabled when the content is paused and are not enabled otherwise. A variety of different controls may be supported by the media playback control module examples of which may be found in relation to the following section.

In an embodiment the media playback control module is implemented to provide a user interface for controlling playback of time based media. The media playback control module may process user input and display onscreen overlays that are configured for interaction by the user. Sources of user input may include controllers e.g. controller remote controls an NUI input device e.g. a motion detector camera and so on. Onscreen overlays may include a progress bar status messages and visible controls for the user to manipulate.

The media playback control module may provide an application programming interface API to an application. As such the application itself may be responsible for the actual rendering of media and managing its transport states but not concern itself with the specifics of the user experience for controlling the media playback.

Although a few examples of media controls were described for the seekbar the seekbar may support a variety of other functionality related to playback. For example the seekbar may include a download indicator describe elapsed and remaining time and include a quality meter. For example the quality meter may involve a visual representation of the quality fidelity of the media content currently being rendered. The quality may be used for streaming media when quality may vary due to bandwidth conditions and may also be used to distinguish standard definition versus high definition quality on downloaded media.

Other controls are also contemplated such as a transport button bar that includes transport controls such as play pause previous chapter rewind stop fast forward next chapter display mode audio language subtitle language and info. Additionally one or more of the controls may be initiated through use of the controller such left right focus navigation of a transport button bar use of an A button to invoke the zooming functionality and so on.

Thus as shown in as user approaches the marker the seekbar zooms in giving the user higher precision in selecting a position. As the seekbar zooms its original position may adjusted to maintain the marker in the same relative position on the display device . Both the seekbar s height and width may scale to achieve a desired degree of zoom. When the marker is selected e.g. attached playback of the media may be paused automatically.

The marker may move smoothly along the entire seekbar but the time indicator and thumbnail may also snap to specific time indications e.g. at 15 second intervals or to a chapter position whichever is nearer. Dragging to extreme left or right may cause the seekbar to scroll until beginning or end of the media is reached . While attached a thumbnail of currently selected position of the marker may be displayed as shown in . When the marker is detached e.g. the user s hand is lowered as a gesture or other gesture as described in relation to media that corresponds to the current position of the marker is played back. Additionally when the marker is detached other media controls may be disabled and left disabled until a short delay e.g. one second after detach to reduce accidental attachment to other media controls during the detach gesture.

The following discussion describes media playback control techniques that may be implemented utilizing the previously described systems and devices. Aspects of each of the procedures may be implemented in hardware firmware software or a combination thereof. The procedures are shown as a set of blocks that specify operations performed by one or more devices and are not necessarily limited to the orders shown for performing the operations by the respective blocks. In portions of the following discussion reference will be made to the environment of and the systems of .

One or more controls are output to control output of content for display in a user interface by a computing device block . Continuing with the previous example the one or more controls may be output responsive to recognition of the above gesture. A variety of controls may be output such as buttons e.g. a pause button a stop button a seekbar and so on as described above.

An input is recognized by the computing device that was detected using a camera as a gesture to interact with one or more controls to control the output of the content block . For instance the input may be recognized as selecting a marker in a seekbar that is manipulable via the gesture to specify a position in the output of the content block . In another instance responsive to the recognition of the selection a display of the seekbar is zoomed to show an amount of time in greater detail in comparison to a display of the seekbar before the recognition of the selection block . A thumbnail view of the media may also be output that corresponds to a point in time in the output of the content indicated by the marker responsive to movement of the marker described by the input block . A variety of other examples are also contemplated such as gestures to press a button indicate a value and so on. For example a user may raise their hand to initiate display of the seekbar move the hand to drag the marker to a desired position in the output of the content and drop the hand to start playback of the media at the position indicated by the marker .

Device also includes communication interfaces that can be implemented as any one or more o f a serial and or parallel interface a wireless interface any type of network interface a modem and as any other type of communication interface. The communication interfaces provide a connection and or communication links between device and a communication network by which other electronic computing and communication devices communicate data with device .

Device includes one or more processors e.g. any of microprocessors controllers and the like which process various computer executable instructions to control the operation of device and to implement embodiments described herein. Alternatively or in addition device can be implemented with any one or combination of hardware firmware or fixed logic circuitry that is implemented in connection with processing and control circuits which are generally identified at . Although not shown device can include a system bus or data transfer system that couples the various components within the device. A system bus can include any one or combination of different bus structures such as a memory bus or memory controller a peripheral bus a universal serial bus and or a processor or local bus that utilizes any of a variety of bus architectures.

Device also includes computer readable media such as one or more memory components examples of which include random access memory RAM non volatile memory e.g. any one or more of a read only memory ROM flash memory EPROM EEPROM etc. and a disk storage device. A disk storage device may be implemented as any type of magnetic or optical storage device such as a hard disk drive a recordable and or rewriteable compact disc CD any type of a digital versatile disc DVD and the like. Device can also include a mass storage media device .

Computer readable media provides data storage mechanisms to store the device data as well as various device applications and any other types of information and or data related to operational aspects of device . For example an operating system can be maintained as a computer application with the computer readable media and executed on processors . The device applications can include a device manager e.g. a control application software application signal processing and control module code that is native to a particular device a hardware abstraction layer for a particular device etc. . The device applications also include any system components or modules to implement embodiments of the gesture techniques described herein. In this example the device applications include an interface application and an input output module which may be the same or different as input output module that are shown as software modules and or computer applications. The input output module is representative of software that is used to provide an interface with a device configured to capture inputs such as a touchscreen track pad camera microphone and so on. Alternatively or in addition the interface application and the input output module can be implemented as hardware software firmware or any combination thereof. Additionally the input output module may be configured to support multiple input devices such as separate devices to capture visual and audio inputs respectively.

Device also includes an audio and or video input output system that provides audio data to an audio system and or provides video data to a display system . The audio system and or the display system can include any devices that process display and or otherwise render audio video and image data. Video signals and audio signals can be communicated from device to an audio device and or to a display device via an RF radio frequency link S video link composite video link component video link DVI digital video interface analog audio connection or other similar communication link. In an embodiment the audio system and or the display system are implemented as external components to device . Alternatively the audio system and or the display system are implemented as integrated components of example device .

Although the invention has been described in language specific to structural features and or methodological acts it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as example forms of implementing the claimed invention.

