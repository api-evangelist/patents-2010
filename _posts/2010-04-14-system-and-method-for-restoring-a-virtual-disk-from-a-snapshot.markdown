---

title: System and method for restoring a virtual disk from a snapshot
abstract: A method and apparatus are disclosed for restoring a virtual disk (vdisk) in a data storage system as the vdisk was at an earlier time. Pointers are maintained to point to data represented by the vdisk. The pointers are saved to persistent storage at the earlier time. The data at the earlier time is maintained on the data storage device. A pointer pointing to data represented by the vdisk at a later time is compared with the pointers saved at the earlier time. If the pointer from the later time matches the pointer saved at the earlier time, keeping the pointer from the later time in the active file system. If the pointer from the later time does not match the pointers saved at the earlier time, copying a set of pointers associated with the pointer saved at the earlier time to the active file system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=07958168&OS=07958168&RS=07958168
owner: NetApp, Inc.
number: 07958168
owner_city: Sunnyvale
owner_country: US
publication_date: 20100414
---
This application is a continuation of U.S. patent application Ser. No. 11 448 558 filed on Jun. 7 2006 entitled SYSTEM AND METHOD FOR RESTORING A VIRTUAL DISK FROM A SNAPSHOT now issued as U.S. Pat. No. 7 743 035 on Jun. 22 2010 which is a continuation of U.S. patent application Ser. No. 10 394 856 filed on Mar. 21 2003 entitled SYSTEM AND METHOD FOR RESTORING A VIRTUAL DISK FROM A SNAPSHOT now issued as U.S. Pat. No. 7 076 509 on Jul. 11 2006 which is a continuation in part of U.S. patent application Ser. No. 10 216 453 filed on Aug. 9 2002 entitled SYSTEM AND METHOD FOR OVERLAYING A VIRTUAL DISK ON A FILE SYSTEM now issued as U.S. Pat. No. 7 107 385 on Sep. 12 2006 by Vijayan Rajan et al. the contents of which are hereby incorporated by reference.

The present invention relates to data backup and restoral and more particularly restoring a virtual disk from a snapshot.

A storage system is a computer that provides storage service relating to the organization of information on writable persistent storage devices such as memories tapes or disks. The storage system may be deployed within a storage area network SAN or a network attached storage NAS environment. When used within a NAS environment the storage system may be embodied as a file server including a storage operating system that implements a file system to logically organize the information as a hierarchical structure of directories and files on e.g. the disks. Each on disk file may be implemented as a set of data structures e.g. disk blocks configured to store information such as the actual data for the file. A directory on the other hand may be implemented as a specially formatted file in which information about other files and directories are stored.

The file server or filer may be further configured to operate according to a client server model of information delivery to thereby allow many client systems clients to access shared resources such as files stored on the filer. Sharing of files is a hallmark of a NAS system which is enabled because of semantic level of access to files and file systems. Storage of information on a NAS system is typically deployed over a computer network comprising a geographically distributed collection of interconnected communication links such as Ethernet that allow clients to remotely access the information files on the filer. The clients typically communicate with the filer by exchanging discrete frames or packets of data according to pre defined protocols such as the Transmission Control Protocol Internet Protocol TCP IP .

In the client server model the client may comprise an application executing on a computer that connects to the filer over a computer network such as a point to point link shared local area network wide area network or virtual private network implemented over a public network such as the Internet. NAS systems generally utilize file based access protocols therefore each client may request the services of the filer by issuing file system protocol messages in the form of packets to the file system over the network. By supporting a plurality of file system protocols such as the conventional Common Internet File System CIFS the Network File System NFS and the Direct Access File System DAFS protocols the utility of the filer may be enhanced for networking clients.

A SAN is a high speed network that enables establishment of direct connections between a storage system and its storage devices. A SAN arrangement or deployment allows decoupling of storage from the storage system such as an application server and placing of that storage on a network. However the SAN storage system typically manages specifically assigned storage resources. Although storage can be grouped or pooled into zones e.g. through conventional logical unit number or lun zoning masking and management techniques the storage devices are still pre assigned by a user e.g. a system administrator to the storage system. The SAN may thus be viewed as an extension to a storage bus and as such an operating system of the storage system enables access to stored information using block based access protocols over the extended bus . In this context the extended bus is typically embodied as Fibre Channel FC or Ethernet media i.e. network adapted to operate with block access protocols such as Small Computer Systems Interface SCSI protocol encapsulation over FC or TCP IP Ethernet.

Storage virtualization generally involves the pooling of storage resources from multiple storage devices such as physical disks typically across a network by one or more storage systems to create a user defined volume . The term volume as conventionally used in a SAN environment implies a storage entity that is constructed by a system administrator by specifying physical disks and extents within those disks via operations that combine those extents disks into a user defined volume storage entity. An extent is a set of contiguously addressed blocks or slices of storage within the specified physical disks. Such construction can occur on either the storage device or application server. Storage virtualization is often used as part of a SAN deployment wherein the user defined volume appears as a single storage entity to the operating system regardless of the types of storage devices pooled. Virtualization thus separates the representation of storage to the operating system from the actual physical storage connected over the network.

Storage virtualization has many interpretations including decoupling of physical disk size limitations and underlying physical structure from a user defined volume corresponding to a disk or lun. Virtualization may also refer to management of luns including defining underlying reliability guarantees of the storage. Commonly this aspect of virtualization is accomplished through explicit mirroring or Redundant Array of Independent or Inexpensive Disks RAID protection levels to a lun that is formed from the storage pool. That is the system administrator explicitly defines the underlying reliability guarantees of the constructed user defined volume. It can be appreciated that this administrative procedure is complex time consuming and therefore costly.

Virtualization may further denote the ability to modify an existing configuration of a lun e.g. to increase its size along with the performance characteristics of the lun. However conventional physical disks and strategies that explicitly construct larger units of storage for use by clients may suffer performance limitations. For example bandwidth to a user defined volume constructed through explicit aggregation of a number of disks and or slices extents of those disks may be limited by physical constraints of the underlying properties of the constructed volume.

In some virtualization systems a SAN or block based data storage model is overlaid onto file based file system thereby enabling clients who require the use of block based addressing to utilize the services of a file server having an appropriate virtualization system. In an exemplary file system each unit of information associated with a file including for example its name its owner time stamps etc is implemented as a file attribute. Both files and directories have attributes wherein each attribute may consist of a single data stream. Such an implementation facilitates the addition of new attributes to a file including data content attributes. Therefore files and directories may contain multiple data streams however each on disk file must contain at least a default data stream through which the file data is accessed.

In the exemplary WAFL file system individual files are described by inodes including for example directory inodes regular inodes and stream inodes. A stream inode represents a named data stream so that multiple data streams may be stored on disks associated with a storage appliance as representations embodying the stream inode type associated with a file. Each stream inode has its own size file share locks byte range locks and data blocks however other file attributes such as time stamps group and user ownership information and access control lists are common for all named data streams and are stored in an on disk base inode . The default data stream along with its size data blocks file share locks and byte range locks is also stored in the base inode. Additionally the names and file handles of the data streams are stored in a hidden directory within the file system that is referenced by the base inode. The hidden directory is represented as a stream dir inode type. The hidden directory is invisible in a directory hierarchy that is viewed by a user e.g. a client external to the file system and thus is inaccessible through an external file system protocol such as the Common Internet File System protocol.

In the example of the Write Anywhere File Layout WAFL file system by Network Appliance Inc. of Sunnyvale Calif. a file is represented as an inode data structure adapted for storage on disks. Broadly stated the on disk format representation of the exemplary WAFL file system is block based using e.g. 4 kilobyte KB blocks and using inodes to describe the files. An inode is a data structure used to store information such as metadata about the file. That is the information contained in an inode may include e.g. ownership of the file access permission for the file size of the file or other attributes described further below. The WAFL file system uses a file handle i.e. an identifier that includes an inode number to retrieve an inode from disk. The exemplary WAFL file system also uses files to store metadata describing the layout of its file system. These metadata files include among others an inode file. The on disk format structure of the WAFL file system including inodes and the inode file is disclosed and described in U.S. Pat. No. 5 819 292 entitled METHOD FOR MAINTAINING CONSISTENT STATES OF A FILE SYSTEM AND FOR CREATING USER ACCESSIBLE READ ONLY COPIES OF A FILE SYSTEM by David Hitz et al. issued on Oct. 6 1998 and incorporated by reference as though fully set forth herein.

Specifically the data section of a regular on disk inode may include user data or pointers the latter referencing 4 kilobyte KB data block on disk used to store the user data. Each pointer is preferably a logical volume block number which is thereby facilitate efficiency among a file system and or disk storage layer of an operating system when accessing the data on disks. Given the restricted size e.g. 128 bytes of the inode user data having a size that is less than or equal to 64 bytes is represented in its entirety within the data section of an inode. However if the user data is greater than 64 bytes but less is than or equal to 64 kilobytes KB then the data section of the inode comprises up to 16 pointers each of which references a 4 KB block of data on disk. Moreover if the size of the data is greater than 64 KB but less than or equal to 64 megabytes MB then each pointer in the data section of the inode references an indirect inode that contains 1024 pointers each of which references a 4 kilobyte data block on disk.

Some known storage operating systems contain the capability to generate a snapshot of the file system. In the example of a WAFL based file system snapshots are described in 3002 by David Hitz et al. published by Network Appliance Inc. which is hereby incorporated by reference and in above incorporated U.S. Pat. No. 5 819 292 entitled METHOD FOR MAINTAINING CONSISTENT STATES OF A FILE SYSTEM AND FOR CREATING USER ACCESSIBLE READ ONLY COPIES OF A FILE SYSTEM by David Hitz et al.

 Snapshot is a trademark of Network Appliance Inc. It is used for purposes of this patent to designate a persistent consistency point CP image. A persistent consistency point image PCPI is a point in time representation of the storage system and more particularly of the active file system stored on a storage device e.g. on disk or in other persistent memory and having a name or other identifier that distinguishes it from other PCPIs taken at other points in time. A PCPI can also include other information metadata about the active file system at the particular point in time for which the image is taken. The terms PCPI and snapshot shall be used interchangeably through out this patent without derogation of Network Appliance s trademark rights.

A snapshot is a restorable version of a file system created at a predetermined point in time. Snapshots are generally created on some regular schedule. The snapshot is stored on disk along with the active file system and is called into a buffer cache of the filer memory as requested by the storage operating system. An exemplary file system inode structure is shown in . The inode for an inode file contains information describing the inode file associated with a given file system. In this exemplary file system inode structure the inode for the inode file contains a pointer to an inode file is indirect block . The inode file indirect block contains a set of pointers to inodes which in turn contain pointers to indirect blocks . The indirect blocks include pointers to file data blocks A B and C. Each of the file data blocks A C is capable of storing in the illustrative embodiment 4 kilobytes KB of data.

When the storage operating system generates a snapshot of a given file system a snapshot inode is generated as shown in . The snapshot inode is in essence a duplicate copy of the inode for the inode file of the file system . Thus the exemplary file system structure includes the inode file indirect blocks inodes indirect blocks and file data blocks A C as in . When a user modifies a file data block the file system layer writes the new data block to disk and changes the active file system to point to the newly created block.

After a snapshot has been created and file data blocks modified the storage operating system can reconstruct or restore the file system inode structure as it existed at the time of the snapshot by accessing the snapshot inode. By following the pointers contained in the snapshot inode through the inode file indirect block inode and indirect block to the unmodified file data blocks A C the storage operating system can reconstruct the file system as it existed at the time of creation of the snapshot.

In known restoration techniques from snapshots the snapshotted files are copied from the snapshot to the active file system. These copies are generated by duplicating inodes and data blocks stored in the snapshot and writing these duplicated blocks and inodes to the active file system. Thus the snapshot is effectively duplicated into the active file system. A noted disadvantage of such a restore technique is that each inode or data block of the snapshot needs to be copied. Such copying in the case of a large file system can require a substantial amount of time and processing power. For example files may be sized on the order of tens of gigabytes. Similarly using known file restore techniques from a snapshot the volume containing the snapshotted file must be large enough to accommodate two full copies of the file namely the snapshot and the file in the active file system. In the example of the large file a volume may not be of sufficient size to accommodate two full copies of the file.

One technique to avoid resource consuming duplication the entire file system is to use the storage operating system s capabilities to restore on demand. Restore on demand techniques are described generally in U.S. Pat. No. 7 475 098 issued on Jan. 6 2009 entitled SYSTEM AND METHOD FOR MANAGING A PLURALITY OF SNAPSHOTS by Hugo Patterson et al. A noted disadvantage of such restore on demand technique is an entire directory tree associated with the file must also be restored. For example if the desired file to be restored is two directories down for example in foo bar file then the directory foo and the subdirectory bar must also be restored. This is reduces the efficiency of the file restoration process. Additionally such restore on demand techniques typically cannot support the restoration of files that include streams or other metadata that are not stored internal to the file but are stored in a separate data stream associated with the file. Such restore on demand techniques typically utilize the snapshot copying methodology described above to restore a particular file. Thus the noted disadvantages of the snapshot duplication method e.g. processing overhead and use of file system space are inherent in these restore on demand techniques.

However there are instances when the restoration of only a single file from a snapshot is desired. For example the entire file system may not suffer an error condition but a single file may become corrupted. Additionally a user may have modified files but later desires to restore the files to a previous state. In these instances the restoration of the entire file system is clearly an inefficient approach.

The disadvantages of the prior art are overcome by providing a system and method for quickly restoring a virtual disk vdisk from a snapshot to an active file system of a storage system. A vdisk is an encapsulated data container that stores both data and metadata. In the illustrative embodiment the metadata associated with the vdisk may be stored in data streams associated with a file implementing the vdisk. Thus in the illustrative embodiment a vdisk is represented by a base inode and one or more stream inodes. The base inode is associated with storing the data contained within the vdisk while the stream inodes associated with the various metadata associated with the vdisk. Initially a determination is made if the vdisk is in the active file system.

If the vdisk has been deleted from the active file system then a vdisk inode is created and its associated buffer tree is generated which points to the data blocks of the vdisk to be restored. This newly created inode and associated buffer tree is then written to the active file system. The associated stream inode is then copied from the snapshot to is the active file system thereby restoring the vdisk. By avoiding duplication of the data blocks substantial storage space processing overhead and time is saved.

If the vdisk exists in the active file system then the snapshot restoration process duplicates the vdisk s inode into a twin inode and moves the buffer tree of the vdisk to the twin inode. A new inode for the restored vdisk is then generated. A reconciliation process then compares block pointers from the duplicated twin inode and the snapshot inodes. If the block pointers match then the block pointer is moved from the twin inode into the inode of the restored vdisk in the active file system. If the block pointers and the block not already in the active file system differ then the block pointer from the snapshot is copied to the active file system. Otherwise the actual data block is copied from the snapshot to the active file system. At the end of the reconciliation process the twin inode only contains block pointers to blocks that have changed with respect to the snapshot. After completion of the reconciliation process the associated streams of the vdisk are copied from the snapshot to the active file system. The vdisk is then restored to the active file system.

By not duplicating the numerous data blocks stored in the snapshot substantial processing time overhead and storage space is saved. In an alternative embodiment a determination can be made by the size of the vdisk to be restored. If the vdisk is of a certain size or smaller the restoration process utilizes a conventional snapshot duplication technique.

When used in a SAN environment a storage system may be embodied as a multi protocol storage appliance having a storage operating system that implements a file system and provides for storage virtualization and support for virtual disks vdisks . An example of a multi protocol storage appliance that may be advantageously used with the present invention is described in co pending and commonly assigned U.S. Pat. No. 7 873 700 issued on Jan. 18 2011 entitled A MULTI PROTOCOL STORAGE APPLIANCE THAT PROVIDES INTEGRATED SUPPORT FOR FILE AND BLOCK ACCESS PROTOCOLS by Brian Pawlowski et al. which was published on Feb. 12 2004 as U.S. Patent Publication No. 2004 0030668 A1 which application is hereby incorporated by reference as though fully set forth herein.

The multi protocol storage appliance is illustratively embodied as a storage system comprising a processor a memory a plurality of network adapters and a storage adapter interconnected by a system bus . The multi protocol storage appliance also includes a storage operating system that provides a virtualization system and in particular a file system to logically organize the information as a hierarchical structure of named directory file and virtual disk vdisk storage objects on the disks .

The clients of a SAN based network environment have a storage viewpoint of blocks or disks. To that end the multi protocol storage appliance presents exports disks to SAN clients through the creation of logical unit numbers luns or vdisk objects. A vdisk object hereinafter vdisk is a special file type that is implemented by the virtualization system and translated into an emulated disk as viewed by the SAN clients. The multi protocol storage appliance thereafter makes these emulated disks accessible to the SAN clients through controlled exports as described further herein.

In the illustrative embodiment the memory comprises storage locations that are addressable by the processor and adapters for storing software program code and data structures associated with the present invention. The processor and adapters may in turn comprise processing elements and or logic circuitry configured to execute the software code and manipulate the data structures. The storage operating system portions of which are typically resident in memory and executed by the processing elements functionally organizes the storage appliance by inter alia invoking storage operations in support of the storage service implemented by the appliance. It will be apparent to those skilled in the art that other processing and memory means including various computer readable media may be used for storing and executing program instructions pertaining to the invention described herein.

The network adapter couples the storage appliance to a plurality of clients over point to point links wide area networks virtual private networks implemented over a public network Internet or a shared local area network hereinafter referred to as an illustrative Ethernet network . For this NAS based network environment the clients are configured to access information stored on the multi protocol appliance as files. Therefore the network adapter may comprise a network interface card NIC having the mechanical electrical and signaling circuitry needed to connect the appliance to a network switch such as a conventional Ethernet switch . The clients communicate with the storage appliance over network by exchanging discrete frames or packets of data according to pre defined protocols such as the Transmission Control Protocol Internet Protocol TCP IP .

The clients may be general purpose computers configured to execute applications over a variety of operating systems including the UNIX and Microsoft Windows operating systems. Client systems generally utilize file based access protocols is when accessing information in the form of files and directories over a NAS based network. Therefore each client may request the services of the storage appliance by issuing file access protocol messages in the form of packets to the appliance over the network . For example a client running the Windows operating system may communicate with the storage appliance using the Common Internet File System CIFS protocol over TCP IP. On the other hand a client running the UNIX operating system may communicate with the multi protocol appliance using either the Network File System NFS protocol over TCP IP or the Direct Access File System DAFS protocol over a virtual interface VI transport in accordance with a remote DMA RDMA protocol over TCP IP. It will be apparent to those skilled in the art that other clients running other types of operating systems may also communicate with the integrated multi protocol storage appliance using other file access protocols.

The storage network target adapter also couples the multi protocol storage appliance to clients that may be further configured to access the stored information as blocks or disks. For this SAN based network environment the storage appliance is coupled to an illustrative Fibre Channel FC network . FC is a networking standard describing a suite of protocols and media that is primarily found in SAN deployments. The network target adapter may comprise a FC host bus adapter HBA having the mechanical electrical and signaling circuitry needed to connect the appliance to a SAN network switch such as a conventional FC switch . In addition to providing FC access the FC HBA offloads fiber channel network processing operations for the storage appliance.

The clients generally utilize block based access protocols such as the Small Computer Systems Interface SCSI protocol when accessing information in the form of blocks disks or vdisks over a SAN based network. SCSI is a peripheral input output I O interface with a standard device independent protocol that allows different peripheral devices such as disks to attach to the storage appliance . In SCSI terminology clients operating in a SAN environment are initiators that initiate requests and commands for data. The multi protocol storage appliance is thus a target configured to is respond to the requests issued by the initiators in accordance with a request response protocol. The initiators and targets have endpoint addresses that in accordance with the FC protocol comprise worldwide names WWN . A WWN is a unique identifier e.g. a node name or a port name consisting of an 8 byte number.

The multi protocol storage appliance supports various SCSI based protocols used in SAN deployments including SCSI encapsulated over TCP iSCSI and SCSI encapsulated over FC FCP . The initiators hereinafter clients may thus request the services of the target hereinafter storage appliance by issuing iSCSI and FCP messages over the network to access information stored on the disks. It will be apparent to those skilled in the art that the clients may also request the services of the integrated multi protocol storage appliance using other block access protocols. By supporting a plurality of block access protocols the multi protocol storage appliance provides a unified and coherent access solution to vdisks luns in a heterogeneous SAN environment.

The storage adapter cooperates with the storage operating system executing on the storage appliance to access information requested by the clients. The information may be stored on the disks or other similar media adapted to store information. The storage adapter includes I O interface circuitry that couples to the disks over an I O interconnect arrangement such as a conventional high performance FC serial link topology. The information is retrieved by the storage adapter and if necessary processed by the processor or the adapter itself prior to being forwarded over the system bus to the network adapters where the information is formatted into packets or messages and returned to the clients.

Storage of information on the appliance is preferably implemented as one or more storage volumes e.g. VOL that comprise a cluster of physical storage disks defining an overall logical arrangement of disk space. The disks within a volume are typically organized as one or more groups of Redundant Array of Independent or Inexpensive Disks RAID . RAID implementations enhance the reliability integrity of data storage through the writing of data stripes across a given number of physical disks in the RAID group and the appropriate storing of redundant information with respect to the striped data. The redundant information enables recovery of data lost when a storage device fails.

Specifically each volume is constructed from an array of physical disks that are organized as RAID groups and . The physical disks of each RAID group include those disks configured to store striped data D and those configured to store parity P for the data in accordance with an illustrative RAID 4 level configuration. However other RAID level configurations e.g. RAID 5 are also contemplated. In the illustrative embodiment a minimum of one parity disk and one data disk may be employed. However a typical implementation may include three data and one parity disk per RAID group and at least one RAID group per volume.

Within each volume may be stored one or more virtual disks vdisks . A vdisk is a special file type in a volume that derives from a plain regular file but that has associated export controls and operation restrictions that support emulation of a disk. In the illustrative embodiment a vdisk is a multi inode object comprising a special file inode and a set of stream inodes that are managed as a single encapsulated storage object within a file system of a storage system. As used herein a set of stream inodes shall be meant as one or more stream inodes. The vdisk illustratively manifests as an embodiment of a stream inode that in cooperation with the special file inode creates a new type of file storage object having the capacity to encapsulate specific security management and addressing export information. A vdisk is thus an encapsulated data container comprising a data section and one or more metadata sections that may be stored in streams associated with the data section within the file system. An example of a stream inode object that may be advantageously used with the present invention is described in U.S. Pat. No. 6 643 654 titled SYSTEM AND METHOD FOR REPRESENTING NAMED DATA STREAMS WITHIN AN ON DISK STRUCTURE OF A FILE SYSTEM by Kayuri Patel et al. which application is incorporated by reference as though fully set forth herein.

To facilitate access to the disks the storage operating system implements a write anywhere file system that cooperates with virtualization modules to provide a function that virtualizes the storage space provided by disks . The file system logically organizes the information as a hierarchical structure of named directory and file objects hereinafter directories and files on the disks. Each on disk file may be implemented as set of disk blocks configured to store information such as data whereas the directory may be implemented as a specially formatted file in which names and links to other files and directories are stored. The virtualization system allows the file system to further logically organize information as a hierarchical structure of named vdisks on the disks thereby providing an integrated NAS and SAN appliance approach to storage by enabling file based NAS access to the files and directories while further enabling block based SAN access to the vdisks on a file based storage platform.

In the illustrative embodiment the storage operating system is preferably the NetApp Data ONTAP operating system available from Network Appliance Inc. Sunnyvale Calif. that implements a Write Anywhere File Layout WAFL file system. However it is expressly contemplated that any appropriate storage operating system including a write in place file system may be enhanced for use in accordance with the inventive principles described herein. As such where the term WAFL is employed it should be taken broadly to refer to any storage operating system that is otherwise adaptable to the teachings of this invention.

As used herein the term storage operating system generally refers to the computer executable code operable on a computer that manages data access and may in the case of a multi protocol storage appliance implement data access semantics such as the Data ONTAP storage operating system which is implemented as a microkernel. The storage operating system can also be implemented as an application program operating over a general purpose operating system such as UNIX or Windows NT or as a general purpose operating system with configurable functionality which is configured for storage applications as described herein. The term metadata refers to data that is generated stores and managed by the storage operating system and its associated file system layer to maintain the structure and organization of the file system. Metadata can include for example security attributes associated with files or data containers. As the storage operating system and its associated file system generate metadata it is referred to herein as internally generated data. Conversely all other data stored by the file system including for example data generated by network clients and or other processes in the storage operating system is referred to as externally generated data. 

In addition it will be understood to those skilled in the art that the inventive technique described herein may apply to any type of special purpose e.g. storage serving appliance or general purpose computer including a standalone computer or portion thereof embodied as or including a storage system. Moreover the teachings of this invention can be adapted to a variety of storage system architectures including but not limited to a network attached storage environment a storage area network and disk assembly directly attached to a client or host computer. The term storage system should therefore be taken broadly to include such arrangements in addition to any subsystems configured to perform a storage function and associated with other equipment or systems.

An iSCSI driver layer provides block protocol access over the TCP IP network protocol layers while a FC driver layer operates with the FC HBA to receive and transmit block access requests and responses to and from the integrated storage appliance. The FC and iSCSI drivers provide FC specific and iSCSI specific access control to the luns vdisks and thus manage exports of vdisks to either iSCSI or FCP or alternatively to both iSCSI and FCP when accessing a single vdisk on the multi protocol storage appliance. In addition the storage operating system includes a disk storage layer that implements a disk storage protocol such as a RAID protocol and a disk driver layer that implements a disk access protocol such as e.g. a SCSI protocol.

Bridging the disk software layers with the integrated network protocol stack layers is a virtualization system that is implemented by a file system interacting with virtualization modules illustratively embodied as e.g. vdisk module and SCSI target module . It should be noted that the vdisk module the file system and SCSI target module can be implemented in software hardware firmware or a combination thereof. The vdisk module interacts with the file system to enable access by administrative interfaces in response to a system administrator issuing commands to the multi protocol storage appliance . In essence the vdisk module manages SAN deployments by among other things implementing a comprehensive set of vdisk lun commands issued through a user interface by a system administrator. These vdisk commands are converted to primitive file system operations primitives that interact with the file system and the SCSI target module to implement the vdisks.

The SCSI target module in turn initiates emulation of a disk or lun by providing a mapping procedure that translates luns into the special vdisk file types. The SCSI target module is illustratively disposed between the FC and iSCSI drivers and the file system to thereby provide a translation layer of the virtualization system between the SAN block lun space and the file system space where luns are represented as vdisks. By disposing SAN virtualization over the file system the multi protocol storage appliance reverses the approaches taken by prior systems to is thereby provide a single unified storage platform for essentially all storage access protocols.

The file system is illustratively a message based system as such the SCSI target module transposes a SCSI request into a message representing an operation directed to the file system. For example the message generated by the SCSI target module may include a type of operation e.g. read write along with a pathname e.g. a path descriptor and a filename e.g. a special filename of the vdisk object represented in the file system. The SCSI target module passes the message into the file system as e.g. a function call where the operation is performed.

The file system illustratively implements the WAFL file system having an on disk format representation that is block based using e.g. 4 kilobyte KB blocks and using inodes to describe the files. The WAFL file system uses files to store metadata describing the layout of its file system these metadata files include among others an inode file. A file handle i.e. an identifier that includes an inode number is used to retrieve an inode from disk. A description of the structure of the file system including on disk inodes and the inode file is provided in the above incorporated U.S. Pat. No. 5 819 292.

SAN clients typically identify and address disks by logical numbers or luns. However the automated storage virtualization technique allows system administrators to manage vdisks and their addressing by logical names. To that end the vdisk module of the multi protocol storage appliance maps logical names to vdisks. For example when creating a vdisk the system administrator right size allocates the vdisk and assigns it a name that is generally meaningful to its intended application e.g. vol vol0 database to hold a database .

The storage virtualization technique addresses the issue of performance limitations by defining a vdisk abstraction of a disk on top of the file system. This abstraction aggregates the bandwidth of the underlying disks by providing greater bandwidth for the vdisk than that obtainable by the concatenation of a smaller number of disk drives needed solely to satisfy space requirements. Additionally delayed allocation policies and write coalescing of the file system can serve to optimize the bandwidth of the vdisk compared to a pure physical implementation. As noted layering of the vdisk on top of the file system also allows the vdisk to inherit the reliability configuration e.g. RAID 4 and or synchronous mirroring of the underlying volume.

Included within the file system is a set of snapshot processes which implement the inherent snapshot capabilities of the file system including e.g. the vdisk restoration process described below. The inherent snapshot capabilities of the WAFL file system are further described in the above incorporated 3002 and U.S. Pat. No. 5 819 292. The snapshot processes include a vdisk restore function that implements the novel vdisk restoration system and method.

The storage system provides an on disk representation of a vdisk stored on for example a multi protocol storage appliance. is a schematic block diagram illustrating an exemplary on disk representation of inode data structures including vdisk lun and stream inodes. A directory DIR inode includes a data section of pointers that references directory data blocks one of which is directory block . The directory block includes a plurality of entries each containing an external representation of an inode i.e. the name of the inode along with mapping information i.e. the inode number for that inode. One of those entries entry contains mapping information e.g. a pointer that references a lun inode .

The lun inode is the special file inode that functions as a main container for storing data associated with the vdisk. That is the lun inode comprises a data section that may store the actual user or application data or pointers referencing 4 KB data blocks on disk used to store the data. The data stored in this default container can be retrieved read and stored written by a client using conventional block access protocols such as the SCSI protocol. When appropriately configured a vdisk may also be accessed using conventional file level access protocols such as the NFS protocol. In this configuration a vdisk appears to be a regular file for such accesses. The lun inode also comprises is a metadata section containing metadata such as the type i.e. a special vdisk type and size of the vdisk that upon creation of the inode is zero. A flag stream flag identifies the lun inode as having not only a default data container section but also one or more stream sections as provided by stream dir inode .

In order to access the stream dir inode the pointer of xinode field in lun inode is modified to reference that inode. The stream dir inode comprises a metadata section that includes a type stream dir field and an xinode field that references another on disk inode structure containing e.g. access control such as CIFS permission information associated with the vdisk. The inode also includes a data section containing a pointer that references a stream directory data block associated with the vdisk such as stream directory block . The stream directory block comprises a data section that includes a plurality of entries each containing an external representation of a stream inode along with mapping information i.e. the inode number for that inode. One of those entries entry contains mapping information e.g. a pointer that references an attributes stream inode .

The attributes inode comprises a metadata section that includes a type stream field and a data section that functions as a persistent store for holding various named attributes associated with the vdisk. Attributes are an implementation mechanism that is internal to the file system and not managed by users. These attributes include information that allows the vdisk to be exported as a logical unit number lun to e.g. SAN clients. In addition the attributes include information that allow the encapsulated vdisk to persist e.g. over reboot operations and enable management of the vdisk as a single disk object in relation to the SAN clients.

Examples of the attributes include among others geometry SCSI serial number space reservation state on line off line and export information the latter controlling access to the vdisk by e.g. specifying a list of initiators to which the vdisk is exported i.e. those that have permissions to access to the vdisk . The geometry information pertains to the physical geometry of the vdisk needed for emulation of a disk or lun. For example the vdisk size as provided by a user is algorithmically converted to geometry information e.g. cylinder size which may be returned to a SAN client as representative of the disk or lun. Although the geometry is illustratively shown as persistently stored in the attributes inode in an alternate embodiment the geometry information may be calculated dynamically on the fly .

Other entries of the stream directory block contain mapping information e.g. pointers that references other stream inodes such as a lunmap stream inode and a persistent reservations stream inode . The lunmap inode comprises a metadata section that includes a type stream field and a data section that functions as a persistent store for holding a list of name value pairs. In the illustrative embodiment the name is an initiator group igroup name and the value is a lun identifier ID . An igroup is a logical named entity that is assigned to one or more addresses associated with one or more initiators depending upon whether a clustered environment is configured . These addresses may comprise WWN addresses or iSCSI IDs. A lun map command is used to export one or more vdisks to the igroup i.e. make the vdisk s visible to the igroup. In this sense the lun map command is equivalent to an NFS export or a CIFS share. The WWN addresses or iSCSI IDs thus identify the clients that are allowed to access those vdisks specified by the lun map command.

The persistent reservations inode comprises a metadata section that includes a type stream field and a data section that functions as a persistent store for holding a list of persistent reservation records that provide ownership and access information relating to the vdisk. Persistent reservations are described in SCSI 3 Primary Commands 3 by Committee T10 of the National Committee for Information Technology Standards. Each persistent reservation record comprises a nexus initiator ID a reservation key WWN and a reservation type shared exclusive read write .

In sum the vdisk storage object is structured to contain data and metadata needed to control and manage that object in a single storage entity that is easy to manage within the framework of a storage operating system executing on a multi protocol storage appliance. To that end the vdisk data and attributes is managed as a single encapsulated unit within the file system.

Specifically the binding between the data file inode and stream inodes of a vdisk creates a single encapsulated object that is self describing in that it contains all the information necessary to e.g. access that object. Thus no external information is needed to describe the vdisk object. It should be noted that there is no binding between a vdisk and disk blocks during write operations or read operations when defragmentation takes place transparently on the fly . The disk blocks are mapped to logical block addresses of an object residing in the file system. In this case the file system functions as a dynamic volume manager. This decoupling is a result of using the file system as an underlying storage manager.

The procedure performed by the file system of the storage operating system or its associated snapshot processes in restoring a vdisk from a snapshot is shown in . Typically such a vdisk restore process would be initiated by the use of a command entered by the user or administrator of the file server. This command could be entered either through a command line interface CLI or via a menu or other selection in a graphical user interface GUI . As options to the command the user enters the name and path to the vdisk to be restored and in alternate embodiments a name and path for the vdisk to be restored to if it is different from the vdisk s original name and or location. Thus for example a vdisk that was snapshotted when it existed in dir sub vdisk could be restored to foo bar othervdisk.

The procedure begins in step and then proceeds to step where the vdisk restore process first locks the associated snapshot. This locking can be accomplished using known file system file locking mechanisms. The locking of the snapshot ensures that the snapshot will not be modified or deleted while the vdisk is being restored. Next in step the inode associated with the vdisk to be restored is locked against access. Such locking can be accomplished by for example setting a flag within the lun inode that is manipulated by an appropriate operating system lock manager. The file system layer and its associated processes recognize the flag and thereby restrict access to the inode. In certain embodiments select file system processes or functions may have access to the lun inode. For example a process or function for determining attributes of the vdisk associated with the lun inode may be permitted to access the inode to determine file system parameters. Similarly in certain alternative embodiments a command or process to delete the vdisk may be permitted to execute even though the lun inode is locked against access.

The vdisk restore process then creates a tracking entry step . This tracking entry described further below is utilized to determine which inodes and block pointers have been compared during the remaining portion of the restore process. Next in step the restore process determines what type of vdisk is being restored. By type of vdisk it is meant in the illustrative embodiment whether the vdisk exists in the active file system is absent from the active file system or is a small vdisk.

If the vdisk to be restored is a small vdisk using an administrator defined definition of small the process performs the conventional copying restore technique by duplicating the inodes block pointers data blocks and streams from the snapshot to the active file system step . If the vdisk is absent from the active file system i.e. the vdisk has been deleted from the active file system the restore process performs the empty file routine routine . Otherwise the vdisk exists in the active file system and is not a small vdisk. In such a case the restore process proceeds to step and performs the standard vdisk restore routine.

The process performed by the restore process for a vdisk that needs to undergo the above referenced reconciliation process is shown in . The procedure begins in step and then proceeds to step where the process performs a series of space checks. The space checks are to ensure that the newly created and restored vdisk will fit within the active file system. While the process of the present invention typically requires little additional space in the active file system for restored vdisks there are several cases where substantial additional space is required. For example if a vdisk was 100 megabytes MB in size when the snapshot occurred but since then has been modified so that it is only 1 MB in size a restoration of the vdisks results in some increased space within the active file system. This increase in space is still significantly smaller than used by conventional restore techniques. Next the process performs a series of copy checks step . In step the restore process performs a type match. This type match ensures that for example no attempt is made to restore the vdisk in the snapshot to a directory or vice versa.

Next in step an inode and associated buffer trees are allocated for use during the restoration process. The inode that is allocated is a new inode for the restored vdisk in the active file system. Additionally the buffer trees of the existing vdisk are copied to a twin. This twin thus has a twin inode and associated buffer trees. The restore process then proceeds to do the reconciliation process in step . This reconciliation process described below walks through the buffer trees of the twin and the snapshot and generates the restored file. Next in step the streams associated with the vdisk are then copied to the active file system. As noted above the streams associated with a given vdisk are relatively small and therefore do not generate a noted performance degradation of the storage appliance. In step the twin inode is turned into a zombie inode. Zombie inodes are later processed by the file system for reallocation. Such zombie processing is described in U.S. Pat. No. 6 751 635 entitled MANIPULATION OF ZOMBIE FILES AND EVIL TWIN FILES by Raymond C. Chen et al. issued on Jun. 15 2004 which is incorporated herein by reference. It should be noted that the use of is zombie files is for illustrative purposes only. In alternate embodiments the twin inode could simply be deleted or otherwise unallocated from the active file system. The tracking entry is then deleted by for example freeing memory or data structures associated with the tracking entry step . The newly created inode of the file system is then unlocked step . At this point the newly restored file is accessible by the active file system. Then in step the snapshot is unlocked. At this point the process is complete step .

The reconciliation process utilized by the restore process is shown in . The process begins at step and then checks for vdisk deletion step . This check is to ensure that if a user deletes the vdisk being restored the vdisk will be deleted and the restoration process will not proceed. The restore process then selects a block pointer from the twin step . The twin block pointer is then compared with the associated block pointer stored in the snapshot in step . A determination is made in step if the block pointers match. By match it is meant that the two block pointers point to the same data blocks. If the two block pointers do match the block pointer from the twin is moved to the active file system in step . If the block pointers do not match a determination is made if the block that is pointed to by the block pointer is already allocated in the active file system step . If the block is already allocated then the data from the block is copied to a new block in the active file system. Otherwise the block pointer from the snapshot is copied to the active file system. Thus if a particular block pointer has not been modified from the time of the snapshot to the time of file restoration the block pointer from the associated twin which is a copy of the block pointer stored in the active file system is moved to the active file system. If the associated block pointer has been modified a copy of the block pointer is generated from that stored in the snapshot and copied to the active file system if the block is not allocated in the active file system. Next in step the restore process determines if there are more block pointers that need to be reconciled. If there are no more block pointers to reconcile the reconciliation process is complete step and the restore process continues on in accordance with the procedure outlined in . If there are more is block pointers to be reconciled the process loops back to step and performs an additional deletion check. Throughout the reconciliation process the tracking entry is used to determine which blocks have been compared and which blocks need to be compared. In accordance with an alternate embodiment multiple blocks can be compared at a time. For example sixteen blocks can be read from the twin and compared with their associated snapshot blocks at a time. The use of multi block comparison improves the performance of the reconciliation process.

To again summarize upon execution of the vdisk restore process which may be included in the file system or snapshot processes of a storage operating system the snapshot and inodes are locked against access and tracking entry is created. The vdisk restore process then determines what type of vdisk is being restored. If the file meets a predetermined or user defined definition of a small vdisk then a conventional snapshot duplication technique can be utilized to restore the vdisk. If the vdisk has been deleted from the active file system then the restore process generates a buffer tree which points to the data blocks stored in the snapshot. Once this buffer tree is created it is written to the active file system. The streams associated with the vdisk in the snapshot are then copied to the active file system thereby restoring the vdisk.

If the vdisk exists in the active file system the reconciliation process occurs. After performing a series of verification operations the restore process allocates a new inode from the restored vdisk and creates a twin inode which contains the inodes associated with the vdisk currently in the active file system. A reconciliation process is then performed whereby a block from a twin inode is then paired to a block in the snapshot. If the blocks are equal the block from the twin is moved to the active file system. If the blocks are not equal then the block from the snapshot is copied to the active file system. This reconciliation procedure proceeds until all blocks and the twin snapshot have been compared. At the end of the reconciliation procedure the twin only contains links and pointers to blocks which have been modified since the time of the snapshot. This twin inode is then turned into a zombie for later processing and deletion. This process thus significantly reduces the number of data blocks that need to be copied from the snapshot is to the active file system. By reducing the number of data copies file system space is saved and processing overhead is reduced. After the reconciliation process the streams associated with the vdisk are then copied from the snapshot to the active file system. At this point the vdisk has been restored to the active file system and may be unlocked for use.

More generally the teachings of the present invention may apply to any logical data containers LDC implemented in an environment comprising an active store and one or more reference stores. In such embodiments the active store permits data to be read from and written to it while the reference stores are read only point in time images of the active store.

The foregoing has been a detailed description of the illustrative embodiment of the invention. Various modifications and additions can be made without departing from the spirit and scope of the invention. For example it is understood that the various data structures and inodes can include additional fields and or be generated or managed by differing layers of a storage operating system while remaining within the scope of the present invention. Additionally while this description has been written and referenced to storage appliances the principles are equally pertinent to all types of computers including stand alone computers. It should be noted that as used herein a set of stream inodes may comprise one or more stream inodes. It is expressly contemplated that encapsulated data containers other than vdisk may be utilized in accordance with the teachings of the present invention. Further it is expressly contemplated that the teachings of this invention can be implemented as software including a computer readable medium having program instructions executing on a computer hardware firmware or a combination thereof. Accordingly this description is to be taken only by way of example and not to otherwise limit the scope of the invention.

