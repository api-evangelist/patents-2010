---

title: Network protocol proxy
abstract: A network proxy can be provided as a layer between an application layer protocol (such as the Remote Desktop Protocol) and a transport layer protocol (such as TCP). The network proxy can intercept communications between the application layer protocol and the transport layer protocol. The network proxy can transmit communications on multiple connections, without the application layer or transport layer protocols being aware of the parallelization.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09054913&OS=09054913&RS=09054913
owner: Dell Software Inc.
number: 09054913
owner_city: Aliso Viejo
owner_country: US
publication_date: 20101129
---
This application claims the benefit of priority under 35 U.S.C. 119 e of U.S. Provisional Patent Application No. 61 265 298 filed on Nov. 30 2009 entitled Parallel Communication Proxy Having Efficient Bandwidth Utilization the disclosure of which is hereby incorporated by reference in its entirety.

TCP Transmission Control Protocol is a widely used transport protocol for sending information over local area networks LANs and wide area networks WANs including the Internet. TCP provides reliable ordered delivery of a stream of bytes from one computer system to another. Many applications rely on TCP including web applications email and file transfer applications.

TCP provides mechanisms for controlling network congestion to reduce packet losses and to promote fair use of network resources. TCP s congestion control features include a slow start mechanism in which TCP slowly ramps up bandwidth usage when a TCP connection is initiated. TCP also employs an algorithm that reduces a connection s bandwidth consumption when TCP detects congestion. In the aggregate when multiple hosts on a network ramp up bandwidth usage slowly and selectively throttle their bandwidth congestion on that network is generally reduced. However TCP s congestion control mechanisms can also adversely impact an individual application s performance.

In certain embodiments a network proxy acts is provided that acts as a layer between an application layer protocol such as the Remote Desktop Protocol and a transport layer protocol such as TCP . The network proxy can intercept communications between the application layer protocol and the transport layer protocol. In some embodiments the network proxy can transmit communications on multiple connections without the application layer or transport layer protocols being aware of the parallelization.

For purposes of summarizing the disclosure certain aspects advantages and novel features of the inventions have been described herein. It is to be understood that not necessarily all such advantages can be achieved in accordance with any particular embodiment of the inventions disclosed herein. Thus the inventions disclosed herein can be embodied or carried out in a manner that achieves or optimizes one advantage or group of advantages as taught herein without necessarily achieving other advantages as can be taught or suggested herein.

Certain application layer network protocols do not efficiently use bandwidth on latent network connections. The inefficiency of such protocols can be exacerbated due to the congestion control properties of TCP described above. The Remote Desktop Protocol RDP is an example of a protocol that can exhibit poor performance in latent network connections over TCP. RDP can be implemented in Virtual Desktop Computing and WINDOWS Terminal Server environments to provide users with remote access to desktop applications. Latent RDP connections over TCP to such environments however can result in a degraded user experience particularly for graphics intensive applications.

The performance of application layer protocols such as RDP can be enhanced by compensating network communications for TCP s congestion control mechanisms. One way to compensate for TCP congestion control is to provide parallel TCP connections between hosts. Using parallel connections instead of a single connection can at least partially circumvent TCP s congestion control mechanisms. As a result throughput can be increased. In certain embodiments these effects can provide benefits on any network including both LANs and WANs. In certain embodiments however parallel TCP connections are particularly beneficial on higher latency networks such as WANs that have a latency of about 30 ms or more.

Although parallel TCP connections can improve throughput RDP and other application protocols are typically coded to access a standard TCP socket application programming interface API . Modifying the source code of an application protocol such as RDP to use a new parallel TCP API would be difficult if not impossible since many application protocols are proprietary. Advantageously in certain embodiments a network proxy can be provided as a layer between a native application layer protocol and TCP. The network proxy can intercept communications between the native application layer protocol and TCP. The network proxy can transmit communications on multiple connections without the native application layer or TCP being aware of the parallelization.

Although this disclosure is described primarily in the context of TCP some or all of the features described herein can also be applied to other transport layer protocols or to other communication protocols.

An application is installed on each host . The application can implement an application layer network protocol such as RDP HTTP SMTP FTP various peer to peer protocols or the like. The applications can but need not be the same type of application. For example the application can be a client application such as a web browser while the application is a server application such as a web server .

A network proxy is interposed between each of the applications and a network. The network proxy can be a software layer or service that overcomes at least some of the limitations of TCP or other protocols. In other embodiments each of the network proxies can be implemented on a hardware appliance in communication with the hosts . When the application on the host attempts to connect to the application on the second host the network proxy on the first host can intercept the communication. The network proxy can buffer the communication and open a plurality of network sessions or connections to the second host. The network proxy can distribute data in the communication over the multiple network connections . The number of connections opened by the network proxy can be user defined or can be determined programmatically as will be described in greater detail below see .

The second host also includes a network proxy that receives the application data over the network connections . The network proxy on the second host can reassemble the data from the multiple network connections into a single stream of data and can provide this stream of data to the application . It should also be noted that the network proxy can also send data over parallel network connections to the network proxy which can reassemble the data received over these connections. Each proxy can therefore include both client and server functionality in certain embodiments.

Advantageously in certain embodiments the actions performed by the network proxies can be transparent to the applications on each host . From the point of view of the application the application calls an API to open a single connection with the application . Likewise the application receives data over what appears to be a single connection to the application . The network proxy can intercept API calls and open multiple connections in place of the single connection while abstracting this activity from the applications . As a result in certain embodiments the network proxy can be configured for use with any application without having to modify the source code of the application.

The network proxy can parallelize network connections at any layer of a network stack. As an example depicts an example network stack that includes an application layer a transport layer a network layer and a link layer . A network proxy depicted as a transport layer proxy is interposed between the application layer and the transport layer . In one illustrative embodiment the application layer implements an application layer protocol such as RDP while the transport layer implements a transport layer protocol such as TCP. The transport layer proxy can therefore parallelize transport layer connections.

The transport layer proxy can parallelize connections based on TCP or other transport layer protocols. For instance in one embodiment the transport layer proxy can intercept a User Datagram Protocol UDP connection request and open parallel UDP connections. In another implementation the transport layer proxy can intercept a UDP connection request and instead open parallel TCP connections. Opening parallel TCP connections instead of a UDP connection can provide the reliability benefits of TCP while at least partially avoiding congestion control thereby providing similar benefits to UDP. Similarly the transport layer proxy can intercept a TCP request and open parallel UDP connections instead.

In some embodiments the network proxy of can parallelize connections between layers other than the application and transport layers. Further the network stack of is merely an illustrative example and can be varied considerably to include fewer or additional layers. Other layers not shown but which may be part of a network stack include presentation layers session layers and a physical layer. In general in various implementations the network proxy can transform any requested connection into multiple connections that represent transmission streams of data or the like.

Referring again to the network connections are illustrated in parallel. The term parallel while having its ordinary meaning is also used herein to refer to logical parallel connections and may but need not imply parallel physical connections such as parallel circuits . Thus data transmitted over parallel connections may be but need not be transmitted on the network connections simultaneously or substantially simultaneously. However the network proxy can cause at least some data to propagate over a network at the same time see e.g. .

Further it should be noted that if an application natively opens multiple TCP connections the network proxy can still open parallel connections corresponding for each of or one or more of the native TCP connections. If a web browser for instance opens a TCP connection for a web page and then a separate TCP connection for an object in the page such as a video the network proxy can optionally open multiple connections for the video or even the web page itself. The application may be unaware of the multiple connections opened by the network proxy as described above. In addition the network proxy can be used in conjunction with other network acceleration compression or encryption technology in certain embodiments.

While the network proxy can increase application throughput circumventing the congestion control mechanism of TCP with additional connections could cause a host to monopolize available bandwidth. In certain embodiments the network proxy therefore dynamically monitors bandwidth usage and makes periodic adjustments to attempt to ensure fair usage of network resources. The network proxy can implement certain congestion control features examples of which are described below with respect to .

Moreover adding more network connections may not always effectively use available bandwidth. Some applications might benefit from more connections than some applications. Merely increasing the number of connections used may provide less than an optimal benefit for other applications. Advantageously in certain embodiments the network proxy can dynamically adjust the number of network connections made and or the size of network buffers e.g. TCP buffers used to more effectively utilize bandwidth. Dynamic connection adjustment is described in greater detail below with respect to . Many other example features of the network proxy are also described in greater detail below.

At block an application attempts to open a single network connection. For instance the application can attempt to open a TCP connection by making a socket API call. At block the connection request is intercepted by a network proxy. The connection request can be intercepted in a variety of ways. One way to intercept the connection is by replacing a network related shared library or dynamic link library DLL used by the application with another library that performs different functions. The network proxy can be or can include the replacement library. Routines in the replacement library can have the same type signatures as the routines used in the replaced library such as the same socket connect routine type signature but different implementing code. Thus the application code need not be modified to call the routines in the replacement library. In one embodiment the replacement library replaces a network services library in an operating system thereby intercepting network connection requests from any application running in the operating system.

Another approach to intercepting the connection request is to inject a monitoring library or DLL into the application process. This monitoring library can monitor connection request calls made by the application trap these calls and issue new calls in their place. The network proxy can be or can include this monitoring library. A third approach to intercepting the connection request is to register a filter library as a network provider with an operating system the application is running in. The network proxy can be or can include the filter library. By registering the filter library with the operating system the filter library can receive network connection requests before they are sent to a normal network stack. Thus routines in the filter library can receive the connection request from the application and open parallel network connections. In some implementations the network proxy can implement any combination of these interception techniques to include a replacement library a monitoring library or a filter library combinations of the same or the like.

At block a plurality of network connections is opened to the remote host by the network proxy instead of a single connection. As used herein the term remote host and its derivatives in addition to having their ordinary meaning can refer to any host that is physically separate from another host regardless of the physical distance separating the two hosts. One or more messages are received from the application at block and these messages are sent by the network proxy to a remote host over the multiple connections at block .

The network proxy has been described primarily as component or set of components that intercepts network connection requests and opens multiple connections in their place. In addition to these features the network proxy can intercept other types of calls made by an application and can execute alternative calls in their place. For example the network proxy can intercept encryption or compression calls made by the application and can perform more secure encryption or enhanced compression in their place.

A more detailed example system for implementing the features of the network proxy will now be described. The example system is described in the context of a server based computing environment that provides client systems with access to shared resources. The shared resources can be virtual desktops implemented as virtual machines WINDOWS Terminal Server sessions blade computers such as blade PCs combinations of the same or the like. However while network proxy features are described in the context of the shared resources system the network proxy can be implemented with other systems that do not include virtual desktops Terminal Servers blade PCs or other shared resources.

Accordingly illustrates an embodiment of a network environment for providing access to a shared resources system . The shared resources system can provide access for users of client systems to shared computing resources . The client systems access the shared resources system using an application process . The application process can implement an application layer protocol such as RDP. In other embodiments the application process can interface with an application layer protocol such as RDP rather than implementing the protocol. A corresponding application process is implemented by the shared resources for communicating with the application process of the client system . The client systems and the shared resources each include a network proxy that can manage multiple parallel network connections between the application processes .

The shared resources system can be implemented by one or more physical computing devices such as servers. These computing devices can be distributed geographically or can be co located. The client systems can include for example desktop computers workstations personal digital assistants PDAs mobile phones other wireless handheld devices laptop computers tablets and the like.

The client systems can further include various software applications for accessing the shared resources system such as browser software applications stand alone software applications plug ins interfaces combinations of the same and the like. The client systems can access the shared resources system over a network which can include a local or wide area network LAN or WAN such as an organization s intranet the Internet combinations of the same and the like.

In the depicted embodiment the shared resources system includes a broker server the shared resources described above an authentication server and a data store . Each of these components can be implemented in software and or hardware. For example in one embodiment the broker server represents a physical computing device. In another embodiment the broker server represents a software service executing on a physical computing device. Although the various components of the shared resources system are illustrated separately some or all of them can be implemented together in one or more of the same computing devices.

The client systems can communicate with the broker server to obtain access to the shared resources . The broker server can perform load balancing by allocating shared resources to client systems in a manner that reduces the load on any given shared resource . The broker server can also provide authentication services for the client systems to authenticate to the shared resources . The broker server can communicate with the authentication server which may include user directory information and or authentication services to authenticate the client systems . In certain embodiments the broker server can also implement certain features of the broker described in U.S. patent application Ser. No. 12 078 174 filed Mar. 27 2008 titled System for Provisioning Allocating and Managing Virtual and Physical Desktop Computers in a Network Computing Environment the 174 application the disclosure of which is hereby incorporated by reference in its entirety.

The shared resources can be implemented using any of the features described in the 174 application referred to above. Further in embodiments where the shared resources include virtual desktops the shared resources can include virtual machines implemented on a hypervisor. The hypervisor can allow multiple virtual desktops having possibly different operating systems to run on a host computer at the same time.

For instance the hypervisor can include a thin piece of software that runs directly on top of a hardware platform of a host computer and that virtualizes resources of the computer e.g. a native or bare metal hypervisor . In such embodiments the virtual desktops can run with their respective operating systems on the hypervisor without the need for a host operating system. In other embodiments the virtual desktops can have a hosted architecture in which the hypervisor runs within a host operating system environment. In such embodiments the hypervisor can rely on the host operating system for device support and or physical resource management. Each virtual desktop can include a guest operating system and associated applications. The virtual desktop can access the resources e.g. privileged resources of the host computer through the hypervisor.

As described above each of the client systems and the shared resources include a network proxy that enables multiple parallel network connections to be made between the client system and the shared resource . More particularly the network proxy can manage parallel network connections between application processes on the client system and shared resource . The application processes are examples of the applications described above with respect to . The network proxies can have all the functionality of the network proxies described above with respect to .

More detailed examples of a network proxy and an application process are illustrated from a client side perspective in and from a server side perspective in . Referring to a client side proxy system A is shown that includes a more detailed version of portions of the shared resources system of . The network proxy system A includes a network proxy in communication with an application process . The example network proxy shown includes an injector module and a connections manager . A management console is also provided to enable customization of network proxy features. Example features of the management console are described below with respect to .

The network proxy can be implemented by the client system described above with respect to . Similarly the application process can be implemented in the client system . The network proxy can intercept connection requests made by the application process . The network proxy can open multiple connections to a remote host and send messages from the application process over the multiple connections. Although not discussed in detail below it should be understood that sending data over logical network connections such as TCP connections can also include receiving packets such as acknowledgement packets.

In the depicted embodiment the network proxy implements the monitoring library features described above with respect to to intercept communication requests from the application process . In particular an interceptor module is shown as an example of a monitoring library that can monitor connection request calls made by the application process trap these calls and issue new calls in their place. It should be understood that in other embodiments the network proxy can implement a replacement library or filter library for intercepting communication requests from the application process or any combination of such libraries.

To prepare the network proxy to manage the opening of parallel network streams in one embodiment the injector module injects a monitoring library into the address space of the application process . The injector module thereby forces the process to run the injected monitoring library. In the depicted embodiment the injector module injects the interceptor module or monitoring library into the application process . The interceptor module can include a library of routines such as a shared library or DLL which can perform various functions. Advantageously the interceptor module can alter the operation of the application process network communications without altering the source code of the application process

The interceptor module can include one or more routines for trapping or intercepting networking function calls made by a communications module of the application process . The intercepted function calls can include calls to a socket API that attempt to create a TCP connection for instance. Upon intercepting a socket connection call the interceptor module can run alternative routines in place of the original calls to redirect the connection to the connection manager of the network proxy . As an alternative to intercepting function calls the interceptor module can include one or more routines that modify one or more network request properties of the application process . Modifying these properties can include changing an intended destination property of a message to refer to a different IP address and port e.g. a TCP port .

In one embodiment the interceptor module redirects the attempted socket connection to the localhost or the same computer system e.g. IP address 127.0.0.1 that the application process is running on. The interceptor module can also specify a port number assigned to the connections manager to which the redirected connection will connect. Over this localhost socket connection the connections manager can receive data for transmission from the interceptor module . With communications redirected to the connections manager the connections manager can open a plurality of socket connections to a remote network proxy on another remote host. The connections manager can then distribute the data intercepted by the interceptor module over these connections thereby transmitting the data over the network . In other embodiments some or all of the functionality of the connections manager can be implemented directly by the interceptor module

Referring to a network proxy is shown that can be implemented in a receiving host system that receives data over parallel network connections from the network proxy of . A connections manager of the network proxy can listen for connections on a port typically used by an application process to thereby intercept connections intended for the application process . For example RDP typically listens on port 3389. The connections manager can modify RDP settings e.g. in the WINDOWS registry to have RDP listen on a different port such as 3390 . The connections manager can then listen on port 3389 in RDP s place receive and reassemble parallelized data and forward the data to RDP s new port 3390 .

This mode of operation can be considered a pass through mode since the connections manager listens on the application process s native port and passes communications through to the application process . In an alternative mode the connections manager listens on any available port of a host such as 3390 receives and reassembles the parallelized data and forwards the data to the native port of the application process such as 3389 . The mode used to receive data with the network proxy can be user configurable through a management console see .

If the port number of the application process is unknown techniques described below with respect to or C can be used by the sending system to inform the receiving system of the application process s port number. Further in alternative implementations the connections manager can use forms of inter process communication other than TCP IP based communication to provide the reassembled data to the application process

Example sending and receiving features of the network proxy will now be described in greater detail with respect to processes illustrated in . The processes described with respect to may be implemented by any of the systems or network proxies described herein including the systems and A B and the network proxies and .

Referring to an embodiment of a connection interceptor process is shown. The connection interceptor process intercepts single network connection requests from an application process and redirects the requests to a network proxy. The connection interceptor process is described from the point of view of a sending host which may be a client or server.

At block an interceptor module is injected into an application process running on a host. The interceptor module may be injected by the injector module described above. As described above the interceptor module can include a library of one or more program routines. Referring again to the injector module can inject the interceptor module by creating a thread in the application process that will run the interceptor module . The interceptor module can therefore run concurrently with other threads of the application process

Any of a variety of techniques can be used by the injector module to inject the interceptor module into the application process . Generally speaking these techniques can be referred to as DLL injection. Some example DLL injection techniques that the injector module can employ include modifying the registry of the process to load the interceptor module at runtime creating a new thread in the process using a function such as CreateRemoteThread in WINDOWS and hooking the process with a function such as SetWindowsHookEx in WINDOWS . Similar library injection techniques or other techniques can be used in operating system environments other than WINDOWS.

Referring again to an available port on the host is scanned for at block . This scanning can be performed by the interceptor module or by another component of a network proxy. The available port can be bound to the connections manager so that communications to the available port are sent to the connections manager see block . In one embodiment the scanning operation of block is performed once instead of each time the connection interceptor process executes.

At block the interceptor module listens for a network connection request by the application process. The interceptor module can listen for a particular socket API call to be made for instance. At block it is determined whether a network connection request was made by the application process. If so at block the request is redirected to connect to the network proxy on the available port instead. With the request redirected to the connections manager messages can pass from the application process to the network proxy. If no request is made however the process loops back to block effectively continuing to listen for a connection request.

The request can be redirected in a variety of different ways. For example the interceptor module can access properties of the request or of the application process itself. For the RDP protocol the properties can be accessed through an ActiveX control. The interceptor module can modify a property of the request that relates to the intended destination of the request. Modifying the property can include changing the IP address of the intended destination to the localhost e.g. 127.0.0.1 and changing the destination port to the port bound to the connections manager . The interceptor module can send the intended destination information to the connections manager so that the connections manager will know which server and port number to access over parallel connections.

In another embodiment the interceptor module can trap the socket API call of the application process and obtain any intended destination information from the socket API call. The interceptor module can then run a replacement socket routine in place of the socket API call which redirects the connection request to the port bound to the connections manager . The replacement socket routine can also send the intended destination information to the connections manager . In another implementation instead of using a replacement socket routine the interceptor module can trap and modify the socket API call of the application process. This modified socket API call can include the localhost address and port number of the connections manager instead of the intended destination information.

As described above with respect to the destination port of some application processes may be unknown to the connections manager in the receiving host. In such situations the sending host can inform the receiving host of the destination port number as illustrated in . illustrates a different approach for handling an unknown destination port.

Referring to an embodiment of a port relaying process is shown. In the port relaying process a target port number is identified in messages intercepted from an application process at block . The target port number can be identified by the connections manager of the sending host s network proxy. At block a message is sent to the receiving host that includes the target port number. This message can be sent by the sending host s network proxy prior to opening parallel network connections to the receiving host.

At the receiving host the network proxy is configured to listen on the target port number at block . The connections manager of this network proxy can for instance modify the settings of the application process e.g. in a WINDOWS registry to listen on a different port than the target port. Then the connections manager can bind itself to the target port. In this manner the network proxy on the receiving host can intercept communications from the sending host on the target port.

At block network connections are opened by the sending host to the target port on the receiving host. In the depicted embodiment each of the parallel connections is opened to a single port. The connections manager on the receiving host can create a thread for each connection to the port. In alternative embodiments the parallel connections can be opened to multiple ports instead.

Over these connections the sending network proxy can communicate the target port number to the receiving network proxy. Alternatively the receiving network proxy can identify the port number of the application process from settings related to the application process which in WINDOWS systems may be obtained from the registry. The receiving network proxy can forward reassembled messages to the application process at the target port number of the application process.

At block a connection from an application process is intercepted using any of the techniques described above. At block a plurality of network connections are created. Each network connection can be created by opening a TCP socket for instance. At block a message is received from the application process. The message can include data to be transmitted over a network to a receiving host. The message can be streamed from the application process such that portions of the message are provided to the network proxy at a time. Thus the remainder of the process can be performed while additional portions of the message are being received from the application process. Alternatively the remainder of the process can be performed once the entire message has been received.

The message is divided into a plurality of submessages at block . Each submessage can be intended for a different one of the network connections. The submessages can be of equal length or of varying length. The submessages may but need not have the same length as a data payload of a TCP segment.

A series number is added to each submessage at block . For instance a header that includes the series number can be created for the submessage. The series number can be used to reassemble the submessages at the receiving network proxy in the proper order. The series number may be useful because submessages can arrive out of order both within an individual connection and among parallel connections. The series number can be separate from the sequence number assigned by TCP to each segment. Advantageously in certain embodiments using series numbers in this manner can facilitate reassembling the messages at the receiving end without modifying TCP or any other existing protocol . In alternative implementations however TCP or another protocol can be modified to include the additional series numbers in each TCP or other segment.

Turning to an example system implementation of the parallel connection creation process of is shown. In the example system a message is received from an application process by a connections manager . The connections manager can include all of the functionality of the connections manager described above. The connections manager divides the message into submessages and assigns series numbers to each submessage . The connections manager opens multiple TCP connections to a remote host see and distributes the submessages over the connections .

For illustrative purposes three connections are shown in . Each connection includes a plurality of submessages . The series number for each submessage is depicted within the submessage numbers 0 through 35 . The numbers shown are merely illustrative and may differ in other embodiments. In the depicted embodiment the connections manager distributes the submessages in a round robin fashion to each connection . For example the connections manager can assign each successive submessage to a different connection . Submessage 0 the first submessage is therefore in connection 1 submessage 1 is in connection 2 submessage 2 is in connection 3 and so on.

Instead of assigning each successive submessage to a different connection the connections manager could instead successively assign a block of submessages to each connection. For instance the connections manager could transmit submessages 0 through 3 on connection 1 submessages 4 through 7 on connection 2 and so on. In other embodiments the connections manager can use other distribution algorithms other than a round robin algorithm to transmit data over the connections . The connections manager can also prioritize certain types of traffic such as multimedia traffic to include more connections than other types of traffic. Such embodiments are described in greater detail below with respect to .

At block submessages are received over a plurality of network connections. These submessages may be received out of order due to taking different routes through a network because of retransmission when packets are dropped or for other reasons. Thus at block the series number for each submessage is identified. The submessages or representations thereof such as pointers to the submessages are assigned to a data structure according to their series numbers at block . Once sufficient in order submessages have been received the submessages are combined into a message at block and sent to an application process in block .

Turning to an example system implementation of the message reassembly process of is shown. The system can be implemented in a receiving host and receives the submessages sent from the system of . With continued reference to a connections manager receives submessages over various connections . Three connections are shown each corresponding to the connections in .

As shown in the submessages may be received out of order as identified by their series numbers. The connections manager therefore maintains a data structure such as an array or the like that holds the submessages or pointers thereto as they arrive. As can be seen submessages 0 2 and 4 have been received in the data structure . Empty slots in the data structure indicate places where not yet received submessages may eventually be placed. Once a sufficient number of submessages have been received the connections manager combines the submessages into a message and outputs the message to an application process not shown .

As described above the network proxy can increase application throughput by circumventing the congestion control mechanism of TCP with additional connections. However in doing so the network proxy may cause a host to monopolize network resources. In certain embodiments the network proxy can balance its goal of congestion avoidance with a goal of attempting to ensure fair usage of network resources. illustrate an example congestion control technique that a network proxy can perform.

The process will also be described in the context of which depicts a congestion control system . In the congestion control system example hosts are shown as in . Each host has an application that communicates with the other over a network through a network proxy or . The network proxy opens multiple network connections to the other network proxy . These connections are referred to as data network connections in .

Referring to at block a congestion control connection is opened. An example of such a congestion control connection is shown in . The congestion control connection can be a separate TCP connection that does not send any application data from the application to the other application . Instead the congestion control connection can send test packets to the network proxy .

Referring again to at block the congestion control connection is monitored for the presence or level of congestion. Congestion can be detected in a variety of ways. For instance the network proxy can send echo packets and measure their round trip return time RTT to infer congestion. A higher RTT can reflect more congestion and vice versa.

It is determined at decision block whether congestion was detected. If so the data network connections are throttled at block to mitigate the congestion. The data network connections can be throttled in a variety of ways. One way is to close one or more of the connections. Another way to throttle the connections is to reduce the TCP receive buffer size for one or more of the connections.

In alternative embodiments a congestion control connection is not used. Instead the connection manager monitors the data network connections to detect the presence of congestion in any of the network connections. If the connection manager detects congestion in any of the connections the connection manager can throttle the bandwidth used by the one or more of the other connections.

Various customization features will now be described. The network proxy can be customized by a user such as a network administrator. In addition the network proxy can automatically adjust its operation based on a variety of factors. User customization of the network proxy is described with respect to while automatic network proxy customization is described with respect to . Any of the network proxies and systems described herein can implement the features described with respect to .

Among other features the customization user interface includes user interface controls to adjust settings of a network proxy referred to in the FIGURE as WAN acceleration. A radio button control allows a user to enable or disable the network proxy. If the network proxy is enabled a user can specify whether to use the network proxy in a pass through mode using a checkbox control . As described above using the network proxy in pass through mode can cause the network proxy to listen for incoming network connections on an application process s native port. Operating in pass through mode can allow a user to avoid configuring a firewall to accept a new port. If a user does not wish to use the network proxy in pass through mode the user can instead specify a port number for the proxy to listen on in a text box control .

Additionally another text box control is provided for enabling a user to specify a maximum number of connections for a network proxy to make. The network proxy need not open the maximum connections but instead may be limited by the maximum number of connections. The control can enable an administrator to tune the performance of the network proxy. In addition the control can enable an administrator to enforce network policy so that a number of connections is not exceeded.

At block one or more application characteristics and or network characteristics are determined. Application characteristics can include the type of application that is using the network proxy the size of a message to be communicated by the application and so forth. Network characteristics can include available bandwidth latency and the like.

One example of an application that can be analyzed at block is an application implementing a native protocol such as RDP. As described above RDP is a protocol that can transmit graphics audio text and other data associated with a virtual desktop or Terminal Server session. Many different types of computer applications can transmit data over RDP including video streaming applications office productivity applications web applications and so on. The application characteristics determined at block can include the type of application layer protocol the application is using to communicate such as RDP or HTTP. The application characteristics can also include what type of application is communicating over the network such as a word processor application or a web browser application.

Some applications tend to use more bandwidth and therefore might benefit from more parallel connections. An example of such an application is a video streaming application. Other applications tend to use less bandwidth and therefore might have sufficiently good performance with fewer parallel connections. In fact for some such applications too many parallel connections can actually degrade performance. One type of application that might use less bandwidth is an office or productivity application such as a word processor application. Similarly TCP receive buffer sizes can affect performance with bandwidth intensive applications potentially benefiting from larger buffer sizes.

Different network characteristics or conditions can also dictate how many connections might be useful to open or how large to make the TCP buffer. With more available bandwidth more connections can be opened to take advantage of the available bandwidth. Similarly larger buffer sizes can be used in higher bandwidth conditions. In addition the higher the latency present on the network the more connections and or higher buffer size might be desirable.

Thus at block based on the application and or network characteristics a number of connections and or buffer size are automatically selected e.g. by the connections manager . The connections are established at block . At block one or more characteristics of the connections and or the application are monitored such as the type of application currently using the connections e.g. media player versus word processor the bandwidth of the connections their latency and the like. Since the application being used its bandwidth consumption and the network can change over time it can be desirable to adjust the number of connections and or buffer size used.

Thus if at decision block it is determined that one or more connection and or application characteristics have changed then an automatic adjustment to the number of connections or buffer size is made at block . For example if the network is experiencing higher latency the network proxy may open additional connections to offset the effects of the latency. In another example the network proxy can open one or more new connections if an application consumes more bandwidth and vice versa . The network proxy can detect when an application s bandwidth usage changes for example by determining whether the application attempts to send a certain different type of data over the network such as video data . The network proxy can then add more connections or close connections as appropriate. It should be noted that instead of closing a connection based on the monitored network conditions a network proxy can simply stop sending submessages on the connection.

If one or more connection and or application characteristics have not changed the process loops back to block where the monitoring continues. At decision block it is further determined whether the connections are closed. If so the process ends. Otherwise the process loops back to block where monitoring continues.

As another potential embodiment the network proxy may also monitor the network characteristics of each individual connection and adjust the data sent over the connections based on these characteristics. For instance if one connection is more congested than another the network proxy can reduce or minimize the amount of data sent over that congested connection. The network proxy can send messages to other connections instead. Similarly the network proxy can favor connections with more data when those connections exhibit lower latency than other connections. Moreover while the process has been described as being implemented by a network proxy the features of the process can also be implemented by an application that opens multiple network connections using API calls. Thus the features of the process are not tied to network proxy features in certain embodiments. Many other variations are possible.

At block a client system suggests to a server system an initial number of network connections and or a buffer size. The suggested number of connections or buffer size can be determined based on the criteria described above with respect to . At decision block it is determined whether the server proposes an alternate number of connections or buffer size. The server might propose these alternate connection characteristics based on information available to the server about network conditions application characteristics and so forth.

If the server proposes an alternate number of connections or buffer size the client system establishes the suggested number of connections and buffer size at block . Otherwise the client system establishes the alternate number of connections and or buffer size at block . In an alternative embodiment the client may further suggest different connection characteristics in response to the servers suggestion. If the server accepts the new characteristics the client system can establish the connections using the new characteristics. Moreover in another embodiment the client system merely uses the server s proposed characteristics as suggestions which the client system may or may not choose to adopt.

Some native protocols such as RDP transmit data over virtual channels. Virtual channels can include certain application specific data that is packed according to a specified format and transmitted over a single RDP TCP connection. Some examples of virtual channels include channels that communicate data related to kernel mode drivers such as printer drivers file system redirection channels channels for user mode applications such as remote cut and paste on a virtual desktop connection and channels for audio devices including Voice over IP VoIP enabled devices .

A drawback to using virtual channels in RDP or other protocols is that granular control over virtual channels can be difficult due to the virtual channels each not being sent over dedicated actual channel or connection. Thus for instance an RDP connection over TCP might have multiple virtual channels possibly intermingled with other information such as data related to mouse or keyboard input such that visibility into the TCP connection to distinguish the virtual channels can be difficult. Further due to architectural limitations with RDP the quality of service of some bandwidth intensive virtual channels such as multimedia redirected channels VoIP channels and the like can be severely degraded over high latency networks.

If visibility were feasible it might be desirable to manipulate the virtual channels to achieve certain outcomes. For a VoIP related virtual channel for instance it can be desirable to promote the bandwidth usage or bandwidth priority of the virtual channel to improve the telephony throughput and thereby increase quality of service QoS . Similarly it can be useful to have access to the VoIP packets so as to reduce their size or other packetization properties to promote QoS.

At block data intended to be sent over a virtual channel is intercepted. The data or virtual channel connection request can be intercepted using any of the interception techniques described above. At block one or more dedicated connections are opened for the transmission of the data. The one or more dedicated connections can be actual channels such as TCP channels rather than virtual channels within a single TCP connection. Thus a virtual channel such as a VoIP channel can be redirected over its own TCP connection or multiple TCP connections. As a result the QoS of the VoIP connection can improve due to better bandwidth utilization.

Further at block one or more aspects of the data are optionally customized. For example the network proxy can include functionality for adjusting the packetization and or priority of the TCP connection to further improve QoS. At block the customized data is transmitted over the one or more dedicated channels. It should be noted that the customization of the data can be omitted in certain embodiments.

Although not shown in certain embodiments certain QoS parameters can be provided for customization by the management console or see B . These QoS parameters can allow a user to define desired network connection characteristics. Examples of QoS parameters include a maximum throughput allowed and a minimum throughput allowed. If a network proxy detects that a maximum throughput parameter is not being met the network proxy can throttle connections by introducing latency reducing TCP buffer sizes closing connections combinations of the same or the like. Similarly if a network proxy detects that a minimum throughput parameter is not being met the network proxy can attempt to increase throughput by increasing TCP buffer sizes opening new connections or both. The QoS parameters can be used to facilitate meeting service level agreement SLA requirements to attempt to meet performance goals or for other purposes.

At block data intended to be sent over a virtual channel is intercepted as above see . In addition as in the process one or more dedicated connections are opened for the transmission of the data at block see . Throughput or bandwidth usage is monitored on the one or more dedicated channels at block . Throughput can be monitored for example by determining an amount of data sent during a given time period. Throughput can be sampled e.g. every second and may be calculated using a running average to smooth out variations while giving greater weight to more recent throughput values.

It is determined at decision block whether the bandwidth usage exceeds a threshold. If it does then at block the bandwidth usage is throttled. The bandwidth usage can be throttled by adjusting the one or more connections and or buffer sizes using any of the techniques described above with respect to . In addition the bandwidth usage may be throttled by introducing latency or delays into one or more of the connections. The process can continue monitoring the bandwidth usage until the one or more connections are closed.

It should be noted that certain of the features described herein such as the features described above with respect to can be implemented without using a network proxy that intercepts connection requests. Instead in certain embodiments these features can be implemented by making multiple calls to socket API routines to open parallel connections. Thus for instance dynamic connection management can be performed by a network component that uses API calls to open multiple network connections. This network component can monitor application and or network usage and adjust the number of open connections accordingly via additional socket API calls.

Many other variations than those described herein will be apparent from this disclosure. For example depending on the embodiment certain acts events or functions of any of the algorithms described herein can be performed in a different sequence can be added merged or left out all together e.g. not all described acts or events are necessary for the practice of the algorithm . Moreover in certain embodiments acts or events can be performed concurrently e.g. through multi threaded processing interrupt processing or multiple processors or processor cores or on other parallel architectures rather than sequentially.

The various illustrative logical blocks modules and algorithm steps described in connection with the embodiments disclosed herein can be implemented as electronic hardware computer software or combinations of both. To clearly illustrate this interchangeability of hardware and software various illustrative components blocks modules and steps have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. The described functionality can be implemented in varying ways for each particular application but such implementation decisions should not be interpreted as causing a departure from the scope of the disclosure.

The various illustrative logical blocks and modules described in connection with the embodiments disclosed herein can be implemented or performed by a machine such as a general purpose processor a digital signal processor DSP an application specific integrated circuit ASIC a field programmable gate array FPGA or other programmable logic device discrete gate or transistor logic discrete hardware components or any combination thereof designed to perform the functions described herein. A general purpose processor can be a microprocessor but in the alternative the processor can be a controller microcontroller or state machine combinations of the same or the like. A processor can also be implemented as a combination of computing devices e.g. a combination of a DSP and a microprocessor a plurality of microprocessors one or more microprocessors in conjunction with a DSP core or any other such configuration.

The steps of a method process or algorithm described in connection with the embodiments disclosed herein can be embodied directly in hardware in a software module executed by a processor or in a combination of the two. A software module can reside in RAM memory flash memory ROM memory EPROM memory EEPROM memory registers hard disk a removable disk a CD ROM or any other form of computer readable storage medium known in the art. An exemplary storage medium can be coupled to the processor such that the processor can read information from and write information to the storage medium. In the alternative the storage medium can be integral to the processor. The processor and the storage medium can reside in an ASIC. The ASIC can reside in a user terminal. In the alternative the processor and the storage medium can reside as discrete components in a user terminal.

Conditional language used herein such as among others can might may e.g. and the like unless specifically stated otherwise or otherwise understood within the context as used is generally intended to convey that certain embodiments include while other embodiments do not include certain features elements and or states. Thus such conditional language is not generally intended to imply that features elements and or states are in any way required for one or more embodiments or that one or more embodiments necessarily include logic for deciding with or without author input or prompting whether these features elements and or states are included or are to be performed in any particular embodiment. The terms comprising including having and the like are synonymous and are used inclusively in an open ended fashion and do not exclude additional elements features acts operations and so forth. Also the term or is used in its inclusive sense and not in its exclusive sense so that when used for example to connect a list of elements the term or means one some or all of the elements in the list.

While the above detailed description has shown described and pointed out novel features as applied to various embodiments it will be understood that various omissions substitutions and changes in the form and details of the devices or algorithms illustrated can be made without departing from the spirit of the disclosure. As will be recognized certain embodiments of the inventions described herein can be embodied within a form that does not provide all of the features and benefits set forth herein as some features can be used or practiced separately from others. The scope of certain inventions disclosed herein is indicated by the appended claims rather than by the foregoing description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.

