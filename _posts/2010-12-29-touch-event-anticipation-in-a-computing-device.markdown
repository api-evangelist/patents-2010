---

title: Touch event anticipation in a computing device
abstract: Systems and methods for anticipation of touch events in a computing device are provided. The computing device may include a multi-touch sensitive display including a sensor configured to sense a position and/or movement of a hand. A graphical user interface (GUI) may be displayed, having a state including a plurality of possible touch inputs. The computing device may further include a touch event prediction module configured to compute one or more anticipated touch inputs based on the sensed hand position and/or movement, and the state of the GUI with the plurality of possible user inputs. The computing device may further include a preprocessing module configured to preprocess data for each anticipated touch input, and upon the detection of an actual touch input received from the user that matches one of the anticipated touch inputs, displaying the preprocessed data for the actual touch input on the GUI.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09354804&OS=09354804&RS=09354804
owner: MICROSOFT TECHNOLOGY LICENSING, LLC
number: 09354804
owner_city: Redmond
owner_country: US
publication_date: 20101229
---
Touch sensitive computing devices such as mobile telephones and tablet computers have become increasingly portable with the development of smaller processors and memory devices. Further consumers have demanded increasingly complex software running on such devices including email games photos movies and various other applications. Further these touch sensitive computing devices typically utilize gesture based input which consumes processing power. To handle these tasks processors and memory of increasingly high performance are continually being developed with smaller footprints.

Nonetheless the software and hardware are sometimes incapable of keeping pace with the user. As a result users sometimes experience a time lag during which the touch sensitive device appears to be thinking immediately after the user has selected a graphical user interface option or swiped a gesture on the screen. These time lags are frustrating to the user as the user is not sure whether the device is properly functioning whether the gesture input was properly received or needs to be re input whether the device is experiencing network connectivity issues etc. During this moment of uncertainty users often stare at their screens frozen in a moment of frustration unable to proceed with tasks within the computer environment nor able to return to interacting with the environment around them. This degrades the user experience with the touch sensitive device potentially harming the adoption of such devices and also negatively affects the social interaction of the user with those persons around them.

Systems and methods for anticipation of touch events in a computing device are provided. The computing device may include a multi touch sensitive display including a sensor configured to sense a position and or movement of a hand. A graphical user interface GUI may be displayed having a state including a plurality of possible touch inputs. The computing device may further include a touch event prediction module configured to compute one or more anticipated touch inputs based on the sensed hand position and or movement and the state of the GUI with the plurality of possible user inputs. The computing device may further include a preprocessing module configured to preprocess data for each anticipated touch input and upon the detection of an actual touch input received from the user that matches one of the anticipated touch inputs displaying the preprocessed data for the actual touch input the on the GUI.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

As shown in computing device typically includes a multi touch sensitive display including a sensor configured to sense a hand position and or hand movement of a user hand . In some embodiments the sensor may be configured to detect spaced apart input indicating the position and or movement of the hand when the hand is spaced apart a distance from a top surface of the display as well as actual touch input when the hand is contacting the display . In some embodiments sensor may be configured to detect and distinguish between the position and movement of one or more digits of the hand as well as the hand as a whole. Further the sensor may be configured to detect the position or movements of a stylus held by the hand and distinguish the stylus from the hand.

Sensor may utilize one or more of a variety of sensor types. For example sensor may be or include one or more of an in pixel optical sensor capacitive touch sensor resistive touch sensor infrared sensor pressure sensor or other sensor type. The sensor may be integrated into display or formed separately from display as indicated in dashed lines. For example while capacitive resistive and in pixel sensors are typically integrated with the display an optical sensor such as a camera may be formed separately from the display and aimed to view the area above the display.

The computing device includes one or more programs and modules stored in a mass storage unit which are executable via processor using portions of memory to process sensor input received from sensor and output the processing results for display on display . The processor memory and mass storage unit may communicate with one another and the display via one or more data buses . A variety of processor memory and mass storage configurations may be utilized. In some embodiments the computing device is configured as a mobile telephone and or a tablet computing device and the memory and mass storage may both be solid state for example. In other embodiments the computing device may be a laptop computer desktop computer tabletop computer kiosk computer etc. and the mass storage may be a hard drive for example.

Program stored on mass storage unit may be an application program operating system component or other program that includes a graphical user interface module configured to generate and display a graphical user interface GUI on the display . The graphical user interface typically includes a state including a plurality of possible touch inputs. In the example shown in the GUI displayed on display includes a plurality of selectable icons arranged in a tile pattern. Each icon represents a possible touch input for the user. Numerous other GUI configurations are possible including elements such as buttons pull down menus sliders scroll bars hyperlinks lists radio buttons each representing one or more possible touch inputs.

The computing device further includes a touch event prediction module stored on mass storage unit . Upon execution the touch event prediction module is configured to compute one or more anticipated touch inputs based on the sensed user hand position and or hand movement and the state of the GUI with the plurality of possible user inputs. Typically the touch event prediction module computes the anticipated touch inputs based on sensed hand position and hand movement from spaced apart input of a hand that is spaced apart from the display by a gap .

The computing device further includes a preprocessing module stored on mass storage unit . The preprocessing module is configured to generated preprocessed data for each anticipated touch input . For example the preprocessing module may be configured to preload data into a preload cache to be displayed upon the realization of an anticipated touch event and or perform advance computations for an anticipated touch event.

Upon the detection of an actual touch input by the user from contact of the user hand with the display that matches one of the anticipated touch inputs the preprocessing module is configured to cause the preprocessed data to be displayed on the graphical user interface for the actual touch input . It will be appreciated that the actual touch event may be detected by the touch event prediction module in one embodiment or by a separate gesture recognition module in other embodiments. The preprocessing module may cause the preprocessed data to be displayed by for example communicating to the program that the preprocessed data is available and enabling the program to retrieve and display the preprocessed data from a predetermined location after it is informed of the actual touch event by the touch event prediction module or alternatively by the above mentioned gesture recognition module.

In the depicted embodiment the touch event prediction module includes a statistics engine configured to compute an estimated probability that each of the anticipated user inputs is selected based on prior usage data and to instruct the preprocessing module to allocate preprocessing resources such as the preload cache and logic for advance computations to one or more anticipated user inputs with higher probability of selection and to forgo preprocessing of the other anticipated user inputs . The prior usage data may be computed for the individual user on the computing device for all users on the computing device or may be aggregated usage statistics for a wide group of users downloaded from a central database over a computer network for example.

A prediction engine of the touch event prediction module may be configured to receive the hand position and hand movement of the spaced apart input from sensor and receive the GUI state information from the GUI module and the probabilities from the statistics engine and compute a ranked list of anticipated touch inputs that is ranked according to an estimated probability of occurrence. The preprocessing module may examine available memory and processor usage on the computing device to determine an available resource threshold for preprocessing activity that can be undertaken and choose to generate preprocessed data for a subset of anticipated touch inputs on the ranked list up until the available resource threshold is reached. In this manner efficient use of resources may be made without over burdening the computing device .

It will be appreciated that the computing device may include an operating system that includes an application programming interface by which various programs communicate with and utilize operating system resources. Thus in one embodiment the touch event prediction module and the preprocessing module may be part of the application programming interface linking programs to operating system functionality on the computing device. In other embodiments the touch event prediction module and the preprocessing module are executable programs such as services running in the background across user sessions on the computing device .

In some embodiments an anticipated touch input may be provided to the user as feedback through an indication on the display. For example one or more icons determined to be an anticipated touch input may become brighter and or change color from other icons on the display. In another example one or more icons determined to be an anticipated touch input may be visible and other icons may fade or disappear from the display. Icons may provide a reversible indication to the user in real time in response to a hand motion e.g. first second third and or fourth hand motions described in . In this way a user may receive feedback associated with the anticipated touch input.

Method includes at displaying a graphical user interface including a state having a plurality of possible touch inputs on a touch sensitive display such as a multi touch display of a computing device. At the method includes sensing a position and or movement of a user hand via a sensor of the computing device. The sensing may be performed by a sensor selected from the group consisting of in pixel optical sensor capacitive touch sensor resistive touch sensor and infrared sensor for example as described above. Alternatively other sensor technologies may be employed.

As indicated at sensing a position and or movement of a user hand may further include detecting the position and or movement of the hand when the hand is spaced apart a distance from a top surface of the display. Further as indicated at sensing a position and or movement of a user hand may further include detecting a position and movement of one or more digits of the hand. This may enable the method to distinguish the difference between right and left hands and between the individual digits a hand which may be useful in determining the position and expected movement of the index and middle finger which may be deemed most likely to perform touch input. Further in some embodiments as indicated at sensing a position and or movement of a user hand may further include detecting a position or movement of a stylus held by the hand which may be used to more precisely predict the anticipated inputs.

At the method may further include computing one or more anticipated touch inputs based on the sensed user hand position and or movement and the state of the user interface with the plurality of possible touch inputs. This computation may be performed by a prediction engine and may be based on prior usage data as described in detail below.

At the method may include preprocessing data for each anticipated touch input. As illustrated at preprocessing data may include preloading data to be displayed upon performance of each anticipated touch event into a cache. Further as indicated at preprocessing data may include performing advance computations for each anticipated touch event. The preprocessed data generated from the preprocessing at may be stored in a known location that is communicated to a requesting program so that the program can access and display the preprocessed data at a later time.

At the method may include detecting an actual touch input that matches one of the anticipated touch inputs. The actual touch input is typically a gesture inputted by the user by contacting a digit and or palm of the hand with a top surface of the display. This detection may be performed by the prediction module described above or alternatively by an independent gesture recognition module executed on computing device .

At the method includes displaying the preprocessed data the on the graphical user interface for the actual touch input. The display of the preprocessed data may be performed by a graphical user interface module of a program that displays the graphical user interface after receiving communication from the preprocessing module that the preprocessed data is available at the known location and ready for display. By displaying the preprocessed data latency may be reduced. That is the lag between a user selection of a GUI element and the display of subsequent data on the display will be reduced with the attendant benefit of enhancing the user experience.

In some embodiments method may include at computing an estimated probability that each of the anticipated user inputs will be selected based on prior usage data and at performing preprocessing of data for anticipated user inputs with a higher probability and forgoing preprocessing for anticipated user inputs with a lower probability as described above.

In some embodiments method may optionally include an indication to the user of the anticipated touch input. The indication may include changing portions of the GUI to become brighter change color fade and or disappear in response to an anticipated user touch as described above.

It will be appreciated that the steps of computing one or more anticipated touch inputs at computing estimated probabilities at and or preprocessing data for each anticipated touch input at may be performed wholly or at least in part by an application programming interface linking programs to operating system functionality on the computing device as described above.

The above described systems and methods may be used to reduce latency in user interaction with a graphical user interface of a touch sensitive display on a computing device thereby enabling the completion of tasks more quickly and enhancing the user experience.

The terms module program and engine are used herein to refer to software that performs one or more particular functions when executed by a processor of a computing device. These terms are meant to encompass individual or groups of executable files data files libraries drivers scripts database records for example. The embodiments described herein show one example organization of these modules programs and engines however it should be appreciated that the functions described herein may be accomplished by differently organized software components.

It is to be understood that the configurations and or approaches described herein are exemplary in nature and that these specific embodiments or examples are not to be considered in a limiting sense because numerous variations are possible. The specific routines or methods described herein may represent one or more of any number of processing strategies. As such various acts illustrated may be performed in the sequence illustrated in other sequences in parallel or in some cases omitted. Likewise the order of the above described processes may be changed.

The subject matter of the present disclosure includes all novel and nonobvious combinations and subcombinations of the various processes systems and configurations and other features functions acts and or properties disclosed herein as well as any and all equivalents thereof.

