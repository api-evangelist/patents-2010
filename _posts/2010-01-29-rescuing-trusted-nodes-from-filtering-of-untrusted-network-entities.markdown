---

title: Rescuing trusted nodes from filtering of untrusted network entities
abstract: Network entities controlling a set of nodes may vary by trustworthiness, such as tolerance for nodes that send spam, distribute malware, or perform denial-of-service attacks. A device receiving such activities may identify a trust rating of the network entity and apply appropriately stringent filtering (such as spam evaluation) to activities received from nodes controlled by the network entity. However, a poor trust rating of a network entity may subject a legitimate node controlled by the network entity to inefficiently or unfairly stringent activity filtering. Instead, the device may evaluate the activities of a particular node, assign a trust rating to the node, and if the trust rating of the node is higher than the trust rating of the network entity, apply less stringent activity filtering to the activities of the node, thereby “rescuing” the node from the more stringent activity filtering applied to the other nodes of the network entity.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08370902&OS=08370902&RS=08370902
owner: Microsoft Corporation
number: 08370902
owner_city: Redmond
owner_country: US
publication_date: 20100129
---
Many computing scenarios involve a network connecting a device with one or more nodes of the network and that particularly involve the filtering of activity of the nodes while interacting with the device. For example an email server may receive email from many nodes but may filter out bulk unsolicited email messages spam from desired email messages a webserver may be configured to differentiate legitimate web requests from unproductive web requests such as disingenuous requests submitted as a denial of service attack and a file server may wish to provide service while identifying and blocking intrusion attempts e.g. attempts to install malware in order to commandeer the server for a botnet controlled by another individual. 

In each of these scenarios it may be desirable to implement filtering techniques on the device that successfully identify and exclude unwanted activity and that reduce the frequency of accidentally excluding wanted activity e.g. a false positive in a filtering scheme while efficiently utilizing the resources of the device e.g. memory network capacity and processor usage in performing the filtering. In the particular scenario of bulk unsolicited email messages filtering techniques often involve various properties of the email messages such as blacklists of notorious or suspected spammers whitelists of senders that are believed to be acceptable to recipients of such email messages and keywords that are often included in spam email messages such as the names of popular pharmaceuticals that are often advertised for sale via spam email messages. Increasing the aggressiveness of these filtering techniques may successfully reduce the delivery of spam email messages but may also raise the number of false positives of non spam email messages that are incorrectly identified as spam by the filtering techniques and withheld from delivery to users.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

One filtering technique that may present particular advantages involves the assignment of a network entity trust rating to a network entity such as an automated system AS identified by an automated system number ASN where the network entity trust rating is correlated with the desirability or undesirability of activities presented to the device by various nodes controlled by the network entity. For example a first network entity may control well secured nodes and may send predominantly significant activities to the device while a second network entity may be tolerant of some undesirable activities of various nodes e.g. the second network entity may host one or more nodes that send bulk unsolicited email messages to the device and a third network entity may host several nodes that coordinate to send significantly undesirable activities to the device e.g. a botnet comprising many nodes that perform a coordinated attempt to commandeer the device by injecting malware or a denial of service attack on the device. Therefore by evaluating the activities of the nodes the device may assign to the network entity a network entity trust rating and may apply a correspondingly strong degree of activity filtering to various nodes controlled by the network entity. If the network entity trust rating is particularly low comparatively heavy and aggressive activity filtering techniques may be utilized such techniques may result in greater success of filtering out undesirable activities but at the cost of increasing the rate of false positives e.g. desirable activities that are incorrectly identified as undesirable activities and or of increased utilization of computing resources e.g. network bandwidth and processor and memory usage. 

However in some scenarios one or more nodes controlled by a network entity may exhibit a significantly higher degree of desirable activities than other nodes controlled by the same network entity. For example a network entity may include several nodes comprising a botnet that send significant amounts of undesirable activities to the device but may also include nodes that generate predominantly legitimate and desirable activities to the device. Therefore while the network entity may be assigned a poor network entity trust rating that may result in heavy filtering of the activities of the nodes controlled by the network entity e.g. the application of particularly aggressive spam filtering of email messages it may be unfair or inefficient to apply similarly heavy activity filtering to nodes controlled by the network entity but having a higher node trust rating.

In view of these considerations techniques may be devised to rescue nodes with a high node trust rating from the heavy filtering caused by a poor trust rating of a network entity controlling the nodes. According to these techniques when a node trust rating is assigned to a node based on an evaluation of the activities generated by the node while interacting with the device the node trust rating may be compared with a network entity trust rating assigned to the network entity controlling the node. If the node trust rating is higher than the network entity trust rating the device may filter the activities of the node based on the node trust rating e.g. by using comparatively lighter and less stringent filtering corresponding to the higher trust rating. If not the device may filter the activities of the node based on the network entity trust rating e.g. by using comparatively heavier and more stringent filtering corresponding to a poor network entity trust rating. In this manner the filtering of the activities of the node may more accurately reflect the trust rating of the node thereby improving communication of the device with trusted nodes reducing the incidence of false positives of incorrectly excluded activities and economizing potentially resource intensive filtering of activities that are predominantly legitimate.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.

Within the field of computing many scenarios involve the communication of a device such as a server a router a firewall a workstation a notebook a smartphone or a network appliance with various nodes each node comprising another device over a wired or wireless network. However along with the proliferation of advantageous uses of network communication many uses of network communication have been developed that are undesirable to an owner of the device. As a first example the device may comprise an email server configured to receive email messages from various nodes and addressed to users of the device. However some of the nodes may send bulk unsolicited email messages spam to the device and the device may filter the received email messages to reduce the delivery of spam to users. As a second example the device may comprise a webserver configured to receive and fulfill web requests received from users of other nodes but some such requests may be disingenuous and intended to consume the resources of the webserver e.g. a denial of service attack. The webserver may be configured to identify and fulfill genuine requests in order to provide productive web service while disregarding disingenuous requests. As a third example the device may be exposed via the network to some nodes that attempt to deliver malware e.g. trojan software that surreptitiously commandeers a portion of the computing resources of the device on behalf of another individual such as by joining a botnet comprising a network of commandeered devices under the control of the other individual. The device may utilize various techniques to reduce contact from potentially malicious nodes such as a stateless or stateful firewall that excludes types of contact that are likely to be illegitimate.

In these and other scenarios an operator of the device may endeavor to configure the device to utilize various forms of filtering of activity of various nodes of the network that attempt to interact with the device. The operator may seek to employ one or more filtering techniques that achieve a high accuracy of excluding undesirable activity while reducing the mis identification and exclusion of desirable activity false positives and while conserving computing resources e.g. network bandwidth memory and processor usage and processing delays in evaluating the activity. Thus while more aggressive filtering may result in the exclusion of a higher percentage of undesirable activity such as the rerouting of spam email messages to a spam email folder instead of to users inbox folders the consequences of false positives e.g. non spam messages incorrectly routed to the spam email folder and or the consumption of computing resources may be too costly. Therefore efficient and accurate filtering techniques are desirable in configuring devices to filter the activity of nodes interacting with the device.

In particular email servers are often configured to reduce the delivery of spam to users by utilizing a combination of filtering techniques. Content based filters may be utilized to examine email messages received from various nodes for indicators of bulk unsolicited email e.g. spam email messages may be highly correlated with particular keywords such as the names of popular pharmaceuticals that are often offered for sale via spam email messages. Sender based filters may also be utilized to identify senders of email messages that are known to send large amounts of spam. For example some phishing spammers endeavor to send email that appears to originate from various trusted senders such as banks auction sites and software sites and that include a hyperlink that leads to a false representation of the website of the sender that captures valuable data provided by the user e.g. account identifiers and passwords and delivers such data to another individual. In order to detect and reduce phishing email messages a webserver may be configured to identify email messages that appear to originate from such trusted websites and to contact the trusted website to verify the contents of the email message before delivering the email message to the recipient s . By using a combination of these and other techniques an email server may be configured to filter the activities of various nodes that send email messages to the email server thereby differentiating legitimate email messages from various types of spam. Email messages that are identified with a high degree of probability of comprising spam may be processed through various other techniques such as dropping the email message bouncing the email message back to the sender notifying the user that the email message may be spam delivering the email message to a spam email folder instead of the inbox email folder of the user delaying the receipt of the email message from the node thereby imposing a penalty on the node that reduces the rate of delivering spam email messages in bulk while not significantly affecting the delivery of legitimate email messages and time travel upon identifying an email message as spam identifying similar email messages within the inboxes of other users that have not yet been delivered to the users and removing such email messages before delivery. 

In the exemplary scenario of the device receives four email messages from four different nodes of the network and endeavors to filter these activities of the nodes to identify and remove spam email messages . The device may evaluate all four email messages with a first filtering technique comprising a keyword filter that identifies keywords that are highly correlated with spam email messages e.g. the term popular meds in the second email message and that routes email messages containing such keywords to the spam folder of the email account of the client . The device may next evaluate the remaining three email messages with a second filtering technique comprising a sender blacklist which identifies a list of senders that are known to send high volumes of spam email messages e.g. your friend spam.com the sender of the third email message and that routes email messages sent from such senders to the spam folder of the email account of the user . The device may next evaluate the remaining two email messages with a third filtering technique comprising sender authentication which identifies often impersonated senders e.g. security bank.com the sender of the fourth email message which contacts the senders in order to authenticate such email messages and which routes unverified email messages impersonating these senders to the spam folder of the email account. As a result of these filtering techniques the device presents to the client an inbox folder containing the single genuine email message and a spam folder containing the email messages that have been identified as spam.

In this and other scenarios a device may utilize activity filtering techniques to improve communications with nodes interacting with the device of the network . One such technique relates to a network hierarchy aspect wherein one or more nodes are controlled by a network entity such as a recognized operator of a set of components operating on the network . The operator may comprise an individual a group of individuals an organization a corporation a government etc. and may be represented in various ways e.g. as an autonomous system AS which may be identified in by a particular autonomous system number ASN according to an autonomous systems registry such as the Autonomous System Number Registry managed and provided by the Internet Assigned Numbers Authority IANA . A particular network entity may manage the nodes under its control in a particular manner e.g. a first network entity may exercise tight control over the nodes to be utilized only for desirable activities while a second network entity may exercise lax control over the nodes and may be tolerant of some undesirable activities such as a node configured to send bulk unsolicited email messages to various recipients such as the device and a third network entity may configure various nodes to perform significantly undesirable activities such as performing a denial of service attack on the device . Accordingly some activity filtering techniques may involve the assignment of a network entity trust rating to a network entity based on an evaluation of the activities performed by nodes under the control of the network entity. A network entity that controls nodes that send predominantly desirable activities to the device may be assigned a high network entity trust rating while a network entity that controls nodes that send significant amounts of undesirable activities e.g. sending a high volume of spam email messages to the device may be assigned a poor network entity trust rating. Having assigned a suitable network entity trust rating to a network entity the device may then filter the activities received from nodes controlled by the network entity based on the network entity trust rating. This activity filtering technique may therefore roll up or aggregate evaluations of activities to infer a reputation of the network entity and may use this reputation as a predictive indicator of the desirability of subsequent activities received from nodes controlled by the network entity.

While the exemplary scenario of illustrates some advantages of this filtering technique some disadvantages may arise that result in an inaccurate filtering of activities of a particular node . While the poor network entity trust rating assigned to the network entity may be predictive of the desirability of activities that are likely to be received from a new node this prediction may not be accurate. For example the network entity may comprise a network host that is comparatively tolerant of nodes sending bulk unsolicited email messages to the device and may therefore host nodes engaging in such activities but may also host a new node comprising a legitimate user who initiates predominantly desirable activities with the device . However if the device applies more stringent activity filtering to all nodes including the new node of the network entity based on the poor network entity rating this filtering may present an unfair penalty to the new node that is not sending undesirable activities to the device . For example this more stringent activity filtering may be inefficient e.g. by applying resource intensive spam evaluation techniques to scrutinize closely all email messages received from the new node even if the new node demonstrates a consistent pattern of sending only non spam email messages and or unfair e.g. the bandwidth of a network connection of the device to the new node may be throttled in anticipation of receiving undesirable activities even if no such undesirable activities are ever sent by the new node . Moreover in some scenarios this inaccurate filtering may be irredeemable. For example for network entities featuring a particularly poor network entity trust rating e.g. a network entity operating nodes as a botnet in order to conduct a denial of service attack on the device the device may completely block network connections that any nodes controlled by the network entity including the new node may attempt to initiate with the device and the new node may therefore be unable to establish a pattern of sending predominantly desirable activities to the device .

In view of these problems techniques may be developed to filter the activities of nodes controlled by a network entity that permit a more accurate assignment of trust ratings and more accurate activity filtering applied to the nodes . presents an exemplary scenario featuring a filtering of activities sent to the device by various nodes controlled by a network entity . The activities of respective nodes may again be subjected to the activity evaluation such as one or more spam identification techniques applied to email messages sent to the device by the nodes in order to evaluate the desirability of such activities . However in this exemplary scenario the device may assign to each node a node trust rating reflecting the desirability of activities sent by the node to the device . For example a poor node trust rating may be assigned to the first node and the second node which among all activities sent by the node to the device send approximately 50 and 100 respectively of undesirable activities . By contrast a third node may be identified as sending to the device predominantly desirable activities such as non spam email messages and or legitimate web requests and the device may assign to the third node a comparatively high node trust rating . The device may then utilize the node trust ratings assigned to respective nodes controlled by the network entity in order to identify a network entity trust rating . In this exemplary scenario in view of the poor node trust ratings assigned to the first node and the second node and the high node trust rating assigned to the third node the device may assign to the network entity a poor network entity trust rating .

After assigning the node trust ratings to respective nodes and the network entity trust rating to the network entity the device may select an appropriate type and or degree of activity filtering to apply to activities received from nodes controlled by the network entity . For example the device may apply more stringent activity filtering to the nodes controlled by the network entity including the first node and the second node that also have poor node trust ratings . However it may be inefficient and or unfair to apply more stringent activity filtering to the third node which sends to the device predominantly desirable activities . Therefore in selecting a type and or degree of activity filtering to apply to a node the device may consider both the network entity trust rating of the network entity controlling the node and also the node trust rating of the node . Because the node trust ratings of the first node and the second node are not higher than the network entity trust rating the device may filter the activities of these nodes based on the network entity trust rating thereby applying more stringent activity filtering to activities received from these nodes . However the device may determine that the third node is assigned a higher node trust rating than the network entity trust rating of the network entity and may therefore filter the third node based on the node trust rating e.g. by applying less stringent activity filtering to activities received from the third node . In this manner while the device ordinarily operates by selecting the activity filtering of any node controlled by the network entity based on the network entity trust rating the device creates an exception to this operation for the third node in view of the higher node trust rating of the third node thereby rescuing the third node from the heavy filtering applied to the untrusted network entity . The filtering techniques illustrated in this exemplary scenario may thereby benefit the device e.g. by allocating more filtering resources to the activities of less trusted nodes and fewer filtering resources to the activities of more trusted nodes and or the trusted third node e.g. by applying less stringent activity filtering that may result in fewer false positives and more efficient communication between the device and the node . 

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to apply the techniques presented herein. An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable medium e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions configured to operate according to the principles set forth herein. In one such embodiment the processor executable instructions may be configured to perform a method of filtering activities of a node interacting over a network with a device such as the exemplary method of . In another such embodiment the processor executable instructions may be configured to implement a system for filtering activities of a node interacting over a network with a device such as the exemplary system of . Some embodiments of this computer readable medium may comprise a nontransitory computer readable storage medium e.g. a hard disk drive an optical disc or a flash memory device that is configured to store processor executable instructions configured in this manner. Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

The techniques presented herein may be devised with variations in many aspects and some variations may present additional advantages and or reduce disadvantages with respect to other variations of these and other techniques. Moreover some variations may be implemented in combination and some combinations may feature additional advantages and or reduced disadvantages through synergistic cooperation. The variations may be incorporated in various embodiments e.g. the exemplary method of and the exemplary system of to confer individual and or synergistic advantages upon such embodiments.

A first aspect that may vary among embodiments of these techniques relates to the scenarios wherein these techniques may be utilized. A first aspect that may vary among embodiments of these techniques relates to the scenarios wherein the techniques presented herein may be utilized. As a first example the techniques may be used to filter many types of activities received by many types of devices including email messages received by an email server text messages received by a text messaging server such as a chat server or a simple messaging service SMS server social network messages received by a social network server web request received by a webserver such as weblog posts received by a weblog server database queries received by a database server and invocations of services received by various types of servers such as accesses of files on a file server.

As a second example of this first aspect the activities may be received from many types of nodes interacting with the device . As a first variation a node may comprise a device legitimately operated by a user such as an individual a group of individuals an organization a corporation a government or even a fully autonomous device that sends legitimate activities to the device . As a second variation of this second example a node may be configured by a user to distribute undesirable activities to the device such as a spam email server a distributor of various forms of malware or a phishing server that attempts to impersonate a trusted server in order to extract sensitive information from unsuspecting visitors. As a third variation of this second example a node may have been accidentally misconfigured by a user in a manner that generates undesirable activities e.g. an email server that accidentally sends huge numbers of a particular email message to the device or that has been misconfigured as an open relay that is exploited by a spam email server to redeliver large volumes of spam email messages. As a fourth variation of this second example a node may be legitimately operated by a user and may therefore generate some legitimate activities but may have been commandeered by malware to generate undesirable activities e.g. a node may send legitimate web requests to a device comprising a webserver but may also have been infected with malware that attempts to deliver large volumes of spam messages and or perform denial of service attacks against the device and or other nodes of the network . 

As a third example of this first aspect the techniques may be implemented through many types of architectures. As a first variation of this third example the architecture of the exemplary system of may vary in many different ways e.g. a single component may both evaluate the activities of the node interacting with the device to assign a node trust rating to the node and compare the assigned node trust rating of the node with a network entity trust rating of a network entity controlling the node . As a second variation of this third example the device may be configured to store locally the node trust ratings and or the network entity trust ratings . Alternatively the device may store and or reference remotely stored trust ratings such as a node trust rating identified in a blacklist or whitelist database managed by a machine accessible to the device over the network . As another alternative the device may not store the trust rating of a node and or a network entity but may compute these trust ratings only ephemerally in order to perform the comparing and to select a type and or degree of activity filtering to be applied to the node based on these ephemerally computed trust ratings. As yet another alternative an embodiment might not fully compute the node trust rating from all activities as a discrete value rather the results of evaluating respective activities might be computed to make incremental adjustments in the network entity trust rating of the network entity . As a third variation of this third example the device might comprise a plurality of interconnected and interoperating devices such as a set of network servers comprising a network farm that presents a website to various users. Those of ordinary skill in the art may devise many variations in the scenarios and architectures wherein the techniques presented herein may be implemented.

A second aspect that may vary among embodiments of these techniques relates to the manner of evaluating activities of a node in order to assign a node trust rating to the node . As a first example an embodiment of these techniques may evaluate the content of the activities of the node e.g. an email server may evaluate the contents of email messages received from various nodes based on keywords or patterns in the email message that are highly correlated with spam email messages and a webserver may evaluate the contents of web requests to differentiate legitimate web requests that may be productively fulfilled from disingenuous web requests sent as part of a denial of service attack.

As a second example of this second aspect an embodiment of these techniques may evaluate various activity properties of various activities of the node . Such activity properties comprise various metrics such as message metrics relating a volume of messages sent by the node e.g. where low rates of message sending may be indicative of non spam email messages recipient metrics relating to the number of recipients of at least one message sent by the node e.g. where messages having a single recipient or only a few recipients may be indicative of non spam email messages and returned message metrics relating to the number or rate of returned messages sent to the node in response to a message sent by the node e.g. where low rates of bounced messages may be indicative of non spam email messages. Other metrics that may be relevant to the evaluation of the node include connection metrics relating to the number of connections established by the node e.g. where low numbers of connections may be indicative of legitimate activities initiated by a user and bandwidth metrics relating to network bandwidth utilized by the node e.g. where low usage of upload bandwidth may be indicative of legitimate activities initiated by a user . These activity properties may be detected by the device and or may be detected by another device e.g. a registry of legitimate users and or nodes and transmitted to the device for use in evaluating the activities of the node . Other activity properties such as other types of reports and metrics may also be useful in evaluating the activities of a node to assign a node trust rating .

As a third example of this second aspect the node trust rating of a node may be assigned based on various network properties exhibited by the node which may be indicative of the type configuration and uses of the node for distributing desirable or undesirable activities . Such network properties may be selected from a network property set comprising a name registry comprising a network name of the node e.g. some reputable name registries such as domain registrars may be less tolerant of nodes distributing undesirable activities and the registration of the node with a reputable name registry may be more indicative of legitimate activities of the node . Such network properties might also include the network port status of at least one network port of the node which may be indicative of the types of activities engaged in by the user of the node a geographic location of the node e.g. where a node hosted in a first geographic area may be more or less trustworthy than a node hosted in a second geographic area and or at least one property of at least one network route associated with at least one network address of the node e.g. the node may be hosted within a virtual private network that is more or less trustworthy than nodes outside of the virtual private network and this factor may be identified according to the network route involved in reaching the node over the network . Such network routes may be determined e.g. by evaluating the results of a routing path trace performed over the network .

As a fourth example of this second aspect the node trust rating of the node may be assigned based on at least one user property of at least one user of the node where some users or types of users may be more or less trustworthy than other users or types of users . The user properties may be selected from a user property set comprising a geographic location of the user e.g. where users located in a first geographic region may be more or less trustworthy than users located in a second geographic region a user type of the user e.g. a node utilized by a government or a public corporation may be more trustworthy than a node utilized by a private corporation or an individual a reputation of the user e.g. some users may have verifiable identities associated with trustworthy reputations that suggest a higher node trust rating to be assigned to nodes operated by the user while other users may have reputations of distributing undesirable activities such as notorious spammers and a financial status indicator of the user e.g. nodes operated by a publicly traded corporation with high revenue streams may be more trustworthy than nodes operated by bankrupt or struggling corporations or unknown corporations with indeterminate revenue streams. Moreover where the node trust rating may be promoted based on a reputation of the user of the node the identity of the user may be authenticated e.g. upon receiving from the user at least one user credential such as a username and password combination a certificate a cryptographic signature generated an asymmetric private key held by the user or a biometric measurement the device may authenticate the user using the user credentials and may assign the node trust rating to the node based on the identity of the user after authenticating the user .

As a fifth example of this second aspect many types of evaluation may be applied to these various types of information about the activities and the nodes in order to assign a node trust rating to a node . As a first variation of this fifth example an embodiment of these techniques may evaluate the activities of a node by querying a user to evaluate one or more activities e.g. the user may be queried to examine the contents of an email message sent by the node and to identify it as a spam email message or a non spam mail message and upon receiving from the user a node trust rating of the node assigning the node trust rating to the node . In other variations of this fifth example various automated techniques may be utilized such as the rule based filtering techniques illustrated in the exemplary scenario of . In a second variation of this fifth example a node activity classifier may be configured to evaluate the activities of various nodes and an embodiment of these techniques may use the node activity classifier to select a node activity classification of respective activities of a node and may assign the node trust rating of the node based on the selected node activity classifications. For example a classifier technique such as a Bayesian network an artificial neural network a set of heuristics or an expert system may be configured to evaluate various properties of an email message and to output a node activity classification identifying the email message as a spam email messages or a non spam email message and an embodiment of these techniques may use the node activity classifications of the classifier to evaluate the activities of a node and to assign a node trust rating thereto.

As a sixth example of this second aspect the evaluation of the activities of a node may be initiated in many ways. As a first variation of this sixth example the activities of any node contacting the device may be evaluated to determine the node trust rating of the node . However such broad scale evaluation may impose a significant resource cost on the device such as a delay in processing items received over the network and a computational load on the processor . As a second variation of this sixth example the device may occasionally poll some activities received from various nodes e.g. at random or when computational resources such as processor capacity are plentiful and may evaluate such polled activities and assign node trust ratings to the nodes sending the activities . As a third variation of this sixth example the device may be configured to accept a request from a user to evaluate activities of a node and may initiate the evaluation of the activities and the assignment of the node trust rating in response to the request. For example a user of a node may be aware or notified that more stringent activity filtering is being applied to the node due to a poor network entity trust rating of the network entity controlling the node . The user may endeavor to achieve less stringent activity filtering of the node by requesting the device to evaluate the activities of the node in order to achieve an assignment to the node of a high node trust rating that rescues the node from the more stringent activity filtering . The device may receive the request from the user may accordingly evaluate the activities of the node and may assign a node trust rating to the node based on the evaluated activities in response to this request. Those of ordinary skill in the art may choose many types of information relevant in evaluating the activities of various nodes and many ways of evaluating such information to assign node trust ratings to respective nodes while implementing the techniques discussed herein.

A third aspect that may vary among embodiments of these techniques relates to the manner of determining a network entity controlling a particular node . As a first example the network entity may be determined by evaluating a routing table identifying at least one network entity and at least one network address of at least one node controlled by the network entity . This may be achieved e.g. by evaluating a border gateway protocol BGP routing table stored by a routing device of the network which may associate various nodes with a controlling network entity e.g. by identifying a network address group allocated to an autonomous system AS identified by an autonomous system number ASN where the network address group contains the network address of the node . Because the network routes identified for communicating with a particular node may be difficult to alter without disrupting network communication to the node the information within these routing tables maybe comparatively up to date and reliable for determining a network entity controlling a particular node . As a second example the network entity may be registered with a name registry e.g. a domain name service or a WHOIS service that is configured to associate node names with respective nodes of the network . An embodiment of these techniques may be capable of determining the network entity controlling a particular node by identifying a node name of the node according to the name registry and by associating the node name of the node with a network entity according to the name registry. For example a domain name service may be configured to associate nodes controlled by a network entity for a particular corporation with a domain name related to the name of the corporation e.g. a particular store existing as a network entity may register many controlled nodes with the domain name service as having various node names comprising variations of store.com . Those of ordinary skill in the art may devise many ways of identifying a network entity controlling a particular node of the network while implementing the techniques presented herein.

A fourth aspect that may vary among embodiments of these techniques relates to additional actions that may be performed in relation to the evaluation of activities the assignment of node trust ratings to nodes and the filtering of activities based on the node trust ratings . As a first example of this fourth aspect an embodiment of these techniques maybe configured to exchange information about node trust ratings assigned to nodes with other devices such as other trusted servers in order to implement a distributed or broad consensus of node trust ratings . In a first such variation upon identifying a node entity trust rating of a node an embodiment of these techniques may be configured to notify at least one trusted device of the node trust rating assigned to the node . For example a device implementing these techniques may generate and circulate to other devices a network entity trust ratings list that indicates various node trust ratings assigned by an embodiment of these techniques to various nodes . In a second such variation an embodiment of these techniques may be configured to receive at least one node trust rating from a trusted device and to assign to a node a node trust rating based on both the evaluation of the activities of the node and the node trust rating received from the trusted device. In this manner a device and an embodiment of these techniques implemented thereupon may exchange node trust ratings assigned to various nodes in order to pool determinations of trust ratings among trusted devices.

As a first variation if a user of a particular node may be identified and contacted an embodiment of these techniques may be configured to notify the user of events and information relating to the trust ratings of the node and or the network entity . For example upon identifying a network entity trust rating assigned to a network entity based on at least one node trust rating of a node controlled by the network entity the device may identify a user of one or more nodes controlled by the network entity and may notify the users of the network entity trust rating assigned to the network entity . This notification may be helpful for alerting the user that the node s operated by the user are likely to be subjected to more stringent activity filtering . This event may not be desirable to the user and the notification thereof might prompt the user to take actions that alleviate the more stringent activity filtering including working with an administrator of the network entity to improve the network entity trust rating of the network entity switching to a new network entity with a better network entity trust rating or requesting evaluation of the activities of one or more nodes operated by the user in order to achieve rescue of the node from the more stringent activity filtering .

As a second example of this fifth aspect following the assignment thereof to a node an embodiment of these techniques may act to maintain the accurate assignment of node trust ratings to nodes . This maintenance may be advantageous because the activities of a node may change over time e.g. a node that is misconfigured as an open relay that is exploited to retransmit spam email messages may be reconfigured by a user to close the open relay thereby improving the activities of the node conversely a formerly trusted node may be infected with malware that begins generating large volumes of undesirable activities . Accordingly after assigning a node trust rating to a node an embodiment of these techniques may be configured to for nodes interacting with the device and controlled by the network entity evaluate at least one subsequent activity of the node in order to assign an updated node trust rating to the node . In this manner the embodiment may maintain the freshness of the node trust ratings assigned to various nodes based on changes to the activities thereof. Moreover the evaluation of subsequent activities may be performed in many ways. As a first variation an embodiment may randomly poll activities subsequently received from various nodes in order to detect conformity with or deviance from the node trust rating currently assigned to the node . As a second variation an embodiment may detect changes in the behavior of a node that may be indicative of present or imminent changes in the activities received therefrom such as an increase or decrease in bandwidth usage of a node or in the rate of network connections established by a node . As a third variation a node that has been assigned a poor node trust rating may be periodically given a chance to redeem its node trust rating . This variation may be helpful e.g. where a node assigned a particularly poor node trust rating has been aggressively filtered such as by blocking the receipt of many activities from the node or completely refusing network connections initiated by the node because the node may be unable to demonstrate improvements in the desirability of its activities . One such embodiment may reevaluate a node by for a particular evaluation period reducing the filtering of the activities of the node and evaluating activities received from the node during the evaluation period to assign an updated node trust rating to the node . In this manner the embodiment may extend the rescue techniques even to nodes that have previously performed significantly undesirable activities . Those of ordinary skill in the art may devise many ways of maintaining the freshness of the node trust ratings while implementing the techniques presented herein.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

