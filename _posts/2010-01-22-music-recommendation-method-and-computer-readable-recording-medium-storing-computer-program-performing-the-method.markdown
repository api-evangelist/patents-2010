---

title: Music recommendation method and computer readable recording medium storing computer program performing the method
abstract: A music recommendation method and a computer readable recording medium storing a computer program performing the method are provided. In the music recommendation method, music items and rating data matrix comprising ratings and user IDs are first provided. Then, the ratings of each music item are classified into positive ratings and negative ratings. Thereafter, a pre-processing phase comprising a frame-based clustering step and a sequence-based clustering step is performed to transform the music items into perceptual patterns. Then, a prediction phase is performed to determine an interest value of a plurality of target music items for an active user. Thereafter, the target music items arranged into a music recommendation list in accordance with the first interest value and the second interest values, wherein the music recommendation list is a reference for the active user to select one of the target items.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08224818&OS=08224818&RS=08224818
owner: National Cheng Kung University
number: 08224818
owner_city: Tainan
owner_country: TW
publication_date: 20100122
---
The present invention relates to a music recommendation method. More particularly the present invention relates to a music recommendation method for mining a user s preferable perceptual patterns from music pieces.

Recent advances in music compression technologies have eased the access of music pieces. Through the modern communication tools a user may purchase music items such as songs from online e commerce stores such as Amazon Flickr Google and Youtube without visiting the physical music stores in person. However it is not easy for the user to identify what her his favorite music items are from a huge amount of available music pieces. This enables a large increase in the number of music recommender systems. In conventional recommender systems the user s preference is represented by using a rating scale of one to five. Based on the rating scale the user s preference and the music items can be bridged reasonably by machine learning techniques thereby predicting the ratings of un purchased music items for a user thereupon deriving the ranking list of the un purchased items.

Collaborative filtering CF is a typical recommendation paradigm and the basic assumption behind the CF is that if users conduct similar behaviors on rating music items they have correlated interests on the music items. That is the users with similar rating behaviors are always grouped together to assist each other in making a selection decision among a number of music items. Mostly CF has been shown to be effective on predicting users preferences. However CF based methods still incur a rating diversity problem meaning that similar ratings fail to represent the user s preferences on the contents of the musical items precisely. On one hand two different kinds of music items could be similar on having high rating coefficients. On the other hand the ratings of one specific music item could be diverse extremely. Whatever it is it is not east to derive the correct recommendation result merely by users ratings.

Hence there is a need to provide a music recommendation method for overcoming the problem of rating diversity described above.

An aspect of the present invention is to provide a music recommendation method and a readable recording medium storing a computer program performing the method for overcoming the problem of rating diversity and enhancing the quality of music recommendation.

According to an embodiment of the present invention in the music recommendation method at first a plurality of music items and a rating data matrix are provided. The rating data matrix includes a plurality of music item identifications for the respective music items a plurality of ratings belonging to each of the music items and a plurality of user identifications of a plurality of users providing the ratings. Then the ratings of each of the music items are classified into positive ratings and negative ratings in accordance with a predetermined rating threshold. Thereafter a pre processing phase is performed to transform the music items into a plurality of perceptual patterns in accordance with acoustical and temporal features of the music items. Then a prediction phase is performed to determine an interest value of each of a plurality of target music items for an active user in accordance with the perceptual patterns and generate a music recommendation list in accordance with the interest values of the target music items wherein the target music items are the music items not provided a rating by the active use and the music recommendation list includes the target items arranged in accordance with the interest values and thus the music recommendation list is provided as a reference for the active user to select one of the target items.

Reference will now be made in detail to the present preferred embodiments of the invention examples of which are illustrated in the accompanying drawings. Wherever possible the same reference numbers are used in the drawings and the description to refer to the same or like parts.

Referring to is a flow chart showing a music recommendation method in accordance with an embodiment of the present invention. The music recommendation method can be divided into a pre processing phase and a prediction phase . In the pre processing phase a music feature extraction step is first performed to divide the music items stored in a music database into a plurality of frames and extract music features of each of the frames. Then a two stage clustering and symbolization step is performed to transform the frames into perceptual patterns . The two stage clustering and symbolization step includes a frame based clustering step and a sequence based clustering step to cluster the frames and the combinations of the frames thereby extracting two important listening sensitive features acoustical and temporal features. In the prediction phase a music snippet generation and mining step is first performed to mine preference perceptual patterns in accordance with a user item rating matrix for an active user . Then a pattern based preference prediction step is performed to generate a recommendation list for the active user wherein the recommendation list includes music items not provided rating or evaluated by the active user yet.

The user item rating matrix stores ratings belonging to each of the music items stored in the music database . The ratings of each of the music items are provided by a plurality of users. For example after listening one of the music items an active user may provide a rating to the music item to express his her preference. Thus each of the music items may correspond to a plurality of ratings provided by different active users.

Refer to to and to simultaneously. illustrates a flow chart showing the pre processing phase . illustrates a flow chart showing the frame based clustering step . illustrates a flow chart showing the sequence based clustering step . to are structure diagrams of the music items corresponding to steps and . In this embodiment as shown in the music database includes music items CD CD CD CD CD and CD and all the music items are in the form of mpeg 1 audiolayer 3 MP3 for example.

In the music feature extraction step step is first performed to divide each of the music items into a plurality of sections in accordance with a predetermined time period thereby obtaining a plurality of frames Fr of the music items. In this embodiment the predetermined time period is 1 38 second. Then step is performed to calculate Modified Discrete Cosine Transform MDCT coefficients of each of the frames Fr to extract low level features of each of the frames. In general the frame Fr can be represented by 576 MDCT coefficients but in this embodiment only 36 MDCT coefficients are chosen from the 576 MDCT coefficients to represent the frame Fr to reduce the computation cost of a music recommendation server.

In the two stage clustering and symbolization step a frame based clustering step is first performed to transform the music items into a plurality of symbolic strings STR STR STR STR STR and STRin a one to one manner in accordance with the acoustical features of the music items as shown in . Then a sequence based clustering step is performed to transform the symbolic strings STR STR STR STR STR and STRinto a plurality of symbolic strings STR STR STR STR STR and STR in a one to one manner in accordance with the temporal features of the music items wherein each of the symbolic strings STR STR STR STR STR and STR are composed of perceptual patterns P.

In the frame based clustering step step is first performed to calculate a pearson correlation coefficient between every two of the frames Fr wherein the pearson correlation coefficient represents the difference of the tendency of the every two of the frames Fr. The pearson correlation coefficient used in this embodiment is described in Resnick P. Iacovou N. Suchak M. Bergatrom P. and Riedl J. 1994 . Grouplens An open architecture for collaborative filtering of netnews. Proc. ACM 1994 conf. on Computer Supported Cooperative Work. pp. 175 186 New York. The content of which is incorporated herein by reference. Then step is performed to partition the frames into a plurality of frame clusters in accordance with the pearson correlation coefficient wherein the pearson correlation coefficient is calculated in accordance with the Modified Discrete Cosine Transform MDCT coefficients of the every two frames Fr. The algorithms for calculating the pearson correlation coefficients and the MDCT coefficients are well known to those who are skilled in the art and thus are not described in detail herein. Thereafter step is performed to assign symbols such as 1 2 3 4 and 5 to the frame clusters in a one to one manner so as to classify the frames. Thereafter step is performed to transform the music items into the symbolic strings in accordance with the types of the frames Fr.

In this embodiment the frame based clustering step can be viewed as a hierarchical splitting strategy. For each of the leaf nodes in the frame based clustering step the splitting is thresholded by two criteria namely Proportion and Density. Proportion stands for the total number of the frames in a cluster. Density stands for the ratio between the cardinality of the frames in a confident radius and the total number of the frames in the cluster. The confident radius specifies the qualificatory area around the cluster centroid to verify the frame distribution for density. Assume that a cluster Cconsists a set of frames and the c is the centroid of C. The confident radius R is defined as 

After the frame based clustering step is performed each of the musical items can be represented as a set of sequential symbols based on its acoustical features. According to the sequential symbols the sequence based clustering step is performed to consider the temporal continuity of music. In the sequence based clustering step step is first performed to sequentially divide each of the symbolic strings STR STR STR STR STR and STRinto a plurality of symbolic sub sequences Sin accordance with a predetermined number of the frames. In this embodiment for example when the predetermined number is 3 the symbolic sub sequence of this embodiment is composed of 3 frames Fr. Then step is performed to use a sequence alignment like algorithm to calculate the dissimilarity of every two of all the symbolic sub sequences Sof the symbolic strings STR STR STR STR STR and STR.

The sequence alignment like algorithm such as an algorithm introduced in the article A general method applicable to the search for similarities in the amino acid sequence of two proteins written by B. Needleman and C. D. Wunsch is often used in biotechnology. The basic idea of sequence alignment like similarity is that it gives the low penalty if two sequences exist mismatch such as 123 and 143 and the high penalty if two sequences exist gap such as 123 and 1 3 . The gaps are inserted to align the similar sequence in the successive subsequence. For example with respect to two sequences 125341452 and 132534142 the gap is inserted between 1 and 25341452 within the sequence 125341452 so as to form 1 25341452 . Hence the aligned sequence 1 25341452 is more similar to the target sequence 132534142 than the original sequence is.

After the dissimilarity of every two of the symbolic sub sequences Sis calculated step is performed to apply a clustering algorithm onto all the symbolic sub sequences Sto divide all of the symbolic sub sequences Sinto a plurality of sub sequence groups in accordance with the dissimilarity. In this embodiment the clustering algorithm is a K means algorithm. Then step is performed to assign symbols such as A B C D and E to the sub sequence groups in a one to one manner thereby classifying the sub sequence Sinto perceptual patterns. Thereafter step is performed to transform the symbolic string STR STR STR STR STR and STRinto the symbolic strings STR STR STR STR STR and STR in accordance with the sub sequence groups of each of the symbolic string STR STR STR STR STR and STR wherein each of the symbolic strings STR STR STR STR STR and STR represents a sequence composed of at least one of the perceptual patterns P and thus the symbolic strings STR STR STR STR STR and STR are also called perceptual pattern strings . Therefore all of the music items CD CD CD CD CD and CD can be represented by the perceptual pattern strings STR STR STR STR STR and STR .

According to the above description all the music items stored in the music database are transformed into perceptual patterns P by using the frame based clustering step and the sequence based clustering step and all the music items are represented in the form of the perceptual pattern strings as shown in . In the prediction phase the perceptual patterns P and the symbolic strings are used to calculate the interest value of the music item with respect to an active user.

In the prediction phase an active user can access a music recommendation sever for music recommendation function through Internet. When the request for music recommendation is received by the music recommendation sever the refined sub matrix generation step the music snippet generation and mining step and the pattern based preference prediction step will be processed and repeated to calculate the interest value of each of target music items wherein the target music items are the music items which have not been rated by the active user yet.

Referring to is a diagram showing a user item rating matrix according to an embodiment of the present invention. The user item rating matrix stores the ratings of all music items itm itm itm itm itm and itm and the user identifications David Alice Eric Andre Ben and Juice corresponding thereto. In addition rating 0 represents that the music item is not provided with a rating by a user. For example the user Andre does not listen to the music item itmyet and thus the rating of the music item itm corresponding to the user Andre is 0.

For finding a refined sub matrix the refined sub matrix generation step is performed to apply a collaborative filtering algorithm on the rating data matrix with respect to the active user and a target music item and thus the refined sub matrix including most relevant users and most relevant items obtained from the music items is obtained. As shown in in this embodiment the active user is Juice and the target music item is itm. After the step is performed a refined sub matrix shown in a doted block is obtained wherein the users Alice Eric Andre and Ben are the most relevant users and the music items itm itm itm itm and itmare the most relevant items.

Referring to to to illustrate a flow chart showing the music snippet generation and mining step . In the music snippet generation and mining step step is first performed to provide a predetermined sliding window and a predetermined moving distance. The size of the sliding window is equal to a predetermined number of the perceptual patterns and the length of predetermined moving distance is equal to a second predetermined number of the perceptual patterns. Then step is performed to move the predetermined sliding window onto each of the second symbolic strings in accordance with the predetermined moving distance to obtain a plurality of snippets wherein each of the snippets has a perceptual pattern sequence. As shown in in this embodiment the sliding window is equal to 4 perceptual patterns and the predetermined moving distance is equal to 2 perceptual patterns and thus after the music item itmcomposed of perceptual pattern types E A B C C D D A B C C D is processed by the step the perceptual pattern subsequences E A B C B C C D C D D A D A B C and B C C D are obtained. Those perceptual pattern subsequences obtained through the step are called snippet in the following description.

Thereafter step is performed to classify the snippets of all the most relevant items into relevant snippet types in accordance with the perceptual pattern sequence of each of the most relevant items. As mentioned above each of all the music items stored in the music database are already transformed into the perceptual pattern strings composed of snippets and thus the step can classify the snippets of all the most relevant items in accordance with the content thereof. For example as shown in the music item itmcan be processed to obtain the perceptual pattern subsequences E A B C B C C D C D D A D A B C and B C C D and thus the music item itmcorresponds to the snippet types E A B C B C C D C D D A and D A B C and the snippet types of the most relevant items are called relevant snippet types. The perceptual pattern strings of the most relevant items are shown in and the music snippet list of the most relevant items is shown in

Thereafter step is performed to count the number of each of the relevant snippet types appearing in each of the most relevant items thereby obtaining a plurality of snippet numbers of each of the relevant snippet types corresponding to the most relevant items. For example as shown in the most relevant item itmhave snippet types E A B C B C C D C D D A and D A B C and the number of the relevant snippet type B C C D is 2 because the music item itmhave 2 relevant snippets B C C D. Therefore the snippet number of the relevant snippet type E A B C appearing in itmis 1 the snippet number of the relevant snippet type B C C D appearing in itmis 2 the snippet number of the relevant snippet type C D D A appearing in itmis 1 the snippet number of the relevant snippet type D A B C appearing in itmis 1.

Then step is performed to determine a positive occurrence count value and a negative occurrence count value of each of the most relevant items. The positive occurrence count value is the number of positive ratings of each of the most relevant items and the negative occurrence count value is the number of negative ratings of each of the most relevant items. In this embodiment the ratings of the music items are classified into positive ratings and negative ratings. The rating having value greater than 2 is considered to belong to the positive rating and the rating having value smaller than 3 and greater than 0 is considered to belong to the negative rating. Thus as shown in the music item itmhas one positive rating and one negative rating and the positive occurrence count value of the most relevant music item itmis 1 and the negative occurrence count value of the most relevant music item itmis 1. The positive occurrence count value and the negative occurrence count value of the most relevant music items are shown in .

Thereafter a positive frequency calculating step is performed to determine a positive frequency of each of the relevant snippet types. Referring to illustrates a flow chart showing the positive frequency calculating step . In the positive frequency calculating step step is first performed to multiply the snippet number of the relevant snippet type by the positive occurrence count value of the most relevant item corresponding thereto to obtain a product corresponding to the most relevant item. Then step is performed to repeat the step to obtain all the products corresponding to all the most relevant items. Thereafter step is performed to sum up all the products to obtain the positive frequency of the relevant snippet type.

For example as shown in and the snippet numbers of the most relevant snippet type B C C D appearing in the most relevant items itm itm itm itm and itmare respectively 1 1 2 1 and 2. The positive occurrence count values of the most relevant items itm itm itm itm and itmare respectively 1 0 0 1 and 2. In the step the snippet number of the snippet type B C C D appearing in the most relevant items itmis multiplied by the positive occurrence count value of the most relevant items itm thereby obtaining a product value 1. Then step is performed to multiply the positive occurrence count value of the most relevant item itmby the snippet number of the snippet type B C C D appearing in the most relevant items itmto obtain a product value 0 and multiply the positive occurrence count value of the most relevant item itmby the snippet number of the relevant snippet type B C C D appearing in the most relevant items itmto obtain a product value 0 and multiply the positive occurrence count value of the most relevant item itmby the snippet numbers of the relevant snippet type B C C D appearing in the most relevant items itmto obtain a product value 2 and multiply the positive occurrence count value of the most relevant item itmby the snippet numbers of the relevant snippet type B C C D appearing in the most relevant items itmto obtain a product value 2. Then in the step the products are summed up to obtain the positive frequency of the relevant snippet type B C C D.

After all the positive frequencies of the relevant snippet types are calculated step is performed to calculate to determine a negative frequency of each of the relevant snippet types. Referring to illustrates a flow chart showing the negative frequency calculating step . In the negative frequency calculating step step is first performed to multiply the snippet number of the relevant snippet type by the negative occurrence count value of the most relevant item corresponding thereto to obtain a product corresponding to the most relevant item. Then step is performed to repeat the step to obtain all the products corresponding to all the most relevant items. Thereafter step is performed to sum up all the products to obtain the negative frequency of the relevant snippet type.

For example as shown in and the snippet numbers of the most relevant snippet type B C C D appearing in the most relevant items itm itm itm itm and itmare respectively 1 1 2 1 and 2. The negative occurrence count values of the most relevant items itm itm itm itm and itmare respectively 1 3 0 1 and 0. In the step the snippet number of the snippet type B C C D appearing in the most relevant items itmis multiplied by the negative occurrence count value of the most relevant items itm thereby obtaining a product value 1. Then step is performed to multiply the negative occurrence count value of the most relevant item itmby the snippet number of the snippet type B C C D appearing in the most relevant items itmto obtain a product value 6 and multiply the negative occurrence count value of the most relevant item itmby the snippet number of the relevant snippet type B C C D appearing in the most relevant items itmto obtain a product value 0 and multiply the negative occurrence count value of the most relevant item itmby the snippet numbers of the relevant snippet type B C C D appearing in the most relevant items itmto obtain a product value 1 and multiply the negative occurrence count value of the most relevant item itmby the snippet numbers of the relevant snippet type B C C D appearing in the most relevant items itmto obtain a product value 0. Then in the step the products are summed up to obtain the negative frequency of the relevant snippet type B C C D.

After all the negative frequencies of the relevant snippet types are calculated step is performed to determine a plurality of positive snippet types from the relevant snippet types in accordance with a first threshold wherein the positive frequency of each of the positive snippet types is greater than the first threshold. In this embodiment the first threshold is equal to the sum of the positive occurrence count values of all the most relevant items.

Then step is performed to determine a plurality of negative snippet types from the relevant snippet types in accordance with a second threshold wherein the negative frequency of each of the negative snippet types is greater than the first threshold. In this embodiment the second threshold is equal to the sum of the negative occurrence count values of all the most relevant items.

The positive and negative snippet types and the frequency thereof are shown in . It is noted that the relevant snippet type such as the snippet type B C C D can belong to the positive snippet type and the negative snippet type at the same time. Thereafter step is performed to calculate a term frequency inverse document frequency TFIDF of each of the positive snippet types and the negative snippet types. TFIDF represents the weight of the snippet ts. Suppose there exists a set of distinct snippets DS in music item database I and ts is one of DS. The TFIDF for ts is defined as 

The TFIDF represents the importance of each of the positive snippet types and the negative snippet types and the TFIDF of each of the relevant snippet types is shown in .

According to the above descriptions the music snippet generation and mining step is used to mine preference perceptual patterns in accordance with the refined sub matrix and calculate the TFIDFs of the preference perceptual patterns. In the pattern based preference prediction step the preference perceptual patterns and the TFIDFs are used to calculate the interest of the target music item itm.

Referring to illustrates a flow chart showing the pattern based preference prediction step . In the pattern based preference prediction step step is first performed to determine positive matching snippet types and negative matching snippet types of the target music item. The positive matching snippet types are the positive snippet types contained by the target music item and the negative matching snippet types are the negative snippet types contained by the target music item. For example the target music item itmincludes the positive snippet type B C C D and E A B C and the negative snippet type B C C D and thus the positive matching snippet types of the target music item itmare the snippet types B C C D and E A B C and the negative matching snippet type of the target music item itmis the snippet type B C C D.

Thereafter step is performed to multiply the TFIDF of each of the positive matching snippet types by the positive frequency corresponding thereto so as to obtain a partial interest. Then step is performed to multiply the TFIDF of each of the negative matching snippet types by the negative frequency corresponding thereto to obtain another partial interest. In this embodiment the interest value is defined as INTEREST  DGREE  DGREE 4 where T DEGREE and N DEGREE stand for the accumulated positive and negative frequencies of matching snippets respectively targetitm denotes a set of snippets and PF denotes the set of snippets belonging to the positive snippet type.

Thereafter step is performed to sum up the partial interests to obtain the interest value of the target music item for the active user. The matching snippet types and interest value of the target music item itmis shown in .

In general many music items stored in the music database have not been evaluated by the active user yet and thus the refined sub matrix generation step the music snippet generation and mining step and the pattern based preference prediction step have to repeated to calculate the interest values of all the unevaluated music items.

After the interest values of all the unevaluated music items are calculated the music recommendation server will arrange the unevaluated music items in the recommendation list in accordance with their interest values so that the active user may decide which music items he or she is going to buy simply by looking up the recommendation list.

It will be apparent to those skilled in the art that various modifications and variations can be made to the structure of the present invention without departing from the scope or spirit of the invention. In view of the foregoing it is intended that the present invention cover modifications and variations of this invention provided they fall within the scope of the following claims and their equivalents.

