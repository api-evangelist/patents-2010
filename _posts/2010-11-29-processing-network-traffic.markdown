---

title: Processing network traffic
abstract: A system adapted to process network traffic includes at least one processing engine configured to receive network data being transferred over a network and generate metadata relating to the data. The system includes at least one rule engine configured to receive and process the metadata to generate an output, and at least one selection engine configured to receive and process the rule engine output to determine whether the network data is to be processed by a further component and/or whether the network data is to continue to be transferred over the network. The processing engine, rule engine and selection engine can be implemented in system hardware or firmware, and the further component can be software for execution on another processor.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08923159&OS=08923159&RS=08923159
owner: BAE SYSTEMS plc
number: 08923159
owner_city: London
owner_country: GB
publication_date: 20101129
---
It is desirable to monitor and process network traffic for many reasons such as to detect malicious activity. One known system designed for this purpose is Detica s DCI 10 platform. This includes a hardware layer that provides hardware traffic inspection for examining every byte of every packet. Network packets that contain patterns of interest are passed to software for further processing. The software layer of the DCI 10 platform provides a flexible API application programming interface that enables a developer to dynamically indicate to the hardware layer which traffic is of interest and should therefore be passed to the software layer. Software modules produced by the developer are executed against the traffic via a software processing framework.

However there is an increasing need to employ a more powerful set of analytics tools against network traffic. This is partly in response to the increased complexity of network threats meaning that malicious traffic must be identified based on behaviour rather than purely by technology or target identifiers. It is also partly due to the fact that developers have produced improved techniques and tools e.g. to better identify anomalous traffic or suspicious hosts but currently lack a means to deploy them at high traffic rates.

This class of analysis can be characterised by the requirement to track state such as traffic events and statistics across much if not all of the traffic. In many cases it is necessary to correlate such state not just in terms of a flow but also in consideration of peer communication and potentially the network host to which each packet relates. Existing platforms lack native hardware support to provide stateful correlation of traffic and so it is necessary to have large numbers of packets processed by software to achieve this functionality. It is also necessary to have software examine the state that is correlated for each of these packets so that traffic of interest may be identified and processed by the software processing modules. These processing requirements in addition to that of the actual software module amounts to a high software processing load which is prohibitive at high speeds even with modern multi core processors.

Embodiments of the present invention are intended to address at least some of the problems outlined above.

According to a first aspect of the present invention there is provided a system adapted to process network traffic the system including 

at least one processing engine configured to receive network data being transferred over a network and generate metadata relating to the data 

at least one rule engine configured to receive and process the metadata to generate an output and at least one selection engine configured to receive and process the rule engine output to determine whether the network data is to be processed by a further component and or whether the network data is to continue to be transferred over the network.

The at least one selection engine the at least one rule engine and the at least one selection engine will normally be implemented in system hardware or firmware. The further component will normally be implemented by software executing on another remote processor.

The at least one selection engine may be configured to combine the outputs of a plurality of the rule engines.

The metadata generated by the at least one processing engine may include data identifying a flow peer communication destination host and or source host associated with the network data e.g. by extraction from an IP header of the packet. Alternatively another part of the network data may be used to generate the metadata e.g. custom headers associated with the network data. The metadata may include data identifying at least one pattern and or regular expression found in the network data. The metadata may include statistical data regarding the network data.

The processing engine may generate metadata indicating at least one category for the network data. The category may relate to a source port and or IP address and or a destination port and or IP address of the network data. The category may specify whether the network data is associated with a particular flow peer communication or a host. At least one said rule engine and or at least one said selection engine may be configured to count or monitor for events relating to network data in a said category. The events may comprise a pattern match and or a threshold comparison. The events may comprise events occurring within a flow peer communication or data relating to a particular host associated with the network data.

The system may include at least one memory component which may store state data relating to the network data.

The system may include a delay path for delaying transfer of the network data whilst the network data is processed by the further component. The delay path may be used to retrieve selected network data previously transmitted e.g. based on more recent events.

The processes executed by the at least one rule engine and or the selection and processing engines may be configured by a developer to control and or interact with functionality implemented in firmware components.

According to another aspect of the present invention there is provided a method of processing network traffic the method including 

using at least one processing engine to receive network data being transferred over a network and generate metadata relating to the data 

using at least one selection engine to receive and process the rule engine output to determine whether the network data is to be processed by a further component and or whether the network data is to continue to be transferred over the network 

wherein the at least one selection engine the at least one rule engine and the at least one selection engine are implemented in system hardware or firmware and the further component is implemented by software executing on another processor.

According to further aspects of the present invention there is provided computer program configured to execute at least some of the processes described herein.

Whilst the invention has been described above it extends to any inventive combination of features set out above or in the following description. Although illustrative embodiments of the invention are described in detail herein with reference to the accompanying drawings it is to be understood that the invention is not limited to these precise embodiments. As such many modifications and variations will be apparent to practitioners skilled in the art.

Furthermore it is contemplated that a particular feature described either individually or as part of an embodiment can be combined with other individually described features or parts of other embodiments even if the other features and embodiments make no mention of the particular feature. Thus the invention extends to such specific combinations not already described.

Referring to an example of a system adapted to process network traffic is shown. The system receives network traffic e.g. IP packets transmitted over the internet from a source device to a destination device . The system can be inline in a network or may be deployed from a network tap that is configured to send the system a copy of all or some of the network traffic. The hardware includes firmware components that have been configured with criteria created by a developer using an analysis application . The criteria define traffic that is of interest for further analysis. The system applies the criteria to the incoming network data and generates metadata relating to the network data which is transferred to the analysis application . The application can process the metadata and or associated network traffic and depending on the result of that processing may allow the network data to continue to its original destination if the system is inline in the network and or carry out another function e.g. set an alert that suspicious activity has been detected.

It will be appreciated is illustrative of an example only and variations are possible. For instance an application separate to the analysis application may be used to generate and edit the criteria and the various components may be located on board physically distinct devices.

The results from the engines are then passed to at least one selection engine . The Selection Engine combines the results received from the Rule Engines to determine whether the current packet should be processed by software and or egressed for collection for follow on storage processing systems. One purpose of the delay path is to allow the software application time to process network data transferred to it. The delay path can also allow retrieval of packets that were previously transferred within the capacity of the buffer for further processing. Thus the Selection Engine can also receive packets that are evicted from the delay path and based on recovered control flags determines if these packets should be processed in software and or egressed for collection. Packets are processed in software by the applications defined by the developer. The packets are presented together with the metadata generated for the particular packet and any application specific state data.

The system can track state records for statistics and traffic correlation e.g. using engine state memory and or state memory . A new state entry is allocated when a packet arrives relating to a flow peer or host that is not currently being tracked. State records are retired for reuse after a configurable period of inactivity or in the case of a flow when the system can identify that the flow has been terminated. Software is notified when a state record is retired. Software will also be notified if there are no state records available when a new one needs to be allocated for an incoming packet. The system can be configured to handle such an event by either dropping the packet or passing it directly to software assuming sufficient bandwidth is available . The system may be direction agnostic when resolving the state record for a given flow peer or host. This allows traffic events to and from a network entity to be correlated and acted upon.

In more detail each of the processing engines generates metadata regarding the packet being processed. The metadata can include an indication of a flow peer and hosts associated with the packet. For stateful correlation of traffic statistics and traffic events a number of membership categories can be computed for each packet. In the example four such categories are generated for each packet as follows 

The above categories are generated based on potentially masked fields from the packet header. It is possible to configure these four categories with alternative field and masking criteria so that network packets may be correlated on other categories such as class B or class C domain.

The processing engines can also perform pattern matching regular expressions and packet header inspection functions. Each pattern match can be mapped to one or more pattern groups. The group information is presented to the rule engines allowing multiple patterns to process by each engine. The processing engine is also presented with fields from the packet header allowing matches against particular traffic ports IP addresses and other relevant header fields. Regular expressions are supported by means of the combination of pattern match groups and the Boolean selection capability of the Rule Engines. A regular expression can often be translated into several selectors which are typically too weak to be the sole basis of packet selection. A stronger selection criterion can be realised by using the Rule Engines to combine these weak selectors together. The full regular expression can then be validated by software .

The processing engines can also update state and generate metadata fields for each of the packet categories flow peer and host . Examples of metadata statistics include the timestamp of the packet byte and packet counts packet and data rates and duration. Specific examples are given in the table below 

Statistics can be maintained with consideration to directionality. For example when tracking a particular flow packets from A to B will update the same state data as packets from B to A but with the former updating the In counters and the latter updating Out counters or vice versa . The statistics fields can be generated in a compressed format to ensure that the resultant system bandwidth is achievable. The system can permit easy transformation to a standard number representation.

The Rule Engines are configured by the framework in response to API calls invoked by the developer. is an overview of an example Rule Engine configured to take input from the packet header fields or the statistics metadata. It will be appreciated that the components shown are merely one example of how the Rule Engine functionality described herein can be implemented.

The Rule Engine can perform greater than less than and equivalence integer operations against a threshold with a specified bitwise mask. The Rule

Engine can also receive input from pattern match group information and perform an equivalence check of this data with a specified bitwise mask. Each Rule Engine can be associated with a dedicated per flow peer or host state memory which can be loaded with a configured value and updated by the engine. This state can be used to count flow peer or host events such as pattern matches packets or bytes . Additionally each Rule Engine can have a per flow peer of host flag which may be controlled by the software .

The result of the numerical comparison the pattern match check the state memory and the software controlled flag can be fed into a lookup table that is configured at a per engine level to specify how the state memory should be updated and what Boolean result should be expressed for the Rule Engine. The flexibility of this approach allows for variety of functionalities to be realised. Examples include 

Rather than considering a pattern match the examples above could be based on the evaluation of a metadata field such as the packet count compared to a predefined threshold. The lookup table can also be presented with a bit field that is under software control. This allows software to influence each Rule Engine for a given flow peer or host for example to reset the Rule Engine counter or to disable a particular Rule Engine.

The Selection Engine s combine the results of multiple Rule Engines to determine if a particular packet and associated metadata should be forwarded to the software and or egressed to the Ethernet port for collection by down stream systems. The control of how the results from different Rule Engines are combined is configured by the software . This further extends the functionality that is provided by the hardware for example selection of packets occurring on a specific TCP port that also contain a pattern match or selection of flows which exceed a specified data rate and don t contain a specified set of patterns. Additionally the Selection Engine can be presented with packets that emerge from the delay path . The selection flags for these packets are recovered from state memory and are examined to determine what if any forward processing should be performed for the recovered packet.

The software is used to configure the system hardware Engines by means of an API in the example system. The API can take several forms but in the embodiment described herein it is based on the C programming language which advantageously allows standard software engineering practice to be used. The API allows code produced by the developer to work with the system hardware. The compiled code runs on the software blade and makes low level calls to the hardware in order to configure the Rule Engines and the other components. Thus system components including the processing engine s the rule engine s and the selection engine s are implemented by means of configurable hardware firmware onboard the system whilst the software application is executed by an off board processor. The system framework provides hardware acceleration of key functions and the lightweight API can be employed to offload traffic processing criteria to hardware. This allows a higher level of performance to be achieved for a given amount of software processing resource. It is anticipated that several software modules will be running concurrently on the platform during operation. Each module can perform a number of activities as follows for example 

A developer can use relevant standard C techniques and practices for the particular task in hand. Typically a processing flow examines elements of the metadata the state record and the packet content in order to determine what further processing tasks should be performed on the traffic. The developer can make API calls to offload elements of this examination step to the hardware so that overall system performance is improved.

The skilled person will be capable of designing and implementing a suitable API including necessary initialisation and processing methods that will be called by the processing framework.

Software processing of packets can be performed on multiple processing blades with each blade providing multiple processing cores. When several packets for a particular flow peer or host are being processed in parallel there is a race condition in regards to the integrity of the state data associated with the flow peer and host that the packets are a member of. These issues can be addressed in a number of ways with varying complexity and yielding a range of efficiency processor utilisation. In one embodiment a basic load balancing scheme is proposed. The system hardware will support load balancing at a per IP address or per state level and duplication of packet payload and metadata when state based load balancing results in a packet being routed to multiple processors .

An implication of this approach is that processing of a particular flow peer of host will be tied to a specific processor or processor blade. The suitability of this scheme will therefore vary significantly depending on the traffic characteristics of a particular link and the applications that are deployed. The skilled person will appreciate that it may be possible to implement more efficient load balancing or packet distribution schemes but this can require additional hardware resource and more sophisticated software management.

In the example blade design and functional allocation of blocks labelled comprise DIMM comprise CAM comprise SRAM and comprise FPGA. Components in outline comprise the ingress protocol finder comprise the delay buffer comprise the IPQ lookup comprise the statistics block comprise the Rule Engines and comprise the pattern search Rule Engines. The functions performed by these items will be described below in more detail with reference to the data flow of .

It is necessary to consider two host contexts for each packet one relating to the source IP address and one relating to the destination IP address. Given the high packet rates that must be catered for it may be unfeasible to regard the two host memberships as part of the same category because this would require two accesses from the same category memory . However in a live network it is generally reasonable to assume that the routing algorithms are efficient therefore a source IP address in one direction A B should only be seen as a destination IP address in the reverse direction B A . This allows the hosts category to be broken into two hosts at link end A and hosts at link end B. By making this assumption there are now four categories flows peers hosts A and hosts B each of which can be handled separately by the hardware. The mapping of application Host based rules to these two categories will be handled by the software API.

As part of the hardware firmware design each entity a flow peer or host can be handled equally. This allows significant reuse of both hardware and firmware elements and to help avoid confusion in relation to this a set of terms is defined here 

In order to maintain statistics across the different categories of traffic each packet can be associated with 4 states. Each state can be either a pre existing state where the context has already been seen or a new state where this is the first appearance of the context. For instance a TCP IP packet will be associated with a flow state 2 host states and a peer state.

On arrival at the statistics block the packet will have all 4 of its state IDs along with metadata attached. Each of the 4 categories of state will be handled separately as they are mutually exclusive. Two activities are performed in the statistics block state maintenance and statistics production. The state maintenance involves a READ MODIFY WRITE cycle on the state memory while the statistics production requires transforms to be performed to ready the values for inspection. State held for tracking and generating statistics are based on fixed time slicing using simple addition and comparison. This allows the state maintenance to be achieved in a few clock cycles.

A number of different options were considered for achieving the pattern scan functionality performed by block . One example mechanism uses a pair of Ternary CAMs in conjunction with SRAMs to perform a lookup.

Once the statistics have been calculated and the packet has been searched for any target patterns the results along with the packet metadata are presented to the rule engines . In the example there are 4 banks of rule engines one for each of the categories identified above. Each bank of engines has context state held in an associated memory and may use a caching scheme to guarantee coherency.

The delay buffer serves three main purposes. The first is as an intermediate store of the packets as they arrive to allow the statistics pattern scanning and finally rule engines to decide whether a packet should be passed to software. The second purpose is to reduce system bandwidths by not requiring packet data to be moved around the processing elements any more than necessary. As such only the metadata statistics and decisions need to be sent back from the rule engines. Thirdly the delay buffer allows a certain amount of time for the software applications to decide whether or not a flow is wanted.

The delay buffer can be implemented using multiple memories allowing independent delay paths to be created. These can be connected up in any suitable manner e.g. paired with the first pair providing a relatively short delay to allow for hardware and firmware processing latencies. The second pair can be used to provide a longer delay to enable longer term software latencies to be accommodated.

The IPQ lookup block is made available at the end of the delay buffer to allow particular IP tuples to be extracted either as part of simple rules or in response to some software based decision.

The egress control block provides buffering and load balancing across the software processing blades. The data that is egressed can consist of the following 

The embodiments of the system described above can reduce the amount of software processing that must be performed for each packet. Common and expensive analysis tasks are offloaded into dedicated hardware thereby reducing the number of packets that must be processed by software to achieve the required functionality. The developer can employ hardware rules to identify flow peers and hosts of interest based on the related state. Software processing of packets for an uninteresting flow peer or host can be suppressed indefinitely or until a notable event occurs. Further packet content and traffic statistics can be relayed to software periodically i.e. sampling . The statistics can be computed from all packets but the software needs only read these results periodically. Efficiently distributing packets amongst the available software processing resources means that they only receive the data they actually require.

The embodiments can deploy existing analysis techniques on live network traffic at high speed. Additionally they provide an environment for rapid development of new applications and analyses. The API allows the development of traffic processing software modules in C for example using standard software engineering practices and tools. The software modules can be deployed cost effectively and efficiently using COTS processors by means of hardware acceleration of common and expensive analysis tasks including support for stateful flow based processing . The sophisticated selection of packets can reduce the volume of traffic that must be processed by software to achieve a particular design goal and efficiently distributing packets to multiple software processing cores across multiple processing blades or cards also improves efficiency.

