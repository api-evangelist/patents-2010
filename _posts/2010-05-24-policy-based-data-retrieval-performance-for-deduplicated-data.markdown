---

title: Policy based data retrieval performance for deduplicated data
abstract: A method that includes, by one or more computer systems, determining a data retrieval rate policy based on at least one data retrieval rate parameter. The method also includes determining at least one storage subsystem performance parameter. The method further includes determining a fragmentation value based on the data retrieval rate policy and the at least one storage subsystem performance parameter. The method additionally includes determining a storage subsystem fragmentation of a first data object. The storage subsystem fragmentation includes fragmenting the first data object into a plurality of first data object fragments. The method also includes deduplicating the first data object based on the fragmentation value and the storage subsystem fragmentation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08244992&OS=08244992&RS=08244992
owner: 
number: 08244992
owner_city: 
owner_country: 
publication_date: 20100524
---
At least two determinants of input output I O performance for a storage system are the available data transfer rate and the latency of data access. The latter may be relevant even for large files because it may not be possible to store them in a single linear arrangement. Rather for various practical reasons the file may be fragmented into pieces that are stored in disparate locations on a disk or disk array . Reading or writing each fragment to the storage medium involves an amount of time to physically move the disk s head to the start of the new fragment. This may be referred to as a seek penalty . This overhead is exacerbated in deduplicated storage systems in which newly stored data blocks for which copies already exist in the system are replaced by references to the previously stored copies. This means that the number of fragments encountered during a linear read of a stored object is determined not only by the constraints imposed by the storage subsystem but also by the extent that data can be deduplicated. In many instances improvements in the deduplication effectiveness improve the effectiveness of data compression but result in degradation of the retrieval performance. This is at least partly due to the fact that at least for current technology disks seeking to data is more of a bottleneck than transferring a sequential data block.

Certain embodiments may provide data compression through data deduplication that takes into account a specified data retrieval rate. In particular embodiments the performance penalty caused by fragmenting a data object as part of the storage and deduplication processes may be isolated and exposed as a dynamically controllable matter of policy. For example in particular embodiments a deduplication engine may determine an available amount of excess read capacity based on a suitable data retrieval rate policy and the performance characteristics of a disk array. The excess read capacity may among other things take into account the number and pattern of fragments that are created by the storage system as well as the amount by which the storage system is faster than the specified suitable data retrieval rate. The excess read capacity may be indicative of the amount of time that is available for performing inter fragment seeks while still meeting the user requirement. In particular embodiments the excess read capacity may be divided by the time e.g. an estimated or typical worst case scenario to complete a seek operation to determine a maximum fragmentation rate consistent with the user requirement. Some embodiments may use this information to limit the deduplication induced fragmentation rate of a stored data object so as to provide a suitable data retrieval rate.

In particular embodiments the deduplication engine may use a suitable data retrieval rate policy and information about storage subsystem performance to compute a suitable deduplication rate. The data retrieval rate policy may be based on one or more parameters provided by a user e.g. a system administrator a company e.g. the company providing deduplication a supplier e.g. the supplier providing the equipment used in deduplication or any other user or entity that may want to ensure at least one aspect of data retrieval. The deduplication rate may be used in determining when and how a data object is deduplicated. For example when storing a data object deduplication candidates may be bypassed when there is little or no available excess read capacity. This may increase the data retrieval rate while reducing the amount of compression.

In some embodiments the deduplication engine may determine the cost of each seek that would be incurred if a deduplication opportunity were exercised. Then an opportunity would be declined if there is insufficient excess read capacity remaining and the associated data would be stored in linear fashion. Conversely if there is capacity available the opportunity is exercised and the budget is correspondingly reduced for the associated retrieval overhead. In some instances a deduplication opportunity or sequence of deduplication opportunities may involve a fragment of data that is surrounded on both sides by data that may not be deduplicated. In such an instance deduplicating the fragment of data may incur two costs one to seek to the deduplicated data and one to seek back. In some embodiments a cap is maintained so that fragmentation credit does not accumulate without bound e.g. a file that meets performance parameters that are maintained only on average with high performance at the start of the file may be vitiated by extreme fragmentation at the trailing extremity .

In particular embodiments a sliding window e.g. corresponding to the excess read capacity may be maintained during deduplication. Decisions about whether or not to take deduplication opportunities are deferred until the window is full. The excess read capacity may then be systematically allocated to the deduplication opportunities in order of compression payoff e.g. the longest contiguous deduplication opportunities are given highest priority . In some embodiments the physical layout e.g. the physical distance and similar performance impacting considerations of the seeks between fragments of where data is stored may be taken into consideration. This may allow for more accurate estimates of the temporal costs of the individual fragmentations. In certain scenarios the deduplicated data itself may need to be fragmented e.g. a maximum length to a fragment independent of whether deduplication occurs or not . This additional fragmentation may be factored into the budget.

This disclosure contemplates any suitable number of computer systems . This disclosure contemplates computer system taking any suitable physical form. As an example and not by way of limitation computer system may be an embedded computer system a system on chip SOC a single board computer system SBC such as for example a computer on module COM or system on module SOM a desktop computer system a laptop or notebook computer system an interactive kiosk a mainframe a mesh of computer systems a mobile telephone a personal digital assistant PDA a server or a combination of two or more of these. Where appropriate computer system may include one or more computer systems be unitary or distributed span multiple locations span multiple machines or reside in a cloud which may include one or more cloud components in one or more networks. Where appropriate one or more computer systems may perform without substantial spatial or temporal limitation one or more steps of one or more methods described or illustrated herein. As an example and not by way of limitation one or more computer systems may perform in real time or in batch mode one or more steps of one or more methods described or illustrated herein. One or more computer systems may perform at different times or at different locations one or more steps of one or more methods described or illustrated herein where appropriate.

In particular embodiments computer system includes processor memory storage I O interface communication interface and bus . Although this disclosure describes and illustrates a particular computer system having a particular number of particular components in a particular arrangement this disclosure contemplates any suitable computer system having any suitable number of any suitable components in any suitable arrangement.

In particular embodiments processor includes hardware for executing instructions such as those making up a computer program. As an example and not by way of limitation to execute instructions processor may retrieve or fetch the instructions from an internal register an internal cache memory or storage decode and execute them and then write one or more results to an internal register an internal cache memory or storage . In particular embodiments processor may include one or more internal caches for data instructions or addresses. The present disclosure contemplates processor including any suitable number of any suitable internal caches where appropriate. As an example and not by way of limitation processor may include one or more instruction caches one or more data caches and one or more translation lookaside buffers TLBs . Instructions in the instruction caches may be copies of instructions in memory or storage and the instruction caches may speed up retrieval of those instructions by processor . Data in the data caches may be copies of data in memory or storage for instructions executing at processor to operate on the results of previous instructions executed at processor for access by subsequent instructions executing at processor or for writing to memory or storage or other suitable data. The data caches may speed up read or write operations by processor . The TLBs may speed up virtual address translation for processor . In particular embodiments processor may include one or more internal registers for data instructions or addresses. The present disclosure contemplates processor including any suitable number of any suitable internal registers where appropriate. Where appropriate processor may include one or more arithmetic logic units ALUs be a multi core processor or include one or more processors . Although this disclosure describes and illustrates a particular processor this disclosure contemplates any suitable processor.

In particular embodiments memory includes main memory for storing instructions for processor to execute or data for processor to operate on. As an example and not by way of limitation computer system may load instructions from storage or another source such as for example another computer system to memory . Processor may then load the instructions from memory to an internal register or internal cache. To execute the instructions processor may retrieve the instructions from the internal register or internal cache and decode them. During or after execution of the instructions processor may write one or more results which may be intermediate or final results to the internal register or internal cache. Processor may then write one or more of those results to memory . In particular embodiments processor executes only instructions in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere and operates only on data in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere . One or more memory buses which may each include an address bus and a data bus may couple processor to memory . Bus may include one or more memory buses as described below. In particular embodiments one or more memory management units MMUs reside between processor and memory and facilitate accesses to memory requested by processor . In particular embodiments memory includes random access memory RAM . This RAM may be volatile memory dynamic RAM DRAM or static RAM SRAM . Moreover where appropriate this RAM may be single ported or multi ported RAM. The present disclosure contemplates any suitable RAM. Memory may include one or more memories where appropriate. Although this disclosure describes and illustrates particular memory this disclosure contemplates any suitable memory.

In particular embodiments storage includes mass storage for data or instructions. As an example and not by way of limitation storage may include a semiconductor based or other integrated circuit IC such as for example a field programmable gate array FPGA or an application specific IC ASIC a hard disk drive HDD a hybrid hard drive HHD a floppy disk a floppy disk drive FDD flash memory an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive magnetic tape a magnetic tape drive a Universal Serial Bus USB drive a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive a flash card a flash drive or any other suitable computer readable storage medium or a combination of two or more of these where appropriate. Storage may include removable or non removable or fixed media where appropriate. Storage may be internal or external to computer system where appropriate. In particular embodiments storage is non volatile solid state memory. In particular embodiments storage includes read only memory ROM . Where appropriate this ROM may be mask programmed ROM programmable ROM PROM erasable PROM EPROM electrically erasable PROM EEPROM electrically alterable ROM EAROM or flash memory or a combination of two or more of these. This disclosure contemplates mass storage taking any suitable physical form. Storage may include one or more storage control units facilitating communication between processor and storage where appropriate. Where appropriate storage may include one or more storages . Although this disclosure describes and illustrates particular storage this disclosure contemplates any suitable storage.

In particular embodiments I O interface includes hardware software or both providing one or more interfaces for communication between computer system and one or more I O devices. Computer system may include one or more of these I O devices where appropriate. One or more of these I O devices may enable communication between a person and computer system . As an example and not by way of limitation an I O device may include a keyboard keypad microphone monitor mouse printer scanner speaker still camera stylus tablet touchscreen trackball video camera another suitable I O device or a combination of two or more of these. An I O device may include one or more sensors. This disclosure contemplates any suitable I O devices and any suitable I O interfaces for them. Where appropriate I O interface may include one or more device or software drivers enabling processor to drive one or more of these I O devices. I O interface may include one or more I O interfaces where appropriate. Although this disclosure describes and illustrates a particular I O interface this disclosure contemplates any suitable I O interface.

In particular embodiments communication interface includes hardware software or both providing one or more interfaces for communication such as for example packet based communication between computer system and one or more other computer systems or one or more networks. As an example and not by way of limitation communication interface may include a network interface controller NIC or network adapter for communicating with an Ethernet or other wire based network or a wireless NIC WNIC or wireless adapter for communicating with a wireless network such as a WI FI network. This disclosure contemplates any suitable network and any suitable communication interface for it. As an example and not by way of limitation computer system may communicate with an ad hoc network a personal area network PAN a local area network LAN a wide area network WAN a metropolitan area network MAN or one or more portions of the Internet or a combination of two or more of these. One or more portions of one or more of these networks may be wired or wireless. As an example computer system may communicate with a wireless PAN WPAN such as for example a BLUETOOTH WPAN a WI FI network a WI MAX network a cellular telephone network such as for example a Global System for Mobile Communications GSM network or any other suitable wireless network or a combination of two or more of these. Computer system may include any suitable communication interface for any of these networks where appropriate. Communication interface may include one or more communication interfaces where appropriate. Although this disclosure describes and illustrates a particular communication interface this disclosure contemplates any suitable communication interface.

In particular embodiments bus includes hardware software or both coupling components of computer system to each other. As an example and not by way of limitation bus may include an Accelerated Graphics Port AGP or other graphics bus an Enhanced Industry Standard Architecture EISA bus a front side bus FSB a HYPERTRANSPORT HT interconnect an Industry Standard Architecture ISA bus an INFINIBAND interconnect a low pin count LPC bus a memory bus a Micro Channel Architecture MCA bus a Peripheral Component Interconnect PCI bus a PCI Express PCI E bus a serial advanced technology attachment SATA bus a Video Electronics Standards Association local VLB bus or another suitable bus or a combination of two or more of these. Bus may include one or more buses where appropriate. Although this disclosure describes and illustrates a particular bus this disclosure contemplates any suitable bus or interconnect.

Herein reference to a computer readable storage medium encompasses one or more tangible computer readable storage media possessing structures. As an example and not by way of limitation a computer readable storage medium may include a semiconductor based or other IC such as for example an FPGA or an ASIC an HDD an HHD a floppy disk an FDD flash memory an optical disc an ODD a magneto optical disc a magneto optical drive magnetic tape a magnetic tape drive a USB drive a holographic storage medium an SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive a flash card a flash drive or any other suitable computer readable storage medium or a combination of two or more of these where appropriate. Herein reference to a computer readable storage medium excludes any medium that is not eligible for patent protection under 35 U.S.C. 101. Herein reference to a computer readable storage medium excludes transitory forms of signal transmission such as a propagating electrical or electromagnetic signal per se to the extent that they are not eligible for patent protection under 35 U.S.C. 101.

This disclosure contemplates one or more computer readable storage media implementing any suitable storage. In particular embodiments a computer readable storage medium implements one or more portions of processor such as for example one or more internal registers or caches one or more portions of memory one or more portions of storage or a combination of these where appropriate. In particular embodiments a computer readable storage medium implements RAM or ROM. In particular embodiments a computer readable storage medium implements volatile or persistent memory. In particular embodiments one or more computer readable storage media embody software. Herein reference to software may encompass one or more applications bytecode one or more computer programs one or more executables one or more instructions logic machine code one or more scripts or source code and vice versa where appropriate. In particular embodiments software includes one or more application programming interfaces APIs . This disclosure contemplates any suitable software written or otherwise expressed in any suitable programming language or combination of programming languages. In particular embodiments software is expressed as source code or object code. In particular embodiments software is expressed in a higher level programming language such as for example C Perl or a suitable extension thereof. In particular embodiments software is expressed in a lower level programming language such as assembly language or machine code . In particular embodiments software is expressed in JAVA. In particular embodiments software is expressed in Hyper Text Markup Language HTML Extensible Markup Language XML or other suitable markup language.

In particular embodiments one or more links each include one or more buses wireline links wireless links or optical links. In particular embodiments one or more links each include a virtual private network VPN a local area network LAN a wireless LAN WLAN a wide area network WAN a metropolitan area network MAN a portion of the Internet or another link or a combination of two or more such links . In particular embodiments link may include one or more links. The present disclosure contemplates any suitable links . One or more links coupling client to data store may differ in one or more respects from one or more links coupling deduplication engine to data store . Although this disclosure describes and illustrates a particular arrangement among a particular client a particular deduplication engine a particular data store and particular links this disclosure contemplates any suitable arrangement among any suitable client any suitable deduplication engine any suitable data store and any suitable links . As an example and not by way of limitation instead of or in addition to one or more links coupling client to data store one or more links may couple client to deduplication engine . Client deduplication engine and data store may be located at a single physical location or at multiple physical locations.

As described above deduplication engine may include a hardware or encoded software element such as for example a computer program or a combination of two or more such elements that algorithmically perform data deduplication. This disclosure contemplates any suitable programming language for any suitable computer program for data deduplication where appropriate. This disclosure contemplates any suitable number and type of computer systems executing any suitable computer program for data deduplication where appropriate. Each of the computer systems may be unitary or distributed where appropriate and a distributed computer system may span multiple computer systems or multiple datacenters where appropriate. Deduplication engine may include one or more deduplication engines .

In particular embodiments deduplication engine provides in line deduplication. As an example and not by way of limitation deduplication engine may deduplicate data from client as client or another device stores data at data store which may provide back up or other storage for client . In particular embodiments deduplication engine provides post process deduplication in addition or as an alternative to in line deduplication. As an example and not by way of limitation deduplication engine may access data stored at data store which client or another device may have stored at data store without having data deduplication performed on it and then deduplicate and re store it. In particular embodiments deduplication engine may assist in re creating data stored at data store when client accesses it. In both instances deduplication engine may take into account the data retrieval rate e.g. bits per second that can be retrieved by client specified by the data retrieval rate policy.

In particular embodiments deduplication engine includes a data partitioning module a sub block comparison module and a read capacity module . Data partitioning module sub block comparison module and read capacity module may each include a hardware or encoded software element or a combination of two or more such elements that provide particular functionality for data deduplication. In particular embodiments data partitioning module partitions data e.g. data object D or data blocks B B into sub blocks e.g. sub blocks SB SB . In some embodiments fingerprints may be created for the partitioned data. In particular embodiments sub block comparison module determines whether a sub block is identical or similar to one or more other sub blocks. In particular embodiments read capacity module determines whether there is available read capacity to deduplicate sub blocks identified by comparison module as being similar or identical to other sub blocks.

In particular embodiments data partitioning module sub block comparison module and read capacity module are functionally logically or physically separate from each other. As an example and not by way of limitation data partitioning module may have its own hardware or software elements distinct from those of each of sub block comparison module and read capacity module . In particular embodiments two or more of data partitioning module sub block comparison module and read capacity module are functionally logically or physically combined with each other where appropriate. As an example and not by way of limitations two or more of data partitioning module sub block comparison module and read capacity module may share one or more of their hardware or software elements with each other.

Data partitioning module sub block comparison module and read capacity module may access e.g. write to or read from deduplication engine data as needed to provide their functionality. Deduplication engine data may include one or more data retrieval rate parameters one or more differences calculated between similar sub blocks one or more indexes and or other suitable deduplication engine data . One or more portions of deduplication engine data may be internal to deduplication engine where appropriate. One or more portions of deduplication engine data may be external to deduplication engine where appropriate. This disclosure contemplates deduplication engine data being stored in any suitable manner using any suitable memory.

Depending on the embodiment and or scenario deduplication engine may use a data structure known as a primary index to store signature values such as hash values that are associated with sequences of data being stored. These sequences of data known as sub blocks may be smaller portions of a larger file data stream or other data object. Copies of unique sub blocks may be stored in a repository which may reside on a HDD in a storage area network SAN or in other mass storage components. The deduplication engine may use the primary index to store a pointer to an address or location in the repository to point from the signature of a sub block to the actual storage location of the sub block associated with it. Herein reference to a signature encompasses a signature value and vice versa where appropriate. Herein reference to a deduplication engine encompasses a hardware or encoded software element such as for example a computer program or a combination of two or more such elements that algorithmically perform data deduplication where appropriate. In some embodiments there may be multiple indexing mechanisms involving one or more levels of to reach the data. For example certain embodiments may comprise an architecture with an indirect index that takes a hash value to a sequence memory page. These sequence memory pages may themselves be linked together in various ways by local sub indexes.

In particular embodiments during deduplication deduplication engine may replace a sub block that is to be deduplicated with a sub block signature value and associated pointer to the duplicate data in the sub block that is already stored. The associated pointers may be pointers from signature values to addresses in a repository where the data in the sub blocks is stored. In particular embodiments hash based deduplication is a method of data deduplication that involves segmenting data into variable or fixed sized sub blocks calculating the hash of each of the sub blocks and matching identical sub blocks by their hashes. U.S. Pat. No. 5 990 810 issued 23 Nov. 1999 to Ross. N. Williams incorporated herein by reference as an example and not by way of limitation discloses example hash based deduplication. In particular embodiments file differencing is a method of data deduplication that involves calculating a series of fingerprints of each file and matching files based on the number of fingerprints they have in common. Once two files have been found that are similar the old copy is read and the new copy is stored as a difference. Udi Manber USENIX W1994 TCP San Francisco Calif. Jan. 17 21 1994 incorporated herein by reference as an example and not by way of limitation discloses example file differencing. Herein reference to file differencing encompasses sub block differencing where appropriate.

In particular embodiments deduplication engine may segment data for deduplication into variable sized sub blocks as U.S. Pat. No. 5 990 810 discloses. This may be done before after or concurrently with the segmentation done based on the storage system. Thus depending on the embodiment the data that is being segmented for deduplication may be the data object e.g. data object D that is to be stored in data store or it may be the data blocks e.g. data blocks B B segmented from the data object to comply with the storage parameters of data store . Deduplication engine may then determine if there already exists an identical or similar sub block. For example in some embodiments deduplication engine may identify identical sub blocks by calculating a hash which in particular embodiments may be known as a sub block hash of the sub block and comparing it to an index containing hashes of other sub blocks. As another example deduplication engine may determine if a similar sub block is present using fingerprints associated with the sub block. Particular embodiments may use any of a variety of known techniques for identifying identical or similar sub blocks. Because deduplicating the identical or similar sub block will result in fragmenting the data object if an identical or similar sub block is found deduplication engine may determine whether there is sufficient excess read capacity available to perform the corresponding deduplication.

The size of sub blocks SB SB may vary based on a balance between system performance and data compression. A relatively large mean sub block size may reduce the number of sub blocks and therefore reduce the number of potential fragments. This may improve performance but may reduce the space efficiency of the data deduplication. A relatively small mean sub block size may facilitate a higher degree of data deduplication. However a smaller mean sub block length size require the use of more fragments. Therefore using a smaller mean sub block length may reduce performance but increase the space efficiency of the data deduplication.

Although the present disclosure describes and illustrates determining whether sub blocks are identical by looking up corresponding hash values in an index the present disclosure contemplates any suitable method for determining whether sub blocks are identical as an alternative or in addition to determining whether sub blocks are identical by looking up corresponding hash values in an index . As an example and not by way of limitation the deduplication engine may compare data associated with the sub blocks to determine whether they are identical. In particular embodiments the deduplication engine also determines whether non identical sub blocks are similar. In particular embodiments the deduplication engine may use fingerprints to determine whether non identical sub blocks are similar. In particular embodiments the deduplication engine may treat two non identical sub blocks as similar if a certain minimum percentage such as for example at least approximately 75 of the fingerprints associated with them are the same. The deduplication engine may calculate a difference between similar sub blocks and use the difference later to re create one or both of the sub blocks.

Although the present disclosure describes and illustrates partitioning data object D into blocks B B and partitioning data block B into sub blocks SB SB it is not necessary that the partitioning be performed in this manner. For example data object D may be partitioned into sub blocks irrespective of or concurrently with the partitioning of data object D into data blocks B B. The deduplication may be performed for purposes of backing up data transmitting data storing data that is not backed up or any other suitable purpose or combination of purposes.

At step a data retrieval rate policy is determined based on the data retrieval rate parameter. Depending on the embodiment the data retrieval rate policy may be applicable to each data object individually or collectively in whole or in part. For example in some embodiments the data retrieval rate policy may ensure that the data retrieval rate of every data object is within the parameters of the data retrieval rate policy in some embodiments the data retrieval rate policy may ensure that the mean data retrieval rate of two or more data objects is within the parameters of the data retrieval rate policy in some embodiments the data retrieval rate policy may ensure that the data retrieval rate of an amount of data is within predetermined or specific data retrieval parameters.

At step at least one storage subsystem performance parameter is determined. The storage subsystem performance parameter may include one or more of a variety of factors that may impact the rate at which data is retrieved from a data store. For example the storage subsystem performance parameter may comprise an average data access latency e.g. seek time a maximum e.g. worst case scenario data access latency time a minimum data access latency time an average data transfer rate a minimum disk read speed a maximum disk read speed an average disk read speed a minimum data transfer rate a maximum data transfer rate an average data transfer rate or any other measure of speed latency delay or throughput indicative of the performance of the storage subsystem.

At step a fragmentation value is determined based on the data retrieval rate policy and the at least one storage subsystem performance parameter. The fragmentation value may be expressed in any of a variety of suitable formats. For example in some embodiments the fragmentation value may comprise the number of fragments into which a data object can be fragmented and still meet the parameters of the data retrieval rate policy. As another example in some embodiments the fragmentation value may comprise the number of fragments that can be created per megabyte while still meeting the parameters of the data retrieval rate policy. In some embodiments the fragmentation value may comprise a fragmentation budget. The fragmentation budget may represent an amount of excess read capacity that is available for use in deduplication.

At step storage subsystem fragmentation of a first data object is determined. The first data object is the data object that is being stored transmitted or processed and for which deduplication is to be applied. The storage subsystem fragmentation comprises fragmenting the first data object in accordance with the specifications or parameters of the storage subsystem. For example the storage subsystem may require data objects to be stored as data blocks of 10 megabytes or less. This may result in fragmenting the first data object into a number of data blocks with each fragment negatively impacting the data retrieval performance e.g. latency to seek the next data block .

At step the first data object is deduplicated based on the fragmentation value and storage subsystem fragmentation. In particular embodiments deduplicating the first data object may comprise partitioning the first data object into a plurality of sub blocks. The sub blocks may then be assessed to determine and or identify potential sub blocks for deduplication. The identified potential sub blocks may then be deduplicated to the extent that there is excess read capacity available. For example if it were assumed the fragmentation value comprises the number of times a data object can be fragmented each fragment of the first data object by the storage subsystem may reduce the available read capacity. The remaining capacity may be used to deduplicate as many sub blocks as possible within the constraints of the available read capacity. In particular embodiments there may be a cost associated with each fragment whether the fragment was created by the deduplication engine or the storage subsystem. In some embodiments the cost may be static e.g. based on a worst case scenario . In some embodiments the cost may vary e.g. based on the physical distance between fragments . In some situations adding a fragmentation to deduplicate a particular sub block may incur two costs one cost to seek the deduplicated data and a second cost to return to the original data. If the cost to deduplicate a potential sub block of data exceeds the available read capacity then the sub block may not be deduplicated e.g. it is stored as though an identical or similar sub block is not already present .

In some situations the amount of excess read capacity may not allow all potential sub blocks to be deduplicated. Accordingly some embodiments may prioritize potential sub blocks for deduplication. For example those sub blocks or sub sequences of sub blocks for which deduplication will provide a greater level of compression may have a higher priority. The deduplication engine may then deduplicate sub blocks in their order of priority. Some embodiments may comprise a technique in which sub blocks are selected in a manner that is statistically consistent with the goal of selecting sub blocks resulting in greater compression. For example in some embodiments the deduplication process may use a queue that tracks the sub blocks that are to be deduplicated. The queue may be sorted by for example hash values. Sub blocks may then be taken from the queue and deduplicated together with sub blocks that neighboring e.g. in the original input ordering and or some previous sequence against which deduplication is possible the sub block that was just taken from the queue. This may have the stochastic effect of processing those sub blocks belonging to longer deduplicatable subsequences of sub blocks before sub blocks belonging to shorter such subsequences.

Although this disclosure describes and illustrates particular steps of the method of as occurring in a particular order this disclosure contemplates any suitable steps of the method of occurring in any suitable order. Although this disclosure describes and illustrates particular components carrying out particular steps of the method of this disclosure contemplates any suitable components carrying out any suitable steps of the method of .

In particular embodiments accounting for data retrieval rates allows data to be deduplicated without imposing unsuitable data retrieval delays. This may allow for data compression that is capable of meeting predetermined or specified policy parameters for data retrieval performance.

The present disclosure encompasses all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend. Similarly where appropriate the appended claims encompass all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend.

