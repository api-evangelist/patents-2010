---

title: System and method of controlling power in an electronic device
abstract: A method of utilizing a node power architecture (NPA) system, the method includes receiving a request to create a client, determining whether a resource is compatible with the request, and returning a client handle when the resource is compatible with the request.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08745629&OS=08745629&RS=08745629
owner: QUALCOMM Incorporated
number: 08745629
owner_city: San Diego
owner_country: US
publication_date: 20100729
---
The present application claims priority to U.S. Provisional Patent Application Ser. No. 61 294 014 entitled SYSTEM AND METHOD OF CONTROLLING POWER IN AN ELECTRONIC DEVICE filed on Jan. 11 2010 the contents of which are fully incorporated by reference.

Portable computing devices PDs are ubiquitous. These devices may include cellular telephones portable digital assistants PDAs portable game consoles palmtop computers and other portable electronic devices. In addition to the primary function of these devices many include peripheral functions. For example a cellular telephone may include the primary function of making cellular telephone calls and the peripheral functions of a still camera a video camera global positioning system GPS navigation web browsing sending and receiving emails sending and receiving text messages push to talk capabilities etc. As the functionality of such a device increases the computing or processing power required to support such functionality also increases. Further as the computing power increases there exists a greater need to effectively manage the processor or processors that provide the computing power.

The word exemplary is used herein to mean serving as an example instance or illustration. Any aspect described herein as exemplary is not necessarily to be construed as preferred or advantageous over other aspects.

In this description the term application may also include files having executable content such as object code scripts byte code markup language files and patches. In addition an application referred to herein may also include files that are not executable in nature such as documents that may need to be opened or other data files that need to be accessed.

The term content may also include files having executable content such as object code scripts byte code markup language files and patches. In addition content referred to herein may also include files that are not executable in nature such as documents that may need to be opened or other data files that need to be accessed.

As used in this description the terms component database module system and the like are intended to refer to a computer related entity either hardware firmware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a computing device and the computing device may be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers. In addition these components may execute from various computer readable media having various data structures stored thereon. The components may communicate by way of local and or remote processes such as in accordance with a signal having one or more data packets e.g. data from one component interacting with another component in a local system distributed system and or across a network such as the Internet with other systems by way of the signal .

Referring initially to and an exemplary portable computing device PCD is shown and is generally designated . As shown the PCD may include a housing . The housing may include an upper housing portion and a lower housing portion . shows that the upper housing portion may include a display . In a particular aspect the display may be a touch screen display. The upper housing portion may also include a trackball input device . Further as shown in the upper housing portion may include a power on button and a power off button . As shown in the upper housing portion of the PCD may include a plurality of indicator lights and a speaker . Each indicator light may be a light emitting diode LED .

In a particular aspect as depicted in the upper housing portion is movable relative to the lower housing portion . Specifically the upper housing portion may be slidable relative to the lower housing portion . As shown in the lower housing portion may include a multi button keyboard . In a particular aspect the multi button keyboard may be a standard QWERTY keyboard. The multi button keyboard may be revealed when the upper housing portion is moved relative to the lower housing portion . further illustrates that the PCD may include a reset button on the lower housing portion .

Referring to an exemplary non limiting aspect of a portable computing device PCD is shown and is generally designated . As shown the PCD includes an on chip system that includes a multicore CPU . The multicore CPU may include a zeroth core a first core and an Nth core .

As illustrated in a display controller and a touch screen controller are coupled to the multicore CPU . In turn a touch screen display external to the on chip system is coupled to the display controller and the touch screen controller .

As further illustrated in a stereo audio CODEC may be coupled to the multicore CPU . Moreover an audio amplifier may coupled to the stereo audio CODEC . In an exemplary aspect a first stereo speaker and a second stereo speaker are coupled to the audio amplifier . shows that a microphone amplifier may be also coupled to the stereo audio CODEC . Additionally a microphone may be coupled to the microphone amplifier . In a particular aspect a frequency modulation FM radio tuner may be coupled to the stereo audio CODEC . Also an FM antenna is coupled to the FM radio tuner . Further stereo headphones may be coupled to the stereo audio CODEC .

As depicted in the touch screen display the video port the USB port the camera the first stereo speaker the second stereo speaker the microphone the FM antenna the stereo headphones the RF switch the RF antenna the keypad the mono headset the vibrator and the power supply are external to the on chip system .

In a particular aspect one or more of the method steps described herein may be stored in the memory as computer program instructions. These instructions may be executed by the multicore CPU in order to perform the methods described herein. Further the multicore CPU the memory or a combination thereof may serve as a means for executing one or more of the method steps described herein in order to sample data within a central processing unit.

Referring to a processing system is shown and is generally designated . In a particular aspect the processing system may be incorporated into the PCD described above in conjunction with . As shown the processing system may include a multicore central processing unit CPU and a memory connected to the multicore CPU . The multicore CPU may include a zeroth core a first core and an Nth core . The zeroth core may include a zeroth dynamic clock and voltage scaling DCVS algorithm executing thereon. The first core may include a first DCVS algorithm executing thereon. Further the Nth core may include an Nth DCVS algorithm executing thereon. In a particular aspect each DCVS algorithm may be independently executed on a respective core .

Moreover as illustrated the memory may include an operating system stored thereon. The operating system may include a scheduler and the scheduler may include a first run queue a second run queue and an Nth run queue . The memory may also include a first application a second application and an Nth application stored thereon.

In a particular aspect the applications may send one or more tasks to the operating system to be processed at the cores within the multicore CPU . The tasks may be processed or executed as single tasks threads or a combination thereof. Further the scheduler may schedule the tasks threads or a combination thereof for execution within the multicore CPU . Additionally the scheduler may place the tasks threads or a combination thereof in the run queues . The cores may retrieve the tasks threads or a combination thereof from the run queues as instructed e.g. by the operating system for processing or execution of those task and threads at the cores .

In a particular aspect the controller may be a software program. However in an alternative aspect the controller may be a hardware controller that is external to the memory . In either case the controller the memory the cores or any combination thereof may serve as a means for executing one or more of the method steps described herein in order to sample data from the cores .

Referring to a node power architecture NPA system is shown and is generally designated . The NPA system may include a first client a second client and an Nth client . Further the NPA system may include a first resource connected to the first client and the second client . A second resource may be connected to the Nth client .

Further as illustrated in the NPA system may include a third resource connected to the first resource . A fourth resource may be connected to the first resource and the second resource . Moreover an Nth resource may be connected to the third resource and the fourth resource . further indicates that an event handler may be connected to the first resource . The event handler may receive one or more events from the first resource .

In a particular aspect each resource may be a central processing unit a core a modem a clock a bus etc. Each client may be a software application. In the alternative each client may represent a software application or an instance of a software application.

It may be appreciated that the connectivity shown in is exemplary and is not intended to limit the scope of the NPA system . Further it may be appreciated that any number of clients and any number of resources may be included in the system . Also the clients and resources may be interconnected in numerous ways not shown in .

In a particular aspect as shown in the NPA system may be shown as a directed acyclic graph structure instead of code. Further the NPA system may make inter resource dependencies explicit and may implicitly document the components of the NPA system . Further the NPA system may ease the porting of resources and clients to new hardware HW . In a particular aspect a client may issue requests to any resources directly used. Indirect requests may be issued from resource to resource.

The NPA system may also enhance work requests beyond on off or level. Further the NPA system may allow hints and deadlines to be issued by clients resources or a combination thereof. The hints may indicate a particular workload requirement of a client or resource as expressed in instructions per second e.g. millions of instructions per second MIPS . Alternatively the workload requirement may be expressed as a frequency e.g. a kilohertz value kHz a megahertz MHz value a gigahertz GHz value etc. In another aspect the workload requirement may be expressed as a data transfer rate e.g. kilobits per second KB S megabits per second MB S gigabits per second GB S or a combination thereof. Further the workload requirement may be expressed as any combination described above. The deadline associated with a particular workload requirement may indicate when a particular workload must be finished.

The NPA system shown in further provides separate power optimization from resource requests. For example the NPA system may utilize hints durations deadlines or a combination thereof in order to optimize power without having to modify client requests.

The NPA system may include an event mechanism i.e. the event handler for the notification of resource state changes. The event handler may allow software programs to react to resources as they are enabled disable oversubscribed etc. Further the event handler may allow dynamic profiling of resource utilization. Since the NPA system may be considered a distributed system this may allow additional resources to be dynamically added to the NPA system . Further power optimization may be performed separately from resource definition.

In a particular aspect the resources may be nodes in the NPA system . The clients may be edges. Each resource may propagate requests as necessary to other resources connected thereto. In particular each resource may issue requests to dependent resources via clients in the same manner as external requests are issued. More specifically from the perspective of a resource there may be no distinction between an external client issuing a request or another resource issuing a request. In a particular aspect resource may be dynamically added. Further clients and the event handler or handlers may be dynamically added and removed.

In a particular aspect the resources may be the entities that the clients may issue work requests against. All resource requests and updates may be logged. Moreover the resources may be responsible for meeting the various client requests and optimizing power consumption. In a particular aspect the function responsible for determining the correct level to meet the client requests i.e. workload may be user defined and overridden. The function responsible for updating the hardware HW and other resource dependencies may be user definable.

In the NPA system all resources may be identified by name. Further using the NPA system there is no compile time linkage between the clients and the resources . Specifically the string lookup may be resolved at the time that the clients are created. Further there is no request time overhead. Each resource may have multiple names i.e. aliases and each resource may define its own units e.g. MIPS MHz MB S etc. and work requests are made in the defined units.

The resource graph that shows the NPA system is highly dynamic and does not always appear as show in . The resource graph that represents the NPA system is constructed during initialization of the device in which the resources and clients are installed. Clients and event handlers may be added dynamically and client requests may be issued against resources. Resources may aggregate multiple concurrent requests to compute a new resource state. Moreover resources may update and cancel dependency requests as needed in order to satisfy a new resource state.

In a particular aspect a node may be a collection of one or more resources . A node with more than one resource is called a compound node e.g. the second node . An example of a compound node may include a coupled CPU and bus clock. The same driver function may be share by both CPU and bus resources. Updating one clock may implicitly update the other clock.

Resources may be named interfaces. The naming convention may be file system like e.g. clk cpu bus arbiter etc. Resources may represent physical resources e.g. a clock a voltage rail etc. Resources may also represent a logical resource e.g. a CPU a bus etc. Resources may also represent subsystem use cases e.g. a bus flow. Further resources may present a control signal e.g. DCVS enable etc.

An example of a logical resource may include a CPU latency resource. In such a case a client may issue a request with a particular latency requirement. A sleep task may use the constraint to allow or disallow certain low power modes. As a sleep state is implemented or new hardware changes lower power mode LPM transition times lower power modes may be enable or potential failure cases may be avoid. In such a case any changes to the LPM behavior may be transparent to all registered clients.

As stated herein the same resource may have more than one name i.e. a symlink or an alias. This may establish a virtual resource. In such a case multiple hardware HW independent names may be created for the resource. For example one resource may be named power cpu and power C2 . These names may be linked together and links may be defined independently of the resource definition. In a particular aspect resources must exist prior to a link being created and links may be resolved at client creation time. Further no request time overhead may be incurred.

The use of virtual resources may provide some hardware abstraction. In other words clients do not need to know which rail powers a particular CPU and clients do not need to know which CPU they are operating on.

In a particular aspect a node may manage the dependencies of all the collected resources . Moreover each resource in a compound node may share the same driver function dependencies NPA lock or a combination thereof. Also in a particular aspect updates or requests to each resource in a compound node may be processed atomically. Driver and update functions may access the state of all resources in a compound node . Each node may be identified by name or alias and each node name may be used to identify dependencies.

Nodes may be defined via a set of structures that include a name a driver function which may be a custom function one or more attributes user data a dependency array a resource definition array or any combination thereof. The dependency array may include a name of dependency and a dependency client type. A resource definition array may be provided and may include a resource name a maximum value one or more resource attributes a plug in from a library e.g. an update function user data or a combination thereof.

A node creation function may utilize a node definition structure an initial resource state array an optional node creation event or a combination thereof. After all of the node dependencies exist the node creation function may create one or more resources and adds them to a resource graph. Further the node creation function may create clients for dependencies and the node creation function may invoke driver functions with initial values. In a particular aspect a node may not be created until all dependencies for the node exist. A client may be notified when a node is fully constructed.

In a particular aspect a resource graph that represents an NPA system may be constructed in a distributed manner. Any technology may define its own resources and add them to the graph. Nodes can be defined in arbitrary order.

The work request may include a work model. The work model may include registered workloads impulse workloads isochronous workloads pulsed workloads best effort workloads scheduled workloads etc.

Additionally the resource may further customize a client via optional client creation and client destruction function. The resource may use a client s user data field to add arbitrary extra data to each client. This data may be used form caching workload statistics client identification database access etc.

A registered workload may include a workload may indicate one or more requirements to complete the workload e.g. a particular CPU frequency. An impulse workload may include a workload that has a well known starting point but no well known end and no well known load. An isochronous workload may be a workload that occurs at a substantially regular interval at a substantially regular duration. A pulsed workloads may include workloads that begin at a certain level and automatically ceases at fixed time interval. Further a best effort workload may include a hint that there is work that could be performed but is not performance critical it can be arbitrarily deferred. The schedule workload may be a workload that includes a notification that some amount of work will be required at a defined point in the future. Each type of workload may indicate its type before it is performed and the resource may utilize the workload type to effectively and efficiently perform the workload e.g. by altering a dynamic clock and voltage scaling DCVS algorithm.

In a particular aspect each client may be identified by name. Each client name may be used for informational purposes. Further in a particular aspect users may access clients via an opaque client handle . Client requests may be derived from hardware HW feedback e.g. CPU idle time bus monitoring etc and from software SW applications. A user may register clients with the resource in order to issue requests to the resource . Client registration may happen at runtime and a resource may support multiple client request types. Each client type is potentially a different interface and some default client types may be defined.

Referring now to a fourth aspect of an NPA system is shown and is designated . As shown the NPA system may include a resource . The resource may include a collection of all registered event handlers. The collection of registered event handlers may be a list and may include a first event handler a second event handler and a third event handler . The event handlers may be associated with the resource but not to each other.

As shown the resource may include a list of event handlers . Clients may register event handlers . However an event handler may not always be associated with a client. Users may access event handlers via an opaque event handler handle .

In a particular aspect each event handler may register for hi watermarks lo watermarks or a combination thereof and the watermarks may be expressed as headroom. Events may include any changes in a resource state e.g. for profiling purposes. Moreover events may be used to monitor resource loads or trigger other actions off resource state changes. This may be used to reduce a workload when a resource is oversubscribed or disable optional functions when a resource goes away.

In a particular aspect every public NPA call may be logged to a common log file. The log may use names i.e. strings that are human readable. String parsing may happen in a separate thread.

Referring now to a method of utilizing an NPA system is shown and is generally designated . As shown beginning at step a user i.e. a software application may create a particular type of client for a resource using a create client function. The create client function may include the following arguments resource name client name client work model or a combination thereof. At step after the resource receives the request to create a client the resource may return a client handle for the client. The client should check the return value in order to determine that a handle was actually created. If a handle is not created e.g. due to an incompatible work model lack of availability at the resource etc. The method may end and the user may attempt to create a client for another resource.

At step the user may use the handle to issue a work request to the resource. Work includes the resource state e.g. on off level and the duration for which the state is needed. Work request parameters may be known or unknown. Known parameters are requirements to the resource. Unknown parameters may be hinted and may be modified by the resource.

If possible a resource must honor a work request with known work parameters. The client may register with an event handler to receive notification if the request will not be met. Unknown and hinted work parameters may provide opportunities for the resource to optimize power consumption. Where possible clients should leave parameters unknown or hinted in order to maximize opportunities for power optimization.

The work request may also include a work model. The work model may include registered workloads impulse workloads isochronous workloads pulsed workloads best effort workloads scheduled workloads etc. If a work model does not make sense for a resource or is incompatible with a particular resource the resource may not support the work model. Accordingly if the resource does not support a particular work model the work request may fail when the client is created at step . In a particular aspect other work models may be defined as necessary and new work models may be added in a backwards compatible fashion.

Moving to step the request may be processed atomically in two stages an update function is performed and a driver function is performed. Specifically at step an update function may be performed to aggregate the new request with any outstanding client requests in order to determine a new resource state. In other words the update function may be invoked by the resource to compute the resource state given concurrent client request of various work models. For example if one client requires at least 200 MIPS and another client requires at least 350 MIPS the update function may determine that the new resource state should be at least 350 MIPS in order to satisfy both clients. In another aspect the client requirements may be summed and 550 MIPS may be the new resource state. The update function maybe considered a plug in that is dynamic i.e. the update function may be overridden. For example the update function may be overridden in order to optimize power consumption without changing the clients of the resource. The update function may also be overridden in a bring up situation or a de bug situation to force a resource to an on state.

In a particular aspect the update function may use the resource and the requesting client as argument. Further the current active client requests and the pending client requests are available to the update function. The update function may return a desired state and the desired state as computed by the update function may not be supported by hardware HW . A driver function may quantize the desired state as needed.

Next at step a driver function may be performed. The driver function applies the new resource state calculated by the update function to the resource. Accordingly the driver function updates the managed resource and issues one or more requests to dependent resources. Target dependencies may be captured in the driver function. Further the driver function may differ on a per target basis without changing the client interface or the update function.

The driver function may utilize a resource and a desired state as arguments. Specifically the driver function may compute the desired state in MIPS and derive a frequency request to a CPU clock and a bandwidth BW request to a bus. The driver function may issue requests to dependencies as describe below. The dependencies may be a function of state. Further dependencies may be indexed from the dependency array that is part of the resource definition array. The driver function may also issue requests to hardware HW . However these requests may not be necessary if the resource is a logical resource. Further the driver function may return an actual state set associated with the resource and its dependencies.

At step the driver function issues a dependency request to any other dependent resources as necessary. For example if the resource is unable to apply the new state the resource may pass the client request to another resource connected thereto in the node associated with the resource if available. At step the resource may output one or more trigger events to an event handler. The trigger events may be a function of the resource state. The trigger events may be used to monitor the resource load or trigger other actions off resource state changes. For example the trigger events may be used to reduce a workload when a resource is oversubscribed or disable optional functions when a resource goes away.

Moving to step the resource may be utilized by the user until the need for the resource is finished by the user. At step when the user not longer needs the issue requests the user may transmit a request to destroy the client handle and the resource may destroy the client handle. The method may then end. It may be appreciated that users may cancel requests without destroying the client handle. This may allow a client handle to be reused.

As depicted in the user space of the NPA system may include a user space NPA client API connected to the NPA kernel driver . Moreover a user space NPA event API may be connected to the NPA kernel driver .

In a particular aspect any element in the kernel space may have full access to the NPA functionality. For example any element in the kernel space may issue requests and receive events to any resource. Further any element in the kernel space may create resources. In another aspect the user space NPA client API may be a duplicate of the kernel space NPA client API and the user space NPA event API may be a duplicate of the kernel space NPA event API . Elements in the user space may issued requests and receive events but only to explicitly exported resources. The elements in the user space however may not create resources.

In a particular aspect user space NPA client API may issue a request to the kernel space NPA client API through the NPA kernel driver . The kernel space NPA client API may pass the request to the kernel space NPA resource definition API . The kernel space NPA resource definition API may return an event to the kernel space NPA event API . Then the kernel space NPA event API may pass the event to the user space NPA event API through the NPA kernel driver .

The NPA kernel driver may be configured to operate with a specific operation system OS . Further the NPA kernel driver may provide a user space library that maps the NPA API onto the kernel driver model. The user space APIs that are on top of the NPA kernel driver may be configured to operate independently of the OS. A resource author may not have to write any kernel driver code to allow user space access to resources.

It may be appreciated that NPA resource graphs may be processor local i.e. each processor or address space may define its own resource graph. However there are some resources that may be shared across processors. These shared resources may be controlled on one processor e.g. a modem. Alternatively these shared resources may be controlled by a common resource manager e.g. a resource power manager RPM . Clients may not know if a resource is local or distributed.

In a particular aspect a distributed resource may be any resource that requires action by a resource on another processor in order to service a request. A remote resource may be a distributed resource that maintains a local state independent of the state of the resource on another processor. Further a proxy resource may be a distributed resource whose state tracks the state of the resource on another processor. A resource on another processor ROAP may be the resource to which the distributed resource is distributing access. The ROAP may not know that it is being accessed in a distributed fashion.

A distributed resource with local aggregation may be distributed resource that aggregates all requests locally and issues the aggregated request to the ROAP. A distributed resource with local aggregation only requires one client on the ROAP. A distributed resource with remote aggregation may be a distributed resource that forwards each request independently to the ROAP for aggregation on the other processor. A distributed resource with remote aggregation requires one client on the ROAP per local client. In a particular aspect the various distributed use cases may require that one or more of the following NPA functions be exported by the remote interface create client destroy client issue request register event resource available and query state.

Referring now to a method of using a remote resource with local aggregation is shown and is generally designated . As shown the method may begin at step with a request to create a client. The request to create a client may cause the remote resource to invoke an update function at step and a driver function at step .

At step a define node function may be invoked. This may cause the remote resource to invoke a driver function at step . When invoked the driver function may trigger a create client event at step . The create client event may be passed through a remote interface to a ROAP. The ROAP may return a handle to the remote resource at step . Thereafter at step the node definition may be completed. At step the remote resource may issue a work request on behalf of the client to the ROAP. At step the ROAP may perform the work until it is finished.

Moving to step the client may issue a work request to the remote resource. At step the remote resource may invoke an update function. Further at step the remote resource may invoke a driver function. Thereafter at step the remote resource may issue a work request to the ROAP. At step the ROAP may perform the work as needed and pass the work to the remote resource. At step the remote resource may transmit the work to the client.

At step the client may issue a request to destroy a client handle to the remote resource. The remote resource may invoke a destroy client handle function at step . Then at step the remote resource may output a destroy client event to the ROAP. The ROAP may return an event indicating that the client is destroyed at step to the remote resource. Then the remote resource may transmit an indication to the client indicating that the client handle is destroyed.

Referring to a method of using a proxy resource is shown and is generally designated . At step a user may issue a create event to the proxy resource. At step the proxy resource may invoke a create event function. At step the proxy resource may issue a create any change event to a ROAP through a remote interface. At step the ROAP issues a response that may be returned to the proxy resource via the remote interface. The proxy resource may send the response to the user at step .

At step the ROAP issues an event callback to the proxy resource via the remote interface. At step the proxy resource may invoke an npa assign resource state function in response to the event callback. Then at step the proxy resource may issue one or more trigger events to the user.

Moving to step the user may issue a destroy event to the proxy resource . At step the proxy resource may invoke a destroy event function that may trigger a destroy any change event at step that may be transmitted to the ROAP via the remote interface. The ROAP may transmit a response to the destroy any change event at step through the remote interface to the proxy resource. The proxy resource may pass the response to the user at step .

At step the ROAP may indicate that the restart is complete to the remote interface. The remote interface may then issue a reset resource to the distributed resource at step . Next at step the distributed resource may invoke a resync client function. Then at step the distributed resource may issue a create client request to the ROAP via the remote interface. At step the distributed resource may issue a work request to the ROAP via the remote interface. The method may then end.

In a particular aspect each resource may define whether it is to be accessed remotely. If a resource does not define that it may be accessed remotely remote clients and remote events may not be created. Further the remote command protocol may be transport agnostic. The same commands may be used with multiple inter processor transports even simultaneously. In particular the same command protocol may be used between user space and kernel space as well as for remote access.

It is to be understood that the method steps described herein need not necessarily be performed in the order as described. Further words such as thereafter then next etc. are not intended to limit the order of the steps. These words are simply used to guide the reader through the description of the method steps. Moreover the methods described herein are described as executable on a portable computing device PCD . The PCD may be a mobile telephone device a portable digital assistant device a smartbook computing device a netbook computing device a laptop computing device a desktop computing device or a combination thereof.

With the configuration described herein the present system and methods may create a common software solution for defining and making requests of dynamic resources. Further the system and method may natively handle concurrent requests and allow power optimization while meeting client quality of service QoS requirements with minimal client impact. Further the system and methods may allow software SW and hardware HW feedback of resource utilization for optimization purposes. Using the system and methods disclosed herein resource dependencies may be expressed as data and not as code. Further actions may be triggered off of resource state changes. Additionally the system and methods may substantially improve visibility into system definition and resource utilization and substantially improve build times and integration issues.

In a particular aspect resource names should be unique across the resource graph. The resources may be named using a filesystem metaphor with a top level such as bus . . . ahb axi . . . clk . . . tcxo cpu . . . core . . . cpu gfx . . . pwr . . . c1 c2 . . . etc. In another aspect client names may be used for information purposes and do not need to be unique. The following convention may be used for clients created by technologies system subsystem subsystem usecase e.g. modem cdma srch idle. Clients that are created by other resources may be named after the creating resource.

In another particular aspect the NPA structures may be dynamically created at runtime. A fixed size memory pool allocator may be used to prevent fragmentation minimize allocation costs. The pools may be initialized with user allocated memory. Further pools may be optionally extended via heap allocations but heap support is not required. Moreover memory that is added to pools may not be freed.

For debugging purposes all client work requests and resource state changes may be captured in a common log. Specifically clients and resources may be logged by name for improved readability. An active client list may provide insight into resource utilization. During debugging the update function for a resource may be dynamically overridden to force the resource into a known state. This may defer power management during an initial bring up phase and may isolate power management during bug hunts. In addition the active clients and resource state may be retrieved programmatically at runtime or via other utilities while halted.

In a particular aspect compile time coupling may be minimized. Client Resource binding may be accomplished via name lookup and lookup may be resolved at initialization time. Moreover clients may be dynamically allocated and there may not be a fixed enumeration based set of clients. Clients may be accessed via handles i.e. opaque structure pointers. Also there may not be any visibility into actual client data structure by clients.

The NPA system described herein may provide a mechanism for defining dependencies. Moreover the NPA system may allow arbitrary order of definition while sequencing initialization in dependency order. Subsystems may own their dependencies but they may also use NPA dependency management to sequence initialization without needing to adopt an NPA style interface. If adopted comprehensively subsystem startup may be done in an arbitrary order. This may substantially reduce start up maintenance and substantially increase robustness of and visibility into the startup sequence. Also this may be extended to automatically parallelize startup sequences on multi core processors.

In a particular aspect resources may explicitly list which other resources they depend upon. Clients and non resources may register for an event e.g. a callback signal when a required resource exists. Further definition and creation may be logged. Subsystems may define logical init resources to allow other subsystems to express initialization dependencies and allow the NPA system to properly sequence system startup. There is no requirement that a subsystem support an NPA style request interface. However subsystems may in turn leverage NPA dependency management and initialization sequencing for their own dependencies.

In one or more exemplary aspects the functions described may be implemented in hardware software firmware or any combination thereof. If implemented in software the functions may be stored on or transmitted over as one or more instructions or code on a computer program product such as a machine readable medium i.e. a computer readable medium. Computer readable media includes both computer storage media and communication media including any medium that facilitates transfer of a computer program from one place to another. A storage media may be any available media that may be accessed by a computer. By way of example and not limitation such computer readable media may comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that may be used to carry or store desired program code in the form of instructions or data structures and that may be accessed by a computer. Also any connection is properly termed a computer readable medium. For example if the software is transmitted from a website server or other remote source using a coaxial cable fiber optic cable twisted pair digital subscriber line DSL or wireless technologies such as infrared radio and microwave then the coaxial cable fiber optic cable twisted pair DSL or wireless technologies such as infrared radio and microwave are included in the definition of medium. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

Although selected aspects have been illustrated and described in detail it will be understood that various substitutions and alterations may be made therein without departing from the spirit and scope of the present invention as defined by the following claims.

