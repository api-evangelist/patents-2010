---

title: Processing packets using a virtualized descriptor queue
abstract: In a method for processing packets among at least a first computing device and a second computing device, in which the first computing device is configured to transmit and receive packets through a Network Interface Card (NIC), in the second computing device, descriptors of packets to be one of transmitted and received by the first computing device through a device descriptor queue are received and placed in a virtualized descriptor queue accessible by the second computing device. In addition, the packets associated with the descriptors placed in the virtualized descriptor queue are processed prior to one of transmission and receipt of the packets by the first computing device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08396953&OS=08396953&RS=08396953
owner: Hewlett-Packard Development Company, L.P.
number: 08396953
owner_city: Houston
owner_country: US
publication_date: 20100312
---
The present application related to and contains some common subject matter with commonly assigned and U.S. patent application Ser. No. 12 555 552 entitled Deep Packet Inspection DPI Using a DPI Core by Monchiero et al. filed on Sep. 8 2009 the disclosure of which is incorporated by reference in its entirety.

Data centers are increasingly deploying a growing range of bump in the wire services that perform packet processing on behalf of applications. Deep Packet Inspection DPI in particular is experiencing growing popularity for services such as intrusion detection content insertion performance monitoring traffic classification and flow management. Conventional packet processing services often have strict performance requirements and should be transparent to the operating system OS or hypervisor and application software at traffic end points. Those conventional packet processing services are typically implemented as custom hardware appliances which become aggregation points in the data center that require careful data center wide configuration to ensure that all appropriate network or storage traffic is routed correctly to the hardware appliances without first passing through untrusted or otherwise inappropriate devices. As aggregation points the hardware appliances often require special purpose acceleration hardware to handle relatively large data and packet rates. The resulting hardware appliances are typically expensive difficult to scale incrementally and have inflexible or hardwired functionality.

For simplicity and illustrative purposes the present invention is described by referring mainly to an example embodiment thereof. In the following description numerous specific details are set forth to provide a thorough understanding of the present invention. However it will be apparent to one of ordinary skill in the art that the present invention may be practiced without limitation to these specific details. In other instances well known methods and structures have not been described in detail to avoid unnecessarily obscuring the description of the embodiments.

Disclosed herein are a system and method for processing packets among at least a first computing device and a second computing device in which the first computing device is configured to transmit and receive packets through a Network Interface Card MC . In one example embodiment the first computing device and the second computing device comprise cores of a multicore processor. In other example embodiments as discussed below the first computing device and the second computing device comprise processors servers etc. In the system and method the second computing device receives descriptors of the packets to be one of transmitted and received by the first computing device through a device descriptor queue accessible by the first computing device. In addition the second computing device places the received descriptors in a virtualized descriptor queue that is accessible by the second computing device and processes the packets associated with the descriptors placed in the virtualized descriptor queue prior to one of transmission and receipt of the packets by the first computing device. The descriptors of the packets generally comprise pointers or referents to an address in a memory or buffer location that denotes the starting point and size of the memory or buffer location.

According to an example embodiment the device descriptor queue comprises a descriptor queue pair one descriptor queue for transmission of packets and one descriptor queue for receipt of packets. Likewise the virtualized descriptor queue comprises a virtualized descriptor queue pair one virtualized descriptor queue for transmission of packets and one virtualized descriptor queue for receipt of packets. For purposes of simplicity the first device descriptor queue pair and the virtualized descriptor queue pair are referenced herein as a device descriptor queue and a virtualized descriptor queue respectively. In this regard the device descriptor queue discussed herein may represent either or both of the transmission and receipt descriptor queues and the virtualized descriptor queue may represent either or both of the virtualized transmission and receipt descriptor queues.

In addition and as discussed in greater detail herein below from a perspective of an Operating System OS running on the first computing device it appears that the NIC is using the device descriptor queue to transmit and receive packets. However the NIC is configured to access the virtualized descriptor queue instead of the device descriptor queue to transmit and receive packets. The virtualized descriptor queue in the second computing device thus provides the illusion to the OS running on the first computing device that NIC is accessing the device descriptor queue.

Through implementation of the system and method disclosed herein packets may thus be intercepted by the second computing device such that the second computing device or other computing device may process the packets prior to transmission and or receipt of the packets by the first computing device. Thus for instance the second computing device may process the packets to determine whether to drop leave unchanged or modify the packets. In addition the interception and processing of the packets by the second computing device may be transparent to the first computing device.

With reference first to there is shown a simplified block diagram of a system which provides a platform upon which example embodiments disclosed herein may be implemented according to an embodiment. It should be clearly understood that the system may include additional components and that some of the components described herein may be removed and or modified without departing from a scope of the system . As such the system may include any number of computing devices CPUs and memories.

Generally speaking the system depicted in shows a number of various environments in which example embodiments of the invention may be employed. More particularly for instance the example embodiments of the invention may be employed in a single multi core processor multiple processors located in a single computing device multiple processors cores located in multiple computing devices etc.

As shown in the system includes a plurality of computing systems in the form of a plurality of compute blades . One or more of the compute blades may comprise multiple processors and or multiple cores. Each of the compute blades is positioned proximate to an electronics cabinet and is operatively connected logically or physically to a network . The system may also include additional compute blades positioned proximate to one or more additional electronics cabinets. The network may be an intranet the Internet a Wide Area Network WAN a Local Area Network LAN or some other network and suitable topology associated with the network. In some example embodiments operatively connected to the network are a plurality of devices including a cellular telephone a Personal Digital Assistant PDA a computer system and a television or monitor .

Turning now to there is shown a block diagram of a compute blade which provides a platform upon which example embodiments disclosed herein may be implemented according to an example. It should be clearly understood that the compute blade may include additional components and that some of the components described herein may be removed and or modified without departing from a scope of the compute blade

As shown therein the example compute blade includes a processor a main memory a platform hub controller and a NIC . Although the compute blade has been depicted as including a single processor the compute blade may include any number of processors . In addition although the processor has been depicted as including an Operating System OS Core and a Packet Processing PP Core the processor may include any number of cores configured to perform functions similar to or different from the OS core and the PP core .

The OS core may include an OS not shown residing therein which may comprise a suitable OS including the LINUX operating system Microsoft Corporation s WINDOWS operating system Sun Corporation s SOLARIS operating system the UNIX operating system or the like. The PP core may include a packet processing module not shown residing therein which may be configured to perform one or more packet processing operations on packets that are received and or transmitted by the OS core . By way of example the PP core may include a Deep Packet Inspection DPI module configured to process the packets for services such as intrusion detection content insertion performance monitoring traffic classification flow management etc. As another example the PP core may include one or more other types of modules configured to perform other functions with respect to the packets such as dropping leaving unchanged and modifying the packets based upon results of the packet processing. As discussed in greater detail here in below the PP core is configured to employ a mechanism based on the virtualization of the descriptor queues of the OS to intercept the packets for processing prior to transmission and receipt by the OS of the packets.

The main memory has been depicted as including an OS packet buffer and a PP memory . The processor also includes an integrated memory controller which operates as an interface to the main memory and is associated with a Direct Memory Access DMA module . The processor also includes a point to point high speed link QPI Control that connects to the Platform Hub Controller PHC . The QPI Control may comprise QPI available from Intel Corporation HYPERTRANSPORT available from the AMD Corporation or the like. The PHC hosts an Interrupt Controller IOAPIC an Input Output Memory Management Unit IOMMU and a peripheral component interconnect controller PCIE CTRL .

The OS core and the PP core are equipped with respective Memory Management Units MMUs . The MMUs generally provide virtual to physical translation logic. In addition the OS core and the PP core are equipped with respective Local Interrupt Controllers Local APICs . The Local APICs are operatively connected to an interrupt controller . The processor is further illustrated as including a cache that is operatively connected to the memory controller the OS Core and the PP Core .

In some example embodiments interfaces associated with each of the IOMMU interrupt controller and memory controller are made available only to the PP Core to allow the PP Core to modify the functionality of the IOMMU interrupt controller and memory controller . These interfaces need the physical interfaces or Application Programming Interfaces APIs . An example of a modified functionality includes the MMU directing updated descriptors to the PP module residing on the PP Core from the NIC and the interrupt controller interrupting the PP module to perform packet processing.

Examples of methods in which packets may be processed among at least one first computing device and a second computing device will now be described with respect to the following flow diagram of the method depicted in . It should be apparent to those of ordinary skill in the art that the method represents a generalized illustration and that other steps may be added or existing steps may be removed modified or rearranged without departing from the scope of the method .

The description of the method is made with reference to the system illustrated in and the compute blade illustrated in and thus makes reference to the elements cited therein. It should however be understood that the method is not limited to the elements set forth in the system and compute blade . Instead it should be understood that the method may be practiced by a system or compute blade having a different configuration than that set forth in the system and compute blade

The computing devices referenced with respect to the method may comprise cores of a common processor multiple processors cores of one or more compute blades etc. Thus in a first example the first computing device comprises the OS Core and the second computing device comprises the PP Core . In a second example the first computing device comprises a first processor in a compute blade and the second computing device comprises a second processor in the same compute blade. In a third example the first computing device comprises a processor in a first compute blade and the second computing device comprises a processor in a separate second compute blade. In the third example another compute blade for instance may operate as a NIC .

In each the examples above the first computing device is configured to transmit and or receive packets through a NIC and the second computing device is configured to perform packet processing operation on the packets prior to the transmission of the packets through the MC and or receipt of the packets by the first computing device. More particularly the first computing device is configured to update device descriptor queues transmit and receive descriptor queues of the first computing device and the second computing device is configured to update virtualized descriptor queues virtualized transmit and receive descriptor queues based upon the updated device descriptor queues prior to transmission and receipt of packets through the NIC . In addition the NIC is configured to access the virtualized descriptor queues during transmission and receipt of the packets as described in greater detail herein below.

At step the second computing device such as the PP Core receives descriptors of packets to be transmitted or received by the first computing device. The descriptors of packets are generally employed by the OS and the PP module to access the data packets stored in the OS packet buffer and or the PP memory . In one example the PP Core is configured to intercept the descriptors. In this example the interception of the descriptors by the PP Core may be transparent to the OS. In another example the OS is configured to inform the PP Core of the descriptors when the OS transmits or receives packets. Various manners in which the second computing device may receive the descriptors are described in greater detail herein below with respect to the following figures.

At step the second computing device places the received descriptors in a virtualized descriptor queue that is accessible by the second computing device. Generally speaking the virtualized descriptor queue of the second computing device is a virtualized version of a device descriptor queue of the OS. In addition the NIC is configured to use the virtualized descriptor queue instead of the device descriptor queue in transmitting and receiving packets. The second computing device instead of the OS is therefore responsible for synchronizing the virtualized descriptor queue with the descriptor queue of the first computing device.

At step the second computing device processes the packets associated with the descriptors placed in the virtualized descriptor queue prior to one of transmission and receipt of the packets by the first computing device. The second computing device may perform various types of processing operations on the packets such as intrusion detection malware detection performance monitoring traffic classification flow management content insertion modification etc.

At step the second computing device may determine whether the packets require modification. Step is considered optional because performance of step may be limited to those instances where the second computing device is configured to manipulate or cause the packets to be manipulated based upon the processing. In other instances such as when the second computing device is not configured to modify the packets which include instances where the second computing device merely tracks or classifies the packets the second computing device would not perform step .

In instances where the second computing device is configured to manipulate or cause the packets to be manipulated the second computing device may determine whether the packets are to be modified at step . If the second computing device determines that the packets require modification the second computing device modifies the packets as indicated at step . Thus for instance in the event that the second computing device determines that the packets contain malware the second computing device may modify the packets by dropping the packets such that the packets do not reach the first computing device. In another example the second computing device may modify the packets to remove detected malware.

In instances where the second computing device is not configured to manipulate the packets or when the second computing device determines that the packets do not require modification at step the second computing device communicates a signal to the NIC or the first computing device to copy the packets as indicated at step . Various examples of mechanisms through which the NIC or the first computing device are informed to copy the packets are described in greater detail herein below. In addition or alternatively the second computing device may send the instruction at step following modification of the packets at step .

Through implementation of the method the second computing device such as the PP Core may relatively easily inspect the packets referenced by the descriptors in the virtualized descriptor queue. In addition once the processing is completed the second computing device may safely move the descriptors to the device descriptor queue. The second computing device thus interposes between the first computing device and the NIC . This interposition may be transparent in terms of functionality from the perspective of both the OS running on the first computing device and the NIC .

Turning now to there are shown respective diagrams and of states of a device descriptor queue and a PP descriptor queue which is equivalent to the virtual descriptor queue discussed above prior to transmission of packets by an operating system OS according to an example. Thus for instance depict states of the device descriptor queue and the PP descriptor queue during performance of a packet transmission operation steps in . Although particular reference is made herein to the OS Core and the PP Core it should be understood that the operations discussed herein are applicable to other computing devices such as processors servers etc. In addition the device descriptor queue in may comprise a transmit descriptor queue of the first computing device and the PP descriptor queue may comprise a virtualized transmit descriptor queue of the second device.

As shown in the device descriptor queue includes a head pointer and a tail pointer and the PP descriptor queue includes a head pointer and a tail pointer . depicts the states of the device descriptor queue and the PP descriptor queue when the first computing device is not transmitting or receiving packets.

With reference now to the diagram in when an OS not shown residing in the first computing device transmits a descriptor the OS advances the tail pointer in the device descriptor queue . More particularly for instance at step the MMU of the OS core directs this write descriptor to a PP module not shown residing on the PP core . In addition the interrupt controller notifies the PP module that a packet is ready for processing via using an interrupt or by writing a memory mapped register. Upon notification the PP module copies the newly posted descriptors which are associated with packets stored in a packet buffer into the PP descriptor queue as noted at step .

In addition the PP module is configured to use the descriptor provided to it by the MMU of the first computing device to perform packet processing on the data packet as indicated at step . In some example embodiments the PP module uses a modified NIC device driver to retrieve the descriptor. Upon completion of the packet processing at step and in response to the packet being validated for transmission by the PP module diagram in a signal is sent to the NIC to transmit the data packet. In addition the NIC consumes the descriptors from the PP descriptor queue and marks the descriptors as completed and updates the head pointer as shown in the diagram . In some example embodiments the packet processing and the sending of the data packet to the NIC occur synchronously with the operations of the NIC and the OS.

As shown in the diagram in the PP module copies the completed descriptors to the device descriptor queue and updates the head pointer in the device descriptor queue . In addition the OS may clean the device descriptor queue .

Turning now to there are shown respective diagrams and of states of a device descriptor queue and a PP descriptor queue which is equivalent to the virtual descriptor queue discussed above prior to receipt of packets by an operating system OS according to an example. Thus for instance depict states of the device descriptor queue and the PP descriptor queue during performance of a packet receipt operation steps in . Although particular reference is made herein to the OS Core and the PP Core it should be understood that the operations discussed herein are applicable to other computing devices such as processors servers etc. In addition the device descriptor queue in may comprise a receipt descriptor queue of the first computing device and the PP descriptor queue may comprise a virtualized receipt descriptor queue of the second device.

As shown in the diagram in the OS makes descriptors available in the device descriptor queue by increasing the OS tail pointer which prepares empty buffers for packets that will arrive in the future. Further for instance the NIC transmits an updated descriptor referencing the location of the stored data packet to the MMU of the PP core . As used herein an update descriptor denotes a pointer or referent to an address in an OS buffer and a size of the OS buffer in which is stored a data packet. In some example embodiments the update descriptor describes the particular location of the data packet in the OS buffer. The MMU of the PP core detects the updated descriptor and directs it to the PP module. This updated descriptor may be stored in the PP memory for instance at steps and in . An interrupt is generated by the interrupt controller to allow the PP module to perform packet processing on the data packet referenced by the update descriptor step .

As shown in the diagram in the PP module updates the tail pointer in the PP descriptor queue corresponding to the update in the tail pointer of the device descriptor queue step . In addition with reference to the diagram in the NIC copies the received packets and descriptors and marks the descriptors in the PP descriptor queue as being completed. Moreover the NIC updates the head pointer in the PP descriptor queue step . The PP module is configured to use the descriptor provided to it by the MMU to perform packet processing on the data packet as indicated at step . Upon completion of the packet processing at step and in response to the packet being validated for receipt by the OS the updated descriptor is sent by the PP module to the OS requesting that the data packet be processed. In some example embodiments the interrupt may be an extra inter processor interrupt. As with the sending of the data packet the receiving of the data packet may occur synchronously with the operations of the NIC and OS .

As shown in the diagram in the PP module copies the completed descriptors to the device descriptor queue and updates the head pointer in the device descriptor queue . In addition the OS may consume the packets and may clean the device descriptor queue .

Some or all of the operations set forth in the figures may be contained as a utility program or subprogram in one or more computer readable storage mediums. In addition the operations may be embodied by computer programs which can exist in a variety of forms both active and inactive. For example they may exist as software program s comprised of program instructions in source code object code executable code or other formats. Any of the above may be embodied on a computer readable storage medium which include storage devices.

Exemplary computer readable storage devices include conventional computer system random access memory RAM read only memory ROM erasable programmable read only memory EPROM electrically erasable programmable read only memory EEPROM and magnetic or optical disks or tapes. Concrete examples of the foregoing include distribution of the programs on a compact disc read only memory CD ROM or via Internet download. It is therefore to be understood that any electronic device capable of executing the above described functions may perform those functions enumerated above.

The computing device includes one or more processors each of which includes one or more cores such as a central processing unit one or more display devices such as a monitor one or more network interfaces such as a Local Area Network LAN a wireless 802.11x LAN a 3G mobile WAN or a WiMax WAN and one or more computer readable mediums . Each of these components is operatively coupled to one or more buses . For example the bus may be an EISA a PCI a USB a FireWire a NuBus or a PDS.

The computer readable medium may be any suitable medium that participates in providing instructions to the processor s core s for execution. For example the computer readable medium can be non volatile media such as an optical or a magnetic disk volatile media such as memory and transmission media such as coaxial cables copper wire and fiber optics. Transmission method can also take the form of acoustic light or radio frequency waves.

The computer readable medium may also store an operating system such as Mac OS MS Windows Unix or Linux network applications and one or more packet processing application s . The operating system may be multi user multiprocessing multitasking multithreading real time and the like. The operating system may also perform basic tasks such as recognizing input from input devices such as a keyboard or a keypad sending output to the display keeping track of files and directories on the computer readable medium controlling peripheral devices such as disk drives printers image capture device and managing traffic on the one or more buses . The network applications includes various components for establishing and maintaining network connections such as software for implementing communication protocols including TCP IP HTTP Ethernet USB and FireWire.

The packet processing application s provides various software components for receiving descriptors processing packets associated with the descriptors updating descriptor queues and modifying packets as needed as described above. In certain embodiments some or all of the processes performed by the application may be integrated into the operating system . In certain embodiments the processes can be at least partially implemented in digital electronic circuitry or in computer hardware firmware software or in any combination thereof.

What have been described and illustrated herein are embodiments of the invention along with some of their variations. The terms descriptions and figures used herein are set forth by way of illustration only and are not meant as limitations. Those skilled in the art will recognize that many variations are possible within the spirit and scope of the invention wherein the invention is intended to be defined by the following claims and their equivalents in which all terms are mean in their broadest reasonable sense unless otherwise indicated.

