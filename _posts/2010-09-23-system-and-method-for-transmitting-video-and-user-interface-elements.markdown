---

title: System and method for transmitting video and user interface elements
abstract: A method for offloading decoding of encoded video data from a computer system executing a video player application playing the encoded video data to a remote display terminal still enables the video player application to overlay transparent or semi-transparent graphical elements, such elements, such as user interface controls, onto the video, despite not having access to decoded video data. A video decoding function call from the video player application is intercepted and replacement video data is provided to the video player application rather than a decoded version of the encoded video data. The video player application is thereby able to overlay graphical elements onto the replacement video data to create composite video from which the graphical elements are then able to be subsequently extracted and transmitted with the encoded video data to remote display terminal, which decodes the video data and overlays the graphical elements for display.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08724696&OS=08724696&RS=08724696
owner: VMware, Inc.
number: 08724696
owner_city: Palo Alto
owner_country: US
publication_date: 20100923
---
In network environments such as the Internet video data is typically transmitted by a web server or other server such as a streaming server upon request by a personal computer. The software component on the personal computer that often requests the video data is a video player e.g. Adobe Flash Player etc. embedded in a web browser e.g. Internet Explorer etc. and the web server typically transmits the video data to the video player in a known video encoding compressed format such as MPEG 4 or H.263. Once the video player receives the transmitted video data from the network it decodes e.g. decompresses the video data for rendering on the display of the personal computer. Often the video player leverages specialized graphics hardware on the personal computer such as a graphics processing unit GPU to accelerate the processing required to decode and render the video data on the display.

In many cases to enhance a user s viewing experience the video player additionally incorporates or composites a user interface UI of video player controls or other graphical elements as transparent or semi transparent overlays on top of the rendered video frames from the received video data. The video player performs such compositing after decoding the received video data for example by utilizing alpha blending techniques to combine pixel values of the UI elements with pixel values of a frame of video data e.g. upon their decoding in order to construct final composite video frames for display.

With the rise of technologies such as server based computing SBC and virtual desktop infrastructure VDI organizations are able to replace the traditional personal computers described above with instances of desktops that are hosted on remote desktop servers or virtual machines running thereon in a datacenter. A thin client application installed on a user s end terminal e.g. laptop PC thin client device etc. connects to a remote desktop server that transmits a graphical user interface GUI of an operating system session for rendering on the display of the end terminal. One approach to such a remote desktop server system is VMware View in which each user desktop operating system e.g. Windows is implemented in a separate virtual machine hosted on a server residing in an organization s datacenter. A remote display protocol such as Remote Desktop Protocol RDP or PC over IP PCoIP is implemented within the thin client application on the user s end terminal as well as within the corresponding virtual machine running the user s desktop e.g. as a service running in the operating system of the virtual machine etc. that enables the virtual machine to transmit the desktop s GUI display for rendering on the user s end terminal.

In such desktop virtualization environments a video player playing a video as previously discussed e.g. Adobe Flash Player in a web browser would be executing within a virtual machine hosted on a server in the organization s datacenter despite the video itself being ultimately displayed on the user s end terminal i.e. the video data must be additionally transmitted via the remote display protocol to the user s end terminal . However decoding of received encoded video data as is typically performed by the video player as well as the additional task of transmitting the decoded video data over the network from the virtual machine to the user s end terminal for display can consume significant network bandwidth and computing resources which could have otherwise been allocated to other virtual machines in the datacenter generally. In order to alleviate such network and computing resource pressure on a datacenter server the remote display protocol service running within a virtual machine may be configured to intercept the video player s requests e.g. to the operating system and or specialized graphics hardware of the server to decompress and display video data and in turn transmit the still encoded video data to the thin client application on the user s end terminal. Upon receipt of the still encoded video data the thin client application on the user s end terminal may be configured to decode the video data so that it can be rendered on the end terminal display. Furthermore the end terminal may include its own GPU to assist the thin client application in decoding the received video data.

Although the foregoing technique alleviates pressure on the network and computing resources of the virtual machine by passing responsibility for decoding video data from the video player running in the virtual machine to the thin client application on the user s end terminal it also prevents the video player from compositing transparent or semi transparent UI elements into the video data for example by using alpha blending techniques since such alpha blending requires the video player to have access to decoded video data.

One or more embodiments on the invention alleviate pressure on the network and computing resources of a computer system running a video player application such as a virtual machine instantiated on a server in a datacenter by passing responsibility for decoding video data to be played by the video player application to a separate remote display such as a thin client device configured to display the graphical user interface of the virtual machine. Such embodiments however still allow transparent or semi transparent graphical overlays such as video player controls to be overlaid by the video player onto the playing video i.e. such overlaying requiring decoded video even though the video is not decoded by the computer system running the video player application.

A method according to an embodiment offloads decoding of encoded video data from a computer system executing a video player application playing the encoded video data to a remote display terminal wherein the video player application is configured to decode the encoded video data and composite a graphical overlay onto the decoded video data and wherein pixels of the graphical overlay comprise alpha transparency values The method comprises intercepting a video decoding function call from the video player application requesting graphics hardware assistance from the computer system to decode the encoded video data providing replacement video data to the video player application rather than a decoded version of the encoded video data in response to the video decoding function call receiving composite video data from the video player application wherein the composite video data comprises the provided replacement video data and the graphical overlay extracting the graphical overlay from the received composite video data by subtracting the replacement video data from the composite video data and transmitting the encoded video data and the extracted graphical overlay to the remote display terminal wherein the remote display terminal decodes the encoded video data and composites the graphical overlay onto the decoded video data to generate a final composite video data for display.

A virtualization software layer also referred to hereinafter as hypervisor is installed on top of hardware platform . Hypervisor supports virtual machine execution space within which multiple virtual machines VMs may be concurrently instantiated and executed. In one embodiment each VM supports a desktop environment for a different user who is remotely connected from a user end terminal. For each of VMs hypervisor manages a corresponding virtual hardware platform i.e. virtual hardware platforms that includes emulated hardware implemented in software such as CPU GPU RAM hard drive NIC and video adapter also sometimes generally referred to herein as virtual devices .

Virtual hardware platform may function as an equivalent of a standard x86 hardware architecture such that any x86 supported operating system e.g. Microsoft Windows Linux Solaris x86 NetWare FreeBSD etc. may be installed as guest operating system OS to execute applications for an instantiated virtual machine e.g. VM . Applications that require rendering video on a display such as video player e.g. Adobe Flash Player in a web browser request graphics hardware assistance to decode encoded video data e.g. H.263 MPEG 4 etc. through a video rendering application programming interface API e.g. Microsoft DirectX Video Acceleration Windows Media Foundation DirectShow etc. which in turn leverages virtual GPU and ultimately physical GPU via communications with GPU driver in device driver layer to decode the video data. For example video rendering API may be implemented as a dynamically linked library provided as a component of guest OS . In the embodiment of an additional proxy video rendering API hereinafter referred to as proxy API is additionally installed or otherwise provided in guest OS e.g. again as a dynamically linked library in one embodiment to intercept calls made by video player to video rendering API and assess whether to forward such calls to video rendering API or take alternative action as further discussed herein. It should be recognized however that use of a proxy API as depicted in to perform certain actions described herein is merely exemplary and that alternative embodiments may utilize alternative techniques to provide the functionality of proxy API . For example in one alternative embodiment video rendering API may itself be modified extended configured or otherwise re implemented to provide the functionality of proxy API . Yet another alternative embodiment may utilize a special binary interception library to intercept function calls from video player and perform the functionality of proxy API e.g. Microsoft Detours etc. . Other embodiments may incorporate the functionality of proxy API in the device driver layer in a modified version of GPU driver or in any other appropriate device driver. Another embodiment may alternatively incorporate the functionality of proxy API into the virtual device level such as in virtual GPU . Yet other embodiments may incorporate the functionality of proxy API into a functional component or plug in to video player that is supported by video rendering API . For example Windows Media Foundation and DirectShow support such plug ins to video players.

Upon receiving decoded video data back from video rendering API or proxy API as the case may be in certain embodiments video player further composites a transparent or semi transparent UI interface e.g. video player controls other graphical elements etc. on top of the decoded video data by for example utilizing alpha blending techniques to combine pixel values of the UI interface with the received decoded pixel values of the video data and then transmits the composite video data to a video adapter driver in device driver layer for rendering on a display. Device driver layer further includes additional device drivers such as NIC driver that interacts with virtual devices in virtual hardware platform e.g. virtual NIC etc. as if such virtual devices were the actual physical devices of hardware platform . Hypervisor is generally responsible for taking requests from device drivers in device driver layer that are received by virtual devices in virtual platform and translating the requests into corresponding requests for real device drivers in a physical device driver layer of hypervisor that communicates with real devices in hardware platform . For example if an actual physical display e.g. monitor is coupled to remote desktop server the composite video data transmitted by video player to video adapter driver would be further transmitted to virtual video adapter which would further facilitate transmission of the video data to a physical video adapter in hardware platform that interacts with the monitor to render the video.

In the embodiment of however rather than utilizing a locally coupled physical display the video data as well as display data for the entire graphical user interface of guest OS is transmitted to a display of a remote user end terminal by a display protocol agent e.g. running as a service in guest OS in one embodiment . One example of such a display protocol agent is View Agent a component of the VMware View VDI solution offered by VMware Inc. of Palo Alto Calif. VMware . In one embodiment display protocol agent interacts with video adapter driver e.g. through an API to obtain video data and desktop GUI displays and subsequently transmits such data onto the network through NIC driver e.g. through virtual NIC and ultimately through physical NIC to the remote user end terminal. It should be recognized that in alternative embodiments display protocol agent may obtain video data and desktop GUI displays using alternative techniques other than interacting with video adapter driver . For example in an alternative embodiment display protocol agent may include a proxy library component similar to proxy API that intercepts calls from video player and any other components in VM that generate graphics for display to video adapter driver or may otherwise intercept and obtain such display data utilizing other techniques similar to those previously described as alternatives for proxy API e.g. re implemented video adapter driver video player plug ins special binary interception library etc. .

Those with ordinary skill in the art will recognize that the various terms layers and categorizations used to describe the virtualization components in may be referred to differently without departing from their functionality or the spirit of the invention. For example virtual hardware platforms may be considered to be part of virtual machine monitors VMM which implement the virtual system support needed to coordinate operations between hypervisor and corresponding VMs . Alternatively virtual hardware platforms may also be considered to be separate from VMMs and VMMs may be considered to be separate from hypervisor . One example of hypervisor that may be used in an embodiment is VMware vSphere Hypervisor which is included as a component of VMware s vSpheres solution commercially available from VMware. It should further be recognized that embodiments may be practiced in other virtualized computer systems such as for example hosted virtual machine systems where the hypervisor is implemented on top of an operating system e.g. VMware Workstation etc. .

Returning to in step video player transmits the composite video data to video adapter driver for display. In step display protocol agent requests or otherwise receives display data which includes the composite video data from video adapter driver and in step extracts the UI elements from the composite video data e.g. by subtracting the replacement video data from the composite image . In one embodiment display protocol agent also utilizes graphics hardware support e.g. GPU in performing such extraction. depicts an example of extracting user interface elements from composite video data for example as performed by display protocol agent in step . Replacement video data is generated or otherwise accessed e.g. retrieved from memory or storage by display protocol agent and subtracted from composite video data i.e. received by display protocol agent from video adapter driver in step thereby resulting in UI element .

Returning to in step display protocol agent then transmits the encoded video data e.g. MPEG 4 H.263 etc. received in step as well as the UI elements extracted in step to user end terminal . It should be recognized that the various components performing actions and receiving data and instructions in are merely exemplary and that alternative embodiments may distribute functionality and transmit data to different components. For example in one alternative embodiment proxy API may transmit the encoded video data in step to a video adapter driver that is modified or configured to receive such encoded video data rather than transmitting such encoded video data to display protocol agent . Similarly rather than receiving encoded video data from video server in step video player may alternatively play encoded video data stored as a local file.

Although one or more embodiments herein have been described in some detail for clarity of understanding it should be recognized that certain changes and modifications may be made consistent with the teachings herein. For example although depicts an embodiment in which display protocol agent executes within VM it should be recognized that alternative embodiments may implement display protocol agent in other components of remote desktop server for example as a driver within guest OS or within the virtual machine monitor or elsewhere in hypervisor . Similarly although depicts an embodiment in which display protocol agent and video adapter driver run in a virtual machine that communicates with a virtual video adapter in a hypervisor it should be recognized that these components may be deployed in any remote desktop server architecture including non virtual machine based computing architectures. Additionally it should be recognized that the functionality of video adapter driver as described herein e.g. transmitting composite video data to display protocol agent in step can be implemented in a separate extension or component to a pre existing or standard video adapter driver i.e. display protocol agent may communicate with such a separate extension to the video adapter driver rather than the pre existing video adapter driver itself .

It should further be recognized that certain functions that have been described as being performed within VM may be performed at user end terminal in alternative embodiments to the extent for example performance of such functions by user end terminal alleviates computing resource pressure on remote desktop server . For example in an alternative embodiment rather than extracting UI elements from composite replacement video data in step in VM the composite replacement video data e.g. checkerboard image composited with UI elements and the replacement video data itself e.g. checkerboard image etc. is transmitted to end user terminal along with the encoded video data in step . In such an embodiment the thin client application installed on user end terminal extracts the UI elements from the composite replacement video data by subtracting the replacement video data from the composite replacement video data and then composites the resulting extracted UI elements with decoded video data as in step of .

Additionally although the foregoing embodiments discuss composite video data in reference to actual video data that has been combined with transparent or semi transparent UI elements it should be recognized that the steps of compositing discussed herein may relate to any type of visual elements or overlays i.e. UI related or otherwise such as additional streaming data e.g. subtitles etc. and embedded displayed metadata e.g. markers frame numbers indices etc. and the like. It should further be recognized that although the foregoing embodiments herein have utilized a static play button displayed in a first video frame of a video as an example UI element any additional elements displayed over video data at any time to produce composite video data may be utilized consistent with the teachings herein whether such elements are static images that do not change frame to frame as they are overlaid on the video or whether such elements are dynamic such as video player controls that dynamically appear and correspondingly disappear when a user moves a mouse over the video display or otherwise touches the video display or other video clips that change between frames either synchronously or asynchronously with the video content.

Similarly although depict a certain embodiment of a checkerboard image as replacement video data it should be recognized that alternative embodiments may employ alternative and or additional techniques to generate known images or video data to serve as replacement video data that facilitates the extraction of UI elements that may be composited with such replacement video data. In certain embodiments in order to adequately extract the color values e.g. RGB or YUV values as well as transparency values alpha values of UI elements from composite replacement video data that includes both replacement video data e.g. known images and the UI elements themselves e.g. as in step it is insufficient to merely subtract or otherwise remove the color values of the pixels of the known image from the composite replacement video data since the values resulting from such subtraction or removal can represent any of a number of combinations of color and transparency values for each pixel of the UI elements. In order to obtain additional information to assist in the extraction of UI elements from composite replacement video data one embodiment utilizes a finely granular checkerboard image as the known image wherein each adjacent pixel in the known image is either white or black or any other different solid colors . Each known image for the previous and subsequent video frame is further alternated such that a previously black pixel in a known image for a current video frame is switched to a white pixel in the previous and next video frame. Such an embodiment enables the UI elements extraction process e.g. step to analyze and compare both adjacent pixels i.e. spatial analysis as well as the same pixel across time i.e. temporal analysis in order to determine or otherwise more accurately estimate color and transparency pixel values for the UI elements. Alternative embodiments may generate known images for replacement video data based only for spatial analysis or temporal analysis rather than both.

The various embodiments described herein may employ various computer implemented operations involving data stored in computer systems. For example these operations may require physical manipulation of physical quantities usually though not necessarily these quantities may take the form of electrical or magnetic signals where they or representations of them are capable of being stored transferred combined compared or otherwise manipulated. Further such manipulations are often referred to in terms such as producing identifying determining or comparing. Any operations described herein that form part of one or more embodiments of the invention may be useful machine operations. In addition one or more embodiments of the invention also relate to a device or an apparatus for performing these operations. The apparatus may be specially constructed for specific required purposes or it may be a general purpose computer selectively activated or configured by a computer program stored in the computer. In particular various general purpose machines may be used with computer programs written in accordance with the teachings herein or it may be more convenient to construct a more specialized apparatus to perform the required operations.

The various embodiments described herein may be practiced with other computer system configurations including hand held devices microprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers and the like. In general aspects of the one or more embodiments described herein may be implemented on one or more computers executing software instructions.

One or more embodiments of the present invention may be implemented as one or more computer programs or as one or more computer program modules embodied in one or more computer readable media. The term computer readable medium refers to any data storage device that can store data which can thereafter be input to a computer system computer readable media may be based on any existing or subsequently developed technology for embodying computer programs in a manner that enables them to be read by a computer. Examples of a computer readable medium include a hard drive network attached storage NAS read only memory random access memory e.g. a flash memory device a CD Compact Discs CD ROM a CD R or a CD RW a DVD Digital Versatile Disc a magnetic tape and other optical and non optical data storage devices. The computer readable medium can also be distributed over a network coupled computer system so that the computer readable code is stored and executed in a distributed fashion.

Although one or more embodiments of the present invention have been described in some detail for clarity of understanding it will be apparent that certain changes and modifications may be made within the scope of the claims. Accordingly the described embodiments are to be considered as illustrative and not restrictive and the scope of the claims is not to be limited to details given herein but may be modified within the scope and equivalents of the claims. In the claims elements and or steps do not imply any particular order of operation unless explicitly stated in the claims.

Unless the context clearly requires otherwise throughout the description and the claims the words comprise comprising and the like are to be construed in an inclusive sense as opposed to an exclusive or exhaustive sense that is to say in a sense of including but not limited to. Words using the singular or plural number also include the plural or singular number respectively. Additionally the words herein hereunder above below and words of similar import refer to this application as a whole and not to any particular portions of this application. When the word or is used in reference to a list of two or more items that word covers all of the following interpretations of the word any of the items in the list all of the items in the list and any combination of the items in the list.

In addition while described virtualization methods have generally assumed that virtual machines present interfaces consistent with a particular hardware system persons of ordinary skill in the art will recognize that the methods described may be used in conjunction with virtualizations that do not correspond directly to any particular hardware system. Virtualization systems in accordance with the various embodiments implemented as hosted embodiments non hosted embodiments or as embodiments that tend to blur distinctions between the two are all envisioned. Furthermore various virtualization operations may be wholly or partially implemented in hardware. For example a hardware implementation may employ a look up table for modification of storage access requests to secure non disk data.

Many variations modifications additions and improvements are possible regardless of the degree of virtualization. The virtualization software can therefore include components of a host console or guest operating system that performs virtualization functions. Plural instances may be provided for components operations or structures described herein as a single instance. Finally boundaries between various components operations and data stores are somewhat arbitrary and particular operations are illustrated in the context of specific illustrative configurations. Other allocations of functionality are envisioned and may fall within the scope of the invention s . In general structures and functionality presented as separate components in exemplary configurations may be implemented as a combined structure or component. Similarly structures and functionality presented as a single component may be implemented as separate components. These and other variations modifications additions and improvements may fall within the scope of the appended claims s .

