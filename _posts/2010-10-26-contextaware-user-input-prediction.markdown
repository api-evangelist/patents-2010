---

title: Context-aware user input prediction
abstract: Predicted input data is obtained by initially acquiring a set of operations that are performed on non-editable user interface elements of a user interface prior to a subsequent data input into an editable user interface of the user interface. The set of operations is then classified into a pattern class based on the operations in the set and the subsequent data input that corresponds to the set. Subsequently, a pattern type for the pattern class is generated that describes a relationship between the set of operations and the subsequent data input. Accordingly, when a new set of operations is received, input data is predicted for the new set by applying the pattern type to the new set.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08448089&OS=08448089&RS=08448089
owner: Microsoft Corporation
number: 08448089
owner_city: Redmond
owner_country: US
publication_date: 20101026
---
Users often input single line text into an editable user interface element of an application user interface. For example the editable user interface elements may include an address bar e.g. in a web browser application a file name field in a save as dialog box and other editable user interface elements that accept single line text. Over a time period a user may input text into many different user interface elements of a user interface or input multiple instances of the same data into the same user interface element of the user interface. Such text inputs may become time consuming or repetitive thereby degrading the computing experience of the user.

Described herein are techniques that perform context aware user input prediction to predict data that a user may desire to input into an editable user interface UI element of a UI. The UI may be presented by a graphical user interface GUI of an operating system. The techniques may predict an upcoming user input to the editable UI element based at least in part on user operations performed on the UI and previous user inputs to the UI. The predicted input data may be presented to the user and depending on user feedback regarding the predicted input data the predicted input data or a modified version of the predicted input data may further serve as training data for the refinement of the prediction techniques.

In at least one embodiment the predicted input data is obtained by acquiring a set of operations that a user performs on non editable elements of a user interface prior to a subsequent data input into an editable element of the user interface. The acquired operations and the associated subsequent data input are then classified into a pattern class. Subsequently a pattern type for the pattern class is generated that describes a relationship between the set of operations and the subsequent data input. Accordingly when a new set of operations is received corresponding input data is predicted for the new set of operations by applying the pattern type to the new set of operations.

This Summary is provided to introduce a selection of concepts in a simplified form that is further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

Techniques described herein may perform context aware data input prediction to predict single line textual data that may be input into a field of a user interface UI that is provided by a computing device. For example the single line textual data may be a uniform resource locator URL that is entered into an address bar of a web browser a name of a document that may be entered into a file name field of a save as dialog box and so forth. Single line textual data generally does not include natural language content such as a paragraph of text which are inherent in multi line text data.

The user may express the desire to enter textual data into the UI of the application by performing an action on an editable UI element in the UI. For example the user may click on an editable UI element implemented as a web browser address bar when the user desires to enter a URL. On the other hand the user generally interacts with the application via non editable UI elements of the user interface. For example a word processing application typically includes non editable UI elements in the form of a spell check button a copy button a paste button a format button and so forth.

In the actual program code of an application the UI elements of the application may be organized in a tree view hierarchic string structure from a main window to a smallest element e.g. a button a lowest level drop down menu item etc. . Accordingly any UI element in the application may be represented using a hierarchic string structure that denotes a path from the main window of the application to the associated UI element. Moreover all of the actions that are performed over each of the UI elements of the application may be included in a predefined set e.g. right click left click drag and or the like . As a result an operation as used herein may denote a combination of a hierarchic string structure of a UI element and a predefined action from the predefined set of actions that is performed on the UI element.

A user s single line input into an editable UI element may correlate with two types of information 1 a series of operations that the user performs on one or more non editable UI elements before the user enters the single line input and 2 prior input values that the user entered into the same editable UI element. Collectively the series of the operations that the user performs on one or more non editable UI elements immediately prior to a data input to an editable UI element may be referred to herein as a set of operations.

The techniques described herein may be implemented by an input prediction engine. The input prediction engine may predict the data input that the user desires to input into an editable UI element of an application. The input prediction engine may acquire and analyze the series of operations that a user performs on the one or more non editable UI elements. The prediction engine may then generate predicted input data for an editable UI element prior to the user entering a user input into the editable UI element. The predicted input data may be populated into the editable UI element or otherwise presented to the user via the UI. In some instances depending on whether the user accepts or modifies the predicted input data the predict data input or the user modification may further serve as training data for refining the prediction techniques of the input prediction engine.

In various embodiments the input prediction engine may be integrated into various applications to increase user efficiency during the use of the applications and increase user satisfaction with such applications. Various example implementations of the context aware data input prediction techniques are described below with reference to .

The computing device may include one or more processors and memory . The memory may store an operating system and applications . The operating system may provide an overall user interface UI that includes non editable UI elements e.g. buttons selectable objects etc. and editable UI elements e.g. search input fields text input fields etc. .

Further each of the applications may have non editable UI elements and editable UI elements. For example as shown in one of the applications may be a web browser . The web browser may include non editable elements in the form of menu items that are in a menu bar . The activation of a menu item in the menu bar may provide another non editable element in the form of a drop down menu list . In turn the drop down menu list may further include non editable elements in the form of drop down list items and so on and so forth. The web browser application may also include an editable UI element in the form of an address bar in which a user may type in universal resource locators URLs or internet protocol IP addresses. The applications may also include other programs that run on top of the operating system such as a word processing application a spread sheet application an email application and so forth.

The user may interact with the user interfaces of the applications via the data input devices e.g. a keyboard a mouse etc. and the data output devices e.g. a monitor a printer etc. of the computing device . The input prediction engine may have access to data regarding operations that are performed on each of the applications . In some embodiments the input prediction engine may be an integral part of at least one of the applications .

The memory may also store components of the input prediction engine . The components or modules may include routines programs instructions objects and or data structures that perform particular tasks or implement particular abstract data types. The components may include a capture module a classification module a pattern type generation module a prediction module a feedback module and a data cache .

In operation the capture module may acquire a set of operations that are performed on the one or more non editable UI elements of the UI. The performance of the set of operations may occur prior to an attempt to input data into an editable UI element of the UI. The set of operations may include multiple operations e.g. five operations six operations etc. . Following acquisition by the capture module the set of operations may be classified into a particular pattern class in a group of one or more pattern classes by the classification module . The classification may be performed by comparing the set of operations to one or more previous sets of operations . Subsequently the classification module may use the pattern type generation module to generate a pattern type for each of the one or more pattern classes. The prediction module may then apply the pattern type of the particular pattern class to the set of operations to predict an input data for the editable UI element of the UI. The feedback module may then receive user feedback data on the predicted input data and further refine the prediction accuracy of the input prediction engine . Thus with the introduction of this overview the various functions performed by the components of the input prediction engine are described in detail below.

The capture module may acquire the set of operations that are performed on the UI elements of the UI. As described above an operation may denote a combination of a hierarchic string structure of a UI element and a predefined action that is performed on the UI element. An example hierarchic string structure is discussed next and illustrated in .

Returning to the capture module may acquire the set of operations that relate to both non editable UI elements as well editable UI elements of the UI. With respect to the editable UI elements the capture module may further acquire the values that are inputted into the editable UI elements as part of the performed operations. In turn the capture module may cache the acquired data in the data cache .

In various embodiments when the capture module senses that a data input into an editable element is about to be performed by a user the capture module may feed a predetermined number of immediately preceding operations such as the set of operations to the classification module for analysis. For example the capture module may expect an input of data into the editable UI element when a user clicks on the address bar of a web browser.

The classification module may receive sets from the capture module . As described above each set of operations is a series of operations that are preformed on one or more non editable UI elements of a UI prior to a data input to an editable UI element of the UI. Since the classification module is receiving the sets from the capture module the capture module may set the number of operations in each set that is received by the classification module e.g. five operations six operations etc. .

The classification module may use an enhanced Weighted Edit Distance WED method to classify the sets of operations received from the capture module into one or more existing pattern classes. In various embodiments the classification module may compare a new set that it receives such as the set of operations with one or more previously encountered sets of operations and classify the new set of operations into an existing pattern class of one of the sets of operations that has a minimum edit distance to the new set. However if no existing pattern class is available e.g. when the classification module is used for the first time the classification module may create a new pattern class for the new set of operations .

In at least one implementation assuming there are two sets of operations X and Y in which both of these sets operations include a predetermined number of operation steps such as N 5 operations steps and in which X A A . . . A Y B B . . . B then the function performed by the classification module may be illustrated in the context of X and Y.

Initially the classification module may use a biggest weighted common sequence method to determine an alignment between the X and Y sets of operations. In the implementation of this method the classification module may use the operation type of the operations in the sets e.g. right click left click drag etc. to make an alignment between the two sets.

For example given that X A B A C A Y B A A B A where A B and C denote different user operation types respectively and the match weight are a 0.1 a 0.2 a 0.3 a 0.4 a 0.5 then the biggest weighted common subsequence may be ABA and the biggest weighted sum may be 0.5 0.4 0.3 1.2 In at least one embodiments the classification module may use the following algorithm to derive this sum assuming that the W i j denote the biggest weighted sum between X 1 . . . i and Y 1 . . . j 

Subsequently the classification module may attempt to obtain a predetermined number of candidate weighted common subsequences in terms of the weighted sum and sum up the edit distance between the corresponding operations in the X and Y sets to derive the edit distance between the X and Y sets. For example if the common a candidate weighted common subsequence is ABA then the similarity that is the edit distance ED between the X and Y sets may be derived as ED 5 5 ED 2 4 ED 1 3 .

In other words the ED between the X and Y sets may be derived from the corresponding operations in the X and Y sets. Thus in order to calculate the ED between any two sets the classification module may also have the ability to calculate the edit distance between any two arbitrary operations such as each pair of corresponding operations in the X and Y sets.

Each operation may be represented by a hierarchic structure such as the hierarchic structure described in and each level in a particular hierarchic structure may be expressed as a string. This is because as stated above an operation may include a combination of 1 a hierarchic string structure of a UI element and 2 a predefined action that is performed on the UI element. Thus by leveraging such characteristics the classification module may use an edit distance to measure similarity between any two arbitrary operations. More specifically in order to obtain the edit distance between two operations the classification module may actually calculate the edit distance between the two UI elements that are operated on by the two operations as two operations with different operation types may be deemed as completely different and unrelated to each other.

In order to calculate the edit distance between two UI elements the classification module may initially calculate the edit distances of the corresponding strings in those UI elements. Subsequently the classification module may sum up the edit distances of the corresponding strings to derive the edit stance between the two UI elements. In turn the edit distance between the two UI elements represents the edit distance of the two corresponding operations.

Thus as described above the classification module may derive an edit distance between any two sets of operations by calculating the edit distances of corresponding operations in the two sets and summing such edit distances to obtain an overall edit distance. Further as described above the classification module may compare a new set of operations that it encounters with one or more previously encountered sets and classify the new set of operations into an existing pattern class of a particular previously encountered set of operations that has a minimum edit distance to the new set of operations.

In some scenarios it may be possible that the new set of operations may be classified into multiple pattern classes. For example such a scenario may occur if the user has previously performed two sets of operations that are identical but ultimately inputted two different values into the same editable UI element of an application such as one of the applications . In such scenarios the interaction of the classification module with the pattern type generation module and the prediction module as described below may ultimately produce two different predicted input data values.

The classification module may leverage the pattern type generation module to generate a pattern type for each pattern class. A pattern type may describe the relationship between the input values to the editable UI elements that correspond to sets of operations in a pattern class on the one hand and related context information on the other hand. The related context information may include 1 the operations in the sets that have been classified into the particular pattern class and 2 the input values that have been previously inputted into the editable UI elements associated with those sets of operations. In other words the pattern type of a pattern class is a unique signature that identifies the pattern class and no pattern class may share a pattern type with another pattern class.

The pattern type of each pattern class may be represented by a unique regular expression. Thus the pattern type generation module may perform pattern analysis on the sets of operations and associated input values in each pattern class to find a suitable regular expression to illustrate the relationship between inputs values and corresponding context information in the class. In various embodiments the pattern type generation module may initially define a set of parameters for the operations within the pattern class that are contributors to the corresponding user inputs. The parameters may be based on strings in the hierarchic structures of the UI elements corresponding to operations that are different in different sets of operations. For example if a user is clicking on a particular file object e.g. test.doc the control type of a UI element may be file object and the control value of the UI element may be test.doc . Thus the parameter may be the control value test.doc if the user did not clicked the particular file object in other sets of operations.

Subsequently the pattern type generation module may define a plurality of rules such as linear combination rules as potential regular expression representations of the set of parameters. The pattern type generation module may then find the most fitting regular expression from the set of regular expressions based on sets of operations and input values in the pattern class using one or more predefined rules. In at least one embodiment the one or more predefined rules may describe a relationship among multiple data inputs to the same editable UI element. For example the predefined rules may stipulate that the input values to a particular editable UI element are identical. In another example the predefined rules may stipulate that the input values to the particular editable UI element following a particular trend such as XYZ XYZ and XYZ . In this way the pattern type generation module may derive a regular expression that represents each pattern class.

The prediction module may derive predicted input data for a new set of operations by applying a particular pattern type to the new set to calculate the predicted input data . The prediction module may calculate the predicted input data when the capture module senses that the user is about to enter a data input into an editable UI element of an application such as one of the applications . Accordingly when the new set of operations immediately preceding the imminent data input is classified into an existing pattern class the prediction module may then apply the particular pattern type of the existing pattern to the new set to obtain the predicted input data . In turn as further described below the predicted input data that is calculated by the prediction module may be provided to the user as the possible data input that the user is about to entered into the editable UI element.

The prediction module may calculate predicted input data by applying a regular expression that represents a pattern type of an existing pattern class to defined parameters in the new set of operations. In various embodiments the pattern type generation module may defined the parameters for the new set of operations in the same manner as parameters are defined for a pattern class as described above. For example given that three parameters are defined for the new set X X and X the classification module may classify the new set of operations into an existing pattern class that has the regular expression input value X X . In such an example the classification module may calculate the predicted input data by following this regular expression and set X X as the value of the predicted input data . It will be appreciated that in scenarios in which the new set of operations is classified into multiple existing pattern classes the predicted input data may include multiple predicted input values.

The feedback module may present the predicted input data to a user. In some embodiments the feedback module may automatically populate the predicted input data to an editable UI element to which the user is about to enter data. In other embodiments in which the predicted input data includes multiple predicted input values the feedback module may provide a drop down menu in relation to the editable UI element so that the user may select the desired predicted input data.

The feedback module may further store data into the data cache to refine the prediction ability of the input prediction engine . In various embodiments if the user accepts predicted input data for the new set of operations that is presented the feedback module may add the predicted input data and the new set of operations into the corresponding pattern class as a training example. Alternatively if the user edits or rewrites the predicted value in the predicted input data into a corrected input value that is identical to a value derived with the application of another existing pattern type to the new set of operations the feedback module may add the predicted input data with the corrected input value and the new set of operations into the class that corresponds to the other existing pattern type as a training example. However if the user edits or rewrites the predicted value in the predicted input data into a corrected input value that cannot be derived with the application of any existing pattern type to the new set of operations then the feedback module may cause the classification module to create a new pattern class for the new set of operations and the predicted input data with the corrected input value.

Accordingly since all training data in the form of operations may be acquired online by the input prediction engine the engine may not employ offline training data to learn operation input patterns. Instead the input prediction engine relies on incremental learning via the feedback module .

The data cache may store the metadata related to the acquired operations generated pattern classes generated pattern types values of the predicted input data as well as corrected input values of the predicted input data. The data cache may also store any additional data used by the input prediction engine such as various additional intermediate data produced during the derivation of the predicted input data .

The context aware data input prediction techniques performed by the various modules of the input prediction engine may be described as follows assuming L sets of operations belong to M pattern types already exist 

Accordingly as time goes by the input prediction engine may accumulate an increasing number of sets of operations and pattern classes and the accuracy of the input value predictions by the input prediction engine may be continuously improved. Moreover it will be appreciated that a result of the design of the input prediction engine is that any two sets of operations may be successfully classified into the same pattern class only when 1 the two sets of operations are initially classified into the same pattern class based on edit distance and 2 the relationships between the input value and corresponding parameters of the operations in each set may be described using the same regular expression.

At block the capture module may store the operation into the data cache . Subsequently the process may loop back to block so that the capture module may capture another operation.

However if at decision block the capture module determines that the acquired operation is an operation on an editable UI element yes at decision block the process may proceed to block . For example a user may have clicked on the editable UI element in preparation for entry of data into the editable UI element.

At block the classification module may obtain a new set of operations that is a plurality of immediately preceding operations that were performed on the non editable UI elements. The new set of operations may include a predetermined number of operations e.g. four operations seven operations etc. . For example the new set may be the set of operations . In various embodiments the capture module may provide the data on the new set of operations to the classification module from the data cache .

At block the classification module may classify the new set of operations into a pattern class. In various embodiments the classification module may use an enhanced Weighted Edit Distance WED method to classify the new set of operations into a particular pattern class that includes a corresponding existing set of operations . The particular pattern class may be selected based on the fact that the corresponding existing set of operations has the greatest similarity that is the shortest edit distance to the new set of operations. The particular pattern class may also have a corresponding pattern type that is generated by the pattern type generation module . The pattern type may be expressed as a regular expression that is based on the defined parameters of the corresponding existing set of operations .

At block the prediction module may apply the corresponding pattern type of the particular pattern class to the new set of operations to obtain predicted input data . In various embodiments the prediction module may calculate the predicted input data such as the predicted input data by applying the regular expression that represents the pattern type to defined parameters in the new set of operations.

At block the feedback module may present the predicted input data to the user. In various embodiments the feedback module may populate the editable UI element with the predicted input data .

At decision block the feedback module may ascertain whether the user has determined that a value in the predicted input data is acceptable. If the feedback module determines that the predicted input data is accepted yes at decision block the process may proceed to block . At block the feedback module may add the predicted input data and a set of operations on which the predicted input data is generated into a corresponding pattern class as new training data. In various embodiments the predicted input data may be generated from the set of operations via the process described in .

However if the feedback module determines that the predicted input data is not accepted no at decision block the process may proceed to decision block . In various embodiments the feedback module may determine that the predicted input data is not accepted when the user edits or rewrites the value of the predicted input data into a corrected input value.

At decision block the feedback module may determine whether a modified input data that includes the corrected input value is related to another pattern class. In various embodiments the modified input data is related to another existing set of operations when the corrected input value is capable of being derived with the use of an existing pattern type of the other pattern class on the new set of operations. Thus if the feedback module determines that the modified input data is related to another set of operations yes at decision block the process may proceed to block .

At block the feedback module may add the modified input data that includes the corrected input value and the new set of operations into the other existing pattern class. However if the feedback module determines that the modified input data is not related to another existing set of operations no at decision block the process may proceed to block .

At block the feedback module may cause the classification module to create a new pattern class for the new set of operations and the modified input data that includes the corrected input value. The pattern type generation module may also generate a corresponding type for the new pattern class based on the operations in the new set of operations and the modified input data.

In at least one configuration computing device typically includes at least one processing unit and system memory . Depending on the exact configuration and type of computing device system memory may be volatile such as RAM non volatile such as ROM flash memory etc. or some combination thereof. System memory may include an operating system one or more program modules and may include program data . The operating system includes a component based framework that supports components including properties and events objects inheritance polymorphism reflection and provides an object oriented component based application programming interface API . The computing device is of a very basic configuration demarcated by a dashed line . Again a terminal may have fewer components but may interact with a computing device that may have such a basic configuration.

Computing device may have additional features or functionality. For example computing device may also include additional data storage devices removable and or non removable such as for example magnetic disks optical disks or tape. Such additional storage is illustrated in by removable storage and non removable storage . Computer storage media may include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. System memory removable storage and non removable storage are all examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by Computing device . Any such computer storage media may be part of device . Computing device may also have input device s such as keyboard mouse pen voice input device touch input device etc. Output device s such as a display speakers printer etc. may also be included.

Computing device may also contain communication connections that allow the device to communicate with other computing devices such as over a network. These networks may include wired networks as well as wireless networks. Communication connections are some examples of communication media. Communication media may typically be embodied by computer readable instructions data structures program modules etc.

It is appreciated that the illustrated computing device is only one example of a suitable device and is not intended to suggest any limitation as to the scope of use or functionality of the various embodiments described. Other well known computing devices systems environments and or configurations that may be suitable for use with the embodiments include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor base systems set top boxes game consoles programmable consumer electronics network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and or the like.

The use of the input prediction engine to predict input data during the use of various applications may improve user efficiency and increase user satisfaction with the user interfaces of the applications.

In closing although the various embodiments have been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended representations is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as exemplary forms of implementing the claimed subject matter.

