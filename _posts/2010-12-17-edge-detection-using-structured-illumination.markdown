---

title: Edge detection using structured illumination
abstract: A machine vision inspection system (MVIS) and a related light stripe edge feature location method are disclosed. The MVIS comprises a control system, a light stripe projection system, an imaging system, and a user interface. In a region of interest including the edge feature, the light stripe projection system focuses a light stripe transverse to the edge direction and across the edge feature, such that the light stripe has a changing stripe intensity profile along the light stripe. The imaging system acquires an image of the light stripe and the control system analyzes the image to determine the location of the edge feature based on a changing light intensity profile along the stripe. The method may be implemented in an edge detection video tool. The method may be advantageous for inspecting highly textured, beveled, chamfered, rounded or damaged edges, for example.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08773526&OS=08773526&RS=08773526
owner: Mitutoyo Corporation
number: 08773526
owner_city: Kawasaki-shi
owner_country: JP
publication_date: 20101217
---
The invention relates generally to machine vision inspection systems and more particularly to methods of edge detection on workpiece surfaces.

Precision machine vision inspection systems or vision systems for short can be utilized to obtain precise dimensional measurements of inspected objects and to inspect various other object characteristics. Such systems may include a computer a camera and optical system and a precision stage that is movable in multiple directions so as to allow the camera to scan the features of a workpiece that is being inspected. One exemplary prior art system that is commercially available is the QUICK VISION series of PC based vision systems and QVPAK software available from Mitutoyo America Corporation MAC located in Aurora Ill. The features and operation of the QUICK VISION series of vision systems and the QVPAK software are generally described for example in the 3 published January 2003 and the 3 published September 1996 each of which is hereby incorporated by reference in their entirety. This product as exemplified by the QV 302 Pro Model for example is able to use a microscope type optical system to provide images of a workpiece at various magnifications and move the stage as necessary to traverse the workpiece surface beyond the limits of any single video image. A single video image typically encompasses only a portion of the workpiece being observed or inspected given the desired magnification measurement resolution and physical size limitations of such systems.

Machine vision inspection systems generally utilize automated video inspection. U.S. Pat. No. 6 542 180 the 180 patent teaches various aspects of such automated video inspection and is incorporated herein by reference in its entirety. As taught in the 180 patent automated video inspection metrology instruments generally have a programming capability that allows an automatic inspection event sequence to be defined by the user for each particular workpiece configuration. This can be implemented by text based programming for example or through a recording mode which progressively learns the inspection event sequence by storing a sequence of machine control instructions corresponding to a sequence of inspection operations performed by a user with the aid of a graphical user interface or through a combination of both methods. Such a recording mode is often referred to as learn mode or training mode. Once the inspection event sequence is defined in learn mode such a sequence can then be used to automatically acquire and additionally analyze or inspect images of a workpiece during run mode. 

The machine control instructions including the specific inspection event sequence i.e. how to acquire each image and how to analyze inspect each acquired image are generally stored as a part program or workpiece program that is specific to the particular workpiece configuration. For example a part program defines how to acquire each image such as how to position the camera relative to the workpiece at what lighting level at what magnification level etc. Further the part program defines how to analyze inspect an acquired image for example by using one or more video tools such as edge boundary detection video tools.

Video tools or tools for short and other graphical user interface features may be used manually to accomplish manual inspection and or machine control operations in manual mode . Their set up parameters and operation can also be recorded during learn mode in order to create automatic inspection programs or part programs . Video tools may include for example edge boundary detection tools autofocus tools shape or pattern matching tools dimension measuring tools and the like.

Various methods are known for locating edge features in workpiece images. For example various algorithms are known which apply brightness gradient operators to images which include an edge feature to determine its location e.g. a Canny Edge detector or a differential edge detector. Such edge detection algorithms may be included in the machine vision inspection systems which also use carefully configured illumination and or special image processing techniques to enhance brightness gradients or otherwise improve edge location accuracy and repeatability. Nevertheless edge features located near a highly textured surface or located at one edge of a surface feature such as a chamfer have proven difficult for unskilled machine vision users to inspect reliably when using known techniques for edge detection. An improved edge detection system and or method which may be used to reliably inspect such edges would be desirable.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to identify key features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

A system and method for determining a location of an edge feature of a workpiece using a machine vision inspection system is provided. Determining the location of an edge feature in an image may also be referred to herein as edge detection. Edge detection often refers to edge discovery or identification of edges in the field of image processing and may or may not encompass determining their precise location. However it should be appreciated that the systems and methods disclosed herein are particularly valuable for precisely determining the location of an edge in various embodiments e.g. with sub pixel accuracy in some embodiments or applications regardless of whether they are characterized as edge detection operations or edge location operations.

The machine vision inspection system comprises a control system a light stripe projection system an imaging system and a user interface usable to define a sequence of operations usable to determine the location of the edge feature. The method in various embodiments may generally comprise steps including A positioning the edge feature in a field of view of a machine vision inspection system B focusing the imaging system at an imaging focus plane at a height corresponding to the edge feature and C determining the edge feature location wherein determining the edge feature location comprises C1 operating the light stripe projection system to project at least one light stripe oriented to extend across the edge feature and focused such that a height change across the edge feature causes at least one of a changing width and a changing intensity along the light stripe C2 operating the imaging system to acquire an image of the at least one light stripe at the imaging focus plane and C3 analyzing the acquired image of the at least one light stripe in the region of interest and determining the location of at least a portion of the edge feature based on a changing characteristic along the light stripe that corresponds to at least one of the changing width e.g. a width characterizing a transverse light intensity profile and the changing intensity e.g. a peak intensity of a transverse light intensity profile or other representative intensity along the light stripe.

The method in some particular embodiments may comprise steps including a positioning the edge feature in a field of view of a machine vision inspection system b focusing the imaging system at an imaging focus plane at a height corresponding to the edge feature c defining a region of interest including the edge feature using the user interface d determining an edge direction corresponding to a direction along the edge feature in the region of interest and e determining the edge feature location based on operations comprising e1 operating the light stripe projection system to project at least one light stripe oriented transverse to the determined edge direction in the region of interest and extending across the edge feature e2 operating the light stripe projection system to focus the at least one light stripe at a light stripe focus plane at a height corresponding to the edge feature such that a height change across the edge feature causes a changing stripe intensity profile e.g. a changing transverse intensity profile along the light stripe e3 operating the imaging system to acquire an image of the at least one light stripe at the imaging focus plane and e4 analyzing the acquired image of the at least one light stripe in the region of interest and determining the location of at least a portion of the edge feature based on a changing characteristic of the changing light stripe intensity profile along the at least one light stripe. In some embodiments the user interface may comprise an edge detection video tool comprising a region of interest indicator and the step c may comprise defining the region of interest by displaying and configuring the region of interest indicator. In some embodiments the user interface may comprise an edge detection video tool and the step d may comprise determining the edge direction by aligning a displayed feature of the video tool to correspond to the direction along the edge feature in the region of interest. In some embodiments in step e1 orienting the at least one light stripe transverse to the determined edge direction may comprise automatically orienting the at least one light stripe relative to the alignment of the displayed feature of the video tool. In some embodiments the at least one light stripe may be oriented nominally perpendicular to the displayed feature of the video tool and a scan line of the video tool may be aligned with the at least one light stripe. In some embodiments the edge detection video tool may include a region of interest indicator and the displayed feature that is aligned to correspond to the direction along the edge feature may comprise at least a portion of the region of interest indicator. In some embodiments the step e2 may comprise adjusting the brightness of the at least one light stripe such that the brightness of the light stripe is within a detection range of the imaging system at least in the vicinity of the edge feature.

In some embodiments the method may further comprise performing the step e for at least a first set of light stripes arranged laterally along the edge direction in the region of interest at a first time. In some embodiments the method may further comprise repeating the step e for at least a second set of light stripes arranged laterally along the edge direction in the region of interest at least a second time wherein the second set of light stripes includes light stripes arranged laterally along the edge direction at different locations than light stripes in the first set of light stripes.

In some embodiments the light stripe focus plane may correspond to a plane of the workpiece surface in the region of interest.

In some embodiments the edge feature may be curved the edge direction may follow a corresponding curve and the first set of light stripes may comprise light stripes which are not parallel to each other.

In some embodiments the workpiece may be a representative workpiece and the method may be performed in association with a learn mode of operation of the machine vision inspection system which is used for creating a part program to be used for determining the location of an edge feature on a workpiece that is similar to the representative workpiece.

In some embodiments the method may be performed in association with a run mode of operation of the machine vision inspection system by executing a part program that includes determining the location of an edge feature on a workpiece that is similar to a representative workpiece used to create a part program.

A machine vision inspection system is provided which is operable to determine a location of an edge feature of a workpiece. The machine vision inspection system in various embodiments may comprise a control system a light stripe projection system an imaging system operable to focus at an imaging focus plane at a height corresponding to an edge feature in a field of view of the machine vision inspection system and a user interface operable to define a region of interest including the edge feature and determine an edge direction corresponding to a direction along the edge feature in the region of interest. The light stripe projection system may include an adjustable element that can be adjusted such that a projected light stripe is oriented transverse to the determined edge direction in the region of interest and extended across the edge feature and is configurable to project the stripe such that it is focused such that a workpiece surface height change across the edge feature causes a changing stripe intensity profile along the light stripe. The control system may be configured to perform operations comprising a adjusting the adjustable element to orient the light stripe transverse to the determined edge direction in the region of interest and extending across the edge feature 9b operating the light stripe projection system to project a light stripe at a light stripe focus plane at a height adjusted to correspond to the edge feature c operating the imaging system to acquire an image of the light stripe at the imaging focus plane at a height corresponding to an edge feature and d analyzing the acquired image of the light stripe in the region of interest and determining the location of at least a portion of the edge feature based on a changing characteristic of the changing light stripe intensity profile along the light stripe. In some embodiments the machine vision inspection system may comprise an edge detection video tool including a graphical user interface element which is user configurable to set parameters that define the region of interest including the edge feature and the edge direction corresponding to a direction along the edge feature in the region of interest. In some embodiments the control system may be configured to perform at least the operation a based on the parameters set using the edge detection video tool.

In some embodiments the adjustable element of the light stripe projection system may comprise a controllable spatial light modulator. In some embodiments the controllable spatial light modulator may comprise one of a controllable LCD array and a controllable micro minor array.

In some embodiments the light stripe projection system is configured to use an objective lens of the imaging system to project the light stripe.

In some embodiments the imaging system may comprise a configurable pupil filter that is located between an objective lens and a camera system of the imaging system at a Fourier plane of the objective lens and that includes a pupil shape that is configurable such that it is aligned with the light stripe which spatially filters light from the light stripe. In some embodiments the pupil filter is provided by a spatial light modulator that modifies at least one of an amplitude and a phase of a light which forms the light stripe or b light which is reflected from the workpiece to form the image of the light stripe.

A method for determining a location of an edge feature of a workpiece using a machine vision inspection system is provided. The machine vision inspection system may comprise a control system a light stripe projection system an imaging system and a user interface usable to define a sequence of operations usable to determine the location of the edge feature. The method may comprise a positioning the edge feature in a field of view of a machine vision inspection system b focusing the imaging system at an imaging focus plane at a height corresponding to the edge feature and c determining the edge feature location. Determining the edge feature location may comprise c1 operating the light stripe projection system to project at least one light stripe oriented to extend across the edge feature and focused such that a height change across the edge feature causes at least one of a changing width and a changing intensity along the light stripe c2 operating the imaging system to acquire an image of the at least one light stripe at the imaging focus plane and c3 analyzing the acquired image of the at least one light stripe and determining the location of at least a portion of the edge feature based on a changing characteristic along the light stripe that corresponds to at least one of the changing width and the changing intensity along the light stripe. In some embodiments c1 may comprise adjusting the brightness of the at least one light stripe such that the brightness of the light stripe is within a detection range of the imaging system at least in the vicinity of the edge feature.

It should be appreciated that the edge detection operations outlined above which use focused structured illumination are sensitive to surface height changes across an edge regardless of other characteristics of the edge that would otherwise make precise edge location difficult when using the conventional edge detection methods. For example when performing edge detection using conventional illumination e.g. illumination which is approximately uniformly applied to the field of view surfaces which have textures or additional features such as a chamfer may diminish the accuracy and reliability of conventional edge detection and or location operations through unwanted specular reflections or the like which disturb the brightness gradient across the edge arising from conventional illumination which is the basis for conventional edge detection and location methods. Therefore the various embodiments outlined herein are aimed at determining an edge location using at least one light stripe which has an intensity which varies based on surface height changes across an edge to provide edge detection and location operations which may robustly provide sub pixel edge location accuracy despite various surface textures and surface features near an edge feature which would be disruptive to conventional edge detection methods.

The vision measuring machine includes a moveable workpiece stage and an optical imaging system which may include a zoom lens or interchangeable lenses. The zoom lens or interchangeable lenses generally provide various magnifications for the images provided by the optical imaging system . The machine vision inspection system is generally comparable to the QUICK VISION series of vision systems and the QVPAK software discussed above and similar state of the art commercially available precision machine vision inspection systems. The machine vision inspection system is also described in commonly assigned U.S. Pat. Nos. 7 454 053 7 324 682 U.S. Patent Application Publication No. 2010 0158343 and U.S. patent application Ser. No. 12 343 383 filed Dec. 23 2008 and Ser. No. 12 608 943 filed Oct. 29 2009 which are each incorporated herein by reference in their entireties.

The machine vision inspection system may be configured for imaging and measuring workpiece features including determining edge locations as described below with respect to various embodiments.

In various exemplary embodiments the optical assembly portion is movable in the vertical Z axis direction relative to the workpiece stage using a controllable motor that drives an actuator a connecting cable or the like to move the optical assembly portion along the Z axis to change the focus of the image of the workpiece captured by the camera system . The term Z axis as used herein refers to the axis that is intended to be used for focusing the image obtained by the optical assembly portion . The controllable motor when used is connected to the input output interface via a signal line .

As shown in in various exemplary embodiments the control system portion includes a controller the input output interface a memory a workpiece program generator and executor and a power supply portion . Each of these components as well as the additional components described below may be interconnected by one or more data control buses and or application programming interfaces or by direct connections between the various elements.

The input output interface includes an imaging control interface a motion control interface a lighting control interface and a lens control interface . The motion control interface may include a position control element and a speed acceleration control element . However it should be appreciated that in various exemplary embodiments such elements may be merged and or indistinguishable. The lighting control interface includes lighting control elements which control for example the selection power on off switch and strobe pulse timing if applicable for the various corresponding light sources of the machine vision inspection system . The lighting control interface also includes a lighting control element which controls the selection power and on off switch for the focused structured light source .

The memory includes an image file memory portion a workpiece program memory portion that may include one or more part programs or the like and a video tool portion . The video tool portion includes tool portion and other similar tool portions e.g. as well as an edge detection video tool which determine the GUI image processing operation etc. for each of the corresponding tools. The video tool portion also includes a region of interest generator that supports automatic semi automatic and or manual operations that define various ROIs that are operable in various video tools included in the video tool portion . It should be appreciated that the edge detection video tool may be configured in one mode to perform conventional edge detection operations using the light source to provide source light and may be additionally configured to perform edge detection operations in another mode using the focused structured light source to provide source light . The latter mode will be described in further detail in later figures.

In general the memory portion stores data usable to operate the vision system components portion to capture or acquire an image of the workpiece such that the acquired image of the workpiece has desired image characteristics. The memory portion may also store inspection result data may further store data usable to operate the machine vision inspection system to perform various inspection and measurement operations on the acquired images e.g. implemented in part as video tools either manually or automatically and to output the results through the input output interface . The memory portion may also contain data defining a graphical user interface operable through the input output interface .

The signal lines or busses and of the stage light the coaxial light the focused structured light source and the surface light respectively are all connected to the input output interface . The signal line from the camera system and the signal line from the controllable motor are connected to the input output interface . In addition to carrying image data the signal line may carry a signal from the controller that initiates image acquisition.

One or more display devices e.g. the display of and one or more input devices e.g. the joystick keyboard and mouse of can also be connected to the input output interface . The display devices and input devices can be used to display a user interface which may include various graphical user interface GUI features that are usable to perform inspection operations and or to create and or modify part programs to view the images captured by the camera system and or to directly control the vision system components portion .

In various exemplary embodiments when a user utilizes the machine vision inspection system to create a part program for the workpiece the user generates part program instructions either by explicitly coding the instructions automatically semi automatically or manually using a workpiece programming language and or by generating the instructions by operating the machine vision inspection system in a learn mode to provide a desired image acquisition training sequence. For example a training sequence may comprise positioning a workpiece feature of a representative workpiece in the field of view FOV setting light levels focusing or autofocusing acquiring an image and providing an inspection training sequence applied to the image e.g. using video tools . The learn mode operates such that the sequence s are captured or recorded and converted to corresponding part program instructions. These instructions when the part program is executed will cause the machine vision inspection system to reproduce the trained image acquisition and inspection operations to automatically inspect a workpiece or workpieces matching the representative workpiece used when creating the part program.

These analysis and inspection methods that are used to inspect features in a workpiece image are typically embodied in various video tools included in the video tool portion of the memory . Many known video tools or tools for short are included in commercially available machine vision inspection systems such as the QUICK VISION series of vision systems and the associated QVPAK software discussed above.

In the embodiment shown in the focused structured light source comprises a light stripe projection system. In operation the light source illuminates the controllable pattern generator CPG indicated by arrows such that the spatial light modulator arrangement emits patterned source light from the controllable pattern generator CPG to the lens which outputs the source light such that it creates a focused image of the light pattern produced at the controllable pattern generator CPG in the field of view at the workpiece as shown by representative imaging light rays in . In the illustrated embodiment the source light is reflected by the beam splitter to the objective lens . The objective lens focuses the source light i.e. a pattern output by the controllable pattern generator CPG on the workpiece .

In various embodiments the controllable pattern generator CPG may comprise a controllable LCD array as shown in or a controllable micro mirror array or the like. In particular in various embodiments the focused image of the light pattern comprises a light stripe or a plurality of light stripes and the controllable pattern generator CPG is operable to control the orientation of the light stripes in the field of view and their location as described further below. The light in the field of view is reflected as workpiece light and the workpiece light used for imaging passes through the interchangeable objective lens the optional pupil filter if present and the turret lens assembly and is imaged by the camera system . The optional pupil filter will be described in further detail with respect to .

It will be appreciated that the specific features and elements outlined above for the optical paths of the light stripe projection system are exemplary only and not limiting. Numerous alternatives for illumination and or imaging in a manner compatible with the methods disclosed herein will be apparent to one of ordinary skill in the art.

As shown in the edge feature is nominally linear. It should be appreciated that the location of an edge feature of a workpiece may also be determined for portions of an edge feature which is curved. Multiple light stripes along multiple non parallel scan lines may be provided in the region of interest along an edge feature. For example the edge detection video tool may be an arc tool or a circle tool for determining edge locations along an edge feature with an arc shape or a circular shape. In general the operations of the edge detection video tool may be adapted to any desired shape of an edge feature according to principles outlined and claimed herein. It should be appreciated that in the case of non parallel scan lines the optional pupil filter may not be utilized or may be set up to display a series of differently aligned configurations requiring capture and analysis of a series of images of stripes since each pupil filter configuration is capable of effectively filtering along a single stripe direction at a time. The scan lines SL are shown as being parallel linear. However in general the edge detection video tool may define and use scan lines which are not linear and not parallel.

In various embodiments the focused structured light source of comprises a light stripe projection system. The focused structured light source is operated to project at least one light stripe e.g. a light stripe LS shown in oriented transverse to the edge direction ED in the region of interest ROI shown in and extending across the edge feature . The light stripe LS may be oriented based on parameters set using the edge detection video tool e.g. as outlined above . In general the light stripe LS may be aligned with scan line direction SLD or vice versa and in the embodiment shown in B and C the scan line SL of the edge detection video tool is aligned with a light stripe such that the scan line defines and or provides image brightness data along the light stripe. It should be appreciated that the scan line direction SLD does not necessarily correspond to a row or column of pixels in the camera system . The focused structured light source is operated in response to the lighting control element in accordance with parameters defined by the edge detection video tool to focus the light stripe LS at a height corresponding to the edge feature i.e. the light stripe focus plane LSFP in such that a height change across the edge feature produces a changing stripe intensity profile along the light stripe as described below.

The imaging system is operated to acquire an image of the light stripe LS at an imaging focus plane IFP shown in . In the embodiment shown in the imaging focus plane IFP is at the same height as the surface SurfA. The acquired image of the light stripe LS is analyzed in the region of interest ROI and the location of at least a portion of the edge feature is determined based on a changing characteristic of the changing light stripe intensity profile shown in along the light stripe LS. For example shows two exemplary stripe intensity profiles transverse intensity profiles at two respective locations along the light stripe. It will be understood that the stripe intensity profile IPA results from a stripe portion that is well focused at the height of surface SurfA and has a relatively large peak intensity and a narrow width. The stripe intensity profile IPB results from a stripe portion that is poorly focused at the height of surface SurfB and has a relatively low peak intensity and a large width.

Thus generally the light stripe LS has a width and or a nominal stripe brightness or intensity at a given point along the stripe which vary with surface height due to defocus. For example in the embodiment shown in and along the surface SurfA the light stripe LS is focused at the light stripe focus plane LSFP which is coincident with the surface height of the surface SurfA. In general the light stripe focus plane LSFP may correspond to a plane of the workpiece surface in the region of interest ROI e.g. the surface SurfA or the surface SurfB . As shown in because the light stripe LS is focused at the surface SurfA the light stripe LS has a width WA along the surface SurfA which is at a minimum and an intensity along the surface SurfA which is at a maximum. In some embodiments such as that shown in the light stripe focus plane LSFP is coincident with the imaging focus plane IFP. Along the surface SurfB which has a surface height deviation Dev from the laser stripe focus plane the light stripe LS has a larger width WB due to defocus. Therefore for a given point along the light stripe LS along the surface SurfB there is a lower image intensity. Along the chamfer C the light stripe LS slowly becomes wider due to increasing defocus along the scan line direction SLD. Proximate to the location of the edge feature between the chamfer C and the surface SurfB the changing intensity of the light stripe LS shows a sharp gradient along the scan line direction as illustrated in . Using conventional machine vision inspection system illumination with conventional edge detection image processing operations may be problematic in the presence of the chamfer C or other edge imperfections or in embodiments where the surface SurfA is highly textured. Specular reflections and surface reflectivity variations may interfere with the reliability and accuracy of edge detection image processing operations. This may cause the edge detection video tool to fail. However using the light stripe LS in accordance with the operations described herein provides a means for determining the location of an edge feature which is robust to surface features such as a chamfer bevel rounding edge imperfections highly textured surfaces and or surface reflectivity variations.

It should be appreciated that the light stripe LS may be analyzed according to conventional edge detection image processing operations and therefore the operations for determining a location of an edge feature of a workpiece may be conveniently implemented in a machine vision inspection system. Such a machine vision inspection system comprises a control system e.g. the control system portion a light stripe projection system e.g. the focused structured light source an imaging system e.g. the imaging system operable to focus at an imaging focus plane e.g. the imaging focal plane IFP at a height corresponding to an edge feature e.g. the edge feature in a field of view of the machine vision inspection system e.g. the field of view and a user interface operable to define a region of interest e.g. the region of interest ROI including an edge feature and to determine an edge direction e.g. the edge direction ED corresponding to a direction along the edge feature in the region of interest. The light stripe projection system includes an adjustable element e.g. the spatial light modulator arrangement that can be adjusted such that a projected light stripe is oriented transverse to the determined edge direction in the region of interest and extending across the edge feature. The light stripe projection system is configurable to project the light stripe such that it is focused such that a workpiece surface height change across the edge feature causes a changing stripe intensity profile along the light stripe e.g. as represented by the changing intensity and or the changing width along the chamfer C and between the chamfer C and the surface SurfB . The control system is configured to perform various operations. The operations comprise adjusting the adjustable element to orient the light stripe transverse to the determined edge direction in the region of interest and extending across the edge feature operating the light stripe projection system to project a light stripe e.g. the light stripe LS at a light stripe focus plane e.g. the light stripe focus plane LSFP at a height adjusted to correspond to the edge feature operating the imaging system to acquire an image of the light stripe at the imaging focus plane at a height corresponding to an edge feature and analyzing the acquired image of the light stripe in the region of interest and determining the location of at least a portion of the edge feature based on a changing characteristic of the changing light stripe intensity profile along the light stripe as outlined above.

In one embodiment the method shown in may be implemented at least in part by a user by selecting and operating the edge detection video tool shown in and or as described with reference to the operations described in A B and C. In other embodiments the method may be implemented using various known tools and or programming operations.

The routine starts and at a block the edge feature is positioned in a field of view of a machine vision inspection system. For example in the edge feature is positioned in the field of view of the machine vision inspection system .

At a block the imaging system is focused at an imaging focus plane at a height corresponding to the edge feature. For example the imaging system of is focused at an imaging focus plane IFP at a height corresponding to the edge feature in .

At a block a region of interest is defined including the edge feature using the user interface. For example the region of interest ROI is defined including the edge feature by configuring the region of interest indicator ROIin in the user interface shown in .

At a block an edge direction is determined corresponding to a direction along the edge feature in the region of interest. For example the edge direction ED corresponding to a direction along the edge feature in the region of interest ROI in may be determined for purposes of machine control and or analysis by aligning a displayed feature of a video tool with the direction along the edge feature. In some embodiments the edge detection video tool includes a region of interest indicator and the displayed feature that is aligned to correspond to the direction along the edge feature comprises at least a portion of the region of interest indicator. It should be appreciated that in some embodiments the steps outlined at the blocks and may be performed automatically based on image processing performed by the machine vision inspection system or in various alternative embodiments the steps outlined at the blocks and may be performed manually. In yet other embodiments and or specific applications the steps outlined at the blocks and need not be performed explicitly and therefore alternative embodiments of the routine may omit the blocks and .

At the blocks and the edge feature location is determined. At a block the light stripe projection system is operated to project at least one light stripe oriented transverse to the determined edge direction in the region of interest and extending across the edge feature. In some embodiments the user interface comprises an edge detection video tool comprising a region of interest indicator and defining a region of interest comprises defining the region of interest by displaying and configuring the region of interest indicator. For example as outlined in the edge detection video tool comprises a region of interest indicator ROIin which may be used to define the region of interest ROI. In some embodiments the user interface comprises an edge detection video tool and determining an edge direction comprises aligning a displayed feature of the video tool to correspond to the direction along the edge feature in the region of interest. In some embodiments orienting the at least one light stripe transverse to the determined edge direction comprises automatically orienting the at least one light stripe relative to the alignment of the displayed feature of the video tool e.g. the edge detection video tool outlined in . In some embodiments the at least one light stripe is nominally perpendicular to the displayed feature of the video tool and a scan line of the video tool is aligned with the at least one light stripe.

At a block the light stripe projection system is operated to focus the at least one light stripe at a light stripe focus plane at a height corresponding to the edge feature such that a height change across the edge feature causes a changing stripe intensity profile along the light stripe. In some embodiments the light stripe focus plane is coincident with the imaging focus plane. For example in the configuration shown in the light stripe focus plane LSFP is coincident with the imaging focus plane IFP. This may be particularly advantageous when the imaging objective lens is used to focus the light stripes in the field of view as shown in . In some embodiments the light stripe focus plane corresponds to a plane of the workpiece surface in the region of interest. For example in the configuration shown in the light stripe plane LSFP corresponds to the plane of the workpiece surface SurfA and in particular the light stripe focus plane LSFP is coincident with the workpiece surface SurfA.

At a block the imaging system is operated to acquire an image of the at least one light stripe at the imaging focus plane.

At a block the acquired image of the at least one light stripe in the region of interest is analyzed and the location of at least a portion of the edge feature is determined based on a changing characteristic of the changing light stripe intensity profile along the at least one light stripe and the routine ends. In some embodiments the steps at blocks and may be performed for at least a first set of light stripes arranged laterally along the edge direction in the region of interest at a first time. Additionally in some embodiments the steps at blocks and may be repeated for at least a second set of light stripes arranged laterally along the edge direction in the region of interest at a second time wherein the second set of light stripes includes light stripes arranged laterally along the edge direction at different locations than light stripes in the first set of light stripes. This allows for a higher density of sampling of edge feature locations along the edge direction while avoiding crosstalk between adjacent light stripes. In some embodiments the edge feature is curved and the edge direction follows a corresponding curve and the first set of light stripes comprises light stripes which are not parallel to each other. The routine may be adapted to various shapes of edge features for example an arc or a circle where light stripes that are oriented transverse to the edge direction at various locations are not parallel to one another. Also similarly oriented light stripes can be analyzed in separate sets each set filtered by a specific optional pupil filter configuration that is best matched to the dominant direction in the set.

In some embodiments the workpiece is a representative workpiece and the method is performed in association with a learn mode of operation of the machine vision inspection system which is used for creating a part program to be used for determining the location of an edge feature on a workpiece that is similar to the representative workpiece. In other embodiments the method is performed in association with a run mode of operation of the machine vision inspection system by executing a part program that includes determining the location of an edge feature on a workpiece that is similar to a representative workpiece used to create a part program.

It should be appreciated that the workpiece may be illuminated with conventional illumination for defining the region of interest at the block and determining the edge direction at the block . At the blocks and the conventional illumination may be omitted such that the workpiece is illuminated with only the at least one light stripe.

It should be appreciated that the systems and methods disclosed herein provide a more reliable and accurate edge detection method than previously practiced edge detection methods in the presence of problematic surface textures and features adjacent to an edge feature. While various preferred and exemplary embodiments of the invention have been illustrated and described it will be appreciated that various changes can be made therein without departing from the spirit and scope of the invention.

