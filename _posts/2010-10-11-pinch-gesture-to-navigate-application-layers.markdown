---

title: Pinch gesture to navigate application layers
abstract: Using pinch gestures to navigate user interface layers of an application. In particular embodiments, a pinch gesture may cause an application program to close a currently running user interface layer of the application, or return to a previously viewed user interface layer. In some implementations, a pinch gesture may cause an application to close.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08856688&OS=08856688&RS=08856688
owner: Facebook, Inc.
number: 08856688
owner_city: Menlo Park
owner_country: US
publication_date: 20101011
---
The present disclosure generally relates to touch based use interfaces such as touch screen displays and track pads and gesture based navigation and handling of applications on a computing device.

A touch screen is an electronic visual display device that detects the presence and location of user touch inputs. Similarly a touchpad is an input device including a surface that detects a touch based inputs of users. So called dual touch or multi touch displays or track pads refer to devices that can identify the presence location and movement of more than one touch input such as two or three finger touches. More recently multi touch user interfaces have become widely adopted with a diverse array of functions responding to touch gestures.

Gesture recognition in connection with single dual or multi touch devices refers to the interpretation of touch inputs such as position and movement into gestures. A recognized gesture may cause an in focus application to perform one or more operations such as scrolling rotating zooming or selecting an object. Dual and multi touch devices with the ability to recognize two or more touch positions allow for recognition of an increasing number of more complex gestures.

The present invention provides methods apparatuses and systems directed to using pinch gestures to navigate user interface layers of an application. In particular embodiments a pinch gesture may cause an application program to close a currently running user interface layer of the application or return to a previously viewed user interface layer. In some implementations a pinch gesture may cause an application to close. These and other features aspects and advantages of the disclosure are described in more detail below in the detailed description and in conjunction with the following figures.

The present disclosure is now described in detail with reference to a few embodiments thereof as illustrated in the accompanying drawings. In the following description numerous specific details are set forth in order to provide a thorough understanding of the present disclosure. However the present disclosure may be practiced without some or all of these specific details. In other instances well known process steps and or structures have not been described in detail in order not to unnecessarily obscure the present disclosure. In addition while the disclosure is described in conjunction with the particular embodiments it should be understood that this description is not intended to limit the disclosure to the described embodiments. To the contrary the description is intended to cover alternatives modifications and equivalents as may be included within the spirit and scope of the disclosure as defined by the appended claims.

User interface layers of application programs are generally arranged in a hierarchy such as a hierarchical tree structure. A root node of the tree structure may correspond to a home user interface layer or start screen of an application including icons buttons pull down menus hypertext links or other controls that allow users to navigate to child user interface layers. Child user interface layers may include icons or buttons that allow users to navigate back to parent user interface layers by touching an icon or button. Many such buttons are displayed on the top of a menu bar but there are a lot of exceptions.

Touchpads and touchscreens are pointing devices including a specialized surface that can translate the motion and position of user touches to a relative position on screen. Multipoint sensing devices including touchpads and touchscreens can distinguish more than one object finger simultaneously or near simultaneously. In most cases multipoint sensing devices and systems that utilize such devices monitor a surface for a touch or near touch event. When such an event occurs they can determine the distinct area s of contact and identify the nature of the events via their geometric features and geometric arrangement. Once identified the touch or near touch events are monitored to determine if they correspond to various gestures events.

A gesture event may be defined as a stylized interaction with the sensing surface mapped to one or more specific computing operations. Gesture events may be made through various hand and more particularly digit motions taps pressures dwells and or the like. Because the surface is based on multipoint technology complex gesturing may be performed with any number of digits or other contact portions of the hand. A gesture language or map may include for example a set of instructions that recognizes the occurrence of gesture events e.g. motions and informs one or more software agents of the gesture events and or what action s to take in response to the gesture events.

Multitouch devices can be embodied in various forms including but not limited to standard sized touch pads large extended palm pads touch screens touch sensitive housings etc. Furthermore multipoint sensing devices can be configured for many form factors including but not limited to tablet computers netbooks laptop computers desktop computers as well as handheld computing devices such as media players PDAs cell phones smartphones and the like. The multipoint sensing devices may also be found on dedicated input devices such as touch screen monitors keyboards navigation pads tablets mice and the like.

Generally multitouch devices include software hardware and or firmware that can recognize certain touch inputs and generate events. These events are processed by handler functions that register or subscribe as listeners to such events. Gesture libraries refer to code libraries that can interpret the touch events to recognize gestures such as taps scrolls swipes drags and pinch zoom. A pinch zoom event is generally recognized when a user places two fingers on a touchpad and then moves the fingers apart out pinch. or together in pinch . Generally a handler function can listen for in pinch or out pinch events and respond by scaling zooming a displayed object based on the distance and movements of the two fingers. Each time the scale gesture is detected on an image and therefore on the container object a gesture scale event is fired. This is detected by the gesture listener placed on the container object which calls a gesture scaled handler function. Each time this occurs a value for the change in scale is taken from the event and used to incrementally change the scale value of the target in this case the container .

When a user launches the application the application may present the home user interface layer or root layer as illustrated . The user may access user interface elements to navigate to various additional user interface layers supported by the application. For example to navigate to a sublayer from the home layer a user may touch an icon such as Photos icon or a button such as Logout button which is on top of the menu bar . If the user touches Photos icon the current screen which displays the home layer will change to . The layer depicted in includes a list of photo albums and home button . The home button is linked to the home layer if a user touches home button the current screen will display the home layer . If the user chooses one album by touching a picture or an arrow the screen will convert to the contents of the album as depicted in with a title of Picture represents album name . As shows the resulting layer includes a back button named Photos which points to left side. The button name Photos is the same as the previous layer s title. A user can use this button to go back to the Photos layer and then the screen will change back to the . On the other hand if a user touches one of the pictures shown among the contents such as the picture the screen will display another layer such as that depicted in . The layer illustrated in has a similar button called Mobile Uploads which when activated leads the user back to the Mobile Upload layer. However if the user touches the middle of the displayed picture the application hides all menus and displays the final content of this leaf layer as shown in an image . Since the content of this leaf layer includes a scalable object here an image the application allows the user to scale the image by zooming in or out by using out pinch zoom in or in pinch zoom out .

From the foregoing example if a user wants to go to a specific sublayer he may touch an icon or a button that links to the expected sublayer. On the other hand to go back to the parent layer he may select back button . In addition to navigate back to the home layer he may select the home button . While the foregoing allows user to navigate within an application it tails to fully take advantage of multitouch capabilities.

Implementations of the invention allow users to use pinch gestures to navigate between user interface layers of an application. In particular embodiments a pinch gesture such as an in pinch gesture may cause an application program to close a currently running user interface layer of the application or return to a previously visited user interface layer. In addition to or in lieu of using the home button or back button described above a user may use in pinch gestures to navigate to upper layers of the hierarchy or use out pinch gestures to navigate back to previous layers without having to identify the position of these interface buttons.

As discussed above the application may be configured to register a handler function that responds to pinch events. In a particular implementation the handler function for pinch events can be configured to respond to in pinch and out pinch events in a manner that provides for interface navigation functionality as opposed to scaling or zooming a scalable object such as text images or other media objects.

Pinch events may also be processed and utilized in other ways. In one implementation the application may store a navigation history that tracks the layers to which the user navigates. illustrates a flow chart of a method directed to processing an out pinch event . As described below an out pinch gesture may cause the application to implement go back functionality. To implement this functionality the handler function may consider two attributes for example whether an object of the current layer has a scalable object and if a view history exists . If the current layer includes a scalable object the application may perform a zoom in function in response to the out pinch gesture . Otherwise there are two options the application may navigate to the home screen layer or it may navigate back to the previously opened layer . If there is a view history the previously navigated layer will replace current layer. This form of navigation represents similar functionality to web browsers. If no navigation history exists home layer will replace current layer since it is the root layer of application hierarchy. Also if current layer is the same as the root layer without history current stays the same.

The application and functionality described above can be implemented as a series of instructions stored on a computer readable storage medium that when executed cause a programmable processor to implement the operations described above. While the invention may be implemented in a variety of different hardware and computing systems shows a schematic representation of the main components of an example computing platform according to various particular embodiments. Multipoint sensing devices generally include a controller which may comprise a microcontroller or one or more processors configured to execute instructions and to carry out operations associated with a computing platform. In various embodiments controller may be implemented as a single chip multiple chips and or other electrical components including one or more integrated circuits and printed circuit boards. Controller may optionally contain a cache memory unit for temporary local storage of instructions data or computer addresses. By way of example using instructions retrieved from memory controller may control the reception and manipulation of input and output data between components of computing platform .

Controller together with a suitable operating system may operate to execute instructions in the form of computer code and produce and use data. By way of example and not by way of limitation the operating system may be Windows based Mac based or Unix or Linux based or Symbian based among other suitable operating systems. The operating system other computer code including control client described below and or data may be physically stored within a memory block that is operatively coupled to controller .

Memory block encompasses one or more storage media and generally provides a place to store computer code e.g. software and or firmware and data that are used by the computing platform . By way of example memory block may include various tangible computer readable storage media including Read Only Memory ROM and or Random Access Memory RAM . As is well known in the art ROM acts to transfer data and instructions uni directionally to controller and RAM is used typically to transfer data and instructions in a bi directional manner. Memory block may also include one or more fixed storage devices in the form of by way of example solid state hard disk drives HDDs among other suitable forms of memory coupled bi directionally to controller . Information may also reside on a removable storage medium loaded into or installed in multipoint sensing devices when needed. By way of example any of a number of suitable memory cards may be loaded into computing platform on a temporary or permanent basis.

Controller is also generally coupled to a variety of interfaces such as graphics control video interface input interface output interface and storage interface and network interface and these interfaces in turn are coupled to the appropriate devices. In certain embodiment Controller may connected to an input structure and display may be provided together such an in the case of a touchscreen where a touch sensitive mechanism is provided in conjunction with the display . In such embodiments the user may select or interact with displayed interface elements via the touch sensitive mechanism. In this way the displayed interface may provide interactive functionality allowing a user to navigate the displayed interface by touching the display .

Electric signals e.g. analog may be produced by microphone and fed to earpiece . Controller may receive instruction signals from input structure and control the operation of display . By way of example display may incorporate liquid crystal display LCD light emitting diode LED Interferometric modulator display IMOD or any other suitable display technology. Audio signals may be transmitted and received by means of an antenna that may be connected through a radio interface or audio input interface such as microphone to codec configured to process signals tinder control of controller . Additionally multipoint sensing devices may be powered power source .

Mobile device may also include one or more user input devices other than input structure that are operatively coupled to the controller . Generally input devices are configured to transfer data commands and responses from the outside world into multipoint sensing devices. By way of example mobile device may include a keyboard or mouse. Input devices may also include one or more hard buttons.

Display device is generally configured to display a graphical user interface GUI that provides an easy to use visual interface between a user of the computing platform and the operating system or application s running on the mobile device. Generally the GUI presents programs files and operational options with graphical images. During operation the user may select and activate various graphical images displayed on the display in order to initiate functions and tasks associated therewith.

Herein reference to a computer readable storage medium encompasses one or more non transitory tangible computer readable storage media possessing structure. As an example and not by way of limitation a computer readable storage medium may include a semiconductor based or other integrated circuit IC such as for example a field programmable gate array FPGA or an application specific IC ASIC a hard disk an HDD a hybrid hard drive HHD an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive a floppy disk a floppy disk drive FDD magnetic tape a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive or another suitable computer readable storage medium or a combination of two or more of these where appropriate. Herein reference to a computer readable storage medium excludes any medium that is not eligible for patent protection under 35 U.S.C. 101. Herein reference to a computer readable storage medium excludes transitory forms of signal transmission such as a propagating electrical or electromagnetic signal per se to the extent that they are not eligible for patent protection under 35 U.S.C. 101. A computer readable non transitory storage medium may be volatile non volatile or a combination of volatile and non volatile where appropriate.

This disclosure contemplates one or more computer readable storage media implementing any suitable storage. In particular embodiments a computer readable storage medium implements one or more portions of controller such as for example one or more internal registers or caches one or more portions of memory one or more portions of storage or a combination of these where appropriate. In particular embodiments a computer readable storage medium implements RAM or ROM. In particular embodiments a computer readable storage medium implements volatile or persistent memory. In particular embodiments one or more computer readable storage media embody software. Herein reference to software may encompass one or more applications bytecode one or more computer programs one or more executables one or more instructions logic machine code one or more scripts or source code and vice versa where appropriate. In particular embodiments software includes one or more application programming interfaces APIs . This disclosure contemplates any suitable software written or otherwise expressed in any suitable programming language or combination of programming languages. In particular embodiments software is expressed as source code or object code. In particular embodiments software is expressed in a higher level programming language such as for example C Perl or a suitable extension thereof. In particular embodiments software is expressed in a lower level programming language such as assembly language or machine code . In particular embodiments software is expressed in JAVA. In particular embodiments software is expressed in Hyper Text Markup Language HTML Extensible Markup Language XML or other suitable markup language.

The present disclosure encompasses all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend. For example while the implementations described above operates with touchscreens other implementations of the invention can be implemented on touchpad devices having a display separate from a touch sensing surface. Furthermore the relation between in pinch and out pinch gestures to the navigation function described above can be reversed such that out pinch events cause application to close as opposed to in pinch events. In other implementations out pinch and in pinch events can be treated as the same type of command for purposes of navigating a user interface hierarchy. Similarly where appropriate the appended claims encompass all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend.

