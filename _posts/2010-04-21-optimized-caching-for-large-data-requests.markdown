---

title: Optimized caching for large data requests
abstract: An optimized caching mechanism for byte range requests from a web service is provided. When a large file that is not already in cache or being transferred is requested, a background thread may be created to transfer the file and a shared data structure created to track portions of the file that are transferred. For each subsequent request for portions of the same file, the data may be sent back in chunks and the request to read each chunk from the file blocked until that chunk is filled by the background thread. Thus, the locally stored and partially filled file is shared among multiple requestors.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08495166&OS=08495166&RS=08495166
owner: Microsoft Corporation
number: 08495166
owner_city: Redmond
owner_country: US
publication_date: 20100421
---
One of the major contributions of computers and software to people s daily lives was the automation of widely used tasks such as word processing spreadsheet calculations and diagramming. Not only did these applications automate and make various tasks usable by anyone but they also added many new capabilities in manipulating a wide range of documents and data. Until recently a typical environment included a standalone or networked computer with a particular application installed on it. Thus the user was working with an application installed and executed on their local computer using data also stored locally. A recent trend in providing the computing capabilities without the burden of having a full scale application installed on the user s computer is enabling users to perform the computerized tasks through web access. In a typical web service the user may utilize a hosted service to create new documents manipulate existing ones and perform many other computing tasks through a networked medium such as the Internet.

In a typical web service a front end server may make available relatively large files which may be requested via byte range requests. The files may be stored externally database remote storage etc. and cached at a front end server when requested by a client. File content may be served to a requesting client as the file is being copied into the cache since copying the entire file can take amount of significant time. A challenge may be presented if multiple clients concurrently request byte ranges in the same large file. If the web server attempts to fetch the file multiple times from the external storage the operation s may place unnecessary load on the external storage and waste local disk space on the web server. Alternatively clients may have to wait their turn slowing the service speed.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This summary is not intended to exclusively identify key features or essential features of the claimed subject matter nor is it intended as an aid in determining the scope of the claimed subject matter.

Embodiments are directed to an optimized caching mechanism for byte range requests from a web service. In response to a first request for a large file a background thread may be created to transfer the file and a shared data structure created to track portions of the file that are transferred. For each subsequent request for portions of the same file the data may be sent back in chunks and the request to read each chunk from the file blocked until that chunk is actually present i.e. filled by the background thread .

These and other features and advantages will be apparent from a reading of the following detailed description and a review of the associated drawings. It is to be understood that both the foregoing general description and the following detailed description are explanatory and do not restrict aspects as claimed.

As briefly described above in response to a first request for a large file a background thread may be created to transfer the file and a shared data structure created to track transferred portions of the file. Data may be sent back in chunks for each subsequent request for the same file. A request to read a chunk from the file may block a thread until the requested chunk is filled by the background thread. Since each request is on a separate thread a thread that blocks while waiting for its required data does not block any of the other threads if the data they require is already present enabling facilitation of multiple requests for the same file synchronously. In the following detailed description references are made to the accompanying drawings that form a part hereof and in which are shown by way of illustrations specific embodiments or examples. These aspects may be combined other aspects may be utilized and structural changes may be made without departing from the spirit or scope of the present disclosure. The following detailed description is therefore not to be taken in a limiting sense and the scope of the present invention is defined by the appended claims and their equivalents.

While the embodiments will be described in the general context of program modules that execute in conjunction with an application program that runs on an operating system on a personal computer those skilled in the art will recognize that aspects may also be implemented in combination with other program modules.

Generally program modules include routines programs components data structures and other types of structures that perform particular tasks or implement particular abstract data types. Moreover those skilled in the art will appreciate that embodiments may be practiced with other computer system configurations including hand held devices multiprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers and comparable computing devices. Embodiments may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

Embodiments may be implemented as a computer implemented process method a computing system or as an article of manufacture such as a computer program product or computer readable media. The computer program product may be a computer storage medium readable by a computer system and encoding a computer program that comprises instructions for causing a computer or computing system to perform example process es . The computer readable storage medium can for example be implemented via one or more of a volatile computer memory a non volatile memory a hard drive a flash drive a floppy disk or a compact disk and comparable media. The computer program product may also be a propagated signal on a carrier e.g. a frequency or phase modulated signal or medium readable by a computing system and encoding a computer program of instructions for executing a computer process.

Throughout this specification the term platform may be a combination of software and hardware components for managing web service operations. Examples of platforms include but are not limited to a hosted service executed over a plurality of servers an application executed on a single server and comparable systems. The term server generally refers to a computing device executing one or more software programs typically in a networked environment. However a server may also be implemented as a virtual server software programs executed on one or more computing devices viewed as a server on the network.

Referring to conceptual diagram of an example web service structure where embodiments may be implemented is illustrated. In the example system of web service is accessible to users through networked communication between their client devices and front end server . Typically users may access web service through a browsing application or comparable applications executed on the client devices . Client devices may include any computing device capable of communicating with other computing devices over one or more networks. Such devices may include but are not limited to desktop computers laptop computers handheld computers mobile computers terminals smart phones and comparable ones. Front end server may receive user requests retrieve relevant data from back end service execute programs associated with the requests and provide results back to users .

Back end service may store data associated with the web service as well as perform at least some of the computations e.g. resource heavy background computations updates to data store s etc. . Back end service may include a number of data stores e.g. data store and servers e.g. back end server managing the data stores. Data store may include any form of data storage including but not limited to databases tables spreadsheets multidimensional data stores and comparable ones. The front end and the back end of the web service may be centralized or distributed physically or virtually in separate locations and different portions of the web service may be implemented through a variety of computing devices. Web service may optionally include application server for executing applications requested by a user. Different components of web service may communicate with each other through a number of protocols over one or more networks.

An interface may be provided to the clients on the SDS which requestors may use to seek within the file and read data from the local temporary storage . Subsequent requests e.g. request that are received for the same file may find the SDS and use the interface to seek to desired locations in the file and read data. SDS may employ a monitor which may enable multiple read clients to block and be woken up by the BGTW each time new data is available. This allows the seek and read methods of the interface to block if the requested data is not present and then unblock once the methods are woken up and determine that the requested data is present.

Thus a system according to some embodiments may enable fetching of large files from a back end data store asynchronously and storing in a local disk file both from the beginning of the file and the end of the file such that data consumers like media players can seek to the end of the file and read the last few data chunks before the entire file is fetched. Moreover the system enables multiple requests to request data from the single shared locally stored file.

According to an example interaction scenario shown in diagram front end server requests data from the back end server in response to receiving a first request . The front end server may start a background thread write and begin transferring the data from the back end server to a newly created shared data structure at the front end server once the back end server retrieves the data from data source and renders available in chunks.

Subsequent requests may be received from clients at the SDS and handled through background thread write updates and the SDS monitor such that multiple seek and read methods of the SDS interface may block if the requested data is not yet present and unblock when background thread write updates are received new data chunks written .

Data retrieval may be managed through a system of callbacks e.g. seek and read methods by the code on the front end server. Similarly errors and hangs may also be handled. If one or more data chunks fail to be received from the back end a complete request may fail and an error may be returned to the end user.

Components and actions in diagrams and are for illustration purposes only and do not constitute a limitation on embodiments. Other components software or hardware and configuration may be employed for providing optimized caching of large data files in a web service.

The above discussed scenarios example systems applications and data structures are also for illustration purposes. Embodiments are not restricted to those examples. Other applications web service configurations data structures and operation orders may be used in implementing a web service with optimized caching for multiple request availability in a similar manner using the principles described herein.

As discussed above a shared data structure and background thread write may be employed in conjunction with a monitor to enable multiple users request and receive byte range data requests for large data files from the back end of a web service. Web service data may be stored in one or more data stores e.g. data stores which may be managed by any one of the servers e.g. a back end server or by database server .

Network s may comprise any topology of servers clients Internet service providers and communication media. A system according to embodiments may have a static or dynamic topology. Network s may include a secure network such as an enterprise network an unsecure network such as a wireless open network or the Internet. Network s may also coordinate communication over other networks such as PSTN or cellular networks. Network s provides communication between the nodes described herein. By way of example and not limitation network s may include wireless media such as acoustic RF infrared and other wireless media.

Many other configurations of computing devices applications data sources and data distribution systems may be employed to implement a system for providing optimized caching for byte range data requests in a web service. Furthermore the networked environments discussed in are for illustration purposes only. Embodiments are not limited to the example applications modules or processes.

Cache application may manage byte range data requests from multiple clients for large data files maintained by the web service and enable efficient delivery of data through a shared data structure a background thread write process and a monitor as discussed previously. Cache application may be a separate application or an integral module of a hosted web based service that provides access to large data files among other things to client applications devices. This basic configuration is illustrated in by those components within dashed line .

Computing device may have additional features or functionality. For example the computing device may also include additional data storage devices removable and or non removable such as for example magnetic disks optical disks or tape. Such additional storage is illustrated in by removable storage and non removable storage . Computer readable storage media may include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. System memory removable storage and non removable storage are all examples of computer readable storage media. Computer readable storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer readable storage media may be part of computing device . Computing device may also have input device s such as keyboard mouse pen voice input device touch input device and comparable input devices. Output device s such as a display speakers printer and other types of output devices may also be included. These devices are well known in the art and need not be discussed at length here.

Computing device may also contain communication connections that allow the device to communicate with other devices such as over a wireless network in a distributed computing environment a satellite link a cellular link and comparable mechanisms. Other devices may include computer device s that execute communication applications host service servers and comparable devices. Communication connection s is one example of communication media. Communication media can include therein computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media.

Example embodiments also include methods. These methods can be implemented in any number of ways including the structures described in this document. One such way is by machine operations of devices of the type described in this document.

Another optional way is for one or more of the individual operations of the methods to be performed in conjunction with one or more human operators performing some. These human operators need not be collocated with each other but each can be only with a machine that performs a portion of the program.

Process begins with operation where a first request for a file at the back end storage of the service is received by the front end server of the service. In response to the first request a background thread write is started for transferring the requested file to a local cache at operation . A shared data structure SDS may be created and status of transferred data chunks monitored at operation .

At operation an application programming interface API may be provided on the SDS to enable subsequent requests seek within the locally cached filed and read data from the same file. Any subsequent requests may be directed to the SDS API for seek and read operations. Optional operations and represent blocking of seek and read methods based on subsequent requests for the same file if requested data has not yet been transferred to the local cache or unblocking or waking up the same methods if the requested data has been transferred after the methods were blocked. The local cache may be deleted after a predefined period of lack of requests for the transferred file.

The operations included in process are for illustration purposes. Optimized caching for large data requests in a web service may be implemented by similar processes with fewer or additional steps as well as in different order of operations using the principles described herein.

The above specification examples and data provide a complete description of the manufacture and use of the composition of the embodiments. Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims and embodiments.

