---

title: System and method for rendering a particle-based fluid surface
abstract: A method for rendering a particle-based fluid surface includes generating a depth image of a plurality of particles which form a fluid surface, and smoothing the depth image to generate a smoothed depth image. From the smoothed depth image, a smoothed surface position and a smoothed surface normal for each of a plurality of pixels included within the smoothed depth image is determined, and a shaded surface of the fluid is rendered as a function of the smoothed surface positions and the smoothed surface normals.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08947430&OS=08947430&RS=08947430
owner: NVIDIA Corporation
number: 08947430
owner_city: Santa Clara
owner_country: US
publication_date: 20100226
---
The present invention relates generally to systems and methods for graphics rendering and more particularly to a system and method for rendering a particle based fluid surface.

For interactive scenes particle based fluid simulation methods like Smoothed Particle Hydrodynamics or SPH are commonly preferred to grid based fluid simulation methods. Particle based fluid representation permits fluid flow throughout the scene without the need to define a grid over the scene area which would be costly in memory and computation. It is also more convenient to integrate into existing physics infrastructure as particles can collide against the scene geometry just like other objects.

However a drawback with particle based fluid simulation is it is difficult to extract a surface for rendering. In some conventional techniques the fluid surface is constructed in world space either as a mesh directly or as an implicit surface and then polygonized using Marching Cubes or other similar methods. After this relaxation and optimization operations can be applied to the entire mesh to reduce the bumpiness of the surface which is computationally and memory intensive.

Likewise implicit surface polygonization methods also suffer from grid discretization artifacts in frame to frame coherence as the grid is static and does not move with the fluid. This is especially visible at low resolution grids whereas using high resolution grids can prohibit real time visualizations because evaluating the metaball densities at each grid point is expensive. For acceptable visual quality the grid must be much finer than the particle spacing. The need for a fixed grid also restricts the fluid to a box whereas not having this restriction is one of the reasons for choosing particle based fluid surface rendering.

Accordingly a new particle based fluid surface rendering technique is needed to overcome the aforementioned disadvantages.

The present invention provides an improved technique for rendering particle based fluid surfaces. Among the embodiments of the present invention a method for rendering a particle based fluid surface is included this method including generating a depth image of a plurality of particles which form a fluid surface and smoothing the depth image to generate a smoothed depth image. From the smoothed depth image a smoothed surface position and a smoothed surface normal for each of a plurality of pixels included within the smoothed depth image is determined and a shaded surface of the fluid is rendered as a function of the smoothed surface positions and the smoothed surface normals.

These and other aspects of the invention will be better understood in light of the following drawings and detailed description of exemplary embodiments.

Exemplary embodiments of operations and are further described below. Exemplary of operation scene data residing view wise behind the fluid surface is written to a buffer render target where it is stored as a background image for use in operation . The background image referred to as S x y as described herein can be used to determine the color of the fluid surface depending upon e.g. the color and thickness of the fluid surface as described below. Further particularly the texture coordinates used to sample the background image may be perturbed based upon the normal n of the fluid surface in order to give the illusion of refracting the object behind the fluid. These and other aspects of the background image are described in greater detail below.

At a depth image of the fluid surface e.g. a depth map is generated and stored in a buffer render target . In one embodiment a depth image of the fluid surface is generated whereby the near most view wise surface of the fluid is determined and the particles along that surface are rendered with a corresponding a depth z value. For example the aforementioned SPH algorithm may be employed to determine the positions of the particles and those particles may then be splatted onto the screen. A render target for the surface depth is initialized with a predefined depth value representing a very large depth i.e. furthest most surface . For each pixel the depth value for the near most particle is retained with the current depth value being overwritten by a depth value corresponding to a particle which is closer to the camera view point. After the particles are rendered the render target will contain the depth to the viewer of the nearest particle for each pixel in the viewport.

The particles identified in operation may be rendered as spheres or alternatively as point sprites a feature that is provided by OpenGL Direct3D and other 3D graphics application programming interfaces. As used herein a point sprite refers to a screen oriented quad. Further particularly the depth z value of the point sprite is varied within the fragment shader according to the equation square root over 1 eq. 1 where x and y varies between unit values 1 and 1 over a two dimensional screen space position of the particle and d x y is the depth value of the particle output from the fragment shader. The size of the point sprite is computed by applying projective transformation so that the size is constant in world space. Rendering the particles as point sprites requires significantly less computation with little degradation in the quality of the computation compared to rendering the particles as geometrically correct spheres. When a particle is rendered as a point sprite the corresponding depth z value of the point sprite is according to the equation 

Optionally stray particles may be excluded from rendering as they do not form part of the fluid surface. This effect can be accomplished by applying a threshold on the density obtained from the simulation and rendering the low density particles separately from the fluid surface as spray to make the transition smoother.

Operation represents a process whereby the depth image of the fluid surface generated in operation is smoothed. Smoothing the depth image of the fluid surface hides the spherical nature of the particles so that the surface does not appear unnaturally blobby or jelly like. In one embodiment of this process the smoothing operation includes Gaussian filtering whereby a convolution of a Gaussian kernel is applied to the depth image provided in eq. 2 . In such an embodiment blending over silhouettes is minimized and the amount of smoothing is varied as a function of the particle depth. Further exemplary the kernel is substantially constant in width in world space. Further particular bilateral Gaussian filtering is implemented which e.g. may be split into two one dimensional passes.

According to the method at a normal is computed for each pixel included in the depth image generated at . At a mean curvature value is computed at each of the pixels and at the depth of the pixel is varied as a function of the mean curvature value corresponding to said pixel.

Exemplary of operation a normal for each pixel of the fluid surface image is computed whereby a projection transformation of a pixel is inverted to map a value in the depth buffer to a point P in view space where Vand Vare the dimensions of the viewport and Fand Fis the focal length in x and y direction respectively 

The terms of the derivatives of P that depend on the view position Wand Wmay be ignored because this assumption results in almost no visual difference in rendering and simplifies the following computations significantly. By normalizing n x y the unit normal is obtained 

Exemplary of operation the mean curvature H is defined as the divergence of the unit normal of a surface 2 eq. 7 

The z component of the divergence is zero as z is a function of x and y and thus doesn t change when these are kept constant.

Exemplary of operation the smoothing of the depth image is performed by varying the depth z value of the pixels in proportion to the local pixel s mean curvature H 

The foregoing operations and may be repeated an arbitrary number of times depending on the smoothness that is desired wherein the obtained depth z value is successively modified to provide a smoother depth image. The number of iterations and smoothness obtained can be balanced against the cost of increased computation time for the added iterations.

The depth z values computed according to the foregoing are written to a render target the collective depth z values referred to as the smoothed depth image as an intermediate result for forming a final image of the fluid in operation . In a particular embodiment the render target used to store the depth image eq. 2 is also used as the render target for the smoothed depth image whereby the nearer closer view wise depth z values computed from the aforementioned smoothing operations overwrite the depth z values of the depth image.

Further exemplary of operation from the smoothed depth image a smoothed surface position and a smoothed surface normal are determined for one or more pixels included within the smoothed depth image. The smoothed surface position for a pixel can be ascertained from the depth image d x y of the particles included within the screen space of that pixel by back projecting the pixel coordinates x y and its depth d x y . The smoothed surface normal n for a pixel can be determined by computing for a particle which is overlaid by the pixel the partial derivatives of the particle in the x and y directions and computing the cross product of the partial derivatives to compute the smoothed surface normal as per eq. 6 . When discontinuities occur in the fluid surface using the finite differences in only one direction can result in artifacts along the silhouettes. When the difference in depth is greater than a predefined threshold that is when a discontinuity is detected the smallest absolute finite difference is chosen in an exemplary embodiment. For example the smallest of the quantities z x y z x 1 y and z x y z x 1 y is chosen.

Operation optionally includes computing a thickness value per pixel for the fluid surface image generated in operation and modifying the fluid surface image based upon the thickness values of the pixels composing the fluid surface image. For example the thickness values may be used to model the changes in the visibility or color of a background image over which the fluid is shown to flow.

Exemplary of this operation the particles identified in operation are rendered as spheres using point sprites with a fixed size in world space. Depth test is enabled such that only particles in front of the scene geometry are rendered. The thickness value of a depth image pixel the depth image pixel corresponding to a given particle is computed according to the equation 

Exemplary the noise texture in operation may be generated using Perlin noise. In Perlin noise a fractal noise texture is generated by adding multiple octaves of filter noise where each octave is a filtered random function and scales the amplitude and frequency with a factor dependent on the octave 

Exemplary of operation a point sprite is rendered with a Gaussian kernel to generate a point sprite value and the point sprite value is multiplied by an exponent value the exponent value based upon the depth of the particle below the fluid surface. For example the noise kernel I x y generated at may be computed as noise eq. 15 where noise x y is the Gaussian kernel quantity p is the view space position of the particular pixel quantity d represents the depth z value of the particle as sampled from the surface depth texture computed in eq. 1 and quantities x and y vary between 1 and 1. Further particularly the noise texture is varied per particle to prevent patterns from becoming visibly apparent. A three dimensional noise texture may be used for this with the first two dimensions based on the position within the particle and the third dimension based upon the particle identifier.

Exemplary of operation the noise kernel in eq. 15 is summed for every particle on the screen to provide the noise texture N x y for the fluid surface image 

Further exemplary of operation the noise texture is generated such that the fluid surface appears more turbulent when the flow is fast or violent. This may be achieved by marking particles of the fluid surface image when a large change in velocity occurs. In particular the velocity of a particle may be determined and the amplitude of the noise texture for the particle is modulated based upon the particle s velocity. For example particles may be marked when the velocity vparticles change by more than a threshold value 1 eq. 17 where is a threshold value. Above this change the amplitude of the noise kernel in eq. 15 is varied e.g. increased to provide more pronounced fluid turbulence. Once the change in the particle s velocity falls below this threshold the amplitude of the noise kernel may be reduced to provide the effect of less fluid turbulence. Of course three or more different amplitude levels may be employed to provide different noise effects of the fluid surface image ranging from very still to extremely turbulent. Fluid Surface Rendering

Referring again to operation may be performed by combining the fluid surface image noise texture and background image to form an image of the fluid surface which may be rendered e.g. as a full screen quad.

In one embodiment the fluid surface image may be a depth image of the fluid surface or a smoothed version thereof each as described above. Further exemplary thickness values assigned to pixels of the fluid surface image may be used to modify visible properties of the fluid surface image. For example the output color and transparency opacity of the fluid surface may be based determined as a function of fluid thickness values. In a specific embodiment described below the fluid surface image includes i a smoothed depth image to avoid a blobby or jelly like fluid appearance and ii fluid thickness values which permit additional control over rendering the fluid surface color as a function of the thickness of the fluid and other parameters as described below.

In a detailed implementation of operation depth test is enabled when rendering the fluid surface image and the depth returned by the fragment shader is read from the depth buffer produced when rendering the fluid surface image. This ensures that only particles in front of the scene geometry are rendered.

Normals of the fluid surface image in view space n are calculated to shade the surface of the fluid starting from the surface depth d x y . Further particularly finite differences are used to calculate the partial derivatives in the x and y directions then the normal is derived by taking the cross product of these as per eq. 6 . When discontinuities occur in the fluid surface using the finite differences in only one direction can result in artifacts along the silhouettes. When the difference in depth is greater than a predefined threshold that is when a discontinuity is detected the smallest absolute finite difference is chosen in an exemplary embodiment. For example the smallest of the quantities z x y z x 1 y and z x y z x 1 y is chosen.

The noise texture N x y is used to perturb the normals to add small wave like surface detail to the fluid by adding the partial derivatives of N x y to the calculated normals. In particular the noise texture N x y is used to modulate the normals of pixels which form the depth or smoothed depth image thereby imparting a noisy or irregular appearance to the fluid surface. Further exemplary a grayish color is added to the surface of the fluid to simulate a surface foam effect as a function of the magnitude of the noise N x y .

In a further exemplary embodiment the thickness value T x y is used to attenuate the refracted color of the fluid a according to the equation lerp eq. 18 wherein Cis the color of the fluid per pixel S x y is the background image and T x y is the thickness value of a pixel within the fluid surface as described in eq. 13 above. Quantity increases linearly with the thickness according to the equation eq. 19 where is a constant that depends on the kind of fluid and determines how much the background is refracted. The linear interpolation of eq. 18 allows the effects of a thicker fluid retaining its own color and less of the underlying background image color and a thin fluid showing more of the background image color.

Exemplary the optical properties of the fluid per pixel are based on the Fresnel equation with a reflection and refraction component and a Phong shaded specular highlight computing the output color of the fluid C. 1 eq. 20 where F is Fresnel function a is the refracted fluid color computed in eq. 18 b is the reflected scene color kand are constants for the specular highlight n is the surface normal and h is the half angle between the camera and the light and v is the camera vector. The reflected color b can be determined by sampling a cube map texture of the environment based on the reflected direction and computed from the surface normal and the view vector.

Further exemplary of the operations operations may be performed at a first resolution and operation is performed at a second resolution. This arrangement allows a balancing of image rendering quality versus performance speed. In a specific embodiment operations are performed at a lower resolution than that of the screen for example half or quarter resolution horizontally and vertically and operation is performed whereby the fluid is scaled up to the full resolution of the screen. Exemplary the upscaling is integrated into the rendering step. Further exemplary silhouettes are detected and process separately from the scaling as applying a linear interpolation to them may result in invalid intermediate values. Inside the body of fluid the depth is linearly interpolated and the silhouettes are process separately therefrom. Further exemplary the final shaded color is blended and computed at a low resolution over edges instead of the normal or depth value thus providing a smoothing effect for the silhouettes.

Exemplary of operation point sprites are supplied to a shader the shader operable to generate depth values. For example operation can be carried out in accordance with operations and described above in which an SPH algorithm is used to determine the particle positions the particles splatted onto the screen and a render target is initialized with a predefined depth value representing a very large depth i.e. furthest most surface . The particles may be rendered as point sprites in which case the depth z value of the point sprite is varied within the fragment shader according to the eq. 1 . Alternatively the particles may be rendered as geometric spheres.

Exemplary of operation a filtering process may be applied to the depth image. Further specifically the bilateral Gaussian filtering process may be applied to the depth image as described above. In another embodiment the above described screen space curvature technique may be applied to smooth the depth image of the fluid surface.

Exemplary of operation the smoothed surface position for a pixel can be ascertained from the depth image d x y of the particles included within the screen space of that pixel by back projecting the pixel coordinates x y and its depth d x y . Further exemplary of operation a smoothed surface normal n for a pixel is determined by computing for a particle which is overlaid by the pixel the partial derivatives of the particle in the x and y directions and computing the cross product of the partial derivatives to compute the smoothed surface normal as per eq. 6 . When discontinuities occur in the fluid surface using the finite differences in only one direction can result in artifacts along the silhouettes. When the difference in depth is greater than a predefined threshold that is when a discontinuity is detected the smallest absolute finite difference is chosen in an exemplary embodiment. For example the smallest of the quantities z x y z x 1 y and z x y z x 1 y is chosen.

Exemplary of operation a shaded fluid surface is rendered using the smoothed particle positions and the smoothed particle normals n determined from operation . Further specifically the operations and computations illustrated for eq. 20 are used to render the shaded fluid surface. The fluid surface s output pixel described by eq. 20 includes input arguments n which corresponds to the pixel s smoothed surface normal and v camera vector which corresponds to the pixel s smoothed surface position.

At a fluid thickness value is generated for each of the pixels of the smoothed depth image. Exemplary of this operation the fluid thickness values are computed in accordance with eq. 13 above.

At a shaded surface of the fluid is rendered displayed written to a render target etc. as a function of the smoothed surface positions smoothed surface normals and the fluid thickness values. Exemplary of this operation the shaded fluid surface is rendered using the operations and computations illustrated for eqs. 18 19 and 20 above.

The processor may further include local shared memory which may be physically or logically allocated to a corresponding parallel processing architecture . The system may additionally include a global memory which is accessible to each of the parallel processing architectures . The system may further include one or more drivers for controlling the operation of the processor in accordance with the methods of . The driver s may include one or more libraries for facilitating control of the processor . In one embodiment the system is included within in a graphics card. In another embodiment the system is included within the motherboard of an imaging system e.g. a digital camera. The system may be implemented in other components for example a computer or a game console or in an embedded system such as in a cellular telephone or internet device.

The processor circuitry of the processor is operable to perform e.g. execute instructions to carry out any of the operations illustrated in herein. In an embodiment exemplified by circuitry of processor herein processor circuitry is operable to generate an image of the fluid surface a noise texture of the fluid surface and a background image of the fluid surface and to combine these into a final image.

In an embodiment exemplified by the processor circuitry is operable to determine positions of particles making up the fluid generate and store a depth image of the fluid based upon the determined particle positions and generate and store a smoothed depth image of the fluid surface based upon the depth image. Further optionally the processing circuitry is operable to generate thickness values of the fluid based upon the determined particle positions.

In an embodiment exemplified by the processor circuitry is operable to compute a normal for particles included within the depth image compute a mean curvature value for each particle and vary the depth value of the particle as a function of the mean curvature value corresponding to that particle. In an embodiment exemplified by the processor circuitry is operable to generate a noise kernel for each particle and sum the noise kernels to compute a noise texture for the fluid surface. In a further exemplary embodiment the processor includes processor circuitry operable to perform operations at a first rate of resolution for the images formed thereby and processing circuitry operable to perform operation at a second rate of resolution for the composite image formed thereby the first and second resolution rates being different. In a particular embodiment the first resolution rate is lower than the second resolution rate.

In an embodiment exemplified by the processor circuitry is operable to generate a noise kernel for each particle and to sum the noise kernals over for a plurality of particles to compute a noise texture for the fluid surface.

In an embodiment exemplified by the processor circuitry is operable to generate a depth image of the fluid surface smooth the depth image determine a smoothed particle position and a smoothed particle normal for particles in the smoothed depth image and render a shaded fluid surface using the smoothed particle positions and smoothed particle normals.

In an embodiment exemplified by the processor circuitry is operable to perform operations generate a fluid surface thickness value for each particle of the smoothed depth image and render a shaded fluid surface based upon the smoothed particle positions and normals and the fluid surface thickness values.

In an embodiment exemplified by the processor circuitry is operable to perform operations or to render a shaded fluid surface to further generate a noise texture for the fluid surface and combined the shaded fluid surface with noise texture to render an image of the fluid surface.

In an embodiment exemplified by the processor circuitry is operable to perform operations or operations or operations to render a fluid surface to further provide a background image of the fluid surface and to combine the fluid surface with background image to render an image of the fluid surface.

Several advantages of the invention are realized in that i rendering speed versus image quality can be varied ii processing rendering and shading can be performed directly on graphics hardware iii the screen space curvature flow technique disclosed herein avoids prevents the rendered fluid surface from appearing with a blobby or jelly like consistency iv the rendering technique does not rely upon polygonization and thus does not suffer from artifacts associated therewith v the method is easy to implement requiring a few passes of a fragment shader and intermediate render targets and vi the method has inherent view dependent level of detail as the method is based on a grid on screen space.

As readily appreciated by those skilled in the art the described processes and operations may be implemented in hardware software a computer program element firmware or a combination of these implementations as appropriate. In addition some or all of the described processes and operations may be implemented as computer readable instruction code resident on a computer readable medium or product the instruction code operable to control a computer of other such programmable device to carry out the intended functions. The computer readable medium on which the instruction code resides may take various forms for example a removable disk volatile or non volatile memory etc.

The terms a or an are used to refer to one or more than one feature described thereby. Furthermore the term coupled or connected refers to features which are in communication with each other either directly or via one or more intervening structures or substances. The sequence of operations and actions referred to in method flowcharts are exemplary and the operations and actions may be conducted in a different sequence as well as two or more of the operations and actions conducted concurrently. The described features are not limited only to their implementation in the exemplary embodiment described therefor and the skilled person will appreciate that these features can be implemented in the other described embodiments of the invention as well. Reference indices if any included in the claims serve to refer to one exemplary embodiment of a claimed feature and the claimed feature is not limited to the particular embodiment referred to by the reference indicia. The scope of the clamed feature shall be that defined by the claim wording as if the reference indicia were absent therefrom. All publications patents and other documents referred to herein are incorporated by reference in their entirety. To the extent of any inconsistent usage between any such incorporated document and this document usage in this document shall control.

The foregoing exemplary embodiments of the invention have been described in sufficient detail to enable one skilled in the art to practice the invention and it is to be understood that the embodiments may be combined. The described embodiments were chosen in order to best explain the principles of the invention and its practical application to thereby enable others skilled in the art to best utilize the invention in various embodiments and with various modifications as are suited to the particular use contemplated. It is intended that the scope of the invention be defined solely by the claims appended hereto.

