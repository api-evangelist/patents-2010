---

title: Features such as titles, transitions, and/or effects which vary according to positions
abstract: A software program for creating features for use with a plurality of media objects in a sequence. The program comprises a feature component specifying a feature having parameters affecting at least one variable aspect of the feature. An indicator component identifies a position of the specified feature relative to the media objects in the sequence. The program comprises a sequence generator for modifying the specified feature by varying its parameters of the specified feature as a function of the position of the specified feature relative to the media objects and/or relative to other features in the sequence. The sequence generator also modifies the specified feature by varying its parameters of the feature as a function of the content of the media objects around it or to which it has been applied. A rendering component renders the specified feature according to the varied parameters at the identified position.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09445016&OS=09445016&RS=09445016
owner: Microsoft Technology Licensing, LLC
number: 09445016
owner_city: Redmond
owner_country: US
publication_date: 20100517
---
This application is a division of U.S. patent application Ser. No. 10 976 833 filed Oct. 29 2004 the entire disclosure of which is incorporated herein by reference.

Embodiments of the present invention relate to the field of editing of multimedia objects. In particular embodiments of this invention relate to dynamically executing features such as titles effects and or transitions to media objects in a sequence based on the feature s position relative to the media objects in the sequence and or based on the feature s position relative to other features and or based on analysis of the content of the media objects themselves.

With the popularity and advancement in digital imaging consumers may now create and edit digital multimedia objects by using known commercially available multimedia editing software products. For example a consumer may use an image capturing device such as a digital camcorder or a digital camera to record or capture events such as a wedding or a vacation. With the help of a multimedia editing software product the consumer inputs the recorded events to a computing device having multimedia editing software. The multimedia editing software includes a timeline on which the consumer arranges the recorded events. The consumer chooses which events to include on the timeline the order those events are shown and the extent or duration of each event. The consumer may choose a number of options or features to add to the recorded events on the timeline. For example the consumer may insert an overlay title on an individual video clip image or other media object or on a group or sequence of video clips images or other media objects. The consumer may also create titles that are themselves media objects on the timeline independent of any other media object. The consumer may also apply effects to a video clip image or other media object on the timeline. For example the consumer may apply effects that change the underlying media object to black and white or to a sepia tone change the brightness contrast or hue rotate the image or cause images or media objects to fade in or out over time. Other effects may also change the audio belonging to an underlying media object for example to make it louder or softer or to add an echo. The consumer may also add transitions between clips images or other media objects. Transitions typically combine two media objects to create an image that blends the images from each media object changing during the duration of the transition for example fading from one media object to the other.

In the case of a number of video clips images or other media objects in a timeline sequence a consumer may apply interesting sequences of titles effects transitions or other features to the media objects using existing multimedia object editing software products. For example a consumer can apply a feature such as a wipe transition to a series of video clips according to a particular pattern. In particular the consumer may desire the following feature pattern sequence a left to right wipe between the first two video clips a right to left wipe between the second and third video clips a top down wipe between the third and fourth video clips a bottom up wipe between the fourth and fifth video clips and so on repeating this pattern of four transitions along the timeline. To achieve this pattern the consumer may repeat applying the features to maintain the pattern as he or she continues editing the media objects and or applying other features. After completing editing of the media objects the consumer may output the edited media objects to a display or record them on a computer readable medium such as a DVD.

Over time this process of applying a transition or other features to the entire series of video clips to maintain the feature pattern becomes overwhelming as one modifies and edits the media objects. For example a consumer may need to adjust all transitions effects titles or other features that he or she wants whenever there is a subsequent change to the order of media objects or features in a sequence. In addition it may be tedious and laborious to choose different transitions or effects and apply them to or between media objects on the timeline to achieve the pattern one wants. Also when a consumer inserts or deletes a media object in a sequence the order of previously or subsequently added transitions effects titles or other features may change. As an illustration using the above example where a right to left wipe is to appear between the second and third video clips if the second video clip is removed or a new video clip is inserted after the second video clip the consumer would need to rearrange all wipe transitions after the third video clip to maintain the same wipe transition pattern.

There is a need for multimedia editing software products that have the ability to dynamically apply transitions effects titles or other features to media objects during editing of media objects in a sequence based on position. There is also a need for multimedia editing software which assists a consumer to track features and maintain feature characteristics e.g. wipe or fade transition patterns while editing and or re ordering media objects.

Accordingly a system and method for features such as titles transitions effects and other features is desired to address one or more of these and other needs.

Embodiments of the invention include an application to modify the various aspects or properties of features e.g. effects transitions or title styles as a function of a position of the features relative to media objects and or other features in a sequence. The application uses one or more parameters incorporated in the features to generate appropriate aspects of the features without requiring a consumer to track the position of the features while editing media objects. Embodiments of the invention also include a data structure for including data representing parameters such as local sequence values global sequence values including sequence number and overall count for an individual type or instance of features or for a family of features e.g. all effects that look like an explosion might be part of a family of effects . Embodiments of the invention also include an application to modify the various aspects or properties of the features as a function of the media objects around them and or other features in a sequence.

According to one aspect of the invention a software program creates features for use with a plurality of media objects in a sequence. A feature component specifies a feature having parameters which affect at least one variable aspect of the feature. An indicator component identifies a position of the specified feature relative to the media objects in the sequence. A sequence generator for modifying the specified feature by varying its parameters as a function of the position of the specified feature within the sequence. A rendering component renders the specified feature according to the varied parameters of the specified feature at the identified position when the media objects are sequentially displayed.

In accordance with another aspect of the invention a computer readable medium has computer executable components for applying one or more features to a plurality of media objects in a sequence. Each of the features has parameters that affect at least one variable property of the feature. An indicator component identifies a specified one of the features in a position in the sequence of the plurality of media objects. A modification component modifies the specified feature by varying its parameters as a function of the position of the feature within the sequence.

According to yet another aspect the invention is a method for creating features for use with a plurality of media objects in a sequence. A feature having parameters affecting at least one variable aspect of the feature is specified. The position of the specified feature relative to the media objects in the sequence is identified. The specified feature is modified by varying its parameters as a function of the position of the specified feature within the sequence. The specified feature is rendered according to the varied parameters of the specified feature at the identified position when the media objects are sequentially displayed.

In accordance with a further aspect of the invention a computer readable medium stores a data structure for a feature to be associated with one or more of a plurality of media objects in a sequence. A first field includes data identifying the feature. A second field stores a value representing a position of the feature relative to at least one other feature associated with the media objects in the sequence. The position of the feature is determined as a function of the first field.

According to yet another aspect a software program creates features for use with a plurality of media objects in a sequence. A feature component specifies a feature having parameters which affect at least one variable aspect of the feature. An indicator component identifies a position of the specified feature relative to the media objects in the sequence. A sequence generator modifies the specified feature by varying its parameters as a function of the content of the plurality of media objects within the sequence. A rendering component renders the specified feature according to the varied parameters of the specified feature at the identified position when the media objects are sequentially displayed.

Referring first to block diagrams illustrate a system which is part of multimedia editing software for implementing one or more features with a plurality of media objects in a sequence according to an embodiment of the invention. The system may be a software program an application and a set of computer executable instructions to be installed or implemented in a computing device such as a computer in . The system is capable of editing media objects and or creating interesting results to media objects by applying a feature to one or more media objects such as to M. In one embodiment a media object may be a video clip an image a slide presentation a visual graphical composition an audio composition a visual audio representation or the like. The media object may also be a file an electronic compilation of files a collection of files of visual and or audio compositions an electronic document or the like. Feature may be a transition applied between media objects to create a transition from one media object to the next consecutive media object an overlay title to be placed over a media object a title to be placed before or after a media object an effect to be applied to a media object a blank or colored screen between media objects or other features that may modify a composition of media objects . By way of example and not limitation a feature such as a title or transition may be applied between two consecutive media objects e.g. a wipe a fade or other transitions . In another example of a feature an effect may be applied to a single media object e.g. modifying black and white sepia color balance or the like . In another example of a feature a title may be placed at the beginning of a sequence of media objects to introduce them at the end of a sequence of media objects as in for example credits on a movie or on top of one or more media objects as in for example subtitles on a movie.

Initially one or more features such as to N having parameters which affect at least one variable aspect or property of the feature. Such features are available to a consumer or other user of the system . The variable aspect or property controls a presentation of the feature. By varying the feature s parameters the aspect or property of the features is changed. For example a feature such as a wipe transition includes at least variable aspects or properties such as a directional aspect of a wipe e.g. left to right right to left or the like a shape aspect of a wipe e.g. smooth edge shape zigzag edge shape or the like a velocity aspect of a wipe e.g. fast speed wipe slow speed wipe or the like . In another example a feature such as a title includes variable aspects or properties such as a color aspect of title e.g. a red color title a blue color title or the like a font aspect of title e.g. font size font type font color or the like . In other example a feature such as a hue shift effect includes variable aspects or properties such the color to which the hue should be shifted and the degree to which it should be shifted towards that color. The features may be included as part of the system . In another embodiment a third party supplies and designs the features to be incorporated with the system . Also a sequence of media objects may be supplied to the system in the form of files supplied by an input device such as a digital camera or a digital camcorder.

In the system includes a feature component for specifying a feature such as the feature having parameters which affect at least one aspect which is variable. In the consumer uses an indicator component to identify a position of one of the features e.g. relative to the media objects in the sequence . This can be accomplished for example by using a mouse to drag and drop the feature . The indicator component identifies the position in the sequence to place the feature such as a transition or a title between the media object and the media object . In the case of a feature such as a transition or title the user uses the indicator component to identify the position occupied by the media object or objects such as the position between media object and to which the feature will apply. In the case of an effect the consumer uses the indicator component to identify a position of the media object for the specified feature.

The consumer may continue to use the indicator component to identify other positions in the sequence for the specified features . For example in the consumer uses the indicator component to identify a position between the media objects and in the sequence for the feature . The consumer may also use the indicator component to specify another instance of the feature in a position between media objects and .

The system also comprises a sequence generator or a modification component for modifying the features by varying its parameters to vary at least one aspect A shown by a box inside feature or in . For example the feature may be a wipe transition having directional aspects such as left to right right to left top down bottom up or the like. The feature may be a title feature having color aspects such as blue red green yellow or the like. The sequence generator modifies the sequence data for features and and or other features that are present in the sequence . The sequence generator modifies the features and by varying the parameters of the feature as a function of the position of the feature within the sequence . In particular the aspect A may be modified as a function of the position of the feature relative to the media objects in the sequence or relative to other features in the sequence to be discussed in detail in .

It is contemplated that the consumer does not necessarily see the modification performed by the sequence generator on a display when the features are positioned with the sequence. In other words the system is configured or designed to operate such that the consumer specifies the features and identifies the positions of the specified features and the system executes the features with varying aspects where the sequence is displayed.

The system also includes a rendering component for rendering the features according to its varied parameters at the identified position when the media objects are sequentially displayed. Each specific feature type has its own feature rendering component shown as and in . The feature rendering component renders the feature according to the aspect A of the feature that has been set by the sequence generator . For example after the sequence generator modifies the aspect A of a feature to indicate that it is now third in a sequence of identical features instead of second the rendering component may render a right to left wipe instead of a top to bottom wipe in the identified position.

In one embodiment the system displays the modified features in real time. For example after the consumer specifies the feature s and identifies the position s for the feature s in the timeline the sequence generator modifies the aspects of the specified feature s immediately and the rendering component renders the feature s in the identified position in the sequence. This modification and rendering occurs in real time as the media objects are streamed for display. In another embodiment the system does not begin playback of the timeline until it has completed rendering all of the features that have had their aspect A changed by the sequence generator . For example the consumer may specify a complex feature such as a 3 D transition to be inserted in a position in the timeline sequence. As a 3 D transition may require additional processing the rendering component would begin rendering the feature as soon as the sequence generator has updated its aspect information but would not allow playback of the timeline to begin until it had finished rendering the complex 3 D transition. In yet another embodiment a proxy for the complex feature is substituted in the playback of the timeline such as a static image explaining to the user that the feature is still being rendered until such time as the rendering component has completed rendering all the features present on the timeline.

Referring now to an exemplary diagram illustrates one or more media objects with one or more modified features in a timeline. A timeline identifies media objects and modified features according to their positions such as 1 to 15. A sequence is an example of a displayed sequence showing modified features and media objects. The sequence includes one or more modified features in which TI refers to a title feature e.g. TI refers to title in which E refers to an effect feature e.g. E refers to effect and in which T refers to a transition feature e.g. T refers to transition . The sequence also includes one or more media objects in which VC refers to a video clip e.g. VC refers to video clip . A collection of modified features and media objects illustrates a decomposition of the timeline into its constituent elements.

As discussed earlier the consumer may continue to edit the modified features and or media objects in the sequence . For example the consumer may select a wipe transition T designed to generate a pattern of wipes left to right right to left top down automatically. When the user places this wipe transition on the timeline the sequence generator modifies the aspect of each instance of that wipe transition present on the timeline and the aspect of all other transitions present on the timeline to indicate their new relative positions on the timeline. The rendering component then uses this modified aspect data to generate the appropriate wipe transition for each instance of the wipe transition according to the pattern left to right right to left and top down . Hence as displayed in the sequence T is a left to right wipe T is a right to left wipe T is a top down wipe T is a left to right wipe T is a right to left wipe T is a top down wipe and T is a left to right wipe. Thereafter the consumer may remove VC and T in positions 9 and 10 respectively from the sequence . In some of the existing multimedia editing software the consumer needs to modify wipe transitions T and T to maintain the same wipe transition pattern i.e. left to right right to left and top down . According to one advantage of the invention on the other hand the system dynamically modifies transitions T and T after the removal of VC and T such that the consumer does not need to modify T and T. In other words the system modifies the features according to the positions of the features relative to the media objects and or other features in the sequence such as the sequence .

Another example of how the system modifies the features according to the positions of the features relative to other features in the sequence is as follows. Suppose the consumer specifies an automatic title feature TI that generates a title that looks like the front of a book a title that looks like the back cover of a book and one or more automatically numbered chapter titles between the front cover title and the back cover title. As such in the sequence TI would show a front cover title TI would show Chapter 1 title and TI would show a back cover title. Under some of the existing multimedia software the consumer would need to use three different title styles to achieve this effect on the timeline and if the consumer wants to insert another chapter title after position 3 on the timeline e.g. between VC and T while maintaining the same title pattern the consumer needs to insert a new chapter 1 title after position 3 and they need to modify TI to chapter 2. According to another advantage of the invention the system modifies TI in response to a newly inserted title feature at position 3 because the system modifies features according to positions of the features relative to other features in the sequence by using one or more parameter values included in the features.

By way of example and not limitation a value in one or more of the following parameter categories may be stored in a data structure to be discussed in detail in of the feature 

It is contemplated that each feature will only use a small number of these eight parameters and that in some instances the system might not implement all eight parameters listed above and any addition to the list of parameters listed does not depart from the spirit of the invention.

An individual type linked list links the features according to their individual type number within a particular family. For example the individual type linked list has an individual type 1 list containing features such as T T and T because they are of the type 1 in family 1. Similarly an individual type 2 list contains type 2 features such as T and T of family 2 and an individual type 3 list contains type 3 features such as T and T of family 3. An individual type local sequence number and an individual type global sequence indicate the sequence of the features T to T according to the individual type linked list .

In one embodiment the linked lists noted above in are recalculated whenever a feature e.g. effect transition or title is changed on the timeline e.g. the timeline in . For example if the consumer edits the features in by removing T and VC E the system may recalculate all individual type linked lists that are affected by the change to the timeline. The sequence generator recalculates the parameters for each feature on the timeline in response to any change. It also creates a list of all features whose parameters e.g. the individual local sequence number and the individual global sequence number have changed during the recalculation process. The system next recalculates all family linked lists that are affected by the change to the timeline and adds to the list of all features whose parameters e.g. the family local sequence number and the family global sequence number have changed. Before the rendering component displays the features and the media objects the sequence generator recalculates the parameters for each of the affected features. As discussed earlier some non complex features may be processed in real time while some complex features may require pre rendering or pre calculation. As such the rendering component may recalculate and or redraw the affected portion of the timeline immediately after a change has been notified to it by the sequence generator or at some later time.

Referring next to a block diagram illustrating a data structure for a feature to be associated with one or more of a plurality of media objects in a sequence according to an embodiment of the invention. The feature has a first group of fields including data identifying the feature . The data identifying the feature may include fields for an identification number a feature family number or other identification number that uniquely identifies each feature among other features. For example a wipe transition feature may have an identification number of 1. The system or a third party manufacturer of a feature may have a universal identification system for assigning a unique identification number to all features. The first field may include an identification number identifying a family of features containing one or more members. For example a wipe transition feature family may have members such as a smooth wipe a jugged edge wipe or the like.

Also the data identifying the feature may include a type number or a type number identifying a manufacturer of the feature. For example as in a wipe transition feature may have different types of wipe transition such as a 2 D wipe a 3 D wipe organic wipe or the like.

The feature also comprises a second group of fields storing a plurality of values representing the position of the feature relative to other features associated with the media objects in the sequence and or other data calculated by the sequence generator. In one embodiment of the invention the group of fields holds all eight of the parameter values noted above. In another embodiment of the invention the group of fields also contains values representing information about the media objects around it for example data about the average brightness of the video clip preceding it and following it or a complex set of motion vectors expressing the motion present in the video clip preceding it and following it see discussion of .

It is contemplated by the inventors that the above data structure of the features may be adopted or implemented by a third party vendor manufacturer or designer of features which are compatible with the system . For example a third party vendor of features may design a series of title features to be used with the system for editing media objects. As such the third party vendor of features would configure each of the features with the data structure illustrated in such that the consumer may purchase the set of third party title features to be used with the system . In addition one or more of the above mentioned parameters may also be implemented as part of the design or manufacturing of the features. For example the third party vendor that designs the series of title features elects to incorporate the family global sequence number only.

In another embodiment illustrates varying aspects of a feature according to parameters derived from related media objects. A media object e.g. a video clip may possess actual or derived properties. Actual properties of a media object may include without limitation the duration of the media object and in the case of a video clip or still image the date and time at which the video or image was recorded. Derived properties of a media object may include without limitation properties such as motion properties image color properties and or other properties. Motion properties may include properties such as derived or actual camera velocity in the x axis derived or actual camera velocity in the y axis derived or actual camera velocity in the z axis derived or actual subject velocity in the x axis derived or actual subject velocity in the y axis derived or actual subject velocity in the z axis camera steadiness derived or actual camera zoom velocity or other properties relating to a motion vector. Image color properties may include parameters such as a dominant color in a media object and a frequency of other colors within a media object or other parameters relating to a color histogram. The media object may also include parameter such as the duration of the media object camera settings global position satellite GPS information or other actual or derived data. The sequence generator copies these parameters from the media objects surrounding a feature into fields e.g. the group of fields within the feature for a predetermined number of media objects before or after the current feature. For example in one embodiment of the invention the sequence generator copies the subject motion vectors for the preceding and following media objects into the current feature. In another embodiment of the invention the sequence generator copies the subject motion vectors for the five preceding and five subsequent media objects into the current feature. With these parameters as input at the rendering component in this example determines if the orientation of motion of the subjects in the media objects on either side of the feature being rendered e.g. VC and VC is from left to right at . If the determination is positive the rendering component executes a left to right wipe transition e.g. T between VC and VC at . At if the sequence generator determines the orientation of motion of the subjects in the adjacent media objects is from right to left the rendering component executes a right to left wipe transition between the media objects at . Otherwise the rendering component executes a top bottom transition at . Overall the consumer would see the result of the modified features by the sequence generator at . The overall effect in this case would be for the transition to align itself with the horizontal motion of the subjects in the media clips it is transitioning between or where there is no coherent horizontal motion to perform a vertical wipe.

In other words the rendering component can vary the aspects of a feature by analyzing parameters relating to the content of media objects.

As illustrated in the system may be implemented by using one or more combination of parameter values noted above to achieve desired results.

It is contemplated that any permutation and or manipulation of one or more parameter values does not depart from the spirit of the invention. For example a third party vendor of features may use the individual local sequence number and the individual global total count in varying aspects of a fade transition while another third party vendor of features may use the family global sequence number and the family global total count for a pause feature or the like.

In one embodiment the features include a predetermined set of rules for varying aspects of the feature. For example the third party vendor of features in the process of designing features may configure the features such that the aspects of the features are determined by one or more parameter values noted above. It is contemplated that the rendering component may not use all identified data or values e.g. parameter values in determining how to render the feature. A typical rendering component will use only a small number of the many possible parameters. Some rendering components will use a selection of the sequence based parameters others will use parameters derived from adjacent media objects and others may use a mixture of these two types of parameters.

In another example another third party vendor of features may use parameters relating to the content of media objects and or parameter values noted above in varying aspects of features. In yet another embodiment the features present options to the consumer to override the automatic behavior and to select a particular pattern of how aspects of a feature should vary. For example the consumer may select a pattern for a wipe feature such as left to right right to left or the like. Such user interaction may create yet another parameter which can be passed to surrounding features so that they can automatically adjust to accommodate the user s choice. For example if the user forces a wipe to be left to right the remaining wipes may automatically adjust to start a new sequence beginning with a right to left wipe. In yet another embodiment a third party vendor predefines a set pattern for a feature.

Referring to a flow chart illustrates a method of applying a feature with a plurality of media objects in a sequence according to an embodiment of the invention. At the system receives a plurality of media objects and arranges them to form a timeline or a sequence at . The consumer inputs a plurality of media objects using an input device e.g. a digital camera or digital camcorder . The system may also receive a plurality of media objects from other storage devices or computer readable media.

At the system waits for a user input. At this point the user may request the system to perform one or more tasks including without limitation the tasks shown as A B and C. For example A is for adding feature or more media objects to the timeline. B is for modifying or deleting existing features or media objects on the timeline. C is for previewing or publishing the finished video from the timeline. The system receives the user s input selection of these tasks via an input device such as a mouse. In another embodiment one or more tasks are automatically completed in response to the user selection of A B and or C. For example as a user adds a complex feature e.g. a 3 D transition the system substantially immediately may pre render the 3 D transition feature.

At the consumer uses the system to specify a selected feature or media object to be added to the timeline in the sequence at . For example the consumer selects one or more features in a collection of features supplied by the system or by a third party manufacturer vendor of the features e.g. from in or from in . The consumer may also purchase additional features from a third party vendor by downloading or installing the purchased features to the collection of features. It is contemplated that these third party manufactured features are designed and configured to be compatible with the system and or all of the components modules data structures parameter settings and other settings therein.

At the system identifies a position in the plurality of media objects for inserting the specified feature or additional media object such as the consumer drags and drops the selected feature on the timeline see . Each of the features comprises at least one variable aspect or property such as directions of a wipe transition. As such the system renders the feature in various ways as a function of the identified position of the feature relative to the media objects and or relative to other features in the sequence at . For example the system varies aspects or properties of the feature by evaluating one or more parameter values as discussed in . At the system inserts the modified feature in the identified position in the sequence of media objects for display. At the sequence generator updates the parameters on all the features that have been affected by the feature or media object added to the timeline at .

At the consumer can also decide to modify or delete an existing media object or feature on the timeline. The consumer selects the feature or media object at and s he chooses to delete or modify the selected feature or media object at . As soon as the consumer has finished deleting or modifying the feature or media object the sequence generator updates the parameters for all affected features on the timeline at .

At the consumer decides to preview or publish the timeline after selecting task C at . At the system uses the rendering component to render each feature according to the parameters set on the features at . At the finished video is written to an output file or other medium.

The present invention may be implemented by a software program editing one or more media objects that embodies at least some of the features of the invention. In operation the system may be a software program code or a set of computer executable instructions that are capable of editing media objects. Initially a set of media objects is available for editing such as a number of video clips or images. The feature component specifies a feature from a collection of one or more features. The consumer assists in identifying the feature e.g. by using a mouse clicking on the feature on a display such as a wipe transition feature. The consumer also associates the identified feature to the media objects by using a mouse pointer to drag the identified feature e.g. an icon representing the identified feature to the identified position in the sequence of media objects. In other words the consumer edits the video clips by specifying a position to insert a wipe transition feature such as between and in or inserting a title feature before the media object or in .

The sequence generator thereafter modifies the feature by setting various parameters of the feature as a function of the position of the feature relative to the media objects and or relative to other features in the sequence. Thereafter the rendering component renders the feature as a function of one or more of the parameters set on it For example the rendering component renders various wipe transitions or title styles for the feature as a function of the position and or content of the feature relative to the media objects and or other features in the sequence see . By implementing one or more features of the invention the consumer need not modify the feature to maintain a pattern as the sequence generator automatically modifies the parameters of the feature as a function of the position of the feature relative to the media objects or other features in the sequence and the rendering component automatically renders the feature as a function of those parameters.

After the consumer completes editing the media objects the sequence generator modifies the parameters for all features affected by the editing carried out by the consumer. When the consumer requests that the timeline be previewed or published the rendering component renders the feature according to the parameters set on it by the sequence generator . In one embodiment of the invention the rendering component may pre render some complex features as soon as the sequence generator modifies the parameters on them instead of waiting for the preview or publish component of the system to call upon the rendering component .

The computer typically has at least some form of computer readable media. Computer readable media which include both volatile and nonvolatile media removable and non removable media may be any available medium that may be accessed by computer . By way of example and not limitation computer readable media comprise computer storage media and communication media. Computer storage media include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. For example computer storage media include RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical disk storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium that may be used to store the desired information and that may be accessed by computer . Communication media typically embody computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and include any information delivery media. Those skilled in the art are familiar with the modulated data signal which has one or more of its characteristics set or changed in such a manner as to encode information in the signal. Wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media are examples of communication media. Combinations of any of the above are also included within the scope of computer readable media.

The system memory includes computer storage media in the form of removable and or non removable volatile and or nonvolatile memory. In the illustrated embodiment system memory includes read only memory ROM and random access memory RAM . A basic input output system BIOS containing the basic routines that help to transfer information between elements within computer such as during start up is typically stored in ROM . RAM typically contains data and or program modules that are immediately accessible to and or presently being operated on by processing unit . By way of example and not limitation illustrates operating system application programs other program modules and program data .

The computer may also include other removable non removable volatile nonvolatile computer storage media. For example illustrates a hard disk drive that reads from or writes to non removable nonvolatile magnetic media. also shows a magnetic disk drive that reads from or writes to a removable nonvolatile magnetic disk and an optical disk drive that reads from or writes to a removable nonvolatile optical disk such as a CD ROM or other optical media. Other removable non removable volatile nonvolatile computer storage media that may be used in the exemplary operating environment include but are not limited to magnetic tape cassettes flash memory cards digital versatile disks digital video tape solid state RAM solid state ROM and the like. The hard disk drive and magnetic disk drive and optical disk drive are typically connected to the system bus by a non volatile memory interface such as interface .

The drives or other mass storage devices and their associated computer storage media discussed above and illustrated in provide storage of computer readable instructions data structures program modules and other data for the computer . In for example hard disk drive is illustrated as storing operating system application programs other program modules and program data . Note that these components may either be the same as or different from operating system application programs other program modules and program data . Operating system application programs other program modules and program data are given different numbers here to illustrate that at a minimum they are different copies.

A user may enter commands and information into computer through input devices or user interface selection devices such as a keyboard and a pointing device e.g. a mouse trackball pen or touch pad . Other input devices not shown may include a microphone joystick game pad satellite dish scanner or the like. These and other input devices are connected to processing unit through a user input interface that is coupled to system bus but may be connected by other interface and bus structures such as a parallel port game port or a Universal Serial Bus USB . A monitor or other type of display device is also connected to system bus via an interface such as a video interface . In addition to the monitor computers often include other peripheral output devices not shown such as a printer and speakers which may be connected through an output peripheral interface not shown .

The computer may operate in a networked environment using logical connections to one or more remote computers such as a remote computer . The remote computer may be a personal computer a server a router a network PC a peer device or other common network node and typically includes many or all of the elements described above relative to computer . The logical connections depicted in include a local area network LAN and a wide area network WAN but may also include other networks. LAN and or WAN may be a wired network a wireless network a combination thereof and so on. Such networking environments are commonplace in offices enterprise wide computer networks intranets and global computer networks e.g. the Internet .

When used in a local area networking environment computer is connected to the LAN through a network interface or adapter . When used in a wide area networking environment computer typically includes a modem or other means for establishing communications over the WAN such as the Internet. The modem which may be internal or external is connected to system bus via the user input interface or other appropriate mechanism. In a networked environment program modules depicted relative to computer or portions thereof may be stored in a remote memory storage device not shown . By way of example and not limitation illustrates remote application programs as residing on the memory device. The network connections shown are exemplary and other means of establishing a communications link between the computers may be used.

Generally the data processors of computer are programmed by means of instructions stored at different times in the various computer readable storage media of the computer. Programs and operating systems are typically distributed for example on floppy disks or CD ROMs. From there they are installed or loaded into the secondary memory of a computer. At execution they are loaded at least partially into the computer s primary electronic memory. Aspects of the invention described herein includes these and other various types of computer readable storage media when such media contain instructions or programs for implementing the steps described below in conjunction with a microprocessor or other data processor. Aspects of the invention also include the computer itself when programmed according to the methods and techniques described herein.

For purposes of illustration programs and other executable program components such as the operating system are illustrated herein as discrete blocks. It is recognized however that such programs and components reside at various times in different storage components of the computer and are executed by the data processor s of the computer.

Although described in connection with an exemplary computing system environment including computer aspects of the invention are operational with numerous other general purpose or special purpose computing system environments or configurations. The computing system environment is not intended to suggest any limitation as to the scope of use or functionality of aspects of the invention. Moreover the computing system environment should not be interpreted as having any dependency or requirement relating to any one or combination of components illustrated in the exemplary operating environment. Examples of well known computing systems environments and or configurations that may be suitable for use with aspects of the invention include but are not limited to personal computers server computers hand held or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics mobile telephones network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

Aspects of the invention may be described in the general context of computer executable instructions such as program modules executed by one or more computers or other devices. Generally program modules include but are not limited to routines programs objects components and data structures that perform particular tasks or implement particular abstract data types. Aspects of the invention may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote computer storage media including memory storage devices.

An interface in the context of a software architecture includes a software module component code portion or other sequence of computer executable instructions. The interface includes for example a first module accessing a second module to perform computing tasks on behalf of the first module. The first and second modules include in one example application programming interfaces APIs such as provided by operating systems component object model COM interfaces e.g. for peer to peer application communication and extensible markup language metadata interchange format XMI interfaces e.g. for communication between web services .

The interface may be a tightly coupled synchronous implementation such as in Java 2 Platform Enterprise Edition J2EE COM or distributed COM DCOM examples. Alternatively or in addition the interface may be a loosely coupled asynchronous implementation such as in a web service e.g. using the simple object access protocol . In general the interface includes any combination of the following characteristics tightly coupled loosely coupled synchronous and asynchronous. Further the interface may conform to a standard protocol a proprietary protocol or any combination of standard and proprietary protocols.

The interfaces described herein may all be part of a single interface or may be implemented as separate interfaces or any combination therein. The interfaces may execute locally or remotely to provide functionality. Further the interfaces may include additional or less functionality than illustrated or described herein.

The order of execution or performance of the methods illustrated and described herein is not essential unless otherwise specified. That is elements of the methods may be performed in any order unless otherwise specified and that the methods may include more or less elements than those disclosed herein. For example it is contemplated that executing or performing a particular element before contemporaneously with or after another element is within the scope of the invention.

When introducing elements of the present invention or the embodiment s thereof the articles a an the and said are intended to mean that there are one or more of the elements. The terms comprising including and having are intended to be inclusive and mean that there may be additional elements other than the listed elements.

In view of the above it will be seen that the several objects of the invention are achieved and other advantageous results attained.

As various changes could be made in the above products and methods without departing from the scope of the invention it is intended that all matter contained in the above description and shown in the accompanying drawings shall be interpreted as illustrative and not in a limiting sense.

